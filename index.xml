<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</title>
    <link>https://shikihuiku.github.io/</link>
      <atom:link href="https://shikihuiku.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 10 Aug 2025 12:16:56 +0900</lastBuildDate>
    <image>
      <url>https://shikihuiku.github.io/images/icon_hu127225d7ed9c50974404790b7c221374_401884_512x512_fill_lanczos_center_3.png</url>
      <title>shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</title>
      <link>https://shikihuiku.github.io/</link>
    </image>
    
    <item>
      <title>Resampled Importance Samplingについて</title>
      <link>https://shikihuiku.github.io/post/ris_revisit/</link>
      <pubDate>Sun, 10 Aug 2025 12:16:56 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/ris_revisit/</guid>
      <description>&lt;p&gt;知識のアップデートという事で、2020年に書いたImportance Resamplingの記事を書き直します。Siggraph2023で行われた、「A Gentle Introduction to ReSTIR」というコースが包括的にRISやReSTIRについて説明してくれています。コースノートも参照可能ですので本格的に学びたい方は、ぜひこちらの方を皮切りに勉強することをお勧めします。ここでは、Weighted Reservoir Samplingの手法やReSTIRのフレームワークについては説明しません。RISについてのみ説明します。&lt;/p&gt;
&lt;h3 id=&#34;参考文献リスト&#34;&gt;参考文献リスト&lt;/h3&gt;
&lt;p&gt;Wyman, C., Kettunen, M., Lin, D., Bitterli, B., Yuksel, C., Jarosz, W., &amp;amp; Kozlowski, P. (2023). &lt;em&gt;A Gentle Introduction to ReSTIR Path Reuse in Real-Time&lt;/em&gt;. ACM SIGGRAPH 2023 Courses.&lt;br&gt;
Bitterli et al. (2020), &amp;lsquo;Spatiotemporal Reservoir Resampling for Real-Time Ray Tracing with Dynamic Direct Lighting&amp;rsquo;&lt;br&gt;
Lin et al. (2022), &amp;lsquo;Generalized Resampled Importance Sampling&amp;rsquo;&lt;br&gt;
Veach (1997), &amp;lsquo;Robust Monte Carlo Methods for Light Transport Simulation&amp;rsquo;&lt;/p&gt;
&lt;h2 id=&#34;モンテカルロ積分&#34;&gt;モンテカルロ積分&lt;/h2&gt;
&lt;p&gt;レンダリングの話はひとまず置いておいて、ある関数(被積分関数):$f(x)$を、領域(ドメイン):$\Omega$で積分したものを$I$とします。&lt;/p&gt;
&lt;p&gt;$$
I = \int_{\Omega} f(x) dx
$$&lt;/p&gt;
&lt;p&gt;上記の積分がClosed Form(簡単な算術形式)で表せない場合は、モンテカルロ法による推定が有効な手法となります。モンテカルロ法による積分の推定を、モンテカルロ積分と呼びます。
また、モンテカルロ法で推定値を計算する行為そのものをモンテカルロ推定、MC推定などと呼びます。
モンテカルロ法で推定した積分の値を$\langle I \rangle$とするならば、ドメイン:$\Omega$内の、$M$個の一様分布で生成したサンプル:$S$を用いて、以下のように計算できます。&lt;br&gt;
この式は、ドメイン:$\Omega$における関数:$f(x)$の平均値にドメインの大きさを乗じたものと解釈することもできます。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with} \quad S=\{X_1​,X_2​,\: &amp;hellip;\:,X_M \} \quad \text{where}\quad X_i \sim Uniform(\Omega), \newline
I \approx \langle I \rangle = |\Omega|\frac{1}{M}\sum^{M}_{i=1} f(X_i)
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;有限個のサンプルでは、計算結果は必ずしも積分の真の値と一致しませんが、サンプル:$S$の分布が、ドメイン:$\Omega$と一致する限り、このモンテカルロ推定の期待値は、積分の値に等しくなります。推定の期待値が真値に一致する状態を、Unbiasedもしくは不偏であるといいます。&lt;/p&gt;
&lt;p&gt;$$
E[\langle I \rangle] = I
$$&lt;/p&gt;
&lt;p&gt;また、$f(x)$のサポート (関数の非ゼロ領域）がドメイン:$\Omega$全体より小さい場合は、$\Omega$で積分しても、$f(x)$のサポート:$supp(f)$で積分しても同じ値なります。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with}\quad supp(f) \subseteq \Omega \quad \text{where}\quad supp(f)=\{x ∣ f(x) \neq 0\},\quad  \newline
I = \int_{supp(f)} f(x) dx
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;同様に、サンプル:$S$の一様分布が、$f(x)$のサポートを覆う限りは、ドメイン：$\Omega$全域を覆ってなくても、モンテカルロ法による積分の推定は可能です。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with}\quad S=\{X_1​,X_2​,\: &amp;hellip; \: ,X_M\} \quad \text{where}\quad X_i \sim Uniform(supp(f)) \quad \text{and}\quad supp(f) \subseteq \Omega, \newline
I \approx \langle I \rangle = |supp(f)|\frac{1}{M}\sum^{M}_{i=1} f(X_i)
\end{gather}
$$&lt;/p&gt;
&lt;h2 id=&#34;importance-sampling&#34;&gt;Importance Sampling&lt;/h2&gt;
&lt;p&gt;M個のサンプル:$S$が、確率密度関数:$p(x)$に基づく分布で与えられるとき、被積分関数:$f(x)$のドメイン：$\Omega$による積分をモンテカルロ法で推定:$\langle I \rangle$する場合、以下のようになります。先ほどの式で乗算されていた、ドメインの大きさ：$|\Omega|$や、サンプル分布領域の大きさ$|supp(f)|$の役割は、確率密度関数:$p(x)$が担います。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with}\quad S=\{X_1, X_2,\: &amp;hellip; \:, X_M\} \quad \text{where} \quad X_i \sim p(x) \quad \text{and} \quad X_i \in \Omega, \newline
\langle I \rangle = \frac{1}{M}\sum^{M}_{i=1} \frac{f(X_i)}{p(X_i)}
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;ドメイン:$\Omega$全域において$f(x)$が非ゼロであるならば、確率密度関数:$p(x)$がドメイン全域において$&amp;gt;0$であれば、この推定の期待値はドメイン:$\Omega$における関数:$f(x)$の積分の値に等しくなります。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with} \quad \Omega \subseteq supp(f) \quad \text{and} \quad \Omega = supp(p),\newline
\qquad E[\langle I \rangle] = I 
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;$f(x)$のサポートがドメイン:$\Omega$全体より小さい場合は、$f(x)$のサポートにおいて$p(x)$が$&amp;gt;0$ならば、この推定の期待値は積分の値に等しくなります。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with} \quad supp(f) \subseteq \Omega \quad \text{and} \quad supp(f) \subseteq supp(p),\newline
E[\langle I \rangle] = I 
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;ここから先は、被積分関数:$f(x)$のサポートは積分のドメインに含まれる: $supp(f) \subseteq \Omega$として説明します。&lt;/p&gt;
&lt;h2 id=&#34;1サンプルのimportance-sampling&#34;&gt;1サンプルのImportance Sampling&lt;/h2&gt;
&lt;p&gt;ここで、サンプルが一つだけのImportance Samplingを考えてみます。&lt;br&gt;
直感的に、このMC推定は分散が大きいと考えられますが、もしも、確率密度関数:$p(x)$が被積分関数:$f(x)$に完全に比例している場合、この推定値は、$supp(f)$全域において一定の値を返します。そして、その値は積分の真の値と一致するはずです。しかし、実際には$f(x)$に完全に比例する$p(x)$を用意するには、事前に$f(x)$の積分が解析的に解ける必要があり、これは、モンテカルロ積分の適用と矛盾します。しかし、たとえサンプルが１つだけのモンテカルロ積分でも有効な推定で、上記で説明した、確率分布関数のサポートの条件を満たせば、その期待値は積分の値と一致します。ただし、推定値の分散は、一般的に著しく大きいと考えられます。&lt;/p&gt;
&lt;p&gt;$$
\langle I \rangle = \frac{f(X)}{p(X)}
$$&lt;/p&gt;
&lt;h2 id=&#34;multiple-importance-samling--mis&#34;&gt;Multiple Importance Samling : MIS&lt;/h2&gt;
&lt;p&gt;次に、サンプル:$X_i$ごとに異なる確率密度関数:$p_i(x)$を用いてサンプリングして、被積分関数:$f(x)$の積分をモンテカルロ法で推定:$\langle I \rangle$する場合を考えます。&lt;br&gt;
M個のサンプル:$S$が、それぞれの要素に対応する確率密度関数: $\{p_1(x), p_2(x), &amp;hellip; , p_m(x)\}$ に基づく分布で与えられるとき、MC推定は最もシンプルな形では以下のように書けます。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with} \quad S =\{X_1,\: &amp;hellip; \:, X_M\}, \quad \text{where} \quad X_i \sim p_i(x) \: (\text{for}\: i=1,\: &amp;hellip; \:,M) \quad \text{and} \quad X_i \in \Omega \newline
\langle I \rangle = \frac{1}{M}\sum^{M}_{i=1} \frac{f(X_i)}{p_i(X_i)}
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;この式は、複数の確率密度関数を用いた、1サンプルのImportance SamplingのMC推定の平均をとったものと解釈できます。このように複数の確率密度関数を用いてサンプリングして行うMC推定をMultiple Importance Sampling:MISと言います。この時、それぞれの確率密度関数の事を、サンプリング戦略と呼びます。個々の戦略は違えど、目的は同じなので、複数のサンプリング戦略という言葉は、複数の確率密度関数よりも直感的で分かりやすいかもしれません。&lt;/p&gt;
&lt;p&gt;MISでは、サンプリング戦略ごとに重みづけをすることができます。上式のように、$1/M$と一定の値を乗算していた部分に、サンプリング戦略ごとに異なる$x$の関数による係数:$m_i(x)$を導入します。
通称MISウエイトと呼ばれるこの関数によって、サンプリング戦略の重要度を、サンプル値に応じて変化させます。MISウエイトは、サンプリング戦略ごとに異なる関数なので、同じサンプル値:$x$でも、異なるサンプリング戦略の$m_i(x)$は、異なる値を返す点に注意が必要です。MISウエイトは、サンプリング戦略ごとに得意な範囲（$f(x)$と比例した形近い形の範囲）で、大きなウエイトを返すように設計することで、MC推定の分散の低減を目指します。&lt;/p&gt;
&lt;p&gt;一般的には、サンプリング戦略の数とサンプリング戦略ごとに生成するサンプル数は、それぞれ独立の変数で、MISは複数サンプリング戦略の加重平均という解釈が正しいです。ここでは、$M$個のサンプリングを$M$種類のサンプリング戦略でサンプリングしているので混乱しやすいですが、あくまで、複数サンプルの加重平均という解釈ではなく、複数サンプリング戦略による1サンプルImportance Samplingの加重平均と解釈した方が良いと思います。&lt;/p&gt;
&lt;p&gt;$$
\langle I \rangle = \sum^{M}_{i=1} m_i(X_i) \frac{f(X_i)}{p_i(X_i)}
$$&lt;/p&gt;
&lt;p&gt;上記のMC推定の期待値が積分の値と一致するためには、以下の条件を満たす必要があります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;どのサンプル値:$x$においても、$f(x)$のサポート内は、すべてのサンプリング戦略のMISウエイト関数の合計は1である必要があります。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\sum^{M}_{i=1} m_i(x) = 1 \qquad \text{if}\quad x \subseteq supp(f)
$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;ある確率密度関数:$p_i(x)$が、あるサンプル値:$x$を生成しない場合（つまり$p_i(x)=0$）、$m_i(x)$はゼロである必要があります。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
m_i(x) = 0 \qquad \text{if} \quad x \notin supp(p_i)
$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;すべての$p_i(x)$のサポートの和集合が、$supp(f)$を包含する必要があります。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
supp(f) \subseteq \bigcup_{i=1}^{M} supp(p_i)
$$&lt;/p&gt;
&lt;h2 id=&#34;balance-heuristic&#34;&gt;Balance Heuristic&lt;/h2&gt;
&lt;p&gt;MISウエイト関数として、$m_i(x)$を以下のように計算するものが、Balance Heuristicとして提案されており、良いMISウエイトとして一般的に使われています。
この式は、一見して、$m_i(x)$の総和が1になることが分かります。加えて、サンプリング戦略ごとに確率が高い範囲で、大きなウエイトを返すよう設計されています。言い換えれば、いくつかの確率密度関数が、それぞれ高確率になる領域で、$f(x)$に比例する形に近くなっていれば、このMISウエイトは良い選択になると言えると思います。&lt;/p&gt;
&lt;p&gt;$$
m_i(x) = \frac{p_i(x)}{\sum_{j}p_j(x)}
$$&lt;/p&gt;
&lt;h2 id=&#34;misウエイトの総和が１であることの意味&#34;&gt;MISウエイトの総和が１であることの意味&lt;/h2&gt;
&lt;p&gt;MISウエイトの総和が1であることが、MC推定が不偏であることの条件になっていることについて、少し考えてみたいと思います。&lt;br&gt;
MISウエイトの総和が1であるならば、$M$個の、MISウエイトと被積分関数の乗算:$m_i(x)f(x)$の総和をドメインで積分した値は、
$f(x)$の積分に等しくなるのは直感的にわかるかと思います。これは、ドメイン全域、サンプリング戦略全てを対象とした積分です。&lt;/p&gt;
&lt;p&gt;$$
\int_{\Omega}f(x)dx = \int_{\Omega} \sum_{i=1}^{M}m_i(x)f(x) dx = \sum_{i=1}^{M} \int_{\Omega} m_i(x)f(x) dx
$$&lt;/p&gt;
&lt;p&gt;一方で、MISによる推定では、各サンプルは、それぞれ別のサンプリング戦略から生成され、それらサンプルの値は異なると考えるべきです。
そして、異なるサンプルの値のMISウエイト関数同士には総和の条件がありません。&lt;/p&gt;
&lt;p&gt;MISウエイトを用いたMC推定の式は、上式における$m_i(x)f(x)$の積分の総和に対応していると考えられます。そのため、各サンプリング戦略は等しく用いられる必要があります。
$M$個のサンプリング戦略が、それぞれ1サンプルのImportance Samplingで、$m_i(x)f(x)$の積分を推定している見ることができ、
その総和は$f(x)$の積分の推定になると解釈できます。&lt;/p&gt;
&lt;p&gt;$$
\langle I \rangle = \sum^{M}_{i=1} m_i(X_i) \frac{f(X_i)}{p_i(X_i)}
$$&lt;/p&gt;
&lt;h2 id=&#34;unbiased-contribution-weight-ucw&#34;&gt;Unbiased Contribution Weight: UCW&lt;/h2&gt;
&lt;p&gt;これまでサンプルの生成において、確率密度関数が閉形式もしくはclosed formとして計算可能な場合について説明してきましたが、そうでない場合について考えてみます。&lt;/p&gt;
&lt;p&gt;あるサンプル$X$が複雑な過程を経て生成された場合に、その生成における確率密度関数を計算することが困難な場合でも、期待値が、そのサンプルの生成確率の逆数になる値:$W_{X}$が分かれば、不偏なモンテカルロ積分を行うことができます。この$W_X$のことを、Unbiased Contribution Weight: UCWもしくは、不偏寄与重みと呼びます。&lt;/p&gt;
&lt;p&gt;$$
E[W_{X} | X] = \frac{1}{p(X)}
$$&lt;/p&gt;
&lt;p&gt;条件付き期待値の書式で書かれている理由は、あるサンプル$X$が与えられた後に、$W_{X}$を計算するからです。
UCWが分かれば、1サンプルのMC推定を以下のように定義することができ、その期待値は被積分関数:$f(x)$の積分の値となります。&lt;/p&gt;
&lt;p&gt;$$
E[f(X) W_{X}] = E[f(X) / p(X)] = E[\langle I \rangle] = I
$$&lt;/p&gt;
&lt;p&gt;UCWは、ここでは、単純な確率密度関数の逆数の言い換えのように感じますが、サンプル:$X$が生成された後で計算できればよく、また、値が確率密度関数の逆数に一致しなくても、その期待値が一致することで、MC推定の不偏性が保てるという点で⁠重要な意味を持ちます。&lt;/p&gt;
&lt;h2 id=&#34;resampled-importance-sampling-ris&#34;&gt;Resampled Importance Sampling: RIS&lt;/h2&gt;
&lt;p&gt;Importance Samplingにおいて、サンプルの生成確率は、確率密度関数:$p(x)$に基づいています。確率密度関数は、全体を積分すると1である必要があるため、少なくとも積分可能な関数でなくてはなりません。そのため、モンテカルロ積分のサンプリングを、ある別の重みづけで行いたいとして、勝手なサンプリング関数や分布を用意しても、直接Importance Samplingすることはできません。&lt;/p&gt;
&lt;p&gt;少々雑な言い方をすれば、RISは、MC推定の期待値を変えることなく、サンプルの分布を、任意の重みづけ関数:$\hat{p}(x)$に基づくようにするためのものです。
簡単に手順を説明すれば、まず、多数のサンプルを、ある確率密度関数:$p(x)$に基づいて事前に生成して、次に、サンプルそれぞれに、任意の重みづけ関数:$\hat{p}(x)$で重みづけをして、その重みに比例する形でサンプルを選択することで、積分の対象の関数:$f(x)$と乗算するサンプルである、選択サンプルの分布を$\hat{p}(x)$に比例した形に近づけます。&lt;/p&gt;
&lt;p&gt;もし、$\hat{p}(x)$が$p(x)$よりも$f(x)$に比例した形に近ければ、$\hat{p}(x)$を用いたRISによる推定は、$p(x)$を用いたImportance Samplingよりも、分散が低減されるはずです。これがRISを使う動機になります。では、$\hat{p}(x)$に$f(x)$そのものを用いれば、理想的で良いのかという事になりますが、$\hat{p}(x)$はRISで推定値を計算する過程で何度も評価されるので、$\hat{p}(x)$は$f(x)$に比べて計算コストがかなり低いことが、RISを合理的に使うための前提条件になります。まとめると、RISを合理的に使う条件は以下の通りになります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p(x)$に比べて$\hat{p}(x)$が$f(x)$に対して比例した形に近い&lt;/li&gt;
&lt;li&gt;$f(x)$に比べて$\hat{p}(x)$の評価コストが大きく低い&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この二つの条件を満たす$\hat{p}(x)$が事前に分かるときは、RISを効果的に使用できます。&lt;/p&gt;
&lt;h2 id=&#34;resampled-importance-sampling-risidentically-distributed-samples&#34;&gt;Resampled Importance Sampling: RIS（Identically distributed samples）&lt;/h2&gt;
&lt;p&gt;RISの一番簡単な例として、生成されるサンプルが同一の確率密度関数:$p(x)$に基づく場合について説明します。はじめに、ある確率密度関数:$p(x)$に基づいてM個のサンプル候補を生成します。&lt;/p&gt;
&lt;p&gt;$$
S=\{X_1, X_2,\: &amp;hellip; \: , X_M \} \quad \text{where} \quad X_i \sim p(x) \quad \text{and} \quad X_i \in \Omega
$$&lt;/p&gt;
&lt;p&gt;次に、各生成サンプルに、リサンプリング重み:$w_i$を計算します。リサンプリング重みを制御する関数:$\hat{p}(x)$は、サンプルの生成確率と関係ない任意の関数で、確率密度関数である必要もありません。
直感的に、サンプルの生成率:$p(x)$が小さく$\hat{p}(x)$が大きい値を取る領域では、$w_i$は大きな値になるのが分かります。&lt;/p&gt;
&lt;p&gt;$$
w_i = \frac{1}{M} \frac{\hat{p}(X_i)}{p(X_i)} \quad (\text{for}\: i=1,\: &amp;hellip; \:,M)
$$&lt;/p&gt;
&lt;p&gt;そして、計算されたリサンプリング重み:$w_i$に比例する形で、サンプルを選択します。
リサンプリング重みは、$\hat{p}(X_i)$と$p(X_i)$の比で計算されているので、全体的なサンプルの選択確率は、$\hat{p}(x)$に比例する形に近づくようになっています。
以降は、選択されたサンプルを$Y$と表記します。そして、選択されたサンプルのUnbiased Contribution Weights: UCW:$W_Y$を計算します。&lt;/p&gt;
&lt;p&gt;$$
W_Y = \frac{1}{\hat{p}(Y)} \sum_{i=1}^{M}w_i
$$&lt;/p&gt;
&lt;p&gt;最後に、被積分関数:$f(Y)$とUCW:$W_Y$を乗算することで、RISによるMC推定となります。&lt;/p&gt;
&lt;p&gt;$$
\langle I \rangle = f(Y)W_{Y}
$$&lt;/p&gt;
&lt;p&gt;この、RISによるMC推定の不偏性を保つためには、$f(x)$のサポートにおいて、以下の条件を満たす必要があります。&lt;/p&gt;
&lt;p&gt;$$
\begin{gather}
\text{with} \quad supp(f) \subseteq supp(\hat{p}) \subseteq supp(p), \newline
\quad E[\langle I \rangle] = I
\end{gather}
$$&lt;/p&gt;
&lt;h2 id=&#34;risの理解について&#34;&gt;RISの理解について&lt;/h2&gt;
&lt;p&gt;RISの理解として、まず、$W_Y$の$\sum_M w_i$の部分は、確率密度関数:$p(x)$に基づく$M$個のサンプルで、リサンプリング重み関数:$\hat{p}(x)$をImportance Samplingしていると考えることができます。
したがって、その推定値は、ドメイン:$\Omega$における、$\hat{p}(x)$の積分と考えることができます。この推定値を$\langle I_{\hat{p}} \rangle$とします。
$p(x)$のサポートが、$\hat{p}(x)$のサポートを内包すれば、$\langle I_{\hat{p}} \rangle$の期待値は、$\hat{p}(x)$の積分に一致します。
$$
\begin{gather}
\text{with} \quad supp(\hat{p}) \subseteq supp(p) \subseteq \Omega, \newline
\qquad E[\langle I_{\hat{p}} \rangle]＝\int_{\Omega} \hat{p}(x)dx
\end{gather}
$$&lt;/p&gt;
&lt;p&gt;UCW: $W_Y$は、$\hat{p}(Y) / \langle I_{\hat{p}} \rangle$の逆数となっているので、$\hat{p}(x)$を正規化して確率密度関数にした関数:$\bar{p}(x)$に、サンプル$Y$を渡した値の逆数と考えることができます。&lt;/p&gt;
&lt;p&gt;$$
W_Y = \frac{1}{\hat{p}(Y)} \sum_{i=1}^{M}w_i \approx \frac{|\hat{p}|}{\hat{p}(Y)} = \frac {1}{\bar{p}(Y)}
$$&lt;/p&gt;
&lt;p&gt;そして、$\langle I \rangle = f(Y)W_{Y}$は、被積分関数:$f(x)$の確率密度関数:$\bar{p}(x)$による、1サンプルのImportance Samplingと考えることができます。
このようにRISを理解すると、RISによるMC推定の不偏性は、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$supp(\hat{p}) \subseteq supp(p)$であることで、$E[\langle I_{\hat{p}} \rangle]$の不偏性が保てる。&lt;/li&gt;
&lt;li&gt;$supp(f) \subseteq supp(\hat{p})$であることで、$E[\langle I \rangle]$の不偏性が保てる。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;と考えることができます。&lt;/p&gt;
&lt;h2 id=&#34;リサンプリングmisウエイト&#34;&gt;リサンプリングMISウエイト&lt;/h2&gt;
&lt;p&gt;上記の解釈では、$W_Y$は、$\bar{p}(x)$の逆数でした。特に$\langle I_{\hat{p}} \rangle$の部分は、実質的にImportance Samplingになっています。
この部分は、$\int \hat{p}$の推定が出来れば良いわけで、Multiple Importance Samplingに変更しても問題ありません。
したがって、$w_i$の式にある、$1/M$という係数は、MISウエイトと考えることができます。これをリサンプリングMISウエイト:$m_i(x)$とします。
$$
w_i = m_i(X_i) \frac{\hat{p}(X_i)}{p(X_i)}
$$
今のところ、同一の確率密度関数から全てのサンプルを生成しているので、リサンプリングMISウエイトは$1/M$が適切です。
$$
m_i(x) = \frac{1}{M}
$$&lt;/p&gt;
&lt;h2 id=&#34;ris手順の一般化&#34;&gt;RIS手順の一般化&lt;/h2&gt;
&lt;p&gt;RISでは、RISで選択されたサンプルを、次のRISのサンプル候補として扱い、再帰的にRISを適用することができます。
そのために、RISの計算手順の一般化をします。先ほどの説明とは少し順序が入れ替わります。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$M$個のサンプル:$S$をドメイン:$\Omega$で用意します。ついで、各サンプルのUCWを用意します。$Ｗ_{X_i}$はサンプル$X_i$のUCWで、サンプルの生成確率:$p(X_i)$がわかる場合は、単に$1/p(X_i)$になります。
$$
\begin{gather}
S=\{X_1, X_2,\: &amp;hellip; \: , X_M \} \in \Omega \newline
\{W_{X_1}, W_{X_2},\: &amp;hellip; \: , W_{X_M}\}
\end{gather}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;各サンプルのリサンプリングMISウエイト:$m_i(X_i)$を計算します。すべてのサンプルが同一の確率密度関数から生成された場合は、$m_i(X_i) = 1/M$が適切となります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
m_i(X_i) = \frac{1}{M} \quad (\text{for}\: i=1,\: &amp;hellip; \:,M)
$$&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;リサンプリング重み:$w_i$を計算します。UCWとリサンプリングMISウエイトがわかれば、以下のように計算することができます。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
w_i = m_i(X_i) \hat{p}(X_i) W_{X_i} \quad (\text{for}\: i=1,\: &amp;hellip; \:,M)
$$&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;リサンプリング重み:$w_i$に比例する形でサンプル列:$S$からサンプルを選択します。選択されたサンプルを$Y$とします。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;サンプル$Y$の新しいUCW:$W_Y$を計算します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
W_Y = \frac{1}{\hat{p}(Y)} \sum_{i=1}^{M}w_i
$$&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;最後に、選択されたサンプル$Y$を用いて、$f(Y)$とUCW:$W_Y$を乗算することで、RISによるMC推定となります。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\langle I \rangle = f(Y)W_{Y}
$$&lt;/p&gt;
&lt;p&gt;この一般化で、RISの候補サンプルと対応するUCWから、リサンプリング重みを計算するように手順を変更しました。
これによって、RISの候補サンプルは、必ずしもサンプルの生成確率が計算可能なサンプルである必要がなく、UCWが計算可能ならばRISの候補サンプルになれることを示しています。&lt;/p&gt;
&lt;h2 id=&#34;resampled-importance-sampling-differently-distributed-samples&#34;&gt;Resampled Importance Sampling, Differently Distributed Samples&lt;/h2&gt;
&lt;p&gt;次に、サンプルごとに異なる確率密度関数:$p_i(x)$を用いた場合のRISについて説明します。これは、RISのMultiple Importance Sampling版と考えられます。&lt;/p&gt;
&lt;p&gt;まず、サンプル列$S$は、サンプルごとに対応する確率密度関数$p_i(x)$によって生成します。&lt;/p&gt;
&lt;p&gt;$$
S =\{X_1,\: &amp;hellip; \:, X_M\}, \quad \text{where} \quad X_i \sim p_i(x) \: (\text{for}\: i=1,\: &amp;hellip; \:,M) \quad \text{and} \quad X_i \in \Omega \newline
$$&lt;/p&gt;
&lt;p&gt;UCW:$W_{X_i}$は、サンプルの生成に使った確率密度関数:$p_i(x)$がわかっているので、以下のように計算できます。
$$
W_{X_i} = \frac {1}{p_i(X_i)} \quad (\text{for}\: i=1,\: &amp;hellip; \:,M)
$$&lt;/p&gt;
&lt;p&gt;次に、リサンプリングMISウエイト:$m_i(X_i)$を計算します。これは、先のMultiple Importance Samplingの項で説明したMISウエイトと同様です。
不偏である条件は、各サンプリング戦略の$m_i(x)$の総和が1であること、代表的なMISウエイトとして、Balance Heuristicsが挙げられるのも同様です。ここでは、各サンプルの生成に使った確率密度関数が
分かるので、Balance Heuristicsで計算します。&lt;/p&gt;
&lt;p&gt;$$
m_i(X_i) = \frac{p_i(X_i)}{\sum_{j=1}^{M}p_j(X_i)}
$$&lt;/p&gt;
&lt;p&gt;次に、リサンプリングの選択ウエイト:$w_i$を以下のように計算します。&lt;/p&gt;
&lt;p&gt;$$
w_i = m_i(X_i) \hat{p}(X_i) W_{X_i}
$$&lt;/p&gt;
&lt;p&gt;そして、リサンプリング重み:$w_i$に比例する形でサンプル列:$S$からサンプルを選択し、そのサンプルを$Y$とします。そしてUCWを更新します。&lt;/p&gt;
&lt;p&gt;$$
W_Y = \frac{1}{\hat{p}(Y)} \sum_{i=1}^{M}w_i
$$&lt;/p&gt;
&lt;p&gt;最後に、選択されたサンプル$Y$を用いて、$f(Y)$とUCW:$W_Y$を乗算することで、RISによるMC推定となります。&lt;/p&gt;
&lt;p&gt;$$
\langle I \rangle = f(Y)W_{Y}
$$&lt;/p&gt;
&lt;p&gt;結局、$\langle I_{\hat{p}} \rangle$に該当する部分がMultiple Importance Sampling化された部分以外は、同一確率密度関数を使ったRISと特に違いはありません。
不偏であるための条件等も、Multiple Importance Samplingの不偏条件に準じます。&lt;/p&gt;
&lt;h2 id=&#34;risのサンプル選択に関する重みづけ&#34;&gt;RISのサンプル選択に関する重みづけ&lt;/h2&gt;
&lt;p&gt;RISでは、候補サンプルの中から$w_i$に比例した形でサンプルを選択します。$i$番目のサンプルを選択する確率:$p_s(i)$は以下のとおりです。
$$
p_s(i) = \frac{w_i}{\sum_{j=1}^{M}w_j}
$$
このサンプルの選択による重みづけは、ここまで言及していませんでしたが、確率的選択をするという事は、その重みづけが必要になってくるはずです。&lt;/p&gt;
&lt;p&gt;ここで、RISの候補サンプルごとに、ある寄与関数:$g_i(x)$を定義します。これは、とりあえずのRISの被積分関数だと考えてください。
そこで、$w_i$に比例した形で、あるサンプルインデックス:$s$が選択されたとします。寄与関数:$g_s(x)$に、対応するUCW:$W_{X_s}$を乗じたものに、さらに選択確率の重みづけ:$1/p_s(s)$を乗じたものの期待値を考えます。この期待値は、選択サンプルの全て場合の、選択確率に基づく加重平均と等しいはずです。
したがって、各々の加重平均の重み（分子側）と、選択確率に基づく重みづけ（分母側）は、相殺します。結果的に$g_i(X_i)W_i$の総和が残り、これは、$g_i(x)$の積分の総和に等しくなります。
$$
E[\frac{g_s(X_s)W_{X_s}}{p_s(s)}] = E[\sum_{i=1}^{M}g_i(X_i)W_i \frac{p_s(i)}{p_s(i)}] = \sum_{i=1}^{M} \int_{\Omega} g_i(x) dx
$$&lt;/p&gt;
&lt;p&gt;では逆に、右辺が、もともとの被積分関数:$f(x)$の積分になるように$g_i(x)$を考えると、$g_i(x)$は以下のようであるべきだと分かります。
$c_i(x)$は同じサンプル値$x$において、総和が1になるとします。これはMISウエイトと同じ考え方です。&lt;/p&gt;
&lt;p&gt;$$
\text{if} \quad g_i(x) = c_i(x)f(x) \qquad \text{with} \quad \sum_{i=1}^{M} c_i(x) = 1,
$$&lt;/p&gt;
&lt;p&gt;$$
E[\frac{c_s(X_s)f(X_s)W_{X_s}}{p_s(s)}] = E[\sum_{i=1}^{M} c_i(X_s)f(X_s)W_{X_s}]= \int_{\Omega} f(x) dx
$$&lt;/p&gt;
&lt;p&gt;UCWは、$f(x)$との乗算の期待値が$f(x)$の積分になる値であるべきなので、RISのサンプル選択を行ったら、UCWは以下のように更新されるべきです。&lt;/p&gt;
&lt;p&gt;$$
W_Y = c_s(X_s) \frac{\sum_{j=1}^{M}w_j}{w_s}W_{X_s}
$$&lt;/p&gt;
&lt;p&gt;$w_s$を展開すると、以下の式が得られます。$X_s$は選択されたサンプルなので$Y$と表記します。&lt;/p&gt;
&lt;p&gt;$$
W_Y = \frac{c_s(Y)}{m_s(Y)} \frac{1}{\hat{p}(Y)} \sum_{j=1}^{M}w_j
$$&lt;/p&gt;
&lt;p&gt;$m_i(x)$は$\langle I_{\hat{p}} \rangle$の推定で使われるMISウエイトなので、リサンプリングMISウエイトと呼ばれ、$c_i(x)$は$\langle I \rangle$の推定で使われるMISウエイトなので、Contribution MIS Weights, 寄与MISウエイトと呼ばれます。$m_i(x)$と$c_i(x)$に同じ関数を使用した場合は、$W_Y$の式の先頭にある係数は相殺されるので、元のRISの式と一致します。Contribution MIS Weightsについては、後の項で軽く触れます。&lt;/p&gt;
&lt;h2 id=&#34;risにおけるmisウエイトについて&#34;&gt;RISにおけるMISウエイトについて&lt;/h2&gt;
&lt;h3 id=&#34;balance-heuristicsについて&#34;&gt;Balance Heuristicsについて&lt;/h3&gt;
&lt;p&gt;$$
m_i(x) = \frac{p_i(x)}{\sum_{j=1}^{M}p_j(x)}
$$&lt;/p&gt;
&lt;p&gt;Balance Heuristicsは、Multi Importance Samplingにおいて一般的に良いMISウエイトを算出できます。RISにおいても、リサンプリングMISウエイトで一般的に良いとされているのは、Balance Heuristicsです。
しかし、RISの候補に使うサンプリング戦略数:$M$が増えると、分母の総和の項数が多くなり計算コストが高くなります。例えば、$M=20$のRISを計算する時には、確率密度関数を400回評価しないと全てのMISウエイトが計算できません。計算量は$O(M^2)$になります。加えて、RISを再帰的に適用した場合の候補サンプルは、そのサンプルを生成した確率密度関数:$p(x)$が簡単に導出できない場合があります。そのため、MISウエイトの計算自体が困難になることがあります。そのため、RISにおいてBalance Heuristicsは、サンプリング戦略数が少なく、各戦略の確率密度関数が計算可能な時に実用的であるといえると思います。&lt;/p&gt;
&lt;h3 id=&#34;generalized-balance-heuristics&#34;&gt;Generalized Balance Heuristics&lt;/h3&gt;
&lt;p&gt;RISを再帰的に適用する場合、候補サンプルのUCWは必ず計算されていますが、候補サンプルの確率密度関数がわからない、もしくは追跡するのが困難な場合があります。そのため、リサンプリングMISウエイトに、Balance Heuristicsの代わりとしてGeneralized Balance Heuristicsを使うことが考えられます。
このMISウエイトは、RISで選択されたサンプルは、ある程度$\hat{p}(x)$の分布に基づくものになっているという仮定のもと、以下のようにリサンプリングMISウエイトを計算します。&lt;/p&gt;
&lt;p&gt;$$
m_i(x) = \frac{\hat{p_i}(x)}{\sum_{j=1}^{M}\hat{p_j}(x)}
$$&lt;/p&gt;
&lt;p&gt;このMISウエイトが不偏性を維持するためには、$supp(\hat{p})$が、対応する候補サンプルの取りうる範囲に含まれている必要があります。&lt;/p&gt;
&lt;h3 id=&#34;contribution-mis-weights&#34;&gt;Contribution MIS Weights&lt;/h3&gt;
&lt;p&gt;前の項で示した通り、RISのMISウエイトにBalance Heuristics等を使うと、最悪で$O(M^2)$の計算コストがかかります。計算コストを削減しつつ、MISを適用する方法として、
リサンプリングMISウエイトと寄与MISウエイトに、別の関数を使う方法があります。リサンプリングMISウエイトは、候補サンプルの数だけ計算されるのに対して、寄与MISウエイトは、サンプル選択後に一度だけ計算されるので、例えば、リサンプリングMISウエイトに$m_i()=1/M$などの比較的簡単な関数を使い、寄与MISウエイトにBalance Heuristics、もしくはGeneralized Balanced Heuristicsを使うことが考えられると思います。こうすることで、$O(M^2)$だったBalance Heuristicsの計算コストを、O(M)に削減することができます。ただし、このRIS推定の分散は、リサンプリングMISウエイトにBalance Heuristicsを使った場合に比べて分散が増えてしまいます。&lt;/p&gt;
&lt;h3 id=&#34;pairwise-mis-weight&#34;&gt;Pairwise MIS Weight&lt;/h3&gt;
&lt;p&gt;Pairwise MISの考え方は、実践的なReSTIRのアルゴリズムと一緒に考えるとわかりやすいです(この記事ではReSTIRのアルゴリズムについては言及しません。詳しくは他の資料を当たってください)。たとえば、ReSTIRのリサンプリング過程で、過去のピクセルや、近傍のピクセルのRISと、現在評価中のピクセルのRISを結合してリサンプリングするとします。この場合、現在評価中のピクセルのRISのサンプルが基準のサンプルとなります。これをPairwise MISでは、Canonical Sampleと呼びます。Canonical Sampleの分布は、被積分関数:$f(x)$のサポートを1サンプルで覆います。そしてリサンプリングMISウエイトは、Canonical Sampleと他のサンプルとの相対的な関係で計算します。ここで、Canonical Sampleのインデックスを$c$とします。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_i(x) &amp;amp;= \frac{1}{M-1}\frac{p_i(x)}{p_i(x) + p_c(x)},                     &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \frac{1}{M-1}\sum_{i\ne c}^{M} \frac{p_c(x)}{p_i(x) + p_c(x)},   &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Canonical SampleのMISウエイトのみ、$O(M)$の計算量が必要となりますが、Balance Heuristicsよりも計算コストが低いのがわかります。そして、MISウエイトの総和が1になる条件を満たしているのは、式より簡単にわかります。ただし、上式は、Canonical Sampleに、不必要に大きなウエイトを割り振ってしまいます。例えば、全てのサンプルが同一の$p(x)$より生成されていると仮定した場合、理想的には、全てのMISウエイトは等しくなるべきですが、$m_c(x)$が全体のほぼ$1/2$のウエイトを占めてしまいます。&lt;br&gt;
このことを考慮すると、上式は以下のように修正されます。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_i(x) &amp;amp;= \frac{1}{M-1}\frac{p_i(x)}{p_i(x) + p_c(x)/(M-1)},                         &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \frac{1}{M-1}\sum_{i\ne c}^{M} \frac{p_c(x)/(M-1)}{p_i(x) + p_c(x)/(M-1)}, &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;p&gt;さらに、上式にGeneralized Balance Heuristicの考え方を導入すれば、Generalized Pairwise MISになります。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_i(x) &amp;amp;= \frac{1}{M-1}\frac{\hat{p_i}(x)}{\hat{p_i}(x) + \hat{p_c}(x)/(M-1)},                         &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \frac{1}{M-1}\sum_{i\ne c}^{M} \frac{\hat{p_c}(x)/(M-1)}{\hat{p_i}(x) + \hat{p_c}(x)/(M-1)}, &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;p&gt;関数$\hat{p}(x)$は、あくまで、それぞれのRISサンプルが十分な数になった時に推定として有効な関数なので、Canonical Sample以外の$m_i(x)$の値が大きいにもかかわらず、そのサンプルの信頼性が低い場合も考えられます。Canonical Sampleは、被積分関数のドメイン由来のサンプルなので、これを優先するようにウエイトに固定で、$1/M$を加えることで、保守的なリサンプリングMISウエイトにすることができます。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_i(x) &amp;amp;= \frac{1}{M}\frac{\hat{p_i}(x)}{\hat{p_i}(x) + \hat{p_c}(x)/(M-1)},                                         &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \frac{1}{M} \Big( 1 + \sum_{i\ne c}^{M}\frac{\hat{p_c}(x)/(M-1)}{\hat{p_i}(x) + \hat{p_c}(x)/(M-1)} \Big), &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Canonical Sampleとその他のサンプルの信頼性に相対的な指標を適用したい場合は、サンプルごとにConfidence Weight:$c_i$を導入することもできます。例えば、この値は、それまでRISで選択対象になったサンプル数などを基準にすることが考えられます。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\text{where} \quad c = \sum_{j=1}^{M} c_j, \newline
m_i(x) &amp;amp;= \frac{c_i}{c}\frac{(c - c_c)\hat{p_i}(x)}{(c- c_c)\hat{p_i}(x) + c_c\hat{p_c}(x)},                               &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \frac{c_c}{c} + \sum_{i\ne c}^{M} \frac{c_i}{c} \frac{c_c \hat{p_c}(x)}{(c - c_c)\hat{p_i}(x) + c_c \hat{p_c}(x)}, &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Confidence Weightを導入して、Canonical Sampleを保守的に選択しなくて良い場合は元の形にConfidence Weightを適用したものを使用できます。&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_i(x) &amp;amp;= \frac{c_i\hat{p_i}(x)}{(c- c_c)\hat{p_i}(x) + c_c\hat{p_c}(x)},                               &amp;amp; \text{if} \quad i &amp;amp;\ne c \newline
m_c(x) &amp;amp;= \sum_{i\ne c}^{M} \frac{c_i}{c} \frac{c_c \hat{p_c}(x)}{(c - c_c)\hat{p_i}(x) + c_c \hat{p_c}(x)}, &amp;amp; \text{if} \quad i &amp;amp;= c
\end{align}
$$&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>スクリーンスペースでピクセル位置ごとのタスクをソーティング/パッキングするときのCompute Shader</title>
      <link>https://shikihuiku.github.io/post/pixelsortingcs/</link>
      <pubDate>Wed, 06 Aug 2025 15:46:21 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/pixelsortingcs/</guid>
      <description>&lt;p&gt;　コンピュートシェーダーを使って処理をしていると、GPU上で後続の複雑なシェーダーの並列実行性や、メモリアクセスのコヒーレンシーを高めるために、ピクセル（タスク）のパッキング／ソーティングを行いたい場合があります。例えば、ピクセルを、レイの種類ごとにソートしたり、マテリアルIDごとにソートしたり、ライトリストのIDごとにソートするなどが考えられます。
後続のシェーダーのメモリアクセスや、アルゴリズムの分岐方向などは、warp内でなるべく同じになるほうがシェーダー実行速度と、キャッシュヒット率の面で有利です。
そのため、簡単なコンピュートシェーダーでピクセルをソートできれば、後続のシェーダーで、ソートにかかる時間以上の処理速度向上が得られる場合があります。
今回は、スクリーンスペースで、ピクセル位置をタスク要素とみなし、関連付けられた情報（Material ID, Light List IDなど）でピクセルをソートすることを考えてみます。&lt;/p&gt;
&lt;h2 id=&#34;タイルごとに分割したリストにする&#34;&gt;タイルごとに分割したリストにする&lt;/h2&gt;
&lt;p&gt;　ピクセルをタスクごとにソートすれば、後続のシェーダーで、メモリアクセスや、分岐のコヒーレンシーの向上が得られます。しかし、一般的に、画面全体で完璧にソートされたピクセルリストを作ることは、負荷の高い処理となります。一方で、ソートにかけて良いコストは、後続の複雑なシェーダーの高速化で得られる時間を、安定的に下回る必要があります。トントン程度ならば、メモリと時間の無駄遣いなので、やらない方がシンプルでバグも少ないプログラムになります。&lt;br&gt;
　今回は、画面をある程度の大きさ（タイル）に分割して、タイルごとに処理をします。タイルごとにソートされたリストは分かれてしまいますが、タイル同士のメモリアクセス競合が発生しません。結果として、ソート時の並列実行性が高まります。例えばですが、64x64 pixelsでタイルを区切るなら、4096 pixels/tileとなります。レンダリング解像度が2560x1440 pixelsであれば、40x23(22.5) tiles = 920 tilesで処理することになります。
タイルごとにパッキングを行った場合の効率を考えると、32threads/warpのGPUの場合、1タイルあたり最大128 warps分のタスクがあり、タイルごとにパッキングした際のパディングは、最大31threadsで、パディングされるwarpの平均タスク充填率を50%とすると、約0.5warpに相当します。つまり、画面全体で考えると、約410warps分の、処理をしないスレッドが起動されると考えられます。
一方で、画面全体の2560x1440 pixelsのを処理する際に必要なwarp数は、115,200です。画面内のタスク充填率が50%とした場合でも5,7600 warp分のタスクがあり、920tilesに分割してパッキングしたリストを使用した場合に、処理をしないスレッド数が、起動されるスレッド数に占める割合は、おおよそ1%未満程度となります。逆を言えば、起動スレッドに対して、99%以上のタスク充填率になります。
パッキングの効率だけを考えた場合、これ以上タイルのサイズを大きくしてパッキングの効率を上げるという事は、この1%未満の数字を削る行為でしかありません。これ以上タイルサイズを大きくして、パッキング効率を向上させても無駄だといえます。&lt;br&gt;
　一方でソーティングに関しては、このように一概に話すことはできません。ソーティングのキーとなる情報（Material ID, Light List IDなど）の種類が、画面内、タイル内に何種類現れるのか、そして、画面をタイルに分割したときに局所性があるのか、また、後続のシェーダーが、ソーティングによって、どの程度メモリアクセスや分岐のコヒーレンシーを得て、どの程度高速化するのかは、実際に動作させるまで分からないでしょう。したがって、パッキング／ソーティングを処理に組み込むときは、精密なプロファイリングが必須です。&lt;/p&gt;
&lt;h2 id=&#34;簡単な実装を考える&#34;&gt;簡単な実装を考える&lt;/h2&gt;
&lt;p&gt;今回は処理タスクは、ピクセルに紐づいているとして、パッキング／ソーティングしたピクセルの座標リストをUAVバッファに格納します。今回はソート用の鍵要素は、画面に描画されたMeshletのIDです。ソート／パッキングされたピクセルリストのUAVバッファは、画面解像度の2560x1440 pixel分を、1Dバッファとして用意します。タイルIDは64x64ピクセルごとに、画面左上からリニアに割り振るとします。ピクセルリストの情報は、ピクセルあたり4byte/pixelで十分です。ピクセルリストはタイルごとに一度だけ、グローバルメモリへのInterlocked操作を使ってオフセットを取得します。タイル境界では、32要素ごとのアラインメントを取ることにします。タイルを跨いだパッキングやソーティングは行いません。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Texture2D&amp;lt;uint3&amp;gt; t_MeshletID : register(t0); // Input. Screen space sort keyes.
RWByteAddressBuffer g_SortedPixels : register(u0); // Output. 
RWByteAddressBuffer g_Counter : register(u1); // Counter(4 bytes) for packing pixels in g_SortedPixels. Need to be initialized with zero.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NumThreads は[512, 1, 1]=16 warpsでコンピュートシェーダーを起動します。1スレッドあたり8ピクセル処理すると、ちょうど4096ピクセル処理できます。
groupsharedメモリを使って、ピクセルを分類して数えます。ソートの対象は4096ピクセルなので、最大で4096種類の分類が想定されますが、あくまでも、ソート＆パッキングされたピクセルリストを作る理由は、後続のシェーダーの並列実行性の向上であるので、完璧なソートを目指しません。ソート用の鍵(Sort Key)を畳み込んで、127種類(Container Key)として分類します。当然ながら、場合によっては異なる種類のピクセルが同一に扱われてソートされることになりますが、これを許容して処理を行います。これに関する考察は後ほどします。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Works space for gathering pixels that have the same sorting keys.
static const uint NumContainers = 127; // Number of containers in a tile. Sort keys must be folded into this kinds.
groupshared uint ItemCounts[NumContainers];  // 4 x 127 = 518 bytes.
groupshared uint ItemOffsets[NumContainers]; // 4 x 127 = 518 bytes.
groupshared uint ItemOffsetWrk[NumContainers / WaveSize]; // For storing prefix sum of wave boundaries such as 32, 64 and 96.
groupshared uint TileOffset;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まず初めに、各pixelごとに、ソートのキー要素になるSort Keyを読み出します。今回は、Sort Keyは描画されたMeshlet IDをHash関数を使って計算します。Sort Keyがゼロの場合は、該当ピクセルにタスクがないものとして扱います。Sort Keyは32bitの値ですが、Sort Keyを0~126に畳み込んで、Container Keyにしたあとは、ソート作業では、Sort Keyはもう使いません。ピクセルの位置は、スレッドのIDとイテレーションの回数から算出できるので保持しません。Container Keyごとに、ピクセルを127種類に分類する為に、InterlockedAddで数を数えます。その時取得された値を、コンテナ内のオフセットとして保存しておきます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (int i = 0; i &amp;lt; 8; ++i) {
 uint2 pixelPos = GetPixelPos(ThID + i * NumThreads, Gid);
 containerKeys[i] = 0xFFFFFFFF;
 if (pixelPos.x &amp;gt;= screenExtents.x || pixelPos.y &amp;gt;= screenExtents.y) {
  // Out of bounds.
  continue;
 }
 uint3 pixelColor = t_MeshletID.Load(int3(pixelPos, 0));
 uint sortKey = Hash32_1((pixelColor.x &amp;amp; 0xFF) | ((pixelColor.y &amp;amp; 0xFF) &amp;lt;&amp;lt; 8) | ((pixelColor.z &amp;amp; 0xFF) &amp;lt;&amp;lt; 16));
 if (sortKey == 0) {
  // Total black means a empty pixel.
  // Hash32_1(0) always returns 0.
  continue;
 }

 uint containerKey = sortKey % NumContainers;

 InterlockedAdd(ItemCounts[containerKey], 1, containerLocalIndices[i]);
 containerKeys[i] = containerKey;
}
GroupMemoryBarrierWithGroupSync⁠()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;次に、WavePrefixSumを使って、127種類のコンテナ同士のオフセットを計算します。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int containerID = ThID;
int itemCnt;
int itemOfs;
if (ThID &amp;lt; NumContainers) { // 0 ~ 126
 itemCnt = ItemCounts[containerID];
 itemOfs = WavePrefixSum(itemCnt);
 if (ThID % WaveSize == WaveSize - 1) {
  ItemOffsetWrk[ThID / WaveSize] = itemOfs + itemCnt; // [0]=sum(0:31), [1]=sum(32:63), [2]=sum(64:95)..
 }
}
GroupMemoryBarrierWithGroupSync();

if (ThID &amp;lt; NumContainers) { // 0 ~ 126
 for (int waveBoundary = 0; waveBoundary &amp;lt; NumContainers / WaveSize; ++waveBoundary) { // for 32, 64, 96
  if (ThID &amp;gt;= (waveBoundary + 1) * WaveSize) {
   itemOfs += ItemOffsetWrk[waveBoundary];
  }
 }
 ItemOffsets[containerID] = itemOfs;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;画面全体におけるタイル同士のオフセットを計算する為に、ここで、UAVバッファに対して、InterlockedAddを使ってオフセットを取得します。タスク充填率が常に高い状態になることが分かっている場合は、Interlocked命令を使わずに固定オフセットでタイルごとの情報をしまった方が効率的です。ここでは、タスク充填率が変動するものとして、Interlocked命令でオフセットを計算します。単なるパッキングなら、32要素ごとのアラインメントを取らずにタイトなパッキングにすることも可能ですが、ソートしたリストとwarpのアラインメントが崩れてしまいます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;if (ThID == NumContainers - 1) { // ThID: 126 should have the total number of container entires.
 // The first item of each 64x64 tile will be placed with 32 items alignment.
 uint TotalAlignedEntriesInTile = Roundup32(itemOfs + itemCnt);
 g_Counter.InterlockedAdd(0, TotalAlignedEntriesInTile, TileOffset);
}
GroupMemoryBarrierWithGroupSync();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最後に、ソートされたピクセルリストをストアします。これでこのシェーダーの処理は終わりです。
後続のシェーダーでは、ソートされたピクセルのバッファに、warpごとにアクセスして、処理するピクセル位置を取得することで、warp内の処理が、なるべく同じ処理をするように並べられた状態になるはずです。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (i = 0; i &amp;lt; 8; ++i) {
 if (containerKeys[i] == 0xFFFFFFFF)
  continue;
 uint2 pixelPos = GetPixelPos(ThID + i * NumThreads, Gid);
 uint packedPixelPos = ((pixelPos.y &amp;amp; 0xFFFF) &amp;lt;&amp;lt; 16) | (pixelPos.x &amp;amp; 0xFFFF);
 g_SortedPixels.Store((TileOffset + ItemOffsets[containerKeys[i]] + containerLocalIndices[i]) * 4, packedPixelPos);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;container-keyのコンフリクトについて&#34;&gt;Container Keyのコンフリクトについて&lt;/h2&gt;
&lt;p&gt;今回の例では、処理するピクセル数が、4096に対して、コンテナの数が127です。剰余算でSort KeyをContainer Keyに畳み込んだので、Sort Keyの種類が多い場合は高確率でコンフリクトが発生します。しかし、逆を言えば、Container Keyのコンフリクトが頻繁に発生する状況では、タイル内のSort Keyの種類が多いことが考えられ、この場合は、ソートによるコヒーレンシーの向上効果を得ること自体が難しいと考えられます。それでも、Container Keyは127種類しかないので偶発的なコンフリクトも考えられます。偶発的に発生するコンフリクトをある程度回避し、コンフリクト耐性を高める方法を示します。&lt;br&gt;
コンテナのインデックスとSort Keyの対応付けを管理するため、Sort KeyをgroupsharedメモリにInterlockedCompareAndExchangeを使ってストアします。コンテナが空(0)だった場合は交換が成功します。失敗した場合でも、同一のSort Keyが格納されていれば、そのSort Keyが該当のコンテナをすでに確保しているという意味になるので、該当のコンテナのインデックスを使用します。&lt;br&gt;
一方で、異なるSort Keyがすでに該当のコンテナに格納されている場合は、コンフリクトとなります。この場合は、空きコンテナをリニアサーチします。リニアサーチをどの程度行うかは実装次第で、コンテナを完璧に埋めるには、最悪126回のリニアサーチが必要になります。しかし、今回の実装では、あくまで偶発的に発生するコンフリクトの回避なので、2回しか行いません。最終的にコンフリクトが解決できなかった場合は、そのままコンテナのインデクスを使用します。この場合は、同じコンテナに異なるSort Keyのピクセルが格納されます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#if RESOLVE_CONTAINER_KEY_CONFLICTS
groupshared uint OriginalKeys[NumContainers]; // 4 x 128 = 512 bytes, to store original sort keys.
#endif

#if RESOLVE_CONTAINER_KEY_CONFLICTS
if (ThID &amp;lt; NumContainers) {
 OriginalKeys[ThID] = 0;
}
#endif

#if RESOLVE_CONTAINER_KEY_CONFLICTS
{
 const int NumTries = 3;
 uint orgVal;
 int j;
 [unroll]
 for (j = 0; j &amp;lt; NumTries; ++j) {
  InterlockedCompareExchange(OriginalKeys[containerKey], 0, sortKey, orgVal);
  if (orgVal == 0 || orgVal == sortKey) {
   // Succeeded to allocate a slot for the sortKey.
   break;
  }
  // Conflict happened. Linear search.
  containerKey = (containerKey + 1) % NumContainers;
 }
}
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;タイル内をコンテナの要素数でソートする&#34;&gt;タイル内をコンテナの要素数でソートする&lt;/h2&gt;
&lt;p&gt;最初の実装例では、タイル内の127種類のコンテナは、コンテナごとの要素数とは関係なくContainer Key順に格納されます。タイルごとに32要素のアラインメントをとりましたが、先頭のコンテナが少量だった場合は、簡単にアラインメントが崩れてしまいます。そこで、コンテナの要素数に基づいて、コンテナをソートしたいと思います。ただしあまり複雑なアルゴリズムを用いてソートすると、コストとパフォーマンスの向上が見合わなくなってしまうので、簡単なソートのみ適用します。ここで使うのは、32要素のRadixSortのようなアルゴリズムです。127種類のコンテナを、32種類に分類して、コンテナがUAVバッファにストアされる順番を入れ替えます。
一番先頭にストアしたいのは、要素数が32にアラインしているコンテナです。これらは32要素にアラインしているバッファにストアすれば、完璧にwarpにフィットします。次に考えられるのは、コンテナの要素数が多いものです。要素数がある程度多いコンテナが隣接している場合は、warp内の分岐が最大2方向で済みます。要素数の多いコンテナ同士の間に少ないコンテナが挟まって、分岐の方向が増えてしまうのを避けれれば十分です。したがって、コンテナの要素数を8で割って、240~8を30~1にマッピングします。31は要素数が32にアラインしているコンテナにアサインします。このインデックスを反転させてソートすれば、アラインしているコンテナが先頭になり、次いで（おおよそ）要素数の大きい順にコンテナがソートされます。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#if SORTING_CONTAINERS
// Sort containers based on their item counts.
{
 uint radInput;
 uint radLocalIdx;

 if (ThID &amp;lt; NumContainers) { // 0 ~ 126
  // Each container&#39;s item count can be up to 4095 (0x0000_0FFF), however, we just want to put aligned containers and major containers first.
  // We can clip this number with 240 (0xF0) which indicates &#39;major&#39; enough. Also, we can clip minor work items less than 8(&amp;gt;&amp;gt;3) as &#39;minor&#39; enough.
  // So, radixInput can be from 0x00 to 0x1E (0 ~ 30) which is fit into single warp.
  // #31 is a special number for containers aligned with 32.
  radInput = min(ItemCounts[ThID] &amp;gt;&amp;gt; 3, 30);
  radInput = ItemCounts[ThID] % WaveSize == 0 ? 31 : radInput;

  // Reverse order. Bigger container first.
  radInput = 31 - radInput;

  InterlockedAdd(RadixCounts[radInput], 1, radLocalIdx);
 }

 GroupMemoryBarrierWithGroupSync();

 if (ThID &amp;lt; RadixWidth) { // 0 ~ 31
  RadixOffsets[ThID] = WavePrefixSum(RadixCounts[ThID]);
 }
 GroupMemoryBarrierWithGroupSync();

 if (ThID &amp;lt; NumContainers) { // 0 ~ 126
  int containerID = ThID;
  int containerRank = RadixOffsets[radInput] + radLocalIdx;

  // Store sorted array. This is the index for storing containers.
  RadixSortedContainerIndex[containerRank] = containerID;
 }
 GroupMemoryBarrierWithGroupSync();
}
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;観察&#34;&gt;観察&lt;/h2&gt;
&lt;p&gt;実際にタイルごとにソートした結果を視覚化して確認したいと思います。今回はソートの対象は、Meshletで描画されたMeshletのIDです。特に深い意味はありませんが、Material IDの代わりと考えてもらえれば良いかと思います。ソートしたバッファは、1Dバッファなので、そのまま見ても面白くないので、タイル位置ごとにSort Keyで色付けしたピクセルをリニアに並べています。
タイルサイズは64x64なので、タイルの半分の長さが、ちょうどwarpのサイズになります。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-meshlet-id&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Meshlet_hub3ac58224992baa3584aa2431ee18516_160885_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Meshlet ID&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Meshlet_hub3ac58224992baa3584aa2431ee18516_160885_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1440&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Meshlet ID
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-64x64タイルでソートされたものを可視化&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_hue45b4b6dfb42aa627f99cbaaf11911c2_52216_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;64x64タイルでソートされたものを可視化&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_hue45b4b6dfb42aa627f99cbaaf11911c2_52216_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1440&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    64x64タイルでソートされたものを可視化
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;分かりにくいのでCropします。&lt;br&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-meshlet-id&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Meshlet_z_hue3a15d2ea9b6c0f041b6d08ca25a0fe2_13147_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Meshlet ID&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Meshlet_z_hue3a15d2ea9b6c0f041b6d08ca25a0fe2_13147_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;192&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Meshlet ID
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;br&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-sort-keyのコンフリクト回避ありコンテナの要素数によるソートあり&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_z_huca71900b33fb8fd5d274a3631e07a1ac_4159_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Sort Keyのコンフリクト回避：あり、コンテナの要素数によるソート：あり&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_z_huca71900b33fb8fd5d274a3631e07a1ac_4159_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;192&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sort Keyのコンフリクト回避：あり、コンテナの要素数によるソート：あり
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;br&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-sort-keyのコンフリクト回避ありコンテナの要素数によるソートなし&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/AvoidConflict_z_hu941350dadcb4a538a9f713348107e913_4434_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Sort Keyのコンフリクト回避：あり、コンテナの要素数によるソート：なし&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/AvoidConflict_z_hu941350dadcb4a538a9f713348107e913_4434_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;192&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sort Keyのコンフリクト回避：あり、コンテナの要素数によるソート：なし
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;br&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-sort-keyのコンフリクト回避なしコンテナの要素数によるソートなし&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Conflict_z_hu6b0c4553450b1136f016f9415413bf92_5030_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Sort Keyのコンフリクト回避：なし、コンテナの要素数によるソート：なし&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Conflict_z_hu6b0c4553450b1136f016f9415413bf92_5030_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;192&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sort Keyのコンフリクト回避：なし、コンテナの要素数によるソート：なし
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;br&gt;
まず、コンフリクト回避をしていないものは、コンフリクトが発生しているのが視覚化されてよくわかります。見た目がひどいので、コンフリクトの影響が大きいように見えますが、
単なる２種類のコンフリクトであれば、warp内の分岐は2方向なので、見た目ほど酷い実行性能にならないはずです。コンフリクト回避が実行性能に与える影響はおそらく軽微でしょう。&lt;br&gt;
コンテナ要素ごとのソートも、可視化すると良く見えますが、実際はタイルの後半に、要素数の少ないコンテナが密集して、分岐の多いwarpを作ることになるので、全体の速度で考えると
見た目ほど速くなることはないでしょう。&lt;/p&gt;
&lt;p&gt;次に処理速度を計測してみます。RTX5080で2560x1440を処理したときに、NSightGraphicsで計測してみます。
処理の計測では、デバッグ用の視覚化処理を省略して計測します。また、負荷を上げるため、オブジェクトのインスタンスの表示数を増やします。&lt;br&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-meshlet-idベンチマークケース&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Screen_b_huf6f86b56a7559ed7c20fbf1bb0aca1ab_1215867_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Meshlet ID　（ベンチマークケース）&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Screen_b_huf6f86b56a7559ed7c20fbf1bb0aca1ab_1215867_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1440&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Meshlet ID　（ベンチマークケース）
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-64x64タイルでソートされたものを可視化ベンチマークケース&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_b_hu09806bcf02189fadb70dd3e34095f155_356926_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;64x64タイルでソートされたものを可視化（ベンチマークケース）&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/pixelsortingcs/Sorted_b_hu09806bcf02189fadb70dd3e34095f155_356926_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1440&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    64x64タイルでソートされたものを可視化（ベンチマークケース）
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Sort Keyのコンフリクト回避&lt;/th&gt;
&lt;th&gt;コンテナの要素数によるソート&lt;/th&gt;
&lt;th&gt;実行時間&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;あり&lt;/td&gt;
&lt;td&gt;あり&lt;/td&gt;
&lt;td&gt;0.06ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;あり&lt;/td&gt;
&lt;td&gt;なし&lt;/td&gt;
&lt;td&gt;0.05ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;なし&lt;/td&gt;
&lt;td&gt;なし&lt;/td&gt;
&lt;td&gt;0.03ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;参考：1Dバッファとデバッグ視覚化バッファのクリア: 0.03ms&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;どのDispatchも前後にUAVバリアを設置したので、おおよそ正確な値と思われますが、0.01ms精度での計測は難しいので参考程度で。&lt;/p&gt;
&lt;h2 id=&#34;考察&#34;&gt;考察&lt;/h2&gt;
&lt;p&gt;もっと並列度を上げるためにいろいろ考えてしまいますが、処理負荷的にこの程度が適切だと思います。
ソートやパッキングにコストをかけ過ぎれば後続の処理が早くなってもトータルで速くならないので、あくまで程々に。&lt;/p&gt;
&lt;h2 id=&#34;ソース&#34;&gt;ソース&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;#if !defined(DEBUG_VISUALIZATION)
#define DEBUG_VISUALIZATION 1
#endif
#if !defined(RESOLVE_CONTAINER_KEY_CONFLICTS)
#define RESOLVE_CONTAINER_KEY_CONFLICTS 1
#endif
#if !defined(SORTING_CONTAINERS)
#define SORTING_CONTAINERS 1
#endif

Texture2D&amp;lt;uint3&amp;gt; t_MeshletID : register(t0); // Input. Screen space sort keyes.

RWByteAddressBuffer g_SortedPixels : register(u0); // Output.  
RWByteAddressBuffer g_Counter : register(u1); // Counter(4 bytes) for packing pixels in g_SortedPixels. Need to be initialized with zero.

#if DEBUG_VISUALIZATION
RWTexture2D&amp;lt;float4&amp;gt; g_SortedPixlTex : register(u2); // 2D tex for debug visualization.
#endif

#define NumThreads 512 // Thread group size.
static const uint WaveSize = 32;
static const uint2 screenExtents = uint2(2560, 1440); // For simplicty.

// Works space for gathering pixels that have the same sorting keys.
static const uint NumContainers = 127; // Number of containers in a tile. Sort keys must be folded into this kinds.
groupshared uint ItemCounts[NumContainers];  // 4 x 127 = 518 bytes.
groupshared uint ItemOffsets[NumContainers]; // 4 x 127 = 518 bytes.
groupshared uint ItemOffsetWrk[NumContainers / WaveSize]; // For storing prefix sum of wave boundaries such as 32, 64 and 96.
groupshared uint TileOffset;

#if RESOLVE_CONTAINER_KEY_CONFLICTS
groupshared uint OriginalKeys[NumContainers]; // 4 x 128 = 512 bytes, to store original sort keys.
#endif

#if SORTING_CONTAINERS
// Working space for a radix sort to &#39;roughly&#39; sort the containers.
static const uint RadixWidth = 32;
groupshared uint RadixCounts[RadixWidth]; // 4 x 32 = 128 bytes
groupshared uint RadixOffsets[RadixWidth]; // 4 x32 = 128 bytes
groupshared uint RadixSortedContainerIndex[NumContainers]; // 4 x 127 = 518 bytes.
#endif

uint TwoRoundXorShiftMulXorShift(uint s1, uint v1, uint s2, uint v2, uint s3, uint x)
{
	x ^= x &amp;gt;&amp;gt; s1;
	x *= v1;
	x ^= x &amp;gt;&amp;gt; s2;
	x *= v2;
	x ^= x &amp;gt;&amp;gt; s3;
	return x;
}
uint Hash32_1(uint x)
{
	// https://github.com/skeeto/hash-prospector/issues/19
	return TwoRoundXorShiftMulXorShift(15, 0x2c1b3c6d, 12, 0x297a2d39, 15, x);
}

uint Roundup32(uint x)
{
	return ((x + 31) / 32) * 32;
}

uint2 DecodeMorton2D64x64(uint mortonCode)
{
	uint x = mortonCode &amp;amp; 0xFFF; // 0 ~ 4095
	uint y = x &amp;gt;&amp;gt; 1;

	x = (x &amp;amp; 0x00000555); // x &amp;amp; 0101_0101_0101b
	x = (x | (x &amp;gt;&amp;gt; 1)) &amp;amp; 0x00000333;// &amp;amp; 0011_0011_0011b
	x = (x | (x &amp;gt;&amp;gt; 2)) &amp;amp; 0x0000030F;// &amp;amp; 0011_0000_1111b
	x = (x | (x &amp;gt;&amp;gt; 4)) &amp;amp; 0x0000003F;// &amp;amp; 0000_0011_1111b

	y = (y &amp;amp; 0x00000555);
	y = (y | (y &amp;gt;&amp;gt; 1)) &amp;amp; 0x00000333;
	y = (y | (y &amp;gt;&amp;gt; 2)) &amp;amp; 0x0000030F;
	y = (y | (y &amp;gt;&amp;gt; 4)) &amp;amp; 0x0000003F;

	return uint2(x, y);
}

uint2 GetPixelPos(uint pixIdx, uint3 Gid, bool useMortonCode = true)
{
	uint2 tilePos = Gid.xy;
	uint2 localPos;

	if (useMortonCode) {
		localPos = DecodeMorton2D64x64(pixIdx);
	}
	else {
		localPos.x = pixIdx % 64;
		localPos.y = pixIdx / 64;
	}

	return tilePos * uint2(64, 64) + localPos;
}

// Dispatch should be called with Dispatch(ScreenExtents.x / 64, ScreenExtents.y / 64, 1)
[numthreads(NumThreads, 1, 1)]
void main(uint3 GTid : SV_GroupThreadID, uint3 Gid : SV_GroupID)
{
	const uint ThID = GTid.x;

	if (ThID &amp;lt; NumContainers) {
		ItemCounts[ThID] = 0;

#if RESOLVE_CONTAINER_KEY_CONFLICTS
		OriginalKeys[ThID] = 0;
#endif

#if SORTING_CONTAINERS
		if (ThID &amp;lt; RadixWidth) {
			RadixCounts[ThID] = 0;
		}
#endif
	}
	GroupMemoryBarrierWithGroupSync();

	uint containerKeys[8];
	uint containerLocalIndices[8];
	for (int i = 0; i &amp;lt; 8; ++i) {
		uint2 pixelPos = GetPixelPos(ThID + i * NumThreads, Gid);
		containerKeys[i] = 0xFFFFFFFF;
		if (pixelPos.x &amp;gt;= screenExtents.x || pixelPos.y &amp;gt;= screenExtents.y) {
			// Out of bounds.
			continue;
		}
		uint3 pixelColor = t_MeshletID.Load(int3(pixelPos, 0));
		uint sortKey = Hash32_1((pixelColor.x &amp;amp; 0xFF) | ((pixelColor.y &amp;amp; 0xFF) &amp;lt;&amp;lt; 8) | ((pixelColor.z &amp;amp; 0xFF) &amp;lt;&amp;lt; 16));
		if (sortKey == 0) {
			// Total black means a empty pixel.
			// Hash32_1(0) always returns 0.
			continue;
		}

		// Folding the SortKey with no care will cause accidental conflicts, but we may afford it for cost/perf balance.
		uint containerKey = sortKey % NumContainers;

#if RESOLVE_CONTAINER_KEY_CONFLICTS
		{
			const int NumTries = 3;
			uint orgVal;
			int j;
			[unroll]
			for (j = 0; j &amp;lt; NumTries; ++j) {
				InterlockedCompareExchange(OriginalKeys[containerKey], 0, sortKey, orgVal);
				if (orgVal == 0 || orgVal == sortKey) {
					// Succeeded to allocate a slot for the sortKey.
					break;
				}

				// Conflict happened. Linear search.
				containerKey = (containerKey + 1) % NumContainers;
			}
#if 0
			if (j == NumTries) {
				// Failed to resolve a conflict. Leave it as is considering cost/perf balance. 
				// For debugging purpose, kick a DR with an infinite loop to see if this is really happened.
				do {
					InterlockedCompareExchange(OriginalKeys[containerKey], 0, sortKey, orgVal);
				} while (orgVal != (uint) - 1);
			}
#endif
		}
#endif

		InterlockedAdd(ItemCounts[containerKey], 1, containerLocalIndices[i]);
		containerKeys[i] = containerKey;
	}

	GroupMemoryBarrierWithGroupSync();

#if SORTING_CONTAINERS
	// Sort containers based on their item counts.
	{
		uint radInput;
		uint radLocalIdx;

		if (ThID &amp;lt; NumContainers) { // 0 ~ 126
			// Each container&#39;s item count can be up to 4095 (0x0000_0FFF), however, we just want to put aligned containers and major containers first.
			// We can clip this number with 240 (0xF0) which indicates &#39;major&#39; enough. Also, we can clip minor work items less than 8(&amp;gt;&amp;gt;3) as &#39;minor&#39; enough.
			// So, radixInput can be from 0x00 to 0x1E (0 ~ 30) which is fit into single warp.
			// #31 is a special number for containers aligned with 32.
			radInput = min(ItemCounts[ThID] &amp;gt;&amp;gt; 3, 30);
			radInput = ItemCounts[ThID] % WaveSize == 0 ? 31 : radInput;

			// Reverse order. Bigger container first.
			radInput = 31 - radInput;

			InterlockedAdd(RadixCounts[radInput], 1, radLocalIdx);
		}

		GroupMemoryBarrierWithGroupSync();

		if (ThID &amp;lt; RadixWidth) { // 0 ~ 31
			RadixOffsets[ThID] = WavePrefixSum(RadixCounts[ThID]);
		}
		GroupMemoryBarrierWithGroupSync();

		if (ThID &amp;lt; NumContainers) { // 0 ~ 126
			int containerID = ThID;
			int containerRank = RadixOffsets[radInput] + radLocalIdx;

			// Store sorted array. This is the index for storing containers.
			RadixSortedContainerIndex[containerRank] = containerID;
		}
		GroupMemoryBarrierWithGroupSync();
	}
#endif

	// Count containers&#39; entires in the tile and sub-allocate buffer to store sorted pixels.
	{
		int containerID = ThID;
#if SORTING_CONTAINERS
		if (ThID &amp;lt; NumContainers) { // 0 ~ 126
			containerID = RadixSortedContainerIndex[ThID];
		}
#endif

		int itemCnt;
		int itemOfs;
		if (ThID &amp;lt; NumContainers) { // 0 ~ 126
			itemCnt = ItemCounts[containerID];
			itemOfs = WavePrefixSum(itemCnt);
			if (ThID % WaveSize == WaveSize - 1) {
				ItemOffsetWrk[ThID / WaveSize] = itemOfs + itemCnt; // [0]=sum(0:31), [1]=sum(32:63), [2]=sum(64:95)..
			}
		}
		GroupMemoryBarrierWithGroupSync();

		if (ThID &amp;lt; NumContainers) { // 0 ~ 126
			for (int waveBoundary = 0; waveBoundary &amp;lt; NumContainers / WaveSize; ++waveBoundary) { // for 32, 64, 96
				if (ThID &amp;gt;= (waveBoundary + 1) * WaveSize) {
					itemOfs += ItemOffsetWrk[waveBoundary];
				}
			}
			ItemOffsets[containerID] = itemOfs;
		}

		if (ThID == NumContainers - 1) { // ThID: 126 should have the total number of container entires.
			// The first item of each 64x64 tile will be placed with 32 items alignment.
			uint TotalAlignedEntriesInTile = Roundup32(itemOfs + itemCnt);
			g_Counter.InterlockedAdd(0, TotalAlignedEntriesInTile, TileOffset);
		}
		GroupMemoryBarrierWithGroupSync();
	}

	for (i = 0; i &amp;lt; 8; ++i) {
		if (containerKeys[i] == 0xFFFFFFFF)
			continue;

		uint2 pixelPos = GetPixelPos(ThID + i * NumThreads, Gid);
		uint packedPixelPos = ((pixelPos.y &amp;amp; 0xFFFF) &amp;lt;&amp;lt; 16) | (pixelPos.x &amp;amp; 0xFFFF);
		g_SortedPixels.Store((TileOffset + ItemOffsets[containerKeys[i]] + containerLocalIndices[i]) * 4, packedPixelPos);

#if DEBUG_VISUALIZATION
		uint2 linearPixelPos = GetPixelPos(ItemOffsets[containerKeys[i]] + containerLocalIndices[i], Gid, false);

		uint3 pixelColor = t_MeshletID.Load(int3(pixelPos, 0));
		float r = (float)pixelColor.x / 255.0;
		float g = (float)pixelColor.y / 255.0;
		float b = (float)pixelColor.z / 255.0;

		g_SortedPixlTex[linearPixelPos] = float4(r, g, b, 1);
#endif
	}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ID3D12CommandQueue::UpdateTileMappingsが起こすデッドロックについて</title>
      <link>https://shikihuiku.github.io/post/d3d12utm/</link>
      <pubDate>Sat, 01 Feb 2025 18:00:00 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/d3d12utm/</guid>
      <description>&lt;p&gt;English is here. 
&lt;a href=&#34;#Eng&#34;&gt;Deadlocks Caused by ID3D12CommandQueue::UpdateTileMappings&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;D3D12のゲームが低い頻度でハングアップしてしまう理由の一つとして、&lt;code&gt;UpdateTilemappnigs&lt;/code&gt;が原因となるデッドロックがあります。詳しい仕組みは、いまだ不明ですが、最近やっと自分の考えを人に説明できるぐらいにはなってきたので、メモ代わりに残しておこうと思います。&lt;br&gt;
ただし、以下に記述することは、あくまでも、おそらくこういうことだろうなぁ、という程度の想像の話です。確かなことはSDKやOSを設計している人に聞いてみないとわかりません。
今のところ、Windows11 24H2 (OS Build 26100.2894)では起きるようですが、将来的にOS側に修正が入る可能性もあるかと思います。&lt;/p&gt;
&lt;h2 id=&#34;gpuviewで確認するd3d12のid3d12commandqueueupdatetilemappingsの動作&#34;&gt;GPUViewで確認するD3D12のID3D12CommandQueue::UpdateTileMappingsの動作&lt;/h2&gt;
&lt;p&gt;まずは、GPUViewを使って&lt;code&gt;UpdateTileMappings&lt;/code&gt;の動作を確認してみます。GPUViewのEvent Listの中から、&lt;code&gt;DxgKrnl UpdateGPUVirtualAddress&lt;/code&gt;を選択して、呼び出し箇所を特定します。
以下のスクリーンショットは、あるフレームのレンダリング処理を、プロセスのGPU実行キューに積んだ後に、&lt;code&gt;UpdateTileMappings&lt;/code&gt;（以下UTM）を何度か呼び出している箇所です。&lt;br&gt;
UTMの呼び出しで、アプリケーションのスレッドがカーネルモードにスイッチしているのがわかります。また、その区間では、&lt;code&gt;DxgKrnl UpdateGPUVirtualAddress&lt;/code&gt;のイベント一つにつき、フェンスが二つ設定されているのがわかります。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---1&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image1_hub9ccdd4ec5701d8ba5db3e6a9b8229e2_36733_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 1&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image1_hub9ccdd4ec5701d8ba5db3e6a9b8229e2_36733_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;978&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 1
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;次に、このフェンスがプロセスのGPU実行キューで処理されるタイミングを見てみます。まず、積み上げられたフェンスは同一のオブジェクトなのがわかります。１つのフェンスが、フェンス値をインクリメントしながら使用されているようです。UTMのフェンスが、プロセスのGPU実行キューの先頭に到達すると、アプリケーションのスレッドでDPCが呼び出されます（これはOSによる割り込みと解釈して問題ありません。）このDPCは、プロセスのPaging QueueにPaging Queu Packetを送出します。&lt;br&gt;
以下のスクリーンショットでは、UTMが送出した一連のフェンスをハイライトしています。先頭が、実行キューの先頭に到達する直前で、アプリケーションの白いバーで示されているThread上で、DPCが起動されます。このDPCが動作するタイミングでPaging Queue Packetが送出されますようです。矢印で図示しておきました。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---2&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image2_hu3213b80c4faf65051a2dffba27d98fa5_481072_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 2&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image2_hu3213b80c4faf65051a2dffba27d98fa5_481072_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;1000&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 2
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;送出されたPaging Queue Packetは、OSのVidMm WorkerThreadで処理されます。パケットを受け取ったOSのスレッドが、System Paging Contextに、Paging Command Packetを送出します。このパケットは、GPU上のHardware Copy Queueに送出されて、GPU上で処理されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---3&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image3_hu92bebf72723ca2a2ad84b4939408949e_84146_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 3&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image3_hu92bebf72723ca2a2ad84b4939408949e_84146_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;896&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 3
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;System Paging Contextには、Paging Command Packetの直後に、３つのフェンスが設定されており、GPU上でのUTM処理の完了をCPU側で検知するようです。このうちの一つは、UTMを送出したプロセスのスレッドでDPCを起動して、これがUTMのフェンスのフェンス値をインクリメントするようです。その結果、プロセス側のGPU実行QueueでUTMの完了を待っていたフェンスが解決されます。これで一つのUTM処理が完了したことになります。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---4&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image4_huce2858e525986fbbb1701b9fc14dc36c_412330_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 4&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image4_huce2858e525986fbbb1701b9fc14dc36c_412330_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;1017&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 4
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;utmの処理をwindbgで追ってみる&#34;&gt;UTMの処理をWindbgで追ってみる&lt;/h2&gt;
&lt;p&gt;次は、デバッガーを使って、UTMの処理を追ってみます。適当なサンプルアプリケーションのUTMコールを、Microsoftのシンボルサーバーだけを使って追ってみました。処理は、D3Dのランタイム、ユーザーモードドライバー、Windows APIなどで構成されており、その中で主だった処理を、順を追って見てみたいと思います。&lt;/p&gt;
&lt;h4 id=&#34;1-d3d12coreが管理するmutexの取得&#34;&gt;1. D3D12Coreが管理するMutexの取得&lt;/h4&gt;
&lt;p&gt;UTM呼び出しの冒頭で、D3D12Coreが管理するミューテックスを取得します。おそらくこれは、該当の&lt;code&gt;CGraphicsCommandQueue&lt;/code&gt;に対する呼び出しの、排他制御の為と思われます。&lt;code&gt;CGraphicsCommandQueue&lt;/code&gt;はスレッドセーフな設計となっているので、必要に応じてD3Dのランタイム側でで排他制御が行われているのだと思われます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlAcquireSRWLockExclusive     
[0x1]   msvcp_win!Mtx_lock+0x31    
[0x2]   D3D12Core!std::_Mutex_base::lock+0x10    
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0xe2    
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-device-driver-interfaceに登録された関数の呼び出し&#34;&gt;2. Device Driver Interfaceに登録された関数の呼び出し&lt;/h4&gt;
&lt;p&gt;Device Driver Interface (DDI)は、OSやランタイムが、デバイスドライバーを呼び出すときの関数のインターフェースです。呼び出し先は、その時インストールされているドライバーのコードになります。呼び出されたDDIの引数のを見ると、&lt;code&gt;d3d12umddi.h&lt;/code&gt;に定義されている、&lt;code&gt;PFND3D12DDI_UPDATETILEMAPPINGS&lt;/code&gt;だとわかります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e      
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参考：&lt;code&gt;d3d12umddi.h&lt;/code&gt;の&lt;code&gt;PFND3D12DDI_UPDATETILEMAPPINGS&lt;/code&gt;の定義&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef VOID ( APIENTRY* PFND3D12DDI_UPDATETILEMAPPINGS )( D3D12DDI_HCOMMANDQUEUE, D3D12DDI_HRESOURCE,
    UINT NumTiledResourceRegions,
    _In_reads_(NumTiledResourceRegions) const D3D12DDI_TILED_RESOURCE_COORDINATE* pResourceRegionStartCoords,
    _In_reads_opt_(NumTiledResourceRegions) const D3D12DDI_TILE_REGION_SIZE* pResourceRegionSizes,
    D3D12DDI_HHEAP, UINT NumRanges,
    _In_reads_opt_(NumRanges) const D3D12DDI_TILE_RANGE_FLAGS*,
    _In_reads_opt_(NumRanges) const UINT* pHeapStartOffsets,
    _In_reads_opt_(NumRanges) const UINT* pRangeTileCounts,
    D3D12DDI_TILE_MAPPING_FLAGS );
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-umdのコード内でのcritical-sectionの取得&#34;&gt;3. UMDのコード内でのCritical Sectionの取得&lt;/h4&gt;
&lt;p&gt;Critical SectionはWindwosが提供するる、プロセス内で使える同期オブジェクトです。Callstackを見ると、UMDのコードが&lt;code&gt;nvwgf2umx!OpenAdapter&lt;/code&gt;となっていますが、これは、UMDのDLLでExportされているSymbolからのオフセットアドレスを表示しているだけで、DDIコールで&lt;code&gt;OpenAdapter&lt;/code&gt;が呼ばれているわけではありません。NVIDIAのUMDのDLLのPDBファイルが無いので、Symbolが解決できないだけです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlEnterCriticalSection   
[0x1]   nvwgf2umx!OpenAdapter12+0x7e5f   
[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-フェンスのシグナルの送出&#34;&gt;4. フェンスのシグナルの送出&lt;/h4&gt;
&lt;p&gt;次に、UMDのUTM処理コードは、D3DCoreの、&lt;code&gt;SubmitSignalSyncObjectsToHwQueueCB&lt;/code&gt;を呼び出します。このコールバックは、OSがD3DRuntimeに登録するコールバックと思われます。登録されているコールバック関数は、&lt;code&gt;win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt;のようです。この関数のアセンブラコードを見ると、すぐに&lt;code&gt;syscall&lt;/code&gt;を実行して、カーネルモードに入っています。ここまでの呼び出し経路は少々複雑で、Application→D3DRuntime→UMD→D3DRuntime→GDIとなっています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_SUBMITSIGNALSYNCOBJECTSTOHWQUEUE const * __ptr64),_D3DKMT_SUBMITSIGNALSYNCOBJECTSTOHWQUEUE * __ptr64&amp;gt;+0x1d   
[0x2]   D3D12Core!NDXGI::CDevice::SubmitSignalSyncObjectsToHwQueueCB+0xdd   
[0x3]   nvwgf2umx!....
....
[0xa]   nvwgf2umx!....
[0xb]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xc]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参考：&lt;code&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt;のアセンブラコード&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue:
mov     r10, rcx
mov     eax, 125Dh
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue+0x15
syscall 
ret   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-d3dkmt_updategpuvirtualaddressの呼び出し&#34;&gt;5. D3DKMT_UPDATEGPUVIRTUALADDRESSの呼び出し&lt;/h4&gt;
&lt;p&gt;ついにUTMの処理の本体とも呼べる箇所に到達しました。呼び出し経路は、先ほどのシグナルと似た経路です。こちらもGDIの関数で、関数内部で、すぐに&lt;code&gt;sycall&lt;/code&gt;を実行するだけです。処理の実体はカーネルモードにあると思います。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDIUpdateGpuVirtualAddress+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_UPDATEGPUVIRTUALADDRESS const * __ptr64),_D3DKMT_UPDATEGPUVIRTUALADDRESS * __ptr64&amp;gt;+0x11   
[0x2]   D3D12Core!NDXGI::CDevice::UpdateGpuVirtualAddressCB+0x64   
[0x3]   nvwgf2umx!....
....
[0x8]   nvwgf2umx!....
[0x9]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xa]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;参考：&lt;code&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;のアセンブラコード&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDIUpdateGpuVirtualAddress:
mov     r10, rcx
mov     eax, 1264h
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDIUpdateGpuVirtualAddress+0x15 (7ff81e415f15)
syscall 
ret     
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-フェンスのウエイトの設定&#34;&gt;6. フェンスのウエイトの設定&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;D3DKMT_UPDATEGPUVIRTUALADDRESS&lt;/code&gt;が呼ばれた後に、フェンスのウエイトの設定処理があります。私の環境では複数回呼び出されていました。こちらも、GDI関数で処理され、処理の本体は、カーネルモードで実行されています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_SUBMITWAITFORSYNCOBJECTSTOHWQUEUE const * __ptr64),_D3DKMT_SUBMITWAITFORSYNCOBJECTSTOHWQUEUE * __ptr64&amp;gt;+0x1d   
[0x2]   D3D12Core!NDXGI::CDevice::SubmitWaitForSyncObjectsToHwQueueCB+0x4d   
[0x3]   nvwgf2umx!...
...
[0xa]   nvwgf2umx!... 
[0xb]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xc]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue:
mov     r10, rcx
mov     eax, 125Eh
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue+0x15 (7ff81e415e55)
syscall 
ret     
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-umdのコードで取得したcritical-sectionの解放&#34;&gt;7. UMDのコードで取得したCritical Sectionの解放&lt;/h4&gt;
&lt;p&gt;冒頭で、UMDが取得したCritical Sectionをリリースしています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlLeaveCriticalSection   
[0x1]   nvwgf2umx!...
[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-d3dcoreのmutexの解放&#34;&gt;8. D3DCoreのMutexの解放&lt;/h4&gt;
&lt;p&gt;冒頭で、D3DRuntimeが取得したMutexをリリースしています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlReleaseSRWLockExclusive   0xc9a75ffd18   0x7ff81e8a366b   
[0x1]   msvcp_win!Mtx_unlock+0x1b   0xc9a75ffd20   0x7fff94976bd8   
[0x2]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x168   0xc9a75ffd50   0x7ff6e60e183d   
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;windbgで確認できるutmの動作のまとめ&#34;&gt;Windbgで確認できるUTMの動作のまとめ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CommandQueueごとの排他制御と思われるMutex（D3DRuntime管理）を取得している。&lt;/li&gt;
&lt;li&gt;UMDのコード内でCritical Sectionを取得している。（これはGPUやドライバーによって異なる可能性がある）&lt;/li&gt;
&lt;li&gt;以下のGDI関数を呼び出している（いずれも処理の本体はカーネルモード）
&lt;ul&gt;
&lt;li&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/li&gt;
&lt;li&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/li&gt;
&lt;li&gt;NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;d3dkmtupdategpuvirtualaddressの仕様について&#34;&gt;D3DKMTUpdateGpuVirtualAddressの仕様について&lt;/h2&gt;
&lt;p&gt;参考：

&lt;a href=&#34;https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/d3dkmthk/nf-d3dkmthk-d3dkmtupdategpuvirtualaddress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/d3dkmthk/nf-d3dkmthk-d3dkmtupdategpuvirtualaddress&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上記のページのRemarksの最後の部分に、重要なことが記述されています。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ドライバーは多くのUpdateGpuVirtualAddress呼び出しを送信できますが、それはレンダリングフェンスの後ろにキューイングされます。
キューイングされた更新操作の数が128を超えると、呼び出し元のスレッドはビデオメモリマネージャーによって以前の操作が処理されるまでブロックされます。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;つまり、UTMはID3D12CommandQueueのメソッドなので、大量のUTM処理を発行したとしても、それはCommandQueueに蓄積されるだけではないかと我々は想像してしまいますが、実際は、最大で128リクエストしか蓄積することができず、これを超えると、前に発行したUTMが完了するまで処理がブロックされるということがこのドキュメントから分かります。&lt;/p&gt;
&lt;h2 id=&#34;utmのデッドロック条件&#34;&gt;UTMのデッドロック条件&lt;/h2&gt;
&lt;p&gt;UTMのデッドロックは、おそらく先ほど説明した、128以上のUTM処理の蓄積によっておこるUTM処理のブロッキングに起因するものと思われます。このブロッキングの解消には、前に発行したUTM処理がGPU上で完了する必要があります。&lt;br&gt;
UTMは、&lt;code&gt;ID3D12CommandQueue&lt;/code&gt;のメソッドなので、UTMの直前までに実行キューに積まれたすべての処理が完了し、UTM処理を開始するためのフェンスがシグナルされるまで処理は開始されません。もしも、UTMを実行キューに積む前にフェンスのウエイトが設定されて、それが解決しない状況に陥ればデッドロックになることが予想されます。&lt;br&gt;
しかし、一般的に、フェンスが解決しない状況はUTMの動作とは関係なくデッドロック状態に陥るので、UTM特有の問題とは言えません。では、何がUTM特有なのかというと、UTM処理のブロッキング、つまり前に発行したUTMの処理完了待ちをどこで行っているかというところです。
これは、UTMデッドロックに陥っているプロセスのメモリダンプを見るとわかるのですが、UTMのブロッキングは、&lt;code&gt;⁠win32u!NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt; 内の&lt;code&gt;syscall&lt;/code&gt;の箇所、つまりカーネル空間の処理の最中に行われます。&lt;br&gt;
先の章で、WinDbgでUTMの処理をトレースした際に確認しましたが、この箇所に到達するまでに、D3D12Coreにあるミューテックスを取得して、UMDの中でCiritical Sectionを取得しています。他にも、GDIレイヤーのカーネル空間でも排他処理が行われているかもしれません。もしも、これらの排他処理が、UTMより先に設定されたウエイトをシグナルするために必要な処理をブロックした場合はデッドロックが成立します。
そんなことが実際に起きるのか？と疑問に思うのは自然なことだと思います。しかし次の章で、UMTブロッキング時に競合する他のAPIのリストを見れば納得できると思います。&lt;/p&gt;
&lt;h2 id=&#34;utmの排他リソースと競合する処理&#34;&gt;UTMの排他リソースと競合する処理&lt;/h2&gt;
&lt;p&gt;では、UTMブロッキング時に競合する他の処理を見てみましょう。&lt;br&gt;
D3DCoreのミューテックスとUMDのCritical Sectionは、デバッガで追えば競合している状況を確認できます。しかし、複数のUTMデッドロックを起こしたプロセスのメモリダンプを確認すると、どうやらカーネル空間で処理が行われているGDI関数の方にも排他処理が存在するようです。&lt;br&gt;
ここでは、UTMのデッドロックが発生しているプロセスのメモリダンプでよく観測される箇所、つまり、UTMブロッキングで処理が停止する可能性の高い処理をリストアップしたいと思います。&lt;/p&gt;
&lt;h4 id=&#34;id3d12commandqueueexecutecommandlists&#34;&gt;ID3D12CommandQueue::ExecuteCommandLists&lt;/h4&gt;
&lt;p&gt;私の経験上、最もよく見かけます。
D3DCoreの中で、ミューテックスを取得しようとして失敗するため、&lt;code&gt;NtWaitForAlertByThreadId&lt;/code&gt; でスリープして待機状態に入っています。
このミューテックスがUTMが確保したものならば、おそらく同じコマンドキューに対するECLなので、ミューテックスの取得に失敗して待機するのは納得がいきます。しかし、この処理は、UTMの後にキューに積まれるべき処理のはずなので、UTMデッドロックの直接の原因にはならないでしょう。&lt;/p&gt;
&lt;h4 id=&#34;id3d12commandqueuesignal&#34;&gt;ID3D12CommandQueue::Signal&lt;/h4&gt;
&lt;p&gt;Signalは、D3DCoreから、直接Win32uの&lt;code&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt; を呼び出し、&lt;code&gt;syscall&lt;/code&gt;の中で止まっているのを観測します。
私の考えでは、UTMのキューに設定されたウエイトをシグナルするための、他のキューに設定されるべきシグナルが設定できないためにデッドロックが発生します。
したがって、シグナルを呼んでいるスレッドが&lt;code&gt;syscall&lt;/code&gt;の中で止まっているというのは、大変興味深いです。&lt;/p&gt;
&lt;h4 id=&#34;id3d12fenceseteventoncompletion&#34;&gt;ID3D12Fence::SetEventOnCompletion&lt;/h4&gt;
&lt;p&gt;この処理は、&lt;code&gt;D3D12Core!CFence::SetEventOnCompletion&lt;/code&gt;から、&lt;code&gt;D3D12Core!CDevice::SetEventOnMultipleFenceCompletion&lt;/code&gt;というメソッドを呼んでいるので、API上は、&lt;code&gt;ID3D12Fence&lt;/code&gt;ですが、実質上は、&lt;code&gt;ID3D12Device&lt;/code&gt;の処理だと考えたほうがよさそうです。
最終的には、&lt;code&gt;NtGdiDdDDIWaitForSynchronizationObjectFromCpu&lt;/code&gt; を呼び出し、&lt;code&gt;syscall&lt;/code&gt;の中で止まっているのを観測します。&lt;/p&gt;
&lt;h4 id=&#34;id3d12devicecreateplacedresource&#34;&gt;ID3D12Device::CreatePlacedResource&lt;/h4&gt;
&lt;p&gt;このメソッドは、私の環境では、UMDから、&lt;code&gt;D3D12Core!NDXGI::CDevice::UpdateGpuVirtualAddressCB&lt;/code&gt;を呼び出し、最終的には、&lt;code&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;を呼び出しています。
途中から、&lt;code&gt;ID3D12CommandQueue::UpdateTileMappings&lt;/code&gt;と同じコードパスを辿ります。UTMと同じカーネル呼び出しですので、競合するのは理解ができます。&lt;/p&gt;
&lt;h4 id=&#34;id3d12fencerelease&#34;&gt;ID3D12Fence::Release()&lt;/h4&gt;
&lt;p&gt;観測した中で、最も意外だったのが、フェンスオブジェクトの解放処理である、&lt;code&gt;Release()&lt;/code&gt;です。この処理は最終的に、&lt;code&gt;NtGdiDdDDIDestroySynchronizationObject&lt;/code&gt;を呼び出しているのですが、この関数の&lt;code&gt;syscall&lt;/code&gt;で止まっているのが複数回観測できました。&lt;/p&gt;
&lt;h2 id=&#34;utmデッドロックの回避方法&#34;&gt;UTMデッドロックの回避方法&lt;/h2&gt;
&lt;p&gt;まとめです。D3D12のAPIのユーザーとして、どのようなことに気を付ければ、UTMデッドロックを回避できるのでしょうか。&lt;/p&gt;
&lt;h3 id=&#34;プログラム側でutmの発行回数を制限する&#34;&gt;プログラム側で、UTMの発行回数を制限する&lt;/h3&gt;
&lt;p&gt;いろいろと考えられますが、最も効果的な方法を一つだけ提案します。それは、UTMの発行数をアプリ側で監視して制御する方法です。&lt;br&gt;
具体的な方法は、UTM専用のスレッド、UTM専用のCopyQueue、UTM専用のフェンスを用意して、UTMの呼び出しごとに、シグナルを設定して、フェンス値をインクリメントします。そして、UTMを呼び出す前に、&lt;code&gt;GetCompletedValue()&lt;/code&gt;でGPU側での完了状況をチェックして、128個以上キューに積まれそうな状況では、&lt;code&gt;SetEventOnCompletion()&lt;/code&gt;を使って、先に発行されたUTMの完了を待ちます。こうして、128個以上UTMがコマンドキューに積みあがらないようににプログラム側で調整します。GraphicsQueueや、ComputeQueueとの同期が必要な場合は、随時UTM専用のCopyQueueとフェンスを設定して同期します。&lt;/p&gt;
&lt;h4 id=&#34;なぜ専用のスレッドを用意するのか&#34;&gt;なぜ専用のスレッドを用意するのか&lt;/h4&gt;
&lt;p&gt;まず、&lt;code&gt;SetEventOnCompletion()&lt;/code&gt;で、スレッドを待機させなければならない状況も考えられるので、専用のスレッドを用意するのは自然な考えです。
加えて、UTMの呼び出しは、もともとCPU側のフェンス処理を伴います。GPU Viewで観測したとおり多数のDPCコールが発生することが予想されます。これらは、UTMのスレッドからCPU時間を奪い取り、L1キャッシュの状態を乱す可能性があります。ならば、UTMの呼び出し元はUTMの処理に特化し、単純な処理をするスレッドにしておくべきです。&lt;/p&gt;
&lt;h4 id=&#34;なぜ専用のcopyqueueを用意するのか&#34;&gt;なぜ専用のCopyQueueを用意するのか&lt;/h4&gt;
&lt;p&gt;専用のCopyQueueを使う第一の理由は、UTMの個数を正確に数えるためです。UTMブロッキングの128という条件は、コマンドキューごとの数で、プロセス内で発行された総数ではありません。極端な話をすれば、コマンドキューを二つ用意して、UTMを分散すると、256個までUTMを発行できます。
専用のキューを用意してフェンスで他のキューと同期をとるのは、一見するとオーバーヘッドの高い処理に感じるかもしれません。しかし、UTMの処理は、もともとOSのメモリマネージャーによる処理を伴い、フェンスでUTMの発行されたキューと同期をとっています。つまり、もともとオーバーヘッドの高い処理なのです。&lt;br&gt;
他のGraphicsQueueやComputeQueueとフェンスで同期すれば、結局それらのキューはUTMのキューを待つことになり、全体の実行スピードは変わらないかもしれません。しかし、GraphicsQueueやComputeQueueがUTMのキューを長時間待つのを観測できれば、UTMと同期するフェンスの位置を調整したり、他の依存関係のない処理を挿入したりして最適化を行うことができます。ちなみに、UTMの処理は、GPU上ではHWCopyQueue上で非常に短時間に処理されます。つまり、UTM処理中は、GPUの演算ユニットはアイドリングしているのです。上手くスケジューリングすることができればUTMのGPUコストを隠蔽することができます。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;結局、UTMに起因するデッドロックの発生の仕組みは予測の域を出ません。また、ほかにもUTMデッドロックを回避する手法はありますが、UTMブロッキングが発生すると、様々なD3DAPIがブロックされることが分かっており、マルチスレッドで動作するプログラムにおいて、これは多数のレンダリングに関連するスレッドが同時にストールする可能性を意味します。つまり、UTMブロッキングが発生している時点で、すでにプログラムとしては大きな性能の問題に直面しているのです。だとするならば、UTMデッドロックを避けるだけでなく、UTMブロッキング自体を起こさないようにアプリケーションで制御するしかないのが現状です。&lt;br&gt;
APIやドライバモデルの設計から一度やり直した方がよいのではないかという気がしてきます。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;以下英語版&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a id=&#34;Eng&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;deadlocks-caused-by-id3d12commandqueueupdatetilemappings&#34;&gt;Deadlocks Caused by ID3D12CommandQueue::UpdateTileMappings&lt;/h1&gt;
&lt;p&gt;One of the reasons for hang-ups happening infrequently in D3D12 games is a deadlock caused by &lt;code&gt;UpdateTileMappings&lt;/code&gt;. Its precise mechanism is still unknown, but recently I&amp;rsquo;ve been able to compile my observations on this issue to be able to explain to others, so I&amp;rsquo;d like to leave this note as a memo.&lt;br&gt;
However, what I will describe below is merely a guess that it could probably be happening in the system. The exact details can only be confirmed by asking the people who design the SDK and the OS. Additionally, the survey has been done with the current latest OS, Windows 11 24H2 (OS Build 26100.2894), and the issue I&amp;rsquo;m going to descrbie would be fixed in the future.&lt;/p&gt;
&lt;h2 id=&#34;observing-the-behavior-of-id3d12commandqueueupdatetilemappings-with-gpuview&#34;&gt;Observing the behavior of ID3D12CommandQueue::UpdateTileMappings with GPUView&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s use GPUView to check the behavior of &lt;code&gt;UpdateTileMappings&lt;/code&gt;. In the GPUView&amp;rsquo;s event list, select &lt;code&gt;DxgKrnl UpdateGPUVirtualAddress&lt;/code&gt; to identify the call sites. The following screenshot shows a section where, after rendering process for a frame has been enqueued in the process&amp;rsquo;s GPU execution queue, &lt;code&gt;UpdateTileMappings&lt;/code&gt; (from here, we call this UTM) is called several times. During the UTM calls, we can find that the application&amp;rsquo;s thread switches to kernel mode. Also we can see that two fences are set for each UTM call.&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---1&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image1_hub9ccdd4ec5701d8ba5db3e6a9b8229e2_36733_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 1&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image1_hub9ccdd4ec5701d8ba5db3e6a9b8229e2_36733_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;978&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 1
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Next, let&amp;rsquo;s observe the timing when these fences are started to be processed in the process&amp;rsquo;s GPU execution queue. First, you can see that the stacked fence objects are identical. It appears that a single fence object is used with incrimenting its fence value. When the UTM&amp;rsquo;s fence reaches the front of the process&amp;rsquo;s GPU execution queue, a DPC (Deferred Procedure Call) is invoked on the application&amp;rsquo;s thread (which can be interpreted as an OS interrupt). This DPC sends a Paging Queue Packet to the process&amp;rsquo;s paging queue. In the following screenshot, the fence object sent out by the UTMs is highlighted. Just before the head of the series of fences from the UTM reaches the front of the execution queue, a DPC is initiated on the thread indicated by the white bar of the application&amp;rsquo;s thread, then, a Paging Queue Packet seems to be sent out while the DPC is working. I have illustrated this with red arrows.&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---2&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image2_hu3213b80c4faf65051a2dffba27d98fa5_481072_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 2&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image2_hu3213b80c4faf65051a2dffba27d98fa5_481072_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;1000&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 2
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The dispatched Paging Queue Packet is processed by the OS&amp;rsquo;s VidMm Worker Thread. The OS thread that receives the packet sends a Paging Command Packet to the System Paging Context. This packet is then sent to the Hardware Copy Queue on the GPU, where it is actually processed.&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---3&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image3_hu92bebf72723ca2a2ad84b4939408949e_84146_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 3&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image3_hu92bebf72723ca2a2ad84b4939408949e_84146_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;896&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 3
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;In the System Paging Context, three fences are set immediately after the Paging Command Packet. It seems these are used to detect the completion of the UTM processing on the GPU side on the CPU side. One of these fences appears to trigger a DPC on the thread of the process that originally sent out the UTM. The DPC then increments the fence value of the UTM. As a result, the fence that was waiting for the UTM to complete in the process&amp;rsquo;s GPU execution queue is resolved. This means that one UTM processing is completed.&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpu-view---4&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/d3d12utm/image4_huce2858e525986fbbb1701b9fc14dc36c_412330_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;GPU View - 4&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/d3d12utm/image4_huce2858e525986fbbb1701b9fc14dc36c_412330_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;90%&#34; height=&#34;1017&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPU View - 4
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;tracking-utm-processing-with-windbg&#34;&gt;Tracking UTM Processing with Windbg&lt;/h2&gt;
&lt;p&gt;Next, let&amp;rsquo;s use a debugger to track the UTM processing. I traced a UTM call of a sample application using only Microsoft&amp;rsquo;s symbol server. The process consists of the D3D runtime, user-mode driver, and Windows API. I would like to list out some major processing steps in order.&lt;/p&gt;
&lt;h4 id=&#34;1-acquiring-the-mutex-managed-by-d3d12core&#34;&gt;1. Acquiring the Mutex Managed by D3D12Core&lt;/h4&gt;
&lt;p&gt;At the beginning of the UTM call, a mutex managed by D3D12Core is acquired. It is likely that this is for mutual exclusion control for calls to the same &lt;code&gt;CGraphicsCommandQueue&lt;/code&gt;. As &lt;code&gt;CGraphicsCommandQueue&lt;/code&gt; interface is designed to be thread-safe, it appears that the D3D runtime manages mutual exclusion control as needed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlAcquireSRWLockExclusive     
[0x1]   msvcp_win!Mtx_lock+0x31    
[0x2]   D3D12Core!std::_Mutex_base::lock+0x10    
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0xe2    
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-calling-the-function-registered-in-the-device-driver-interface&#34;&gt;2. Calling the Function Registered in the Device Driver Interface&lt;/h4&gt;
&lt;p&gt;The Device Driver Interface (DDI) is an interface for functions used by the OS and runtime to call device drivers. The call destination will be the code of the installed driver. Judging by the arguments of the call of the DDI, it&amp;rsquo;s clear that this is &lt;code&gt;PFND3D12DDI_UPDATETILEMAPPINGS&lt;/code&gt; defined in &lt;code&gt;d3d12umddi.h&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e      
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;FYI, the definition of &lt;code&gt;PFND3D12DDI_UPDATETILEMAPPINGS&lt;/code&gt; in &lt;code&gt;d3d12umddi.h&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;typedef VOID ( APIENTRY* PFND3D12DDI_UPDATETILEMAPPINGS )( D3D12DDI_HCOMMANDQUEUE, D3D12DDI_HRESOURCE,
    UINT NumTiledResourceRegions,
    _In_reads_(NumTiledResourceRegions) const D3D12DDI_TILED_RESOURCE_COORDINATE* pResourceRegionStartCoords,
    _In_reads_opt_(NumTiledResourceRegions) const D3D12DDI_TILE_REGION_SIZE* pResourceRegionSizes,
    D3D12DDI_HHEAP, UINT NumRanges,
    _In_reads_opt_(NumRanges) const D3D12DDI_TILE_RANGE_FLAGS*,
    _In_reads_opt_(NumRanges) const UINT* pHeapStartOffsets,
    _In_reads_opt_(NumRanges) const UINT* pRangeTileCounts,
    D3D12DDI_TILE_MAPPING_FLAGS );
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-acquiring-a-critical-section-in-the-umd-code&#34;&gt;3. Acquiring a Critical Section in the UMD Code&lt;/h4&gt;
&lt;p&gt;A Critical Section is a synchronization object provided by Windows OS that can be used within a process. Looking at the call stack, it shows &lt;code&gt;nvwgf2umx!OpenAdapter&lt;/code&gt; for the UMD code, but this simply indicates the offset address from an exported symbol in the UMD&amp;rsquo;s DLL, not that &lt;code&gt;OpenAdapter&lt;/code&gt; is actually being called by the DDI call. Since we don&amp;rsquo;t have the PDB file for NVIDIA&amp;rsquo;s UMD DLL, the symbol cannot be resolved properly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlEnterCriticalSection   
[0x1]   nvwgf2umx!OpenAdapter12+0x7e5f   
[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-setting-a-fence-signal&#34;&gt;4. Setting a Fence Signal&lt;/h4&gt;
&lt;p&gt;Next, it calls &lt;code&gt;SubmitSignalSyncObjectsToHwQueueCB&lt;/code&gt; of D3DCore. This callback is likely registered by the OS in the D3D runtime. The registered callback function appears to be &lt;code&gt;win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt;. By checking the assembly code of this function, I found it almost immediately called a &lt;code&gt;syscall&lt;/code&gt; to enter kernel mode. The call path up to this point is somewhat complex: Application → D3D Runtime → UMD → D3D Runtime → GDI.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_SUBMITSIGNALSYNCOBJECTSTOHWQUEUE const * __ptr64),_D3DKMT_SUBMITSIGNALSYNCOBJECTSTOHWQUEUE * __ptr64&amp;gt;+0x1d   
[0x2]   D3D12Core!NDXGI::CDevice::SubmitSignalSyncObjectsToHwQueueCB+0xdd   
[0x3]   nvwgf2umx!....
....
[0xa]   nvwgf2umx!....
[0xb]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xc]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;FYI the code snippet of &lt;code&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue:
mov     r10, rcx
mov     eax, 125Dh
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDISubmitSignalSyncObjectsToHwQueue+0x15
syscall 
ret   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-calling-d3dkmt_updategpuvirtualaddress&#34;&gt;5. Calling D3DKMT_UPDATEGPUVIRTUALADDRESS&lt;/h4&gt;
&lt;p&gt;Finally, we have reached the core processing part of UTM. The call path is similar to that of the signaling the fence mentioned earlier. This is also a GDI function, and it immediately executes a &lt;code&gt;syscall&lt;/code&gt; within the function. The actual processing seems to be in kernel mode.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDIUpdateGpuVirtualAddress+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_UPDATEGPUVIRTUALADDRESS const * __ptr64),_D3DKMT_UPDATEGPUVIRTUALADDRESS * __ptr64&amp;gt;+0x11   
[0x2]   D3D12Core!NDXGI::CDevice::UpdateGpuVirtualAddressCB+0x64   
[0x3]   nvwgf2umx!....
....
[0x8]   nvwgf2umx!....
[0x9]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xa]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;FYI, the code snippet of &lt;code&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDIUpdateGpuVirtualAddress:
mov     r10, rcx
mov     eax, 1264h
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDIUpdateGpuVirtualAddress+0x15 (7ff81e415f15)
syscall 
ret     
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-setting-fence-waits&#34;&gt;6. Setting Fence Waits&lt;/h4&gt;
&lt;p&gt;After &lt;code&gt;D3DKMT_UPDATEGPUVIRTUALADDRESS&lt;/code&gt; is called, it sets some fence waits from the UMD code in my environment. This processing is also handled by a GDI function executed in kernel mode.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue+0x12   
[0x1]   D3D12Core!CallAndLogImpl&amp;lt;long (__cdecl*)(_D3DKMT_SUBMITWAITFORSYNCOBJECTSTOHWQUEUE const * __ptr64),_D3DKMT_SUBMITWAITFORSYNCOBJECTSTOHWQUEUE * __ptr64&amp;gt;+0x1d   
[0x2]   D3D12Core!NDXGI::CDevice::SubmitWaitForSyncObjectsToHwQueueCB+0x4d   
[0x3]   nvwgf2umx!...
...
[0xa]   nvwgf2umx!... 
[0xb]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0xc]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue:
mov     r10, rcx
mov     eax, 125Eh
test    byte ptr [7FFE0308h], 1
jne     win32u!NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue+0x15 (7ff81e415e55)
syscall 
ret     
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-releasing-the-critical-section-acquired-in-the-umd-code&#34;&gt;7. Releasing the Critical Section Acquired in the UMD Code&lt;/h4&gt;
&lt;p&gt;The UMD acquired a critical section at the beginning, which is now being released.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlLeaveCriticalSection   
[0x1]   nvwgf2umx!...
[0x2]   D3D12Core!TableFunctionTraits&amp;lt;2&amp;gt;::Detail::InvokerImpl&amp;lt;TableFunctionTraitsImpl&amp;lt;2&amp;gt;::FunctionTraits&amp;lt;70,0,void&amp;gt;,void,void,D3D12DDI_HCOMMANDQUEUE,D3D10DDI_HRESOURCE,unsigned int,D3D12DDI_TILED_RESOURCE_COORDINATE const * __ptr64,D3D12DDI_TILE_REGION_SIZE const * __ptr64,D3D12DDI_HHEAP,unsigned int,enum D3D12DDI_TILE_RANGE_FLAGS const * __ptr64,unsigned int const * __ptr64,unsigned int const * __ptr64,enum D3D12DDI_TILE_MAPPING_FLAGS&amp;gt;::Call&amp;lt;CGraphicsCommandQueue&amp;gt;+0x9f   
[0x3]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x15e   
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-releasing-the-mutex-managed-by-d3dcore&#34;&gt;8. Releasing the Mutex managed by D3DCore&lt;/h4&gt;
&lt;p&gt;At the end, D3D runtime releases the mutex that was acquired at the beginning of the UMD.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[0x0]   ntdll!RtlReleaseSRWLockExclusive   0xc9a75ffd18   0x7ff81e8a366b   
[0x1]   msvcp_win!Mtx_unlock+0x1b   0xc9a75ffd20   0x7fff94976bd8   
[0x2]   D3D12Core!CGraphicsCommandQueue::UpdateTileMappings+0x168   0xc9a75ffd50   0x7ff6e60e183d   
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;summary-of-the-utm-behavior&#34;&gt;Summary of the UTM Behavior&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Acquiring a mutex (managed by the D3D runtime) likely for mutual exclusion control per CommandQueue object.&lt;/li&gt;
&lt;li&gt;Acquiring a critical section within UMD code.  (This may vary depending on the GPU or driver used.)&lt;/li&gt;
&lt;li&gt;Calling the following GDI functions. (Most of the processing for these functions are in kernel mode.)
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NtGdiDdDDISubmitWaitForSyncObjectsToHwQueue&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;specifications-of-d3dkmtupdategpuvirtualaddress&#34;&gt;Specifications of D3DKMTUpdateGpuVirtualAddress&lt;/h2&gt;
&lt;p&gt;FYI：

&lt;a href=&#34;https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/d3dkmthk/nf-d3dkmthk-d3dkmtupdategpuvirtualaddress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/d3dkmthk/nf-d3dkmthk-d3dkmtupdategpuvirtualaddress&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The last part of the remarks section on the page above says important information.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Drivers can submit many UpdateGpuVirtualAddress calls, which will be queued behind the rendering fence. When the number of queued update operations exceeds 128, the calling thread will be blocked until the previous operations are processed by the video memory manager.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is to say, since UTM is a method of ID3D12CommandQueue, we might imagine that even issuing a large number of UTM processes would only result in them being accumulated in the CommandQueue. However, in reality, only up to 128 requests can be accumulated, and once a UTM call touches this limit, the processing is blocked until the UTMs issued earlier are completed.&lt;/p&gt;
&lt;h2 id=&#34;deadlock-conditions-of-utm&#34;&gt;Deadlock Conditions of UTM&lt;/h2&gt;
&lt;p&gt;The deadlock of UTM is likely caused by the blocking of UTM processing due to the accumulation of more than 128 UTM processes, as described earlier. This blocking can only be resolved when the previously issued UTM processes are completed on the GPU. Because UTM is a method of &lt;code&gt;ID3D12CommandQueue&lt;/code&gt;, the UTM processing will not start until all processes enqueued before the UTM are completed and the fence to start the UTM processing is signaled. If a wait of a fence is set before enqueuing the UTM and it is not resolved, a deadlock is expected to occur.&lt;/p&gt;
&lt;p&gt;However, generally, a situation where the wait of a fence is not resolved can lead to a deadlock regardless of the UTM operations, so it cannot be said to be a UTM-specific problem. So, what is unique to UTM is where the blocking to wait for the completion of the previously issued UTM processing is performed.
By examining some memory dumps of processes in UTM deadlock situations, we can see that the blocking occurs during the processing within the &lt;code&gt;syscall&lt;/code&gt; in &lt;code&gt;win32u!NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;, which means it is blocking in kernel space.&lt;/p&gt;
&lt;p&gt;In the previous chapter, when we traced UTM processing with WinDbg, we confirmed that before reaching this point, the mutex in D3D12Core and the Critical Section in UMD are secured. Additional exclusive processing might also be performed in the kernel space of the GDI layer. If these exclusive processes blocks to signal a wait fence set on the queue before calling the UTM, a deadlock will occur.&lt;br&gt;
It&amp;rsquo;s natural to wonder if such a thing could actually happen. However, in the next chapter, I believe you will be convinced when you see the list of other APIs that are blcoked during UMT blocking.&lt;/p&gt;
&lt;h2 id=&#34;apis-that-conflict-with-utm&#34;&gt;APIs that conflict with UTM&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at other API calls that stops during UTM blocking. The mutex in D3DCore and the critical section in UMD can be observed to conflict with a debugger. However, examining dumps of processes that stopped with UTM deadlocks reveals that exclusive processing also seems to exist in the GDI functions performed in kernel space.
Here, I want to list the functions frequently observed in the dumps of processes where UTM deadlocks occurred, meaning the functions that likely be blocked due to UTM blocking.&lt;/p&gt;
&lt;h4 id=&#34;id3d12commandqueueexecutecommandlists-1&#34;&gt;ID3D12CommandQueue::ExecuteCommandLists&lt;/h4&gt;
&lt;p&gt;In my experience, this is most frequently observed. Within D3DCore, the attempt to acquire a mutex fails, causing the thread to sleep and wait in &lt;code&gt;NtWaitForAlertByThreadId&lt;/code&gt;. If this mutex is secured by UTM, it is likely bound to the same CommandQueue, so it makes sense that the API call is blocked to acquire the mutex and enter a wait state. So, this ECL should be queued after the UTM, and it shouldn&amp;rsquo;t be the direct cause of a deadlock caused by UTM.&lt;/p&gt;
&lt;h4 id=&#34;id3d12commandqueuesignal-1&#34;&gt;ID3D12CommandQueue::Signal&lt;/h4&gt;
&lt;p&gt;This is observed to call &lt;code&gt;NtGdiDdDDISubmitSignalSyncObjectsToHwQueue&lt;/code&gt; from D3DCore directly to Win32u and stopped within the &lt;code&gt;syscall&lt;/code&gt;. A deadlock should occur if a signal fence set on another queue to signal the wait fence set on the UTM queue cannot be set.&lt;br&gt;
It is really interesting that the thread calling the signal is halted within the &lt;code&gt;syscall&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;id3d12fenceseteventoncompletion-1&#34;&gt;ID3D12Fence::SetEventOnCompletion&lt;/h4&gt;
&lt;p&gt;This API calls the method &lt;code&gt;D3D12Core!CFence::SetEventOnCompletion&lt;/code&gt; from &lt;code&gt;D3D12Core!CDevice::SetEventOnMultipleFenceCompletion&lt;/code&gt;. Therefore, although the API is classified as &lt;code&gt;ID3D12Fence&lt;/code&gt;, it seems more appropriate to consider it as a process of &lt;code&gt;ID3D12Device&lt;/code&gt;. Ultimately, it calls &lt;code&gt;NtGdiDdDDIWaitForSynchronizationObjectFromCpu&lt;/code&gt; and stooped in the &lt;code&gt;syscall&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;id3d12devicecreateplacedresource-1&#34;&gt;ID3D12Device::CreatePlacedResource&lt;/h4&gt;
&lt;p&gt;In my environment, this method calls &lt;code&gt;D3D12Core!NDXGI::CDevice::UpdateGpuVirtualAddressCB&lt;/code&gt; from UMD, and ultimately calls &lt;code&gt;NtGdiDdDDIUpdateGpuVirtualAddress&lt;/code&gt;. It follows the same code path as &lt;code&gt;ID3D12CommandQueue::UpdateTileMappings&lt;/code&gt;. Since it involves the same kernel call as UTM, it is understandable that it conflicts.&lt;/p&gt;
&lt;h4 id=&#34;id3d12fencerelease-1&#34;&gt;ID3D12Fence::Release()&lt;/h4&gt;
&lt;p&gt;The most surprising observation was the release of a fence object. This process ultimately calls &lt;code&gt;NtGdiDdDDIDestroySynchronizationObject&lt;/code&gt;. I&amp;rsquo;ve seen the API stopped in the &lt;code&gt;syscall&lt;/code&gt; of it multiple times.&lt;/p&gt;
&lt;h2 id=&#34;how-should-we-avoid-utm-deadlocks&#34;&gt;How Should We Avoid UTM deadlocks?&lt;/h2&gt;
&lt;h4 id=&#34;limit-and-manage-number-of-in-flight-utms&#34;&gt;Limit and Manage number of in-flight UTMs.&lt;/h4&gt;
&lt;p&gt;There may be some ways to avoid UTM deadlock, but I propose one of the most effective methods. That is to monitor and control the number of UTM issues on the application side. The method involves preparing a dedicated CPU thread, a dedicated copy queue, and a dedicated fence for processing UTMs. After calling a UTM, set a signal and increment its fence value. Before calling UTM, check the completion status on the GPU side with &lt;code&gt;GetCompletedValue()&lt;/code&gt;, and if it appears that more than 128 requests are likely to be queued, use &lt;code&gt;SetEventOnCompletion()&lt;/code&gt; to wait for the completion of previously issued UTMs. This way, you can prevent more than 128 UTMs from piling up on the command queue. If synchronization with a GraphicsQueue or ComputeQueue is necessary, set a fence between them as needed for synchronization.&lt;/p&gt;
&lt;h4 id=&#34;why-prepare-a-dedicated-thread&#34;&gt;Why Prepare a Dedicated Thread&lt;/h4&gt;
&lt;p&gt;First of all, it is natural to prepare a dedicated thread, considering the situation where the thread may need to wait with &lt;code&gt;SetEventOnCompletion()&lt;/code&gt;. In addition, the UTM call inherently involves CPU-side fence processing. It is expected that many DPC calls will occur as observed in GPU View. These processings may potentially steal CPU time and disturb L1 cache state from the caller thread. Therefore, the UTM calls should be in a thread specialized for UTM processing.&lt;/p&gt;
&lt;h4 id=&#34;why-prepare-a-dedicated-copy-queue&#34;&gt;Why Prepare a Dedicated Copy Queue&lt;/h4&gt;
&lt;p&gt;The primary reason for using a dedicated copy queue is to accurately count the number of UTMs. The condition of UTM blocking with 128 is based on the number per command queue, not the total number issued within the process. As an extreme example, if you prepare two command queues and evenly distribute UTM requests, you can issue up to 256 UTMs.&lt;br&gt;
Preparing a dedicated queue and synchronizing with other queues using a fence might initially seem like a high-overhead process. However, UTM processing inherently involves operations by the OS memory manager and synchronizes with the queue issued by the UTM using a fence. In other words, it is inherently a high-overhead process.&lt;br&gt;
If you synchronize with other graphics queues or compute queues using a fence, those queues will ultimately wait for the UTM queue. The overall throughput may not change. However, if you find that the graphics queue or compute queue is waiting for the UTM queue for a long time, you may want to adjust the timings of the fence synchronizing with the UTM queue, or, insert other non-dependent processes for optimization.&lt;br&gt;
FYI, UTM processing is handled in a very short time on the hardware copy queue on the GPU. This means that during UTM processing, the GPU&amp;rsquo;s compute units are idling. Proper scheduling has a possibility to hide the GPU cost of UTM.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In the end, the mechanism behind deadlocks caused by UTM remains speculative. There are other methods to avoid UTM deadlocks, but when UTM blocking occurs, we found that various D3D APIs are blocked. In a multi-threaded program, this means that many threads related to rendering could stall simultaneously. In other words, once UTM blocking occurs, the program is already facing significant performance issues. Therefore, it is not only necessary to avoid UTM deadlocks but also to control the application to prevent UTM blocking itself.
I hope it will be solved in the OS in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Work Graph in HLSL</title>
      <link>https://shikihuiku.github.io/post/workgraph_in_hlsl/</link>
      <pubDate>Mon, 19 Aug 2024 19:00:41 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/workgraph_in_hlsl/</guid>
      <description>&lt;p&gt;基本的な機能に関する説明は割愛。自分が Work Graph を書くときに、度忘れしたときに参照するもののつもりで書いた。描画系はあとで書き足すかも。&lt;/p&gt;
&lt;h2 id=&#34;hlsl関数のattribute&#34;&gt;HLSL関数のAttribute&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[Shader(&amp;quot;node&amp;quot;)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;この属性をつけたHLSL関数は Work Graph のノードとして宣言。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeIsProgramEntry]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Work Graph のエントリポイントとなれる。つまり、Input RecordをCommand Listや外部のGPUメモリから受け取ることができる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeLaunch(&amp;quot;mode&amp;quot;)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;“broadcasting”&lt;/code&gt;&lt;br&gt;
一つの Input Record を、複数の Dispatch Grid で共有して処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“coalescing”&lt;/code&gt;&lt;br&gt;
複数の Input Redcord を、一つの Dispatch Grid で処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“thread”&lt;/code&gt;&lt;br&gt;
一つの Input Record を、一つのスレッドで処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“mesh”&lt;/code&gt;&lt;br&gt;
&lt;code&gt;“broadcasting”&lt;/code&gt;ノードと同様の起動方式だが、Work Graph の末端でしか使用できない。&lt;br&gt;
Mesh shaderとして動作する。（Amplification Shader は Work Graph ではサポートされていない）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NumThreads(x,y,z)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group のサイズ。通常の Compute Shader と同じ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeDispatchGrid(x,y,z)]&lt;/code&gt; or &lt;code&gt;[NodeMaxDispatchGrid(x,y,z)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NodeLaunch&lt;/code&gt;が&lt;code&gt;“broadcasting”&lt;/code&gt;の場合は、上記のいずれかが宣言されている必要がある。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeMaxDispatchGrid&lt;/code&gt;が宣言されている場合は、Input Record 内の&lt;code&gt;SV_DispatchGrid&lt;/code&gt;セマンティクスの変数で Dispatch Grid のサイズが指定される必要がある。&lt;br&gt;
この場合は、Disapatch Grid サイズが Input Record ごとに変更できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;,arrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;ノードとしての識別名の定義。これを省略すると、関数名がノードの識別名になる。&lt;/li&gt;
&lt;li&gt;複数のHLSL関数で、Work Graph のノード配列を定義する場合は、同一の&lt;code&gt;”nodeName”&lt;/code&gt;で、異なる&lt;code&gt;arrayIndex&lt;/code&gt;を指定する。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;arrayIndex&lt;/code&gt; は省略可能で、省略した場合は０番を宣言したとみなされる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrayIndex&lt;/code&gt; は、必ずしも連続して、隙間なく宣言されている必要はない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ノード配列として定義されるノード要素に相当するHLSL関数は、以下の項目が同一でなければならない。
&lt;ul&gt;
&lt;li&gt;Input Record の宣言&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeLaunch&lt;/code&gt;属性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeDispatchGrid&lt;/code&gt;属性、もしくは&lt;code&gt;NodeMaxDispatchGrid&lt;/code&gt;属性で定義された Dispatch Grid のサイズ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeLocalRootArgumentsTableIndex(index)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;このノードが実行されるとき、&lt;code&gt;index&lt;/code&gt;で指定した Local Root Table がバインドされる。&lt;/li&gt;
&lt;li&gt;この属性を定義しない場合や、&lt;code&gt;index&lt;/code&gt;に-1を設定した場合は、Work Graph がコンパイルされる時に自動で割り振られたインデックスがアサインされる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeShareInputOf(&amp;quot;nodeIDWhoseInputToShare&amp;quot;, optionalArrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;同一の Input Record で、異なる種類のノードを起動する場合は、同時に起動するノードには、この属性で、Input Record を共有するノードが示されている必要がある。&lt;/li&gt;
&lt;li&gt;異なる種類のノードが Input Record を共有する場合は、一つの代表する&lt;code&gt;NodeID&lt;/code&gt;を他のすべてのノードが指すように宣言する。&lt;/li&gt;
&lt;li&gt;最高で256種類のノードが同一の Input Record で起動できる。&lt;/li&gt;
&lt;li&gt;RW Input Record（書き込み可能な Input Record）は、異なる種類のノードで共有することはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeMaxRecursionDepth(count)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;このノードの最大再帰呼び出し回数を宣言する。&lt;/li&gt;
&lt;li&gt;参考：現在のWork Graphでは複数ノードを介した再帰呼び出しグラフはサポートされていない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeMaxInputRecordsPerGraphEntryRecord(count, sharedAcrossNodeArray)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;この&lt;code&gt;”mesh&amp;quot;&lt;/code&gt;ノードが一度に受け取ることのできる Input Record の最大数を宣言する。&lt;/li&gt;
&lt;li&gt;この最大数は、&lt;code&gt;DispatchGrid()&lt;/code&gt;呼び出し時の、一つの Input Record によって動作する全ての Work Graph ノードが出力する、このノードに対する Input Record の総数という意味。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sharedAcrossNodeArray&lt;/code&gt;が&lt;code&gt;true&lt;/code&gt;の場合は、Input Record を受け取るノード配列全体で、この最大数を共有する。&lt;/li&gt;
&lt;li&gt;参考：GPUのアーキテクチャによっては、コンピュートシェーダーを実行するときと、描画用のシェーダーを実行するときに、実行コンテキストのスイッチが必要なものがある。&lt;br&gt;
頻繁な実行コンテキストスイッチを避けるため、&lt;code&gt;”mesh”&lt;/code&gt;ノードへの Input Record は可能な限り蓄積される必要があるが、その上限を定義することで、Backing Memory のサイズと実行性能を適切にバランスすることができるようになると思われる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;input-record&#34;&gt;Input Record&lt;/h2&gt;
&lt;p&gt;Input Recordは、自身の&lt;code&gt;NodeLaunch&lt;/code&gt;属性で受け取れる型が決まる。&lt;/p&gt;
&lt;h4 id=&#34;broadcasting-launch&#34;&gt;Broadcasting Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み出し専用の Input Record。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書きが可能な Input Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;前者と基本的に同じだが、&lt;code&gt;Barrier()&lt;/code&gt;と&lt;code&gt;FinishedCrossGroupSharing()&lt;/code&gt;メソッドを適切に使うことで、&lt;br&gt;
Input Record のメモリ領域を、同時に起動した Dispatch Grid の他の Thread Group とのコミュニケーションにつかうことができる。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;FinishedCrossGroupSharing()&lt;/code&gt;メソッドを使うときは、Input Recordの構造体に、&lt;code&gt;[NodeTrackRWInputSharing]&lt;/code&gt;属性をつけなくてはいけない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;coalescing-launch&#34;&gt;Coalescing Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] GroupNodeInputRecords&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;1 ～ &lt;code&gt;maxCount&lt;/code&gt;数の、読み出し専用の Input Record。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] RWGroupNodeInputRecords&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書き可能なInput Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;li&gt;参考：この Input Record にアクセスできるのは、Coalescing Launch の特性上、一つの Thread Group なので、あまり使い道がないかもしれない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] EmptyNodeInput&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;データの受け渡しはない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;thread-launch&#34;&gt;Thread Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ThreadNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み出し専用の Input Record。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWThreadNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書きが可能な Input Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;li&gt;ただし、Thread Launch なので、他のスレッドとのデータのやり取りなどには使えない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;node-outputとoutput-record&#34;&gt;Node OutputとOutput Record&lt;/h2&gt;
&lt;p&gt;Input Record は、ノード関数の引数で直接受け取る形になっているが、Output Record は、NodeOutput 型が Output Record を抽象化して保持している形になっているので注意。
Input Record とは異なり、呼び出し先のノードの &lt;code&gt;NodeLaunch&lt;/code&gt;属性にかかわらず、同じ型を使用する。&lt;/p&gt;
&lt;h4 id=&#34;node-output&#34;&gt;Node Output&lt;/h4&gt;
&lt;p&gt;配列型かどうかと、Empty型かどうかを選択する形で、計４種類がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attribute-list NodeOutput&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;単一の Node Output を出力する場合。&lt;/li&gt;
&lt;li&gt;注意：Output Record 自体が、基本的には可変長の配列のようなものなので、Output Record が一つしか出力できないという意味ではない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list NodeOutputArray&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;配列型の Node Output を出力する場合。&lt;/li&gt;
&lt;li&gt;この出力を受け取るノードは、配列で宣言されていることが期待される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operator []&lt;/code&gt; で、上記の&lt;code&gt;NodeOutput&lt;/code&gt;型が取得できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list EmptyNodeOutput&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を出力しない場合の Node Output。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list EmptyNodeOutputArray&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;配列型の&lt;code&gt;EmptyNodeOutput&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operator []&lt;/code&gt; で、上記の&lt;code&gt;EmptyNodeOutput&lt;/code&gt;型が取得できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;上記の-attribute-list-について&#34;&gt;上記の &lt;code&gt;attribute-list&lt;/code&gt; について&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(count)]&lt;/code&gt; or &lt;code&gt;[MaxRecordsSharedWith(nameInShader)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;count&lt;/code&gt;で、出力する Output Record の最大数を宣言する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MaxRecordsSharedWith&lt;/code&gt;は、このノードの関数の引数宣言で、先に宣言された&lt;code&gt;nameInShader&lt;/code&gt;引数と同じ最大数を、宣言として使う場合に使用する。
&lt;ul&gt;
&lt;li&gt;同じ最大数を、複数の下流ノードに出力する場合に有用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配列型の Node Output は、配列のすべての要素に対してこの最大数が適用される。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;)]&lt;/code&gt; or &lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;,baseArrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;出力先のノード名を明示的に宣言する。&lt;/li&gt;
&lt;li&gt;この属性をつけない場合は、宣言した変数名が出力先のノードとみなされる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[AllowSparseNodes]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;出力先のノードが存在しないことを許可する。&lt;/li&gt;
&lt;li&gt;特に配列型の Node Output では、いくつかの配列要素に対する出力ノードが存在しないことを許可する。
&lt;ul&gt;
&lt;li&gt;参考：&lt;code&gt;IsValid()&lt;/code&gt;メソッドで、Work Graph に有効な出力ノードが存在するかを確認することができる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeArraySize(count)]&lt;/code&gt; or &lt;code&gt;[UnboundedSparseNodes]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;count&lt;/code&gt;で、配列型の Node Output の最大要素数を宣言する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UnboundedSparseNodes&lt;/code&gt;は、&lt;code&gt;[NodeArraySize(0xffffffff)] [AllowSparseNodes]&lt;/code&gt;と宣言するのと同義。
&lt;ul&gt;
&lt;li&gt;参考：実際には、Work Graphをコンパイルするときに、存在する有効な出力ノードの数と範囲は検出されるので、このサイズの Output Record が作られるわけではない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;output-record-の生成と取得操作など&#34;&gt;Output Record の生成と取得、操作など。&lt;/h4&gt;
&lt;p&gt;基本的には、Output Record を、スレッド単位で確保するか、Therad Group 単位で確保するかで分かれている。&lt;br&gt;
各メソッドの呼び出し時には、Thread Group が Uniform でなくてはならないというルールがある。&lt;br&gt;
（つまり、すべてのスレッドがその命令を通過するか、すべてのスレッドがその命令を通過しないかのいずれかでなくてはならない。）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ThreadNodeOutputRecords&amp;lt;recordType&amp;gt; NodeOutput&amp;lt;recordType&amp;gt;::GetThreadNodeOutputRecords(uint numRecordsForThisThread)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を個々のスレッド単位で確保する。&lt;/li&gt;
&lt;li&gt;呼び出しは Unfirom だが、確保する Output Record の数や、配列型 Output Record の場合の、確保する要素のインデックスは、各スレッドで可変でよい。&lt;/li&gt;
&lt;li&gt;Output Record のハンドルの配列が返される。&lt;code&gt;Get(int index=0)&lt;/code&gt;メソッドが、Output Record の配列の先頭に対する簡単なアクセスを提供する。&lt;/li&gt;
&lt;li&gt;すべての書き込み処理が終了したら、呼び出しが Uniform な状態で、取得した &lt;code&gt;ThreadNodeOutputRecords&amp;lt;&amp;gt;&lt;/code&gt; に対して&lt;code&gt;OutputComplete()&lt;/code&gt;メソッドを必ず呼び出さなければならない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupNodeOutputRecords&amp;lt;recordType&amp;gt; NodeOutput&amp;lt;recordType&amp;gt;.GetGroupNodeOutputRecords(uint numRecords)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を Thread Group 全体で&lt;code&gt;numRecord&lt;/code&gt;数確保する。&lt;/li&gt;
&lt;li&gt;呼び出しは Unfirom で、確保数や、配列型 Output Record の場合の確保する要素のインデックスも Uniform でなくてはならない。&lt;/li&gt;
&lt;li&gt;すべての書き込み処理が終了したら、呼び出しが Uniform な状態で、取得した&lt;code&gt;GroupNodeOutputRecords&amp;lt;&amp;gt;&lt;/code&gt;に対して&lt;code&gt;OutputComplete()&lt;/code&gt;メソッドを必ず呼び出さなければならない。&lt;/li&gt;
&lt;li&gt;Thread Launch のノードではこのメソッドを呼び出すことはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EmptyNodeOutput::ThreadIncrementOutputCount(uint count)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;スレッド単位で（Emptyな）Output Record の数をインクリメントする。&lt;/li&gt;
&lt;li&gt;呼び出しは Uniform である必要があるが、個々のスレッドが指定するインクリメント数は可変でよい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EmptyNodeOutput::GroupIncrementOutputCount(uint count)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group 単位で（Emptyな）Output Recordを&lt;code&gt;count&lt;/code&gt;数インクリメントする。&lt;/li&gt;
&lt;li&gt;呼び出しは Uniform で、インクリメント数も Uniform でなければならない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;barrier組み込み関数&#34;&gt;&lt;code&gt;Barrier()&lt;/code&gt;組み込み関数&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Barrier()&lt;/code&gt;組み込み関数は、Work Graphの導入に伴いShader Model 6.8から新しく導入されたが、Work Graphに関係なく使える。&lt;br&gt;
以下の３つの型がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;void Barrier(uint MemoryTypeFlags, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MemoryTypeFlags&lt;/code&gt;で指定したタイプの、すべてのリソースの同期をとる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MemoryTypeFlags&lt;/code&gt; は ビットマスクになっていて下記を組み合わせて指定できる。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;UAV_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GROUP_SHARED_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NODE_INPUT_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NODE_OUTPUT_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALL_MEMORY&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;これはすべてのビットマスクの組み合わせ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;template&amp;lt;typename UAVResource&amp;gt; void Barrier(UAVResource, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;引数で指定した&lt;code&gt;UAVResource&lt;/code&gt;を同期の対象とする。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;template&amp;lt;typename NodeRecordObject&amp;gt; void Barrier(NodeRecordObject o, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;引数で指定した&lt;code&gt;NodeRecordObject&lt;/code&gt;の同期をとる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeRecordObject&lt;/code&gt;は、&lt;code&gt;RW{Dispatch|Group|Thread}NodeInputRecords&lt;/code&gt; or &lt;code&gt;{Group|Thread}NodeOutputRecords&lt;/code&gt;を指定できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;semanticflagsについて&#34;&gt;&lt;code&gt;SemanticFlags&lt;/code&gt;について&lt;/h4&gt;
&lt;p&gt;どのような同期をとるかを指定するのが&lt;code&gt;SemanticFlags&lt;/code&gt;。以下の３つがある。&lt;code&gt;_SYNC&lt;/code&gt;と&lt;code&gt;_SCOPE&lt;/code&gt;は論理和で組み合わせて指定できる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GROUP_SYNC&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group 内のすべてのスレッドが、このバリア命令の直前の命令まで発行し終わるまで、ここですべてのスレッドが待つことを指示する。&lt;/li&gt;
&lt;li&gt;他の２つはメモリアクセスの完了に関連する制御だが、これはシェーダーの命令発行の制御。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GROUP_SCOPE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このバリア命令の前に発行された、メモリアクセス処理が完了するまで、ここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;と組み合わせて指定した場合は、Thread Group 内のすべてのスレッドが、&lt;br&gt;
このバリア命令の前に記述されたすべてのメモリアクセス処理が、完了するまでここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;がない場合は、Thread Group が複数の Wave に分かれている場合は、Wave 間での同期は保証されない。&lt;/li&gt;
&lt;li&gt;例として、以下のオブジェクトに対してのメモリアクセスを同期したい場合に使う。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;groupshared&lt;/code&gt;で修飾されたオブジェクト&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWGroupNodeInputRecords&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupNodeOutputRecords&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;DEVICE_SCOPE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このバリア命令の前に発行された、メモリアクセス処理が完了するまで、ここで待つことを指示する。&lt;br&gt;
加えて、&lt;code&gt;globallycoherent&lt;/code&gt;で修飾されたオブジェクトに対するメモリアクセス処理と、&lt;code&gt;Interlocked&lt;/code&gt;系の命令によるメモリアクセス処理が完了して、&lt;br&gt;
GPUの他の処理ユニットからその処理結果が正しく読み出せるようになるまで、ここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;と組み合わせた場合の効果は、&lt;code&gt;GROUP_SCOPE&lt;/code&gt;の項で説明したのと同じ。&lt;/li&gt;
&lt;li&gt;具体的には、以下のオブジェクトに対してのメモリアクセスを同期したい場合に使う。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾されたUAV&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾された&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;work-graphにおけるgloballycoherent修飾について&#34;&gt;Work Graphにおける&lt;code&gt;globallycoherent&lt;/code&gt;修飾について。&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;globallycoherent&lt;/code&gt;修飾されたUAVについて&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Work Graph の上流ノードと下流ノードでのデータの受け渡しは、基本的に{Input|Output} Record を使うが、データの格納形式や、必要とされるデータの寿命などによって、UAVを使うのが適切な場合がある。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;修飾されたUAVを介して、上流ノードと下流ノードでデータを受け渡す場合は、上流ノードにおいて、UAVに対する処理と、下流ノードを起動するための Output Record の生成完了（つまり、&lt;code&gt;OutputComplete()&lt;/code&gt;の呼び出しや、&lt;code&gt;IncrementOutputCount()&lt;/code&gt;の呼び出し）の間に、&lt;code&gt;DEVICE_SCOPE&lt;/code&gt;のバリアを設定することで、両ノードの、UAVへのデータ競合を避けることができる。
&lt;ul&gt;
&lt;li&gt;注意：Work Graphの実行順序は、必ずしもグラフの上流ノードから下流ノードと順番が決まっているわけではなく、{Input|Output} Recordの依存関係で決まっている。&lt;/li&gt;
&lt;li&gt;上流ノードの、複数の Thread Group が同一のUAVを処理し、全ての処理の完了を待ってから下流ノードの処理を始めたい場合は、&lt;code&gt;InterlockedAdd()&lt;/code&gt;などを駆使して、上流ノードの Thread Group の中で、最後に処理が完了した Thread Groupを検出して、その Thread Group が下流ノードを起動するための Output Record を生成する必要がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾された&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;について&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Broadcasting Launch では、複数のThread Group が、一つの Input Recordを読み書きすることができる。&lt;br&gt;
&lt;code&gt;globallycoherent&lt;/code&gt;修飾をつけておけば、&lt;code&gt;globallycoherent&lt;/code&gt;修飾のついた短期的なUAVバッファとして扱うことができるので、  &lt;code&gt;Interlocked&lt;/code&gt;系の命令やバリアを適切に使用すれば Thread Group 間で、データのやり取りおよび同期をとることができる。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;::FinishedCrossGroupSharing()&lt;/code&gt;を使えば、最後にこのメソッドを呼び出した Thread Group にのみ、&lt;code&gt;true&lt;/code&gt;が返されるので、複数の Therad Group で行った処理全体の終了を知ることができる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このメソッドを使用するInput Recordの宣言には、&lt;code&gt;[NodeTrackRWInputSharing]&lt;/code&gt;属性がついてる必要がある。この属性をつけると、Input Recordのサイズが4byte大きくなる。
&lt;ul&gt;
&lt;li&gt;参考：結局のところ、この4byteの領域を上流ノードでゼロに設定しておき、各Therad Groupが&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;に対する処理が終了した時点で、その4byte領域に&lt;code&gt;InterlockedAdd()&lt;/code&gt;を実行していると思われる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rwthreadnodeinputrecord-threadnodeoutputrecordsオブジェクトとbarrierについて&#34;&gt;&lt;code&gt;RWThreadNodeInputRecord&lt;/code&gt;, &lt;code&gt;ThreadNodeOutputRecords&lt;/code&gt;オブジェクトと&lt;code&gt;Barrier()&lt;/code&gt;について&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;この二つのオブジェクトは、いずれもスレッドローカルなので、&lt;code&gt;GROUP_SCOPE&lt;/code&gt;, &lt;code&gt;DEVICE_SCOPE&lt;/code&gt;いずれも適用できない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Barrier()&lt;/code&gt;命令を跨いで、対象オブジェクトに対するメモリアクセス命令を、コンパイラによる命令スケジューリングで移動することを抑制する。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(2)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_second_step/</link>
      <pubDate>Mon, 20 Jun 2022 14:54:40 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_second_step/</guid>
      <description>&lt;p&gt;前提知識として、
&lt;a href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/&#34; title=&#34;About Us&#34;&gt;RTXDIのminimal-sampleをSpatioTemporal Resamplingなしの場合の動作&lt;/a&gt;について理解する必要があります。&lt;/p&gt;
&lt;h1 id=&#34;risとrestir&#34;&gt;RISとReSTIR&lt;/h1&gt;
&lt;p&gt;minimal-sampleは、まず初めに、現在レンダリングしているフレーム内でLight SampleとBRDF SampleをMISで結合したRservoirを生成します。この時点でもReservoirの結合を行いますが、基本的には Resampled Importance Sampling: RISのアルゴリズムに基づいて最適なライトパスの選択が行われます。&lt;br&gt;
加えて、&amp;ldquo;Enable Resampling&amp;quot;チェックボックスを有効にした場合は、現在のフレームで生成したReservoirと、前のフレームで生成されたReservoirを結合することで、さらに良質なライトパスの選択を行うことが出来ます。この処理を、Reservoir-based SpatioTemporal Importance Resampling: ReSTIRと呼びます。&lt;/p&gt;
&lt;h2 id=&#34;restirの効果&#34;&gt;ReSTIRの効果&lt;/h2&gt;
&lt;p&gt;端的にReSTIRの効果の有無を比較すると以下のようになります。ReSTIRの処理が追加されるので処理負荷は大きくなりますが、もしもReSTIRを使わずに、これと同等のレンダリングを達成するためには、ずっと多くの処理時間が必要となるでしょう。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-risrestir&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&amp;#43;ReSTIR&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS+ReSTIR
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ris&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;rtxdi_spatiotemporalresamplingの処理&#34;&gt;RTXDI_SpatioTemporalResampling()の処理&lt;/h2&gt;
&lt;p&gt;RTXDI SDKのReSTIRの処理は、&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数で行われます。minimal-sampleではRender.hlslから呼ばれています。引数には、以下の情報を渡します。返り値として、ReSTIRで結合されたReservoirが返されます。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reservoir = RTXDI_SpatioTemporalResampling(pixelPosition, primary.surface, reservoir, rng, stparams, params, temporalSamplePixelPos, lightSample);&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pixelPosition&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelの位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;surface&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelのサーフェース情報（位置, 法線 tec..）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;curSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在のフレームで生成したReservoir&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rng&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;乱数生成用のステート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stparams&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理に関するのパラメーター（後述)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;params&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI SDKの定数パラメーター（バッファのオフセット情報など）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;temporalSamplePixelPos&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに成功した場合は、そのピクセル位置が格納されます。失敗すれば(-1,-1)が格納されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selectedLightSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理でReservoirの選択サンプルが更新された場合は、このライトサンプルの情報が更新されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdi_spatiotemporalresamplingparameters-構造体&#34;&gt;RTXDI_SpatioTemporalResamplingParameters 構造体&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数を呼び出す際の引数にあるこの構造体には、 ReSTIRの制御に関する様々なパラメーターが格納されています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;screenSpaceMotion&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理しているピクセルのモーションベクトルです&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sourceBufferIndex&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoirバッファのフレームごとの参照オフセットを計算するためのインデックスです。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxHistoryLength&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合されたReservoirのウエイトの上限を決めます。この値が大きいほど、過去に多数のReservoirと結合されたサンプルのウエイトが高くなります。&lt;/li&gt;
&lt;li&gt;また、逆を言えば、シーンの変化への追従が悪くなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;biasCorrectionMode&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoir結合時のBiasの補正方法です。&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_OFF
&lt;ul&gt;
&lt;li&gt;Biasの補正をしない結合方法を使います。処理は一番軽いですが、レンダリング結果にBiasを導入します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_BASIC
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正しますが基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_PAIRWISE
&lt;ul&gt;
&lt;li&gt;pairwise MISという方法でBiasを補正します。基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。今回の記事では説明しません。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正したうえで、レイトレースを行い結合されたReservoirが有効かどうかをチェックします。基本的にBiasを導入しない方法です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;depthThreshold, normalThreshold&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionをしたときに、法線とデプスの相似度をチェックする際の閾値です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合を試みるReservoirの数です。最低1必要で、最初の一つは、TemporalResamplingとなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numDisocclusionBoostSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに失敗した場合に、SpartialSampleの数を増やす場合のサンプル数です&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;samplingRadius&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;SpartialSampleのサンプリング半径（ピクセル単位）です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enableVisibilityShortcut&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACEDの時のみ有効です。&lt;/li&gt;
&lt;li&gt;Reservoir結合後に、Visibilityテストを行う際にTemporalSampleが選択された場合はVisibilityテストをスキップします。
&lt;ul&gt;
&lt;li&gt;（ここのIfの判定は不明。おそらくだが、選択されたサンプルのReservoirのVisibilityテストをスキップするのが正しいと思う。（なぜならそれは前フレームで行ったから。））&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enablePermutationSampling&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;BackprojectionとSpartialSamplingの位置にに小さいオフセットを適用します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;backprojectionの処理&#34;&gt;Backprojectionの処理&lt;/h4&gt;
&lt;p&gt;まず、前のフレームのReservoirと結合するためには、Backprojectionの処理を行う必要があります。この処理自体は、通常我々が行っているものと違いはありません。モーションベクトルを基に、過去フレームのサンプル位置を算出し、その近傍で、法線やDepthの類似性が高いサンプルを探します。&lt;/p&gt;
&lt;h4 id=&#34;temporal-sampleの読み出し&#34;&gt;Temporal Sampleの読み出し&lt;/h4&gt;
&lt;p&gt;Backprojectionが成功したら、Reservoirバッファより、前フレームのPixel位置に対応するReservoirを読み出して&lt;code&gt;prevSample&lt;/code&gt;に格納します。読み出されるのは前のフレームに保存されたReservoirの情報になります。読み出したReservoirに対して以下の処理を行います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;をhistoryLimitでクランプ&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spartialDistance&lt;/code&gt;にピクセルオフセットを加算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;age&lt;/code&gt;をインクリメント&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightID&lt;/code&gt;を現在のフレームのライトバッファに対応するIDに変換
&lt;ul&gt;
&lt;li&gt;lightIDの変換では、もし該当するライトが、現在のフレームになければ読み出したReservoirを破棄します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;temporal-sampleの結合&#34;&gt;Temporal Sampleの結合&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;prevSample&lt;/code&gt;が有効なReservoirだった場合は、現在のフレームで生成されたReservoirと結合します。
まず、&lt;code&gt;prevSample&lt;/code&gt;のReservoirの情報を基に、Light Sampleを構築します。ここで構築されるLight Sampleは、読み出し時に、ligtIDを変換したので、現在のフレームにおける光源サンプルの位置になります。そして、現在処理をしているSurfaceとそのLight Sampleで、&lt;code&gt;targetPDF&lt;/code&gt;を計算します。（つまりシェーディングの計算をします。）この値は、前のフレームのReservoirを結合する際の、ウエイトの補正に使います。&lt;/p&gt;
&lt;p&gt;結合の計算の詳細:&lt;br&gt;
まず、&lt;code&gt;prevSample&lt;/code&gt;はFinalizeされて格納されているので、そのメンバー変数&lt;code&gt;weightSum&lt;/code&gt;は意味的には、(1/targetPDF * 1/M * weightSum)の値になっています。
そして、&lt;code&gt;prevSample&lt;/code&gt;のRIS Weightは、プログラム上では(&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;呼び出しの引数の&lt;code&gt;targetPdf&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;weightSum&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;M&lt;/code&gt;)で計算されます。&lt;br&gt;
これを意味的に解釈すると(引数のtargetPDF)/(元のtargetPDF) * weightSum となります。
つまり本来の意味でのweightSumに、新旧のtargetPDFの比を乗算したものがRISWeightとして使われることになります。
結合後は、MとRISWeightはそれぞれ結合先のReservoirに加算され、乱数によるサンプルの選択が行われることで結合が完了します。&lt;/p&gt;
&lt;h4 id=&#34;spartial-sampleの読み出しと結合&#34;&gt;Spartial Sampleの読み出しと結合&lt;/h4&gt;
&lt;p&gt;minimal-sampleにおいて、Spartial SampleはTemporal Sampleと同様に、前フレームのGBufferとReservoirバッファから読み出されます。
テストするサンプル数は、デバッグUI上の&lt;code&gt;Spartial Sample&lt;/code&gt;のスライダーで調整できます。Temporal Sampleとの主な違いは、Backprojectionした位置から、さらに、&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;から取得した値でオフセットを適用するところにあります。&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;はSDK側からその内容があらかじめ提供されている静的なバッファで、Spartial Sampleのサンプリングパターンが格納されています。読み出したサンプルは、Normal, Dpethそして、GbuffのMaterialの相似度をみて、サンプルが有効かを判定します。&lt;br&gt;
有効な場合は、Temporal Sampleの場合と同様にReservoirを結合行います。結合の計算は、Temporal Sampleの場合と同じです。&lt;/p&gt;
&lt;h4 id=&#34;biasの補正とreservoirのfinalize処理&#34;&gt;Biasの補正とReservoirのFinalize処理&lt;/h4&gt;
&lt;p&gt;隣接ピクセルや、過去のフレームのReservoirとの結合はBiasを発生させることがあります。例えば、異なるピクセルで生成した複数のReservoirを結合した場合、個々のピクセルの積分範囲（法線を中心とした半球）は異なるため、もし、結合後に選択したLight Sampleが、結合された、とあるReservoirの積分範囲の外であったり、不可視な状態だったなら、このReservoirから&lt;code&gt;M&lt;/code&gt;の値を、Fianlize処理するときの分母に含めてはいけません。そうしないと、Biasが発生してしまいます。（詳しくはReSTIRの論文を参照）&lt;/p&gt;
&lt;p&gt;可視状態の確認は、&lt;code&gt;biasCorrectionMode&lt;/code&gt;に&lt;code&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED&lt;/code&gt;が設定された場合に実行されます。具体的には、選択されたLight Sampleの位置と、各Reservoirの位置を、過去のフレームのBVHでレイトレースして、可視状態を確認します。（ただし、サンプル内の実際の処理では、シーンがスタティックであると仮定して、単純に現在のフレームのBVHでレイトレースするように実装されています。）&lt;/p&gt;
&lt;p&gt;次にFinazlieの処理についてです。&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数の正規化部分では、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;という変数が、Finalizeする際の係数の分子と分母になるように記述されています。もしも、ここがもっと単純な記述だったら、&lt;code&gt;pi&lt;/code&gt;は常に1で、&lt;code&gt;piSum&lt;/code&gt;には、選択したLight SampleがそのReservoirの積分範囲内で、かつ可視状態の、有効なReservoirの&lt;code&gt;M&lt;/code&gt;のみを加算することで、Finalize処理の係数を算出する形になります。（ReSTIR論文における1/Zに相当）&lt;br&gt;
しかし、RTXDIでは、MISのように正規化の係数を計算しています。具体的には、選択されたLight Sampleと各Reservoirの位置で、&lt;code&gt;targetPDF&lt;/code&gt;を計算し、可視状態ならば(&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;)という値を分母側の&lt;code&gt;piSum&lt;/code&gt;に蓄積しています。分子側の&lt;code&gt;pi&lt;/code&gt;は選択されたLight Sampleを保持していたReservoirとの&lt;code&gt;targetPDF&lt;/code&gt;です。つまり、選択されたLight Sampleを保持していたReservoirの&lt;code&gt;targetPDF&lt;/code&gt;(つまりはシェーディングの輝度）が相対的に他のReservoirと計算した輝度よりも高ければ、Finalizeする際の係数が大きくなるように計算されています。&lt;/p&gt;
&lt;p&gt;また、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;の初期値は、Temporal SampleやSpatial Sampleとの結合前の、現在のフレームで計算されたReservoirの値を設定します(&lt;code&gt;curSample.M&lt;/code&gt;)。これのMISのウエイトとして&lt;code&gt;state.targetPdf&lt;/code&gt;を使っています。これは、現在選択されているLight Sampleと、現在処理中のサーフェースで計算された&lt;code&gt;targetPDF&lt;/code&gt;で、この値は、他のTemporal SampleやSpatial Sampleのために計算する&lt;code&gt;targetPdf&lt;/code&gt;に対応する値です。（この値は、現在のフレームのデータで計算しています。他のTemporal SampleやSpatial SampleのReservoirの&lt;code&gt;targetPdf&lt;/code&gt;は前フレームのデータで計算しているという点は異なります。）&lt;/p&gt;
&lt;p&gt;ループ処理が完了すれば、結合されたすべてのReservoirのBiasの除外のチェックが完了したことになります。そして、&lt;code&gt;pi&lt;/code&gt;には選択されたサンプルの&lt;code&gt;targetPDF&lt;/code&gt;が格納され、&lt;code&gt;piSum&lt;/code&gt;には&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;の総和が格納されています。 &lt;code&gt;pi&lt;/code&gt;/&lt;code&gt;piSum&lt;/code&gt;を正規化係数としてFinalize処理を行うことで、Biasの補正をした結合ができます。&lt;/p&gt;
&lt;h5 id=&#34;biasの補正をしない場合のreservoirのfinalize処理&#34;&gt;Biasの補正をしない場合のReservoirのFinalize処理&lt;/h5&gt;
&lt;p&gt;Biasの補正をしない場合は、単純に結合されたReservoirを1/Mを正規化係数として、Finalize処理します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(1)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_first_step/</link>
      <pubDate>Tue, 07 Jun 2022 19:30:28 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_first_step/</guid>
      <description>&lt;h1 id=&#34;rtxdiとは&#34;&gt;RTXDIとは？&lt;/h1&gt;
&lt;p&gt;GPU上かどうかにかかわらずレイトレーシングやパストレーシングを行う際の重要な課題の一つは、追跡する光線の軌跡（パスもしくはレイと呼ばれるもの）をどのように構築するかです。これはレンダラーの性能や画質などの特性に直結する問題です。たとえば、物体表面からの反射に限定すれば、最も簡単なパスの構築方法は、物体の表面から半球状ににランダムな方向を選択してパスを構築する方法があると思います。また、物体表面の反射特性に合わせて、より反射率の高い方向を高確率で選択する方法や、シーン上に存在する光源の方向にパスを構築する方法もあります。&lt;br&gt;
このように、いろいろなパスの選択戦略があり、実際のレンダリングでは、これらを組み合わせて使うことがよくある思います。そして、最も理想的なパスの確率分布は、その物体表面から、観測者の方向へのRadianceに比例した確率分布といわれています。しかしこれは、一般的には解析的に解くことが極めて困難であることがほとんどです。なぜなら、物体表面の反射特性は分かっても、どの方向から強い光が差し込んでくるかはわかりません。その光も、シーン上に設定された光源からの直接光なのか、それとも何かほかの物体から反射された光なのかわかりません。&lt;br&gt;
RTXDIは、光源からの直接光によって形成されるRadianceに対して、最適なパスの確率分布を形成するようにパスの選択をするためのNVIDIAのSDKです。名前の由来は、おそらくRTX Direct Illuminationです。&lt;/p&gt;
&lt;h4 id=&#34;リポジトリ&#34;&gt;リポジトリ&lt;/h4&gt;
&lt;p&gt;GitHubのリポジトリがあるので、さっそくCloneしてみましょう。&lt;br&gt;
以降の説明では基本的にCloneしたソースを読める状態にある前提で書いています。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;ドキュメント&#34;&gt;ドキュメント&lt;/h4&gt;
&lt;p&gt;RTXDIのSDKのドキュメントを見る前に、前提知識として、Resampled Importance Sampling(RIS)のアルゴリズムの基礎部分を理解した方がよいと思います。（これより先は、Resampled Importance SamplingをRISと省略します。）&lt;br&gt;

&lt;a href=&#34;https://www.google.com/search?q=Importance&amp;#43;Resampling&amp;#43;for&amp;#43;Global&amp;#43;Illumination&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Importance Resampling for Global Illumination&amp;rdquo; by J. Talbot et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RTXDIのSDKには、その概要を把握するのに下記のドキュメントがありますが、これを読んで理解できる人は、この記事はここで読むのを終了していただいて、SDKのドキュメントやソースコードを直接参照した方が良いでしょう。

&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;rtxdi-sampleとminimal-sample&#34;&gt;rtxdi-sampleとminimal-sample&lt;/h4&gt;
&lt;p&gt;このSDKにはサンプルプロジェクトが二つ付いています。&lt;br&gt;
rtxdi-sampleは、RTXDIをパス選択の核として、RTXGIやNRDやDLSSを用いてレンダリングしています。またReGIRという、ワールド空間におけるRISも行っているので、かなり実践的なサンプルになっている一方で、初めのステップとして、RTXDIの動作を理解したい場合には不向きなサンプルです。&lt;br&gt;
一方で、minimal-sampleは、設定を変更することで時間方向のRISや、BRDFに基づくサンプリングも無効にすることが出来ます。また、NRDによるデノイズも行っておらず、レンダリングは極力単純な形で留めてあります。そのため、RTXDIの核であるRISの仕組みや、その効果をわかりやすく見せてくれるサンプルになっています。本記事ではこちらのサンプルプログラムの動作を見ていきます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleのスクリーンショット&#34;&gt;minimal-sampleのスクリーンショット&lt;/h1&gt;
&lt;p&gt;端的にRTXDIの効果の一端を見るためにいくつかのスクリーンショットを用意しました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-1サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;1サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    1サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-8サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;8サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    8サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

まずは上記3枚は、RTXDIのパス選択候補を、8サンプル、16サンプルと増加させたものです。選択候補は増やしているのですが、実際にれらのサンプルでレイトレースを行った訳ではありません。レイトレースはあくまで1回のみ行います。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプルbrdf2サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル＋BRDF2サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル＋BRDF2サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

次は、16サンプル+BRDF2サンプルの場合です。こちらはレイトレース回数は、合計3回となります。BRDFサンプルによって、良い選択候補が見つかるサーフェースでの変化が顕著に見られます。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-4サンプルbrdf1サンプルspatio-temporal-resample&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;4サンプル＋BRDF1サンプル&amp;#43;Spatio-Temporal Resample&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    4サンプル＋BRDF1サンプル+Spatio-Temporal Resample
  &lt;/figcaption&gt;


&lt;/figure&gt;

今回の記事では説明しませんが、Spatio-Temporalのパス選択候補を導入すると、上記のようになります。上記の16サンプルと同等の処理時間ですが、結果は圧倒的にこちらが優れています。デノイズ処理は一切入っていない状態でここまでレンダリングできれば、かなり高画質なレンダリングが期待できます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleを読む前に前提知識&#34;&gt;minimal-sampleを読む前に（前提知識）&lt;/h1&gt;
&lt;p&gt;ここでサンプルプログラムのレンダリングを見る前に、簡単に触れておいた方が良い前提知識について説明します。&lt;/p&gt;
&lt;h4 id=&#34;nvrhiとdonutフレームワーク&#34;&gt;NVRHIとDonutフレームワーク&lt;/h4&gt;
&lt;p&gt;RTXDI SDKのほかに、minimal-sampleが依存している主なライブラリとして、DonutとNVRHIがあります。&lt;br&gt;
NVRHIは、D3D12とVulkanを抽象化するためのグラフィックスAPIの抽象化レイヤーです。とはいえそれほど深い抽象化が行われているわけではありません。&lt;br&gt;
Donutは、サンプルアプリケーションのフレームワークに相当する部分になります。シーンのロードやシェーダーの管理、デバッグUIの表示などを行っています。こちらもサンプル向けのフレームワークなので、シンプルに記述されています。今回のサンプルプログラムでは、それほど多数のDispatchが呼び出されるわけではないので、動作の理解に苦しむことはないかと思います。&lt;/p&gt;
&lt;h4 id=&#34;rab_プレフィックスについて&#34;&gt;RAB_プレフィックスについて&lt;/h4&gt;
&lt;p&gt;RTXDIのサンプルを見ると、RTXDI_プレフィックスの関数や構造体とは別に、RAB_プレフィックスの関数や構造体がたくさんあります。RABの意味はRTXDI Application Bridgeという意味で、その名の通り、RTXDIとアプリケーションの橋渡しの役目があります。&lt;br&gt;
RTXDIがRISを行うときに必要になる情報は、アプリケーションのレンダラーと密接に関係しています。そのため、RTXDIがアプリケーション由来の情報と思われるものを取得する際は、RAB_プレフィックスのついた関数を呼び出します。RTXDIが呼び出している、RABプレフィックスのついた関数を実装するのは、アプリケーション側の責任となります。
しかし実際は、サンプルアプリケーションのRAB実装である、RtxdiApplicationBridge.hlslを改変する形で自身のアプリケーションに組み込む形になると思います。このようにすることで、アプリケーションごとに改変の必要な部分と不要な部分の切り分けを実現しています。&lt;/p&gt;
&lt;h4 id=&#34;rtxdi特有のリソース&#34;&gt;RTXDI特有のリソース&lt;/h4&gt;
&lt;p&gt;通常のG-Bufferなどに加えて、minimal-sampleでRTXDI SDKを導入したことで必要となるリソースは以下の通りです。RTXDIは、SDKの内部でリソースを確保することはありません。リソースの管理は、生成、破棄を含め、すべてアプリケーション側の管理となります。  SDK側からは必要に応じて、リソースのサイズやその中身がAPIを通じて提供されるので、アプリケーションはそれらを正しく管理しなくてはなりません。
以下のリソースは、ソースコード全体の把握では大切な要素ですが、RISのアルゴリズム部分ではあまり関わりが無いので読み飛ばしても問題ありません。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TaskBuffer&lt;br&gt;
RTXDIは、毎フレーム直接光源情報のテーブルの更新を行っています。これはPrepareLightというGPU処理マーカーの中でComputeShaderとして行われています。この処理の入力として TaskBufferが必要となります。このバッファはPrepareLightsTask構造体の配列となっています。
このサンプルでは、シーン上でEmissiveサーフェースを持ったGeometry Instanceの個数分のバッファを確保しています。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightBuffer&lt;br&gt;
RTXDIがアクセスする光源の情報はすべてこのバッファに格納されます。個々の光源は、RAB_LightInfo構造体に格納されます。
このサンプルでは、Emmisiveのマテリアルが設定されたポリゴン一つ一つがEmissiveTriangleの光源としてこの配列に設定されます。
TaskBufferによって入力された情報をもとに、このバッファが構築されます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GeometryInstanceToLightBuffer&lt;br&gt;
Geometry Instanceごとに、そのInstanceに含まれるEmissiveTriangleの光源としてのLightBufferにおける先頭のインデックスを格納します。つまり、GeometryInstanceのインデックスからLightBufferを参照するときに使われるテーブルです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeighborOffsetBuffer&lt;br&gt;
RTXDIがサイズを提供しと内容を指定します。スクリーンスペースでRISを行うときに参照するべきPixelへのオフセットになる値が格納されます。EvenとOddのフィールドがあるのでRTXDIが提供するNeighborOffsetCountの2倍の数で、RG8_SNORMのTypedBufferを確保します。
レンダリングの前に、RTXDIのFillNeighborOffsetBuffer()で取得できるバイト列をこのバッファに書き込む必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightReservoirBuffer&lt;br&gt;
RTXDIがサイズを提供し内容はComputeShaderで算出されます。
ReservoirBuffer一つあたりのサイズはsizeof(RTXDI_PackedReservoir) * context.GetReservoirBufferElementCount()で、RTXDIから提供されます。
これをアプリケーション側の好きな数だけ確保します。サンプルの初期値では3セット分のサイズのバッファを確保しています。
時間方向でRISを行う場合のためのバッファになります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdiのreservoirについて&#34;&gt;RTXDIのReservoirについて&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;（ここより以下、RTXDIもしくはRISの文脈で、&amp;ldquo;サンプル&amp;quot;と言っている場合は、レイトレーシングにおけるサーフェースと光源を結ぶパスを構築するためのLight Sampleを指します。サンプルアプリケーションのことでもなければ、テクスチャのサンプリングのことでもありません。）&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;
RTXDI_Reservoir構造体はRISのReservoirとしての情報を保持します。Reservoirとは、RISをするためのサンプルの集合です。ただし、サンプルの集合の情報をすべて保持していたら、GPU上ではメモリが足りません。したがって、Reservoirは今まで生成してきたサンプルによる確率の計算と、現在そのReservoirで選択されているサンプルの情報を格納しています。具体的には、サンプルの選択確率に関する情報と、パスの接続対象なる光源のインデックス、その光源の表面における位置情報にあたるUVです。これがあれば、ワールド空間でパスを接続するべき位置（つまりは光源の表面位置）が計算でき、シェーディングを行った後にサンプルの確率密度を適用することができます。&lt;br&gt;
Reservoirに関して全くイメージがわかないという場合は、まず初めに紹介した論文を軽く読んで、ReSTIRに関する論文、

&lt;a href=&#34;https://research.nvidia.com/sites/default/files/pubs/2020-07_Spatiotemporal-reservoir-resampling/ReSTIR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting&amp;rdquo;, Bitterli et al. 2020&lt;/a&gt;&lt;br&gt;
を読むとイメージできると思います。（もしこの二つを読んだならば、本記事は、この先読む必要がないでしょう）&lt;/p&gt;
&lt;h4 id=&#34;reservoirを操作する関数群&#34;&gt;Reservoirを操作する関数群&lt;/h4&gt;
&lt;p&gt;ここではRTXDIがReservoirを操作する関数群のなかで、最も基本的なものをザックリと説明します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RTXDI_Reservoir RTXDI_Reservoir RTXDI_EmptyReservoir()&lt;/code&gt;&lt;br&gt;
有効なサンプルが一つも格納されていない、初期化された&lt;code&gt;RTXDI_Reservoir&lt;/code&gt;構造体を返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_StreamSample( inout RTXDI_Reservoir reservoir, uint lightIndex, float2 uv, float random, float targetPdf, float invSourcePdf)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reservoir&lt;/code&gt; - 格納するReservoir&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightIndex&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; - 追加するLight Sampleの情報&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random&lt;/code&gt; - Light Sampleを更新するかどうかをDraw（選択）するときに使う乱数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPdf&lt;/code&gt; - RISにおけるTarget PDF&lt;/li&gt;
&lt;li&gt;&lt;code&gt;invSourcePdf&lt;/code&gt; - 追加するサンプルを生成する確率の逆数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一つのサンプルをReservoirに追加して、現在このReservoirの中で選択されているサンプルを更新します。&lt;br&gt;
&lt;code&gt;targetPDF&lt;/code&gt;は実際は正規化されたPDFである必要はなく、単なるウエイト値で問題ありません。一方で、&lt;code&gt;invSourcePdf&lt;/code&gt;は、サンプルの発生確率に基づいたPDFである必要があります。関数内部では、RIS Weightが &lt;code&gt;targetPdf * invSourcePdf&lt;/code&gt; で計算され、Reservoir構造体の &lt;code&gt;weightSum&lt;/code&gt; に加算されます。Reservoirの保持サンプル数&lt;code&gt;M&lt;/code&gt;もインクリメントされます。また、与えられた &lt;code&gt;random&lt;/code&gt;でサンプルの選択を行い、新たに追加されたサンプルが選択された場合はReservoir内部の選択サンプルの情報を更新します。その場合は、返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;void RTXDI_FinalizeResampling( inout RTXDI_Reservoir reservoir, float normalizationNumerator, float normalizationDenominator) &lt;/code&gt;&lt;br&gt;
通常は、Reservoirへのサンプル追加が終わった段階で呼び出す処理で、Reservoirに蓄積されたサンプルの確率と、現在選択されているサンプルの確率から、選択されているサンプルの評価値（つまりはシェーディング結果）に乗算するべき値 (Importance Samplingにおける 1/PDF) を計算します。&lt;br&gt;
&lt;code&gt;normalizationNumerator&lt;/code&gt;, &lt;code&gt;normalizationDenominator&lt;/code&gt;は蓄積されたサンプルの&lt;code&gt;weightSum&lt;/code&gt;を正規化するときの係数です。単独のReservoirであれば、Reservoirに蓄積されたサンプル数の逆数である、1/&lt;code&gt;M&lt;/code&gt;が係数として適切です。この場合、1/&lt;code&gt;targetPDF&lt;/code&gt; * (1/&lt;code&gt;M&lt;/code&gt; * &lt;code&gt;weightSum&lt;/code&gt;)を計算し、これを &lt;code&gt;weightSum&lt;/code&gt; に代入します。&lt;br&gt;
したがって、この関数を呼び出す前と後では構造体メンバーの&lt;code&gt;weightSum&lt;/code&gt;の値の意味が変わります。呼び出す前はReservoirに蓄積されたサンプルのウエイトの合算で、呼び出した後は、選択されたサンプルの評価値に乗算するべき値となります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float RTXDI_GetReservoirInvPdf(const RTXDI_Reservoir reservoir)&lt;/code&gt;&lt;br&gt;
Sampleの評価値に乗算するべき係数（Importance Samplingにおける1/PDF）を返します。&lt;br&gt;
内部の処理は&lt;code&gt;weightSum&lt;/code&gt;の値を返すだけです。事前に&lt;code&gt;FinalizeResampling()&lt;/code&gt;を呼ぶ必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_CombineReservoirs( inout RTXDI_Reservoir reservoir, const RTXDI_Reservoir newReservoir, float random, float targetPdf)&lt;/code&gt;&lt;br&gt;
二つのReservoirを結合します。&lt;br&gt;
まず、結合前に結合される側の&lt;code&gt;newReservoir&lt;/code&gt;は&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;で正規化されている必要があります。&lt;br&gt;
引数&lt;code&gt;targetPdf&lt;/code&gt;は、結合される&lt;code&gt;newReservoir&lt;/code&gt;で選択されているサンプルの、結合先Reservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;になります。結合される側と結合先でのtargetPdfが同じ場合は、引数の&lt;code&gt;targetPdf&lt;/code&gt;は、&lt;code&gt;newReservoir&lt;/code&gt;に保存されているサンプルのtargetPdfを指定すればよいです。&lt;br&gt;
結合後は、現在どちらかのReservoirで選択されているサンプルが選択サンプルになります。これを&lt;code&gt;random&lt;/code&gt;を用いて決めます。選択サンプルが変更される場合は返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;minimal-sampleの中身brfont-size1spatio-temporalでrisを行わない場合のレンダリングfont&#34;&gt;minimal-sampleの中身&lt;br&gt;&lt;font size=&#34;+1&#34;&gt;~Spatio-TemporalでRISを行わない場合のレンダリング~&lt;/font&gt;&lt;/h1&gt;
&lt;p&gt;レンダリングを理解するうえでの前提知識が整ったので、さっそく一番簡単なケースのレンダリングを見たいと思います。
Spatio-TemporalでのRISは、RTXDIの大きな特長の一つですが、今回は単純化のために無効化した状態でサンプルコードを読み、
RTXDIの最もシンプルな形を理解するこにします。このサンプルアプリケーションは、&amp;ldquo;Enable Resampling&amp;quot;というDebugUIが用意されているのでこれをDisableにします。しかしこれはSpatio-TemporalのRISを行うかどうかを切り替えるためのフラグで、RTXDIを完全にDisableにするためのものではありません。また、BRDF Cutoffも、簡単のため0.0が設定されていると仮定します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-settings&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Settings&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;30%&#34; height=&#34;351&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Settings
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;レイトレーサー本体の概要&#34;&gt;レイトレーサー本体の概要&lt;/h4&gt;
&lt;p&gt;Renderer.hlslのmain()がレイトレーサー本体のシェーダーコードです。カメラからレイを飛ばして、GBuffer相当の情報を取得している部分は特に難しい部分はないと思います。サーフェースにヒットした場合は、乱数シーケンスを初期化して、RTXDI_SampleParamterにサンプリングの設定をしています。その後の主な処理の流れは以下の通りです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空のReservoirに、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;でReservoirの正規化を行う&lt;/li&gt;
&lt;li&gt;選択パスが、RTXDI_SampleLocalLights()だったら、ShadowRayをキャストして、Visibilityをチェック&lt;/li&gt;
&lt;li&gt;ShadeSurfaceWithLightSample()で、Reservoirで選択されたサンプルを使ってシェーディングを行う&lt;/li&gt;
&lt;li&gt;再びShadowRayをキャストしてVisibilityをチェック&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Spatio-TemporalのRISが無効化されている場合は、最後の2度目のVisibilityチェックは必要ないはずです。しかし、大まかな処理の流れとしてはこのようになっています。以上を簡単に言い換えれば、1バウンスのライトサンプル(NEE)と、BRDFサンプルのMulti Importance Samplingのレイトレーサーが実装されているといえると思います。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplelocallights&#34;&gt;RTXDI_SampleLocalLights()&lt;/h3&gt;
&lt;p&gt;さっそくですが、1番めの処理についてです。この関数は&lt;code&gt;ResamplingFunctions.hlsli&lt;/code&gt;に実装されています。
この関数は、&lt;code&gt;numLocalLightSamples&lt;/code&gt;で指定された数だけ、サンプルを構築してReservoirに蓄積する処理を行います。このサンプルアプリケーションの中の様々な個所で行われているRISの最も基本的な形になっています。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;RTXSDKは事前にLight DataバッファにLocal Light (つまりは Emissive Triangle)のリストを構築しています。まず、このリストから、単純に乱数でLocal Lightを選択します。さらに乱数を2つ生成して、光源の三角形上の点を決定して、その位置に向けて、プライマリレイがヒットしたサーフェースからパスを構築します。&lt;br&gt;
構築されたパスのPDFは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;で計算され、&lt;code&gt;blendedSroucePdf&lt;/code&gt;に代入されます。&lt;/p&gt;
&lt;h5 id=&#34;blendedsourcepdfの計算&#34;&gt;blendedSourcePdfの計算&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;blendedSourcePdf&lt;/code&gt;は、RISにおけるsourcePDFなので、実際のパス生成確率に即したものでなければなりません。
この計算を行っているのは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数です。&lt;br&gt;
まず、ライトサンプルの確率は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ライトの選択確率（単なる乱数選択なので、ライトの個数の逆数）&lt;/li&gt;
&lt;li&gt;ライト上の特定の方向に向けたレイを選択する確率（サーフェースから見たLocal Lightの見かけの立体角の逆数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;の乗算で計算できます。&lt;/p&gt;
&lt;p&gt;そして、BRDFサンプルの確率は、&lt;code&gt;RAB_GetSurfaceBrdfPdf()&lt;/code&gt;で計算されるので、アプリケーション側の処理となりますが、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DiffuseRayの場合、CosineWeightedのPDF&lt;/li&gt;
&lt;li&gt;SpecularRayの場合、GGX_VNDFのPDF&lt;/li&gt;
&lt;li&gt;上記いずれかをDiffuseProbabilityで選択&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、&lt;br&gt;
DiffuseProbablity * CosineWeightedPDF + (1 - DiffuseProbability) * GGX_VNDF_PDF&lt;br&gt;
でBRDFサンプルの確率が計算できます。&lt;/p&gt;
&lt;p&gt;1ピクセルあたりで、RISで検討されるライトサンプル数とBRDFサンプル数はDebug UIの設定で決まっていて、&lt;code&gt;numLocalLightSamples&lt;/code&gt;と&lt;code&gt;numBrdfSamples&lt;/code&gt;に設定されます。このサンプル数を用いて、これらはバランスヒューリスティックで結合されます。これは通常のMulti Importance Samplingと同様の考え方です。&lt;/p&gt;
&lt;p&gt;注意点なのですが、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数の最後では、&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;に設定された&amp;quot;ライト上の特定の方向に向けたレイを選択する確率&amp;quot;で除算しています。ここはRTXDIのトリッキーな部分です。あくまで、実際の&amp;quot;sourcePdf&amp;quot;は、この除算の前の値です。
しかし、RTXDIでは&lt;code&gt;targetPdf&lt;/code&gt;も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算するので、計算のつじつまが合うようになっています。また、&lt;code&gt;taregetPdf&lt;/code&gt;は、シェーディング結果を除算しますが、シェーディング結果も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されるので、こちらも計算のつじつまが合う仕組みになっています。&lt;/p&gt;
&lt;h5 id=&#34;targetpdfの計算&#34;&gt;targetPdfの計算&lt;/h5&gt;
&lt;p&gt;説明が多少前後しましたが、&lt;code&gt;targetPdf&lt;/code&gt;の計算についてです。&lt;code&gt;targetPdf&lt;/code&gt;はRISにおいて、積分可能ではないが、理想的なサンプルの確率密度です。(この値は、簡単には積分できず大きさが正規化できないので、PDFと呼ぶべきではなく、単にWeightと呼ぶべきかもしれません。）
&lt;code&gt;targetPdf&lt;/code&gt;はレンダリングの文脈では、サーフェースがカメラ方向に出すRadianceに比例したレイの分布になるのが一番望ましいです。言い換えれば、カメラの方に最も強く反射される光源へのレイを重点的にサンプリングする分布です。これは、光源のサーフェースでのカメラ方向への反射を計算すればわかります。しかし、光源とサーフェースがVisibleかどうかの判断は、実際にShadow Rayをトレースしなくては分かりません。しかし、これを行えば、実際にレイトレースを行ってシェーディングする処理とまったく変わらなくなり、単にレイのサンプル数を増やすことと同義です。これでは、RISの意味がなくなってしまいまいます。&lt;br&gt;
&lt;code&gt;targetPdf&lt;/code&gt;の計算では、シェーディングの中で最も処理負荷の高いShadow Rayのテスト処理を省略した値（つまりい光源とサーフェースがVisibleかどうかの判断をせずにシェーディングした結果）が用いられます。&lt;/p&gt;
&lt;p&gt;実際の計算は、&lt;code&gt;RtxdiApplicationBridge.hlsli&lt;/code&gt;の&lt;code&gt;RAB_GetLightSampleTargetPdfForSurface()&lt;/code&gt;に実装されています。この関数は&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;という関数を呼び出して、シェーディングの計算を行っています。算出された値の輝度値が、そのまま&lt;code&gt;targetPDF&lt;/code&gt;として扱われます。また、&lt;code&gt;blendedSourcePdf&lt;/code&gt;の項で説明した通り、シェーディングの計算の最後で、値は&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されます。&lt;/p&gt;
&lt;h5 id=&#34;reservoirにサンプルを追加する計算&#34;&gt;Reservoirにサンプルを追加する計算&lt;/h5&gt;
&lt;p&gt;上記の通り、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;の計算が完了すれば、Reservoirにサンプルを追加する処理は簡単です。
&lt;code&gt;RTXDI_StreamSample()&lt;/code&gt;に、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;を乱数と共に渡して、渡したサンプルが選択された場合は、現在選択中のサンプルの情報を更新します。&lt;/p&gt;
&lt;h5 id=&#34;サンプル構築後の処理&#34;&gt;サンプル構築後の処理&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;numLocalLightSamples&lt;/code&gt;の数だけサンプルを構築し、Reservoirに蓄積した後は、現在Reservoirが選択中のサンプルの情報と、Reservoirに蓄積されたRISの情報のみが残ります。ここまでで複数のサンプルを検討していますが、実際にレイトレース処理は行っていません。しかし、Reservoirには、一番選択するべきサンプルの情報が残っています。&lt;br&gt;
サンプルを構築するループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;と思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で正規化されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplebrdf&#34;&gt;RTXDI_SampleBrdf()&lt;/h3&gt;
&lt;p&gt;この関数は、numBrdfSamplesで指定された数だけ、サーフェースのBRDFをもとにサンプルを構築してReservoir蓄積する処理を行います。&lt;br&gt;
この処理は、上記で説明した&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の処理と対を成す処理です。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築-1&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RAB_GetSurfaceBrdfSample()&lt;/code&gt;を呼び出して、BRDFに基づいたサンプルを構築します。そして、実際にレイトレースを行い、Local Light（Emissive Triangle）にHitするかをテストします。Hitしなかった場合は、このサンプルの処理は終了しReservoirに関する処理は行われません。（しかし、このサンプルがReservoirに蓄積されないというわけではなく、正確にはtargetPDF=0として蓄積された扱いになります。これはReservoirの結合時の処理を見ると判明します。）&lt;br&gt;
一方でLocal LightにHitした場合は、&lt;code&gt;targetPdf&lt;/code&gt;と&lt;code&gt;blendedSourcePdf&lt;/code&gt;をそれぞれ計算します。計算は、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と全く同じ計算になります。&lt;/p&gt;
&lt;h5 id=&#34;サンプルの構築後の処理&#34;&gt;サンプルの構築後の処理&lt;/h5&gt;
&lt;p&gt;ここも、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と基本的に同じ計算になります。
サンプル構築のループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、Shadow Rayによって棄却されたサンプルを含めるなら、&lt;code&gt;1.0/numBrdfSamples&lt;/code&gt;であるべきと思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;light-sampleとbrdf-sampleのreservoirの結合処理&#34;&gt;Light SampleとBRDF SampleのReservoirの結合処理&lt;/h3&gt;
&lt;p&gt;再び、&lt;code&gt;main()&lt;/code&gt;の処理に戻ります。&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;によって構築された&lt;code&gt;localReservoir&lt;/code&gt;と、&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;によって構築された、&lt;code&gt;brdfReservoir&lt;/code&gt;を結合する処理を見ていきます。&lt;/p&gt;
&lt;h5 id=&#34;rtxdi_combinereservoirsの処理&#34;&gt;RTXDI_CombineReservoirs()の処理&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;を呼ぶ前に、結合される側のReservoirは、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;が呼ばれている約束になっています。したがって、結合される側の&lt;code&gt;weightSum&lt;/code&gt;は、Finalize前の変数で解釈すると&lt;code&gt;1/targetPDF * 1/M * weightSum&lt;/code&gt;
に相当する値が設定されています。（ただし&lt;code&gt;1/M&lt;/code&gt;はFinalize時に引数で渡す正規化係数）&lt;br&gt;
これに、構造体に格納されている&lt;code&gt;M&lt;/code&gt;と、引数で渡された&lt;code&gt;targetPdf&lt;/code&gt;を乗算したものが、&lt;code&gt;risWeight&lt;/code&gt;という変数に設定されます。逆算すれば、&lt;code&gt;risWeight&lt;/code&gt;は、元の&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;(引数の)targetPdf / (構造体に保存されている)targetPdf&lt;/code&gt;を乗算したものですから、もしも、&lt;code&gt;1/M&lt;/code&gt;で正規化されていて、&lt;code&gt;targetPdf&lt;/code&gt;が同じならば、結局のところ元の&lt;code&gt;weightSum&lt;/code&gt;ということになります。&lt;br&gt;
しかし、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の引数に渡す&lt;code&gt;targetPdf&lt;/code&gt;は、結合元のReservoirで現在選択されているサンプルの、結合先のReservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;なので、もしも、結合先で&lt;code&gt;targetPdf&lt;/code&gt;が異なる場合は、その比が&lt;code&gt;weightSum&lt;/code&gt;に乗算されることになります。しかし、今回のサンプルプログラムでは、Spatio-TemporalなRISの結合を行わないので、&lt;code&gt;targetPdf&lt;/code&gt;は結合の前後で変化しないので、この計算について深く考える必要はありません。&lt;/p&gt;
&lt;p&gt;計算された&lt;code&gt;risWeight&lt;/code&gt;は、結合されるReservoir全体の、結合先Reservoirにおけるウエイトに相当する値です。&lt;br&gt;
後は、サンプル数&lt;code&gt;M&lt;/code&gt;を合算し、&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;risWeight&lt;/code&gt;を加算して、選択サンプルを乱数で決定することで、Reservoirの結合が完了します。&lt;/p&gt;
&lt;h5 id=&#34;localreservoir-と-brdfreservoir-の結合&#34;&gt;localReservoir と brdfReservoir の結合&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の項で説明したとおり、&lt;code&gt;localReservoir&lt;/code&gt;は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;で除算して正規化するところを、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算したうえに、サンプル数 &lt;code&gt;M&lt;/code&gt; を1に設定していました。
これを、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の結合される側のReservoirとして処理をすると、&lt;code&gt;risWeight&lt;/code&gt;は、Finalize前の変数で解釈すると以下のようになります。&lt;br&gt;
&lt;code&gt;1/numMisSamples * weightSum&lt;/code&gt;&lt;br&gt;
この式をわかりやすく書き換えると、以下のようになります。&lt;br&gt;
&lt;code&gt;numLocalLightSamples/numMisSamples * 1/numLocalLightSamples * weightSum&lt;/code&gt;&lt;br&gt;
つまり、&lt;code&gt;localReservoir&lt;/code&gt;の正規化処理と、&lt;code&gt;localReservoir&lt;/code&gt;と&lt;code&gt;brdfReservoir&lt;/code&gt;の、それぞれのサンプル数に基づくバランスヒューリスティックによる結合を同時に処理しているわけです。&lt;/p&gt;
&lt;p&gt;同様に、&lt;code&gt;brdfReservoir&lt;/code&gt;の結合時の&lt;code&gt;risWeight&lt;/code&gt;は、&lt;br&gt;
&lt;code&gt;numBrdfSamples/numMisSamples * 1/numBrdfSamples * weightSum&lt;/code&gt;&lt;br&gt;
と解釈できます。（ここで、&lt;code&gt;brdfReservoir&lt;/code&gt;の生成時に、Shadow RayがMissしてサンプルが破棄されているにも関わらず&lt;code&gt;targetPdf&lt;/code&gt;がゼロのサンプルとして扱われているという解釈ができるわけです。）&lt;/p&gt;
&lt;p&gt;最後に、両者の結合後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を正規化係数1.0で呼び出していますが、両者の正規化はMISのウエイトによって行われているので、計算のつじつまが合うわけです。&lt;/p&gt;
&lt;h2 id=&#34;最後のレイトレースとシェーディング処理&#34;&gt;最後のレイトレースとシェーディング処理&lt;/h2&gt;
&lt;p&gt;ついに、最終的に採用すべきサンプルが確定し、乗算すべきPDFの算出も完了しました。&lt;br&gt;
あとはShadow Rayをキャストして、Visibilityを確認すればよいのですが、&lt;code&gt;brdfReservoir&lt;/code&gt;のサンプルはその生成過程ですでにShadow Rayを使ってVisibilityを確認しているので、もし、こちらのReservoirからサンプルが採用された場合は、この作業は不要なのでスキップするように処理が書かれています。&lt;code&gt;localReservoir&lt;/code&gt;側からからサンプルが選択された場合のみShadow Rayのトレースを行います。&lt;/p&gt;
&lt;p&gt;シェーディング関数の&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;は、RISの過程で何度も呼び出しているので説明不要ですが、ここでも&lt;code&gt;solidAndlePDF&lt;/code&gt;が除算されているので、PDFとの計算のつじつまが合うわけです。
&lt;code&gt;RTXDI_GetReservoirInvPdf()&lt;/code&gt;は、既にFinalizeされているReservoirに対して呼び出す関数で、単に&lt;code&gt;weightSum&lt;/code&gt;を返します。Finalizeが行われていればそこには、PDFの逆数に相当する値が格納されているはずです。
シェーディングが終われば、TonemappingをかけてUAVに書き出すと、全体の処理が完了します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ClearUnorderedAccessView*の使い方</title>
      <link>https://shikihuiku.github.io/memo/clearunorderedaccessview/</link>
      <pubDate>Tue, 07 Sep 2021 21:48:09 +0900</pubDate>
      <guid>https://shikihuiku.github.io/memo/clearunorderedaccessview/</guid>
      <description>





  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/memo/clearunorderedaccessview/Title_hu3abdfca4b9a62c4bb7e1e50724b1ec47_35598_2000x2000_fit_lanczos_3.PNG&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/memo/clearunorderedaccessview/Title_hu3abdfca4b9a62c4bb7e1e50724b1ec47_35598_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;338&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;参考資料&#34;&gt;参考資料&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ID3D12GraphicsCommandList::ClearUnorderedAccessViewUint method (d3d12.h)&lt;br&gt;

&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12graphicscommandlist-clearunorderedaccessviewuint&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12graphicscommandlist-clearunorderedaccessviewuint&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ID3D12GraphicsCommandList::ClearUnorderedAccessViewFloat method (d3d12.h)&lt;br&gt;

&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12graphicscommandlist-clearunorderedaccessviewfloat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12graphicscommandlist-clearunorderedaccessviewfloat&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;なにをするためのものか&#34;&gt;なにをするためのものか&lt;/h1&gt;
&lt;p&gt;Texture(RenderTarget)のクリアはRTVを通じて、ClearRenderTargetView()を使う方が効率的です。DepthBufferはDSVを通じてClearDepthStencilView()でクリアする事が強く推奨されます。
では、ClearUnorderedAccessView*メソッドが使われる場合ですが、一般的にはCreateCommittedResource()やCreatePlacedResource()で作成したBuffer(VertexBufferやIndexBuffer、またUAVを通じてアクセスする汎用的なBuffer)をクリアするためのメソッドです。&lt;/p&gt;
&lt;h1 id=&#34;syntax&#34;&gt;Syntax&lt;/h1&gt;
&lt;p&gt;APIインターフェースは以下の様になっています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void ClearUnorderedAccessViewUint(
  D3D12_GPU_DESCRIPTOR_HANDLE ViewGPUHandleInCurrentHeap,
  D3D12_CPU_DESCRIPTOR_HANDLE ViewCPUHandle,
  ID3D12Resource              *pResource,
  const UINT [4]              Values,
  UINT                        NumRects,
  const D3D12_RECT            *pRects
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大変手間のかかることに、GPU_DESCRIPTOR_HANDLEとCPU_DESCRIPTOR_HANDLEを指定しなければなりません。当然ながらこれらにはクリア対象リソースの全部又は一部の領域を設定したUAVが正しく記述されている必要があります。
また、このメソッドでクリアしなくてはならないリソースの99.99%は、いわゆる1DBufferで、2次元の概念を保持していませんが、クリアの範囲をRECTで指定する必要があります。また、クリアの際に書き込む値はUINT[4]となっています。
初見では疑問しか沸かないこのAPIインターフェースについて少し考えてみたいと思います。&lt;/p&gt;
&lt;h3 id=&#34;なんでuavが二つもいるの&#34;&gt;なんでUAVが二つもいるの？&lt;/h3&gt;
&lt;p&gt;このメソッド最大の面倒な点は、CPU側のUAVとGPU側のUAV二つを用意しなくてはならないところです。ちなみにGPU側のDescriptorHeap(つまりShader Visible Descriptor Heap)にも有効なCPU_DESCRIPTOR_HANDLEはありますが、
これをこのメソッドの引数で渡すことはできません。CPU側のDescriptorHeap(つまりShader VisibleではないDescriptor Heap)を用意してUAVを設定して、そのCPU_DESCRIPTOR_HANDLEを引数で渡す必要があります。&lt;/p&gt;
&lt;p&gt;では、なぜこの二つのUAVが必要なのかというと、このクリア作業のコマンド構築をどのように行うかを考えると少しだけ理解できます。
まず、GPUへのコマンド構築を、対象リソースのアドレス解決を含めて行う場合は、CPU側のDescriptor Heapに設定されたUAVを参照することで、キャッシュの効いた高速なメモリから情報を取得出来ます。
一方で、GPU側にはUAVのアドレスとRECTのみを伝えるシンプルな形でのコマンド構築を行う場合は、GPU側から参照可能なUAVが必要となります。この二つのうちどちらが行われるかは、GPUの実装依存となります。&lt;/p&gt;
&lt;p&gt;しかし、ClearRenderTargetView()やClearDepthStencilView()はGPU側のDescriptorを必要としませんが、クリア作業はGPU側で行われます。
つまり、コマンド構築時にUAVに相当する情報をコマンドバッファに書き込んでいるわけです。ClearUnorderedAccessView*()も同様の作りで問題なかったのではないかと思います。&lt;/p&gt;
&lt;h3 id=&#34;rectでクリア範囲を指定しかも4要素&#34;&gt;RECTでクリア範囲を指定？しかも4要素？&lt;/h3&gt;
&lt;p&gt;UAV全域をクリアする場合は、RECTによる範囲指定は必要ありませんが、UAVの領域の一部をクリアする場合はRECTを指定する必要があります。RECTは(left, top, right, bottom)を指定する形式になっています。
クリア対象はテクスチャでない場合が多いにも関わらず、RECT指定なのは、単純にClearRenderTargetView()やClearDepthStencilView()のAPIに引きずられたためと思われます。また、RECTの範囲は(left, top)
で指定した位置は含みますが、(right, bottom)で指定した位置を含みません。&lt;br&gt;
例えば、R32UINTの16Byte(つまりR32UINT x 4)のUAVがあるとします。このUAVの先頭8Byteをクリアする場合は、RECTの指定は、(0, 0, 2, 1)となります。また、後半の8Byteをクリアする場合は、(2, 0, 4, 1)となります。
RGBA32UINTの64Byte(つまりRGBA32UINT x 4)のUAVの場合は、同じRECTでそれぞれ先頭32Byte、後半32Byteをクリアする事ができます。
また、クリアに使われる値ですが、R32UINTのリソースにはValue[4]の先頭の要素(Value[0])が繰り返し書き込まれます。RGBA32UINTには、Value[4]の要素が全て書き込まれます。
ほとんどのケースでゼロを書き込むと思いますが、思い通りの値でBufferを埋めたい場合はUAVのFormatとValue[4]に工夫が必要です。&lt;/p&gt;
&lt;h3 id=&#34;一体いくつのrectを指定可能なのでしょうか&#34;&gt;一体いくつのRECTを指定可能なのでしょうか？&lt;/h3&gt;
&lt;p&gt;さて、今回これを書こうかなと思った直接の原因についてです。このAPIではRECTの数に上限が無いので、理論上はUINTの上限の個数までRECTが指定可能となっています。しかし実際は、クリア対象のリソースがそこまで大きいものを作成できないでしょう。
また、GPUへのコマンド構築時に何らかの形でRECTの情報を含めないといけませんが、UINTの上限はサイズ的に無理でしょう。今回私は256KByteのリソースにカウンタ記録用の16ByteのUAVを動的に確保するプログラムを作成し、
必要に応じてUAVの提供と、ゼロクリアを行うプログラムを記述しました。1フレームに2000個ほどのカウンタが確保されてクリアが行われました。クリア用にリソース全域を指定したUAVを使ってRECTを2000個設定したところ、
プログラムはこそでクラッシュしました。まぁ、2000は無理かと思いましたので、1023, 511, 255とコマンドを分割しましたがまだクラッシュします。127でクラッシュしなくなりました。私のシステムではこの値が上限値の様です。
さて、私が今書いているプログラムでは一体いくつを上限にするべきなのでしょうか。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projection Matrixについて</title>
      <link>https://shikihuiku.github.io/post/projection_matrix/</link>
      <pubDate>Sun, 27 Dec 2020 00:09:34 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/projection_matrix/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;Projection Matrixは何となくややこしいイメージが強い。実際ややこしい。自分でも勘違いすることがある。
なのでいったんまとめることにする。&lt;/p&gt;
&lt;h2 id=&#34;row-major-column-major-ベクトルとの乗算の順序&#34;&gt;Row Major, Column Major, ベクトルとの乗算の順序&lt;/h2&gt;
&lt;p&gt;Projection Matrixは4x4の正方行列で、メモリに格納するときに行要素を優先して格納すればRow-Major、列要素を優先して格納すればColumn-Majorと呼ばれる。&lt;/p&gt;
&lt;p&gt;Row-Majorは以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} a_1    &amp;amp; a_2    &amp;amp; a_3    &amp;amp; a_4    \\ a_5    &amp;amp; a_6    &amp;amp; a_7    &amp;amp; a_8    \\ a_9    &amp;amp; a_{10} &amp;amp; a_{11} &amp;amp; a_{12} \\ a_{13} &amp;amp; a_{14} &amp;amp; a_{15} &amp;amp; a_{16}  \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;対してColumn-Majorは、以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;\begin{pmatrix} a_1 &amp;amp; a_5 &amp;amp; a_9    &amp;amp; a_{13} \\ a_2 &amp;amp; a_6 &amp;amp; a_{10} &amp;amp; a_{14} \\ a_3 &amp;amp; a_7 &amp;amp; a_{11} &amp;amp; a_{15} \\ a_4 &amp;amp; a_8 &amp;amp; a_{12} &amp;amp; a_{16} \end{pmatrix}&lt;/p&gt;
&lt;p&gt;また、行列の積は可換ではない。たとえば、4次元ベクトルを行列の右から掛けるか左から掛けるかによって演算が変わるので、これには2通りの演算が存在する。&lt;br&gt;
$$
\begin{pmatrix} x^{\prime} \\ y^{\prime} \\ z^{\prime} \\ w^{\prime} \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix} \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x^{\prime} &amp;amp; y^{\prime} &amp;amp; z^{\prime} &amp;amp; w^{\prime} \end{pmatrix} = \begin{pmatrix} x &amp;amp; y &amp;amp; z &amp;amp; w \end{pmatrix} \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;シェーダーを記述する場合は、これらの解釈は実装者に委ねられる。一方で、グラフィックスAPIがこれらの演算を提供する場合もある。
OpenGLのCompatibility Profileでは、Column-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算はベクトルに対して左側からである。
Direct3D 9では、Row-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算は、ベクトルに対して右側からである。&lt;/p&gt;
&lt;h2 id=&#34;座標変換の過程について&#34;&gt;座標変換の過程について&lt;/h2&gt;
&lt;p&gt;次に座標変換の過程について簡単に説明する。頂点シェーダーが出力する4次元ベクトルは、一般的にはView座標系の位置にProjection Matrixを乗算した結果が出力される。
この座標は同次座標と呼ばれ、W成分で(X,Y,Z)を除算して正規化することで、Normalized Device Coordinate(正規化デバイス座標系)に変換される(Perspective Division)。次にViewport変換を行い、Normalized Device Coordinateを、描画用のバッファ（スクリーン）の領域にマッピングする。
多少の用語の違いがあるが、OpenGL、Vulkan、Direct3Dの3つのグラフィックスAPIは概ね同じ座標変換のステップを持っている。ただし各APIごとに座標軸の考え方や値の範囲が異なるので注意が必要である。&lt;/p&gt;
&lt;h2 id=&#34;y軸の反転について&#34;&gt;Y軸の反転について&lt;/h2&gt;
&lt;p&gt;一般的に3D空間上ではY軸を上向きと考える事が多い一方で、2Dスクリーン上では、ピクセルデータを画像の左上から格納する事が多い関係上、Y軸は下向きと考えることが多い。そのため、Projection Matrixによる投影変換、Perspective Division、そしてViewport変換の過程においてY軸を反転させることがある。ここではこれについて説明する。各種変換や用語に関する解説と前後するが、先にここにまとめておく。&lt;/p&gt;
&lt;h4 id=&#34;opengl&#34;&gt;OpenGL&lt;/h4&gt;
&lt;p&gt;OpenGLでは、元来Y軸の反転を行わないという思想の基にAPIが設計されていた。したがって、Viewport変換後のWindow座標系では、画像の左下を原点としてピクセルデータを取り扱う。そのため、Framebufferを画像として表示するときは垂直方向でデータを反転させて表示させるのが一般的である。しかし、現在のOpenGLでは、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective Divisionの際にY軸の符号を反転させる。これによって、Normalized Device CoordinateのY軸の上下が反転するので、Framebufferのデータが画像の左上を原点として格納されるようになる。Perspective Divisionについては、
&lt;a href=&#34;https://www.khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenGL 4.6 Core Pprofile&lt;/a&gt;の13.8に記載がある。&lt;/p&gt;
&lt;h4 id=&#34;direct3d&#34;&gt;Direct3D&lt;/h4&gt;
&lt;p&gt;Direct3Dの座標変換に関しては、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/the-direct3d-transformation-pipeline&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;このドキュメント&lt;/a&gt;に記述がある。これによれば、Perspective DivisionはViewport変換のスケーリングの後に行われており、Y軸の符号反転は、Viewportのスケーリングの係数の符号を逆転し、オフセットを調整することで実装されている。
また、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d9/projection-transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;他のドキュメント&lt;/a&gt;でも、Normalized Device CoordinateのY軸はView座標系と同じ向きに描写されている。したがって、Direct3DではViewport変換でY軸の符号の反転が行われていると解釈できる。
Viewport変換後のScreen座標系では、画像の左上を原点としてピクセルデータを取り扱う。&lt;/p&gt;
&lt;h4 id=&#34;vlukan&#34;&gt;Vlukan&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.khronos.org/registry/vulkan/specs/1.2/pdf/vkspec.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vulkan 1.2&lt;/a&gt;によれば、Perspective DivisionでY軸の符号を反転しない。また、Viewport変換時もY軸の符号を反転しない。そして、Viewport変換後のFramebuffer Coordinateの原点は、左上とされている。そのため、VulkanではProjection Matrixの演算でY軸を反転しない限り、Y軸を上向きとする空間を投影変換した像は上下が反転する。
また、Framebuffer Coordinateとの関連性を考えれば、VulkanのNormalized Device CoordinateのY軸は下向きと考えるのが自然である。&lt;/p&gt;
&lt;h2 id=&#34;perspective-division&#34;&gt;Perspective Division&lt;/h2&gt;
&lt;p&gt;Projection Matrixとの演算を終えた4次元ベクトルは、同次座標を表現する。これを正規化する($w=1$にする）作業は、プログラムなどで制御ができない固定された機能として、グラフィックスAPI側が行う作業となっている。
デフォルトの設定のOpenGL, Vulkan, Direct3Dでは、単純な$w$による除算が行われる。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ \frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;ただし、OpenGLでglClipControl()でGL_UPPER_LEFTが設定されているときは、Perspective Divisionの実行時に$Y$の符号が逆転される。
これは、3D空間上ではY軸を上向きと考えることが一般的である一方、画像フォーマットや、Microsoft Windows や X Window Systemでは、
垂直方向は画面の上から下に向かって座標軸を考えることが多いため、座標軸の向きを入れ替えるための計算である。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ -\frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;正規化された後の(X,Y,Z)はNormalized Device Coordinate（正規化デバイス座標系）を表現する&lt;/p&gt;
&lt;h2 id=&#34;normalized-device-coordinate-ndc&#34;&gt;Normalized Device Coordinate (NDC)&lt;/h2&gt;
&lt;p&gt;NDCは、シェーダーコードが出力した同次座標を、Perspective Divitionにより正規化した後の座標系となる。この座標系は$X,Y$は範囲が[-1, 1]と決まっており、
$Z$は[-1, 1]あるいは[0,1]と決まっている。この座標系は、$X,Y$はRenderTargetピクセル位置を表すスクリーン座標系と線形の関係にある。$Z$は深度バッファの値と線形の関係にある。&lt;/p&gt;
&lt;p&gt;OpenGLでは、glClipControl()でNDCのZ軸の範囲を[-1, 1]か[0, 1]のどちらかで選択することができる。デフォルトでは、GL_NEGATIVE_ONE_TO_ONE[-1, 1]が設定されており、GL_ZERO_TO_ONE[0, 1]を設定することで、Direct3D/Vulkanと同じ範囲になる。また、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective DivisionでY軸の符号が反転されるので、NDCのY軸が反転する。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ndc&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;NDC&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;631&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    NDC
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;viewport変換&#34;&gt;Viewport変換&lt;/h2&gt;
&lt;p&gt;NDCにおける$X,Y$の値の範囲は[-1, 1]だが、これをViewport変換によりRenderTargetのピクセル位置を表すスクリーン座標系に線形にマッピングする。RnederTarget上でのオフセットと幅と高さを指定する事でViewport変換が実現される。
一般的には、オフセットをゼロに設定し、幅と高さをRenderTargetの幅と高さとすることで、NDCの$X,Y$の[-1, 1]の範囲をRenderTargetの全ピクセルにマッピングすることが多いが、描画領域を分けて複数のViewportのレンダリング結果を一枚のRenderTargetにレンダリングする事もある。&lt;/p&gt;
&lt;p&gt;Direct3DはViewport変換時にY軸の上下が入れ替わるように計算される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1207&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;$Z$に関しては、Viewport変換後の深度値の値の範囲を$near, far$の二つの値で指定し、範囲は[0, 1]に収まる様にしなくてはならない。Viewportの$near, far$は深度バッファで使用する値の範囲の事で、
Projection Matrixの$near, far$とは全く意味が異なる。ほとんどの場合では、[0, 1]を指定して、深度バッファが表現できる全ての範囲を使用する。
OpenGLは、NDCのZの範囲を[-1, 1]としているときは、必ずViewport変換時に[near, far]への線形変換が行われる。対して、NDCの範囲が[0, 1]の場合は、Viewport変換の$near, far$が、[0, 1]に設定されている場合は、NDCの$Z$の値がそのまま深度バッファの値として格納される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;374&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;右手系左手系&#34;&gt;右手系、左手系&lt;/h2&gt;
&lt;p&gt;右手系、左手系とは、単位マトリクスのX,Y,Z軸の各ベクトルの、認識している空間におけるマッピングである。右手系は、右手の（親指,人差し指, 中指）を自然な形で直交させたとき、(X, Y, Z)の向きとなる空間を指す。
左手系も同様である。デフォルトのOpenGLとDirect3DのNDCは、はX軸が画面左から右、Y軸が画面下から上、Z軸が画面手前から奥なので、左手系である。
一方で、glClipControl()でGL_UPPER_LEFTを設定したOpenGLとVulkanのNDCは、X軸が画面左から右、Y軸が画面上から下、Z軸が画面手前から奥なので、右手系である。&lt;/p&gt;
&lt;p&gt;よく耳にする話として、OpenGLが右手系でDirect3Dが左手系という話があるが、OpenGLに関してはglFrustum()/glOrtho()という関数が、
右手系のViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するためのProjection Matrixを計算することに起因している。
実際にはProjection MatixにはglLoadMatrixで自由に値を設定することができるので、OpenGLは元来シェーダーを使わなくても、右手系でも左手系でも自在に描画できるはずである。
また、Direct3DにはProjection Matrixを計算するAPIは用意されていない。ただし、ユーティリティ関数群のD3DXには、D3DXMatrixPerspectiveRH()という関数が用意されている。
この関数は右手系ViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。同様に、D3DXMatrixPerspectiveLH()という関数も用意されており、
こちらは、左手系のViewMatrixの+Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。&lt;/p&gt;
&lt;p&gt;このように、ある特定のグラフィックスAPIの座標系が右手系左手系のいずれかに属していると考えること自体が誤りだといえる。&lt;/p&gt;
&lt;h2 id=&#34;projection-matrixの役割&#34;&gt;Projection Matrixの役割&lt;/h2&gt;
&lt;p&gt;さて、ここからが本題ののProjection Matrixに関する説明になる。View座標系からNDC座標系への変換を担うProjection Matrixには、主に4つの要素がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y軸の向きの入れ替え (Vulkan)&lt;/li&gt;
&lt;li&gt;Z軸の向きの入れ替え&lt;/li&gt;
&lt;li&gt;X,Y軸に関する透視投影変換&lt;/li&gt;
&lt;li&gt;Z軸のNDC座標へのマッピング&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透視投影変換を行わない正射影というProjection Matrixもあるが、ここでは割愛する。&lt;/p&gt;
&lt;h2 id=&#34;y軸の向きの入れ替え-vulkan&#34;&gt;Y軸の向きの入れ替え (Vulkan)&lt;/h2&gt;
&lt;p&gt;Vulkan特有の事なので一番最初に解説する。Vulkanは先に説明した通り、NDCのY軸は下向きでPerspective DivisionやViewport変換でY軸の符号反転を行わない。
したがって、Y軸が下向きとなる様に頂点シェーダーの出力を行わなければならない。そのため、View座標系でY軸が上向きになるように座標を扱っていた場合、Projection MatrixでY軸を反転させる必要がある。
具体的にはProjection Matrixの、Y成分のスケーリングとオフセットを担当する成分（以下の場合では$a_{22}, a_{23}$）の符号を入れ替える事で、NDCの上下が反転した結果を得る事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; -a_{22} &amp;amp; -a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44}  \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸の向きの入れ替え&#34;&gt;Z軸の向きの入れ替え&lt;/h2&gt;
&lt;p&gt;同次座標の$w$は、単にPerspective Divisionでの除算に使われるだけでなく、ポリゴン平面上の属性値補間でPerspective Correctionを行うときに使用されるので、$Z$軸に沿って正しく透視投影変換をするときは下記のどちらかの設定になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Z_{View}$の正の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのため、$Z_{View}$と乗算される位置に$1$を設定する。&lt;/li&gt;
&lt;li&gt;$Z_{View}$の負の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$-Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのために$Z_{View}$と乗算される位置に$-1$を設定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、それぞれ$Z_{View}$正負の方向にNDCのZ軸を設定し、透視投影変換をする場合のProjection Matrixである。殆どのProjection Matrixは下記のいずれかである。
余談だが、この、$w$と乗算される行（あるいは列）は特徴的なので、これを手がかりに、メモリにダンプされたマトリクスが、Row-MajorなのかColumn-Majorなのかを簡単に見分ける事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;xy軸に関する透視投影変換&#34;&gt;X,Y軸に関する透視投影変換&lt;/h2&gt;
&lt;p&gt;透視投影変換は、空間にある物体が視点から離れる程小さく投影される様に変換する役割がある。これにより遠近感が演出される。
視点からの距離が二倍になれば、物体は長さで二分の一の大きさで描画されるようにする。したがって$Z$軸向きに透視投影した$X,Y$座標は、$1/Z$に比例する。&lt;/p&gt;
&lt;p&gt;$X,Y$軸に関する透視投影変換は、つまるところ、以下の式の$a, b, c, d$を決定することにある。
$$
X_{NDC} = \frac{a * X_{View}}{Z_{View}} + b
$$
$$
Y_{NDC} = \frac{c * Y_{View}}{Z_{View}} + d
$$&lt;/p&gt;
&lt;p&gt;$a, c$の値が、水平、垂直視野角を決定し、$b, d$がView座標系からNDC座標系に変換するときのオフセットになる。$b, d$は、View座標のZ軸がNDC座標のX,Yの中心を通る場合はゼロになる。
水平、垂直視野角から$a,c$の値を計算する場合は、視野の両端がNDCにおける[-1, 1]になるように計算すれば良い。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;808&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

したがって係数$a,c$は、水平視野角を$\theta$、垂直視野角を$\phi$とすれば以下の様に計算できる。（注意：通常は水平視野角と垂直視野角はアスペクト比を通じた線形の関係ではない。通常は水平視野角か垂直視野角のいずれかを基準として正接を計算して、他方はアスペクト比を乗算することで他方の正接を計算するが、ここでは簡便のためそれぞれの視野角を使う。）
$$
a = \frac{1}{tan(\frac{\theta}{2})}
$$
$$
c = \frac{1}{tan(\frac{\phi}{2})}
$$&lt;/p&gt;
&lt;p&gt;もう一つの、係数$a,c$の計算方法として、$Z_{View}=near$平面上での視野の上下左右に相当する$left, right, top, bottom$を指定する方法である。以下の図には$left, right$による水平視野角を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;992&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

この場合の係数$a,c$は、$l, r, t, b$の値と、$near$平面までの距離$n$を用いて以下の様に表せる。
$$
a = \frac{2n}{r - l}
$$
$$
c = \frac{2n}{t-b}
$$
また、この指定方法の場合は、$l, r$の値がZ軸において対称でない場合は、オフセットの値が発生する。例として、$l, r$によるオフセット計算の図を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野のオフセットの計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu26ba68dc21b12d6542ccc7434c2e9e2e_80001_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野のオフセットの計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu26ba68dc21b12d6542ccc7434c2e9e2e_80001_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1303&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野のオフセットの計算
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上図はView座標系での、$Z_{View}=near$平面上でのオフセット値になるので、NDC座標系に変換するには、$2/(r-l)$を乗算する必要がある。したがって、オフセットの値は以下の様になる。
$$b = -\frac{r+l}{r-l}$$
$$d = -\frac{t+b}{t-b}$$
オフセットの値は、NDC座標系において一定なので、View座標系においては$Z_{View}$の値に比例する。&lt;/p&gt;
&lt;p&gt;また、オフセットがない場合は、$near, left, right, top, bottom$と$\theta, \phi$に、以下のような関係が成り立つ。
$$
l = n \cdot tan(\frac{\theta}{2})
$$
$$
r = -n \cdot tan(\frac{\theta}{2})
$$
$$
t = n \cdot tan(\frac{\phi}{2})
$$
$$
b = -n \cdot tan(\frac{\phi}{2})
$$&lt;/p&gt;
&lt;p&gt;次に、Projection Matrixへの各係数の設定だが、$a, c$の値は、それぞれ$X_{View}$, $Y_{View}$と乗算されるように格納する。$Z_{View}$の除算の部分はPerspective Divisionで行われる。
$b, d$の値は、$Z_{View}$と乗算されるようにProjection Matrixに格納する。これは、のちにPerspective Divisionで相殺されることでオフセット値として機能する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;以下のマトリクスはD3DXMatrixPerspectiveOffCenterLHが算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; -\frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; -\frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;一方で、Z軸の向きの入れ替えるために、$a_{43}$に$-1$を設定している場合は、$Z_{View}$が乗算される時と、除算される時で符号が異なるため、オフセットの係数の符号が変わる。
以下のマトリクスはD3DXMatrixPerspectiveOffCenterRHが算出する係数や、glFrustum()が算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; \frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; \frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸のndc座標へのマッピング&#34;&gt;Z軸のNDC座標へのマッピング&lt;/h2&gt;
&lt;p&gt;Z軸に関する変換は透視変換ではなく、Z軸の値の一定の範囲をNDCで許されている値の範囲に、大小関係を損なわずに変換することである。通常は、View座標系の広大なZ軸の範囲を、NDCで許されている高々[0, 1]程度の範囲にマッピングする圧縮作業である。
簡単に考えれば、View座標系のZの値にオフセットとスケールを適用すれば実現できるが、これは残念ながら推奨されない。
$$Z_{NDC} = e * Z_{View}  + f$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一つ目の理由は、Projection Matrixを使った座標変換による制限によるものである。$X, Y$の値を透視投影変換するためには、同次座標系の$W$の値を$Z$（もしくは$-Z$)の値としなければ、$X,Y$軸に関する透視投影変換が実現できない。そのため$W$の値は決定されていると言える。
この条件では、Projection Matrixとの乗算では、View座標系の$Z$と1次比例の関係を作ることができない。一応ながら、Pixel Shader内で深度バッファに出力する値を直接計算することで実現可能だが、GPUの早期Zカリング機能が無効化されるので実際のアプリケーションの運用では現実的な方法とは言えない。&lt;/li&gt;
&lt;li&gt;二つ目の理由は、透視投影変換後のNDCでの$X,Y$平面（つまりはスクリーンスペース）では、$Z_{View}$は線形性を失う。代わりに$1/Z_{View}$が線形性を持つことになる。
投影変換されたポリゴン平面の深度値を高速に計算するならば、線形性を失った$Z_{View}$に比例した式で計算された値は単純な補間では計算出来ず、計算コストが高く効率が良くない。それよりも、大小関係を（反転しつつも）保ちつつ、スクリーンスペースで線形性を持つ$1/Z_{View}$を使う方が合理的だったという経緯がある。
（ちなみに、スクリーンスペースでテクスチャのU,Vなどの頂点属性値は、$attribute/W$と$1/W$をスクリーンスペースで線形補間し、その結果を除算することで補完された頂点属性値を計算している。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、一般的にGPUでは$Z_{View}$ではなく$1/Z_{View}$を線形変換した結果をNDCのZ座標として採用している。
$$Z_{NDC} = \frac{e}{Z_{View}}  + f$$&lt;/p&gt;
&lt;p&gt;また、このようにすると、深度バッファに整数の格納フォーマットを使った場合、$Z$の値が小さいときほど、多くのBitを使って表現することになる。
つまり、近くの物体ほど深度バッファの多くのBitが割り当てられるので、これは合理的であるとも考える事ができる。また、$1/Z$の線形変換であれば、Projection Matixで一元的に扱えるのも利点である。&lt;/p&gt;
&lt;p&gt;係数$e, f$の決定は、View座標系における、Z軸の範囲である$near, far$の値が、[0, 1] （もしくは[-1, 1]）になるように連立方程式を解くだけで計算できる。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;下記の式を解けば、D3DXMatrixPerspectiveFovLHに設定される係数と符合する。&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$0 = \frac{e}{near} + f$$
$$1 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{far \cdot near}{far-near}$$
$$f = \frac{far}{far - near}$$&lt;/p&gt;
&lt;p&gt;Projection Matrixに設定するときは、$Z_{View}$と乗算される位置に$f$を設定し、$W$(通常は1.0)と乗算される方に$e$を設定する。Perspective Divisionで$W$(この時点では$Z_{View}$)による除算が行われ、上記の式と等価な計算が行われる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{far - near} &amp;amp; -\frac{far \cdot near}{far-near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合は、Projection Matrixの乗算をよく観察する必要がある。$1/Z_{View}$の係数である$e$は、$W_{View}$と乗算して、$-Z_{View}$で除算される。$W_{View}$は通常$1.0$で$-Z_{View}$も正の数なので、上記で求めた$e$がそのまま使える。
一方で、オフセットの$f$は、$Z_{View}$と乗算して、$-Z_{View}$で除算される。したがって、上記で求めたものの符号を反転させたものを使う必要がある。こうして求めた結果は、D3DXMatrixPerspectiveFovRHの係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{near-far} &amp;amp; \frac{far \cdot near}{near -far} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同様の手順で係数$e, f$を求める事ができる&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$-1 = \frac{e}{near} + f$$
$$2 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{2(far \cdot near)}{far-near}$$
$$f = \frac{far + near}{far - near}$$&lt;/p&gt;
&lt;p&gt;それぞれをProjection Matrixに設定すると以下の様になる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合も先ほどと同様の手順となる。これはglFrustum()関数の係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;inverse-z&#34;&gt;Inverse Z&lt;/h2&gt;
&lt;p&gt;深度バッファに浮動小数点の格納フォーマットが使えるとき、NDCにおける深度のマッピングを、[Near, Far]を[0, 1]ではなく[1, 0]にマッピングすることで、$far$付近での深度バッファの精度不足を解消することができる。
NDCが[-1, 1]の場合や、深度バッファの格納フォーマットが整数表現の場合は、Inverse Zを使う利点はない。
精度については詳しくは以下に解説がある。&lt;br&gt;

&lt;a href=&#34;http://www.reedbeta.com/blog/depth-precision-visualized/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Depth Precision - Nathan Reed&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zの設定は簡単で、先ほどの連立方程式の$near$と$far$を入れ替えて解くだけで係数は求まる。レンダリングの際には、深度バッファのクリア値を、1ではなく0に設定し、ラスタライザーの深度テストの条件を反転させればよい。
$$1 = \frac{e}{near} + f$$
$$0 = \frac{e}{far} + f$$
$$e = \frac{far \cdot near}{far - near}$$
$$f = -\frac{near}{far-near}$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;infinite-far-plane&#34;&gt;Infinite Far Plane&lt;/h2&gt;
&lt;p&gt;$far$を無限遠に設定する事で、Far Clippingを実質無効化するとともに、浮動小数点の丸め誤差を低減することができる。Projection Matrixに設定する係数の計算は、今まで求めてきた係数の、$far$を無限大で極限を取れば算出される。
Infinite Far Planeのメリットは、非常に遠くのオブジェクトを描画してもクリッピングされることがないことと共に、空や星などを描画する際に、$W_{View}$をゼロとすることで、$(X_{View}, Y_{View}, Z_{View})$方向の無限遠を描画することができることである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-1&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$e = \lim_{far\to\infty} -\frac{far \cdot near}{far-near} = -near$$
$$f = \lim_{far\to\infty} \frac{far}{far - near} = 1$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いないInfinite Far Planeは、無限遠の深度値が1.0となるが、$Z_{View}$が極大化すると正確に描画できないことがあるので注意が必要である。これはProjection Matrixを使った演算とPerspective Divisionでオフセットを設定する場合に、$Z_{View}$による乗算と除算が行われるため、この値が非常に大きな値になれば、浮動小数点数としての精度を失ってしまうからである。&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-1&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;一方で、Inverse Zを用いた場合のInfinite Far Planeの係数は以下の様に計算される。
$$e = \lim_{far\to\infty} \frac{far \cdot near}{far - near} = near$$
$$f = \lim_{far\to\infty} -\frac{near}{far-near} = 0$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeは、オフセットの係数がゼロなので、$Z_{View}$が極大化する事によるProjection Matrixとの乗算による精度の問題を起こさない。以下は、Inverse Zを用いたInfinite Far PlaneのProjection Matrixである。$a_{43}$は$1$でも$-1$でも変わらない。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; near \\ 0 &amp;amp; 0 &amp;amp; a_{43} &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからz_viewの逆算&#34;&gt;深度バッファから$Z_{View}$の逆算&lt;/h2&gt;
&lt;p&gt;マルチパスレンダリング等を行っていると、描画された深度バッファより、$Z_{View}$を求めたい時がある。計算自体は単なる逆算なので簡単である。&lt;/p&gt;
&lt;p&gt;深度バッファから$Z_{View}$を逆算するためには、まず、Viewport変換を逆変換して$Z_{NDC}$を計算する必要がある。Viewportの$near, far$とNDCの$Z$軸の範囲が分かれば計算は簡単である。深度バッファとNDCの範囲が一致する場合は、この計算は不要である。
$$Z_{NDC}  = \frac{Depth - near_{Viewport}}{far_{Viewport} - near_{Viewport}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-2&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;Projection Matrixに設定した係数$e, f$を使って$Z_{NDC}$から$Z_{View}$を逆算する。$Z_{NDC}$が正の$Z_{View}$方向ならば以下の式で計算できる。
$$Z_{NDC} = \frac{e}{Z_{View}} + f$$
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は符合の操作が必要である。まず、オフセットの値$f$の符合を反転させてあるので、これを反転する必要がある。加えて$Z_{View}$は負の方向なので、最後に符合を反転する必要がある。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-2&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{near + Z_{NDC} (far - near)}$$
Inverse Zで、$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{near + Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeの場合は、式はもっと単純になる。ただし、$Z_{NDC}$がゼロの場合はゼロ除算になるので注意が必要である。
$$Z_{View}= \frac{e}{Z_{NDC}} = \frac{near}{Z_{NDC}}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= -\frac{e}{Z_{NDC}} = -\frac{near}{Z_{NDC}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合-1&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同じ手順で計算する。
Depthから$Z_{NDC}$は以下の通り。
$$Z_{NDC}  = \frac{2(Depth - near_{Viewport})}{far_{Viewport} - near_{Viewport}} -1$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$から$Z_{View}$は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は
$$Z_{View}= -\frac{e}{Z_{NDC} + f} = -\frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからlinear-depthの計算&#34;&gt;深度バッファからLinear Depthの計算&lt;/h2&gt;
&lt;p&gt;上記で示した通り、Projection MatrixのNearとFarが分かれば、深度バッファから$Z_{View}$を復元できるが、
実際には$Z_{View}$よりも、単に線形性がある深度値としてのLinear Depthが欲しいケースが多い。
ここでのLinear Depthは[near, far]が[0, 1]にマッピングされており、かつ線形性を保っているものを指す。
計算は先の式の[near, far]を[0, 1]に線形でマッピングするだけである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-3&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$Z_{Linear}= \{ \frac{far \cdot near}{far - Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{Z_{NDC} \cdot near}{far - Z_{NDC}(far - near)} = \frac{Z_{NDC}}{\frac{far}{near} - Z_{NDC}(\frac{far}{near}-1)} $$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-3&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。[near, far]を[0, 1]にマッピングするので、Inverse Zの大小関係は再び反転するので注意。
$$Z_{Linear}= \{ \frac{far \cdot near}{near + Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{near (1 - Z_{NDC})}{near + Z_{NDC}(far -near)} = \frac{1 - Z_{NDC}}{ 1 + Z_{NDC}(\frac{far}{near} - 1)}$$&lt;/p&gt;
&lt;h2 id=&#34;render-targetのピクセル位置から視線ベクトルの逆算&#34;&gt;Render Targetのピクセル位置から視線ベクトルの逆算&lt;/h2&gt;
&lt;p&gt;G-Buffer等を用いている場合は、Render Targetのピクセル位置から視線ベクトルを逆算したい事も多い。これも上記と同様で、Projection Matrixからの逆算で計算自体は簡単である。&lt;/p&gt;
&lt;p&gt;Render Targetのピクセル位置から視線ベクトルの逆算するためには、Viewport変換を逆変換して$X_{NDC}, Y_{NDC}$を計算する。
$$X_{NDC} = \frac{2(X_{Pixel} - OfsX_{Viewport})}{Width_{Viewport}}-1$$
$$Y_{NDC} = \frac{2(Y_{Pixel} - OfsY_{Viewport})}{Height_{Viewport}}-1$$&lt;/p&gt;
&lt;p&gt;また、Render Targetのピクセル位置ではなく、フルスクリーン描画したポリゴンのUV値から$X_{NDC}, Y_{NDC}$を逆算する方法も良く用いられる。いずれにせよ、範囲が明確なNDCの座標を再計算するのは簡単である。&lt;/p&gt;
&lt;p&gt;次に$Z_{View}=1$の場合の、$X_{View}, Y_{View}$を計算する。ここでの$a,b,c,d$は、先ほど透視投影変換で求めた値で、$\theta, \phi$は水平、垂直視野角である。
$$X_{View1} = \frac{X_{NDC} - b}{a} = tan(\frac{\theta}{2})X_{NDC}$$
$$Y_{View1} = \frac{Y_{NDC} - d}{c} = tan(\frac{\phi}{2})Y_{NDC}$$&lt;/p&gt;
&lt;p&gt;三次元ベクトル$(X_{View1}, Y_{View1}, 1)$は、View座標系の原点からピクセルへのベクトル：視線ベクトルを表すが、長さが1ではないのでライティングの計算をする場合は正規化する必要がある。
一方で、ピクセルのView座標系における位置を求める場合は、このベクトルに$Z_{View}$を乗算することで求める事ができる。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;もっと簡単にまとめたかったが、ダラダラと長くなってしまった。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NVIDIA Falcor を使ってみる</title>
      <link>https://shikihuiku.github.io/post/falcor_getting_started/</link>
      <pubDate>Sun, 08 Nov 2020 11:12:51 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/falcor_getting_started/</guid>
      <description>&lt;h2 id=&#34;nvidia-falcor-とは&#34;&gt;NVIDIA Falcor とは&lt;/h2&gt;
&lt;p&gt;D3D12 をバックエンドとした、リアルタイムレンダリングのフレームワークです。
昨今のゲームエンジンほどの手厚い機能はありませんが、レンダリングAPIの抽象化レイヤーが軽量なのでカスタマイズが容易です。
抽象化レイヤーは、ラスタライズのみならず DXR をサポートしているのが大きな特長で、DXR を使って何か試してみたいときには特に有用なフレームワークになります。
また、DepthPre パスや、GBuffer パス、SVGF パスなどが初めから用意されているので、Raster と RT のハイブリッドレンダリングをテストしたい場合や、RT のデノイザー開発にも対応できます。
また、今回は紹介しませんが、CUDA を使った処理もサポートされているので、必要に応じてこちらも使ってみると面白いかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;早速ですが、環境をセットアップします。とはいっても、基本的には GitHub のリポジトリを Clone してビルドするだけです。&lt;br&gt;

&lt;a href=&#34;https://github.com/nvidiagameworks/falcor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/nvidiagameworks/falcor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2020/11現在の推奨されるビルド環境は以下の通りです&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows 10 version 1809 or newer&lt;/li&gt;
&lt;li&gt;Visual Studio 2019&lt;/li&gt;
&lt;li&gt;Microsoft Windows SDK version 1903 (10.0.18362.1)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;また、必須ではありませんが以下のパッケージや機材を準備することをおすすめします&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GeForce RTXシリーズ (もしくはDXRをサポートしたGPU)&lt;/li&gt;
&lt;li&gt;Windows 10 Graphics Tools (WindowsのOptional Featureからインストールするパッケージ。DebugLayerのために必要)&lt;/li&gt;
&lt;li&gt;NVAPI (NVAPIによる拡張機能を使用したい場合)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;gitのリポジトリをclone&#34;&gt;GitのリポジトリをClone&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;git clone --recursive -b master git@github.com:NVIDIAGameWorks/Falcor.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;nvapiのインストール&#34;&gt;NVAPIのインストール&lt;/h4&gt;
&lt;p&gt;NVAPIを使用する方は、
&lt;a href=&#34;https://developer.nvidia.com/nvapi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ここ&lt;/a&gt;より NVAPI の最新パッケージをダウンロードして、Externals/.packman/nvapi に配置します。
ダウンロードの際にNVIDIAの開発者登録アカウントが必要になります。
次にFalcorConfig.hを開き、_ENABLE_NVAPI を1に設定します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#define _ENABLE_NVAPI 1 // Set this to 1 to enable NVIDIA specific DX extensions. Make sure you have the NVAPI package in your &#39;Externals&#39; directory. View the readme for more information.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;falcortest-プロジェクトをビルド&#34;&gt;FalcorTest プロジェクトをビルド&lt;/h4&gt;
&lt;p&gt;Tools/FalcorTest をビルドすると、Falcor (Falcor本体。レンダリングのバックエンドになるDLL) と、FalcorTest（各種単機能テストのレンダリングが書かれたアプリ）がビルドされます。
実行すると、各種機能がテストされて結果がコンソールに表示されます。詳細なテストではありませんが、まずここで自分の使いたい機能が正しく動作しているかチェックしておきましょう。
幾つかの機能は無条件にスキップされるようになっているので、適宜ソースを書き換えてテストしましょう。&lt;/p&gt;
&lt;p&gt;たとえば、ShaderModel6.5 のサポートを確認したければ、このように書き換えます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if 0
    GPU_TEST(ShaderModel6_4, &amp;quot;Requires shader model 6.4&amp;quot;) { test(ctx, &amp;quot;6_4&amp;quot;); }
    GPU_TEST(ShaderModel6_5, &amp;quot;Requires shader model 6.5&amp;quot;) { test(ctx, &amp;quot;6_5&amp;quot;); }
#else
    GPU_TEST(ShaderModel6_4) { test(ctx, &amp;quot;6_4&amp;quot;); }
    GPU_TEST(ShaderModel6_5) { test(ctx, &amp;quot;6_5&amp;quot;); }
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;TraceRayInline は、2020/11現在は、Falcor内にはシェーダーのコンパイルが通るかのテストコードしかありませんが、とりあえずテストすることが出来ます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if 0
    GPU_TEST(testTraceRayInlineAPI, &amp;quot;Requires shader model 6.5&amp;quot;)
#else
    GPU_TEST(testTraceRayInlineAPI)
#endif
    {
        // We don&#39;t actually run the program, just make sure it compiles.
        ctx.createProgram(&amp;quot;Tests/Slang/TraceRayInline.cs.slang&amp;quot;, &amp;quot;testTraceRayInlineAPI&amp;quot;, Program::DefineList(), Shader::CompilerFlags::None, &amp;quot;6_5&amp;quot;);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;サンプルコードに目を通す&#34;&gt;サンプルコードに目を通す&lt;/h2&gt;
&lt;h3 id=&#34;projecttemplate&#34;&gt;ProjectTemplate&lt;/h3&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-project-template&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ProjectTemplate_hu17968daff6882fcdd0a6eccf1134604b_25340_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Project Template&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ProjectTemplate_hu17968daff6882fcdd0a6eccf1134604b_25340_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Project Template
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Samples/ProjectTemplate をビルドして実行すると、ウィンドウが開き、緑の画面とGUIが表示されます。チュートリアルではよくあるお約束の RenderTarget をクリアしているだけのプログラムになります。
プログラム本体はほんの数行で、Guiにボタンを追加するのと画面を緑色でクリアするコードが記述されているだけです。D3D12のAPIは抽象化されており、Render Target のクリアはこの一行で行われます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    pRenderContext-&amp;gt;clearFbo(pTargetFbo.get(), clearColor, 1.0f, 0, FboAttachmentType::All);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RenderingContext は、メンバーに LowLevelContextData クラスを保持しており、これが D3D12 の CommandAllocator / CommandList / CommandQueue などを保持しています。
D3D12Device はグローバル変数としてアクセス可能で、一通りのAPIの抽象化レイヤーが提供されていますが、ネイティブ API へのアクセスも簡単なものになっています。
一方で、Guiのクラスを覗くと、Dear ImGui がGUIのバックエンドとして使われているのが分かります。&lt;/p&gt;
&lt;h3 id=&#34;shadertoy&#34;&gt;ShaderToy&lt;/h3&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-shadertoy&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ShaderToy_hu2b3746a333fae861e5f641d80618c199_316717_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ShaderToy&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ShaderToy_hu2b3746a333fae861e5f641d80618c199_316717_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;759&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ShaderToy
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Samples/ShaderToy プロジェクトをビルドすると、フルスクリーンの PixelShader のパスで、シェーダー Samples/ShaderToy/Toy.ps.slang が実行されます。
初期化処理の OnLoad で幾つかのステートを作成していますが全部不要な処理です。初期化処理で実際に必要とされる処理は下記の一行のみです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load shaders
mpMainPass = FullScreenPass::create(&amp;quot;Samples/ShaderToy/Toy.ps.slang&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;描画時の onFrameRender では、初期化した mpMainPass のConstant Buffer の値を設定して execute を呼び出して描画しているだけです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mpMainPass[&amp;quot;ToyCB&amp;quot;][&amp;quot;iResolution&amp;quot;] = float2(width, height);
mpMainPass[&amp;quot;ToyCB&amp;quot;][&amp;quot;iGlobalTime&amp;quot;] = (float)gpFramework-&amp;gt;getGlobalClock().getTime();
mpMainPass-&amp;gt;execute(pRenderContext, pTargetFbo);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このように FullScreenPass クラスを使うと、ポストプロセス処理などで使うフルスクリーンのPixelShaderパスを簡単に構築することができます。Falcor には、FullScreenPass 以外にも極めて基本的な Dispatch や Draw を呼び出す機能がクラスとして標準で用意されています。これらは、Falcor プロジェクトの RenderGraph/BasePasses にあるので、興味があれば参照してください。&lt;/p&gt;
&lt;h3 id=&#34;modelviewer&#34;&gt;ModelViewer&lt;/h3&gt;
&lt;p&gt;Samples/ModelViewerをビルドして実行します。Gui の Load Model をクリックして、Falcor/Media/teapot.obj を読みます。（他にも、Media/Arcade/Arcade.fbxも読み込むことができます）
Falcor のアセット読み込みのバックエンドは、
&lt;a href=&#34;https://github.com/assimp/assimp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;assimp&lt;/a&gt; を使用しています。ライトとカメラの設定が無いので、初期状態ではカメラはteapotの中にありますし、レンダリングが真っ黒ですが、ASWDでカメラを動かせば、とりあえずジオメトリが読み込まれていることが分かります。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer01_hua46a1c90710a4eb0b2f7280e44c59e65_49694_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer01_hua46a1c90710a4eb0b2f7280e44c59e65_49694_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ModelViewer.ps.slang をチェックすると、単純にシーン上のライトをイテレーションして、マテリアルを評価しています。したがって、ライトさえ配置されていれば正しくレンダリングされるように書かれています。なので、ModelViewer.cpp の、SceneBuilder がファイルを読み終わった後の箇所で、以下の様にライトの数を確認してライトが無ければ DirectionalLight を追加するように処理を書き加えて実行します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (pBuilder-&amp;gt;getLightCount() == 0) {
    // no lights.
    pBuilder-&amp;gt;addLight(DirectionalLight::create());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これで、シーン上にライトが無い場合はデフォルトのDirectionalLightが追加されるので、ライティングの様子が見れるようになりました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-with-a-light&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer02_hu4af4f192b6c567b25173183ebc184c2f_101873_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer with a light&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer02_hu4af4f192b6c567b25173183ebc184c2f_101873_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer with a light
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;次に、Media/Arcade/Arcade.fscene を読み込んでみます。fscene は、Json で記述された Falcorのシーン格納形式で、ライトとカメラの定義が含まれているので、特にソースコードを変更することなくライティングの様子を見ることができます。Arcade.fscene はリファレンスとして Arcade.fbx と Light.fbx を参照して、内部にライトとカメラの定義を保持しています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-fscene&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer03_hu0f84b7f164f683e83adc36f3959be573_2780056_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer fscene&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer03_hu0f84b7f164f683e83adc36f3959be573_2780056_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer fscene
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ModelViewer のプログラムを見てみると、初期化時に WireFrame描画用の RasterStateと、幾つかのCullModeの RasterStatreを作っています。DepthStencilStateも幾つか作っています。これらはGui上で選択して使用する事ができます。
シェーダープログラムは、アプリケーション側は PixelShader のみ指定して、頂点シェーダーと DrawCall の呼び出しは、Falcor 側の mpScene-&amp;gt;render() に任されています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-wire-frame&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer04_hucc614a67c5fbad2ebf671b0c2d57c68c_121887_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer wire frame&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer04_hucc614a67c5fbad2ebf671b0c2d57c68c_121887_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer wire frame
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;hellodxr&#34;&gt;HelloDXR&lt;/h4&gt;
&lt;p&gt;Samples/HelloDXRをビルドして実行します。先ほどの Arcade/Arcade.fscene が起動時から読み込まれています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-hello-dxr-rtx-on&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR01_hu0dad088326deb0b53f9918ad0c5ed738_3254139_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Hello DXR (RTX ON)&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR01_hu0dad088326deb0b53f9918ad0c5ed738_3254139_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Hello DXR (RTX ON)
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-hello-dxr-rtx-off&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR02_hu3ace97392dbdea1ff721805c3675d6a4_2669467_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Hello DXR (RTX OFF)&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR02_hu3ace97392dbdea1ff721805c3675d6a4_2669467_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Hello DXR (RTX OFF)
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Ray Traceのチェックボックスで、DXRの有効/無効を切り替える事ができ、影と反射の効果の有無が違いとして見て取れます。
ソースコードを見ると、DXRが無効な時のレンダリングは、Falcorの組み込みレンダリングパスのRasterScenePassが使用されています。設定されているピクセルシェーダーは、ModelViewerとほぼ同じで、Falcorの組み込みシェーディング関数を使用しています。つまり、先の ModelViewer のサンプルプログラムは、RasterState の変更をしないのであれば、RasterScenePassを使って一行で記述できるという事です。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    mpRasterPass = RasterScenePass::create(mpScene, &amp;quot;Samples/HelloDXR/HelloDXR.ps.slang&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;main&amp;quot;);
    .
    .
    .
    mpRasterPass-&amp;gt;renderScene(pRenderContext, pTargetFbo);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DXR側は、HelloDXR.rt.slangに記述されている各シェーダーをShaderLibraryとしてコンパイルして、RtProgram::Descを使ってHitGroupの定義を行っています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    RtProgram::Desc rtProgDesc;
    rtProgDesc.addShaderLibrary(&amp;quot;Samples/HelloDXR/HelloDXR.rt.slang&amp;quot;).setRayGen(&amp;quot;rayGen&amp;quot;);
    rtProgDesc.addHitGroup(0, &amp;quot;primaryClosestHit&amp;quot;, &amp;quot;primaryAnyHit&amp;quot;).addMiss(0, &amp;quot;primaryMiss&amp;quot;);
    rtProgDesc.addHitGroup(1, &amp;quot;&amp;quot;, &amp;quot;shadowAnyHit&amp;quot;).addMiss(1, &amp;quot;shadowMiss&amp;quot;);
    rtProgDesc.addDefines(mpScene-&amp;gt;getSceneDefines());
    rtProgDesc.setMaxTraceRecursionDepth(3); // 1 for calling TraceRay from RayGen, 1 for calling it from the primary-ray ClosestHitShader for reflections, 1 for reflection ray tracing a shadow ray

    mpRaytraceProgram = RtProgram::create(rtProgDesc);
    mpRtVars = RtProgramVars::create(mpRaytraceProgram, mpScene);
    mpRaytraceProgram-&amp;gt;setScene(mpScene);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Closest Hitのシェーディングの関数は、Rasterで使用しているものと同一で、prepareShadigData()でサーフェースの情報を取得して、envalMaterial()でシェーディングを行っています。
いる。ただし、ライトの評価の際に checkLightHit() で ShadowRay を飛ばして遮蔽のチェックをしています。また、リフレクションの Ray を飛ばしており、GGXのアルファ値（Roughness相当のパラメーター）で適当にブレンディングしています。（PBRではない） そのため、DXRを有効にした場合は、影と反射が追加されたレンダリングになります。&lt;/p&gt;
&lt;h2 id=&#34;mogwaiに目を通す&#34;&gt;Mogwaiに目を通す&lt;/h2&gt;
&lt;h4 id=&#34;注意&#34;&gt;注意&lt;/h4&gt;
&lt;p&gt;ビルドの際にコンパイルエラー等は発生しませんでしたが、実行時にPythonのBindingを設定している個所で例外が発生しました。この問題は、VisualStudioをアップデートすることで解決しました。動作確認は Microsoft Visual Studio Professional 2019 - Version 16.7.7 を用いて行いました。同様の問題が発生した場合は、VSのバージョンをチェックすると良いかもしれません。&lt;/p&gt;
&lt;h4 id=&#34;mogwai&#34;&gt;Mogwai&lt;/h4&gt;
&lt;p&gt;Falcorは Pybind11を使って、RenderGraph を Python で記述するための機構を持っています。Mogwaiはその機構を使ったフレームワークと呼べると思います。
ビルドすると、Pythonで記述されたいくつかの RenderGraph が、実行ファイルの出力先の Data フォルダに用意されます。
起動後に File-&amp;gt;Load Scriptで Data/FowardRenderer.py を読み込みます。これで Foward Rendering の RenderGraph が読み込まれて、使用できるようになります。
次にFile-&amp;gt;Load Sceneで、Falcor/Media/Arcade/Arcade.fsceneを読み込みます。
すると、サンプルの Model Viewerと同様にレンダリングが確認できると思います。しかし、ModelViewerとは異なり、先ほど読み込んだ Pythonのスクリプトに記述された RenderGraph によってレンダリングの動作が定義されています。&lt;/p&gt;
&lt;p&gt;ここで、File-&amp;gt;LoadScript で、MinimalPathTracer.py を読み込むことで、パストレーシングのRenderGraphを、追加で読み込むことができます。
HUD上でRenderGraphを切り替えると、MinimalPathTracerにレンダリングパスを切り替えることができます。このように、Mogwaiを使うと、python で記述された複数の RenderGraph を動的に切り替える事ができます。これはレンダリングの比較評価等を行う際に有用だと言えると思います。&lt;/p&gt;
&lt;p&gt;RenderGraph を ForwardRenderer に戻してEditボタンを押すと、RenderGraph の編集ができます。
基本的には FowardRenderer.py に書かれている内容そのままですが、RenderGraph を視覚的に確認してエディットすることもできます。ただ、オマケ的な要素が強く、実際の RenderGraph の構築では、Pythonスクリプトを直接編集したほうが早いです。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-mogwai-render-graph&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai01_hucf237075bdd7b9e9afe14ce554f09d70_147063_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Mogwai Render Graph&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai01_hucf237075bdd7b9e9afe14ce554f09d70_147063_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Mogwai Render Graph
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;rendergraphのノード&#34;&gt;RenderGraphのノード&lt;/h4&gt;
&lt;p&gt;RenderGraph の個々のノードは、Falcor の RenderPass クラスを継承したクラスです。
たとえば DepthPrePass ノードは DepthPass.dll として事前にビルドされており、これが ForwardRenderer.py の中でインポートされて、他のノードと接続されることでレンダリングパスが構築されています。他にも、GBuffer描画や、CascadedShadowMap, SSAO, Antialias, Tonemapping, SkyBox, それからレイトレーシング用に、MinimalPathTracer, AccumulatePass, SVGFPassなど、他にも幾つかの有用なノードが用意されています。これら RenderGraph のノードは個々のDLLとしてコンパイルされています。そのためのプロジェクトは、Falcor ソリューション内の RenderPasses フォルダに配置されているので確認してみてください。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-mogwai-render-graph&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai02_hu6c2dd509207f4d3927ccb0a42e7f7735_35792_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Mogwai Render Graph&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai02_hu6c2dd509207f4d3927ccb0a42e7f7735_35792_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;592&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Mogwai Render Graph
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;depthpassに目を通す&#34;&gt;DepthPassに目を通す&lt;/h4&gt;
&lt;p&gt;RenderGraph の一つのノードの例として、DepthPass ノードを見てみます。DepthPass ノードは RenderPass クラスを継承して実装され、DepthPass.dllとして配置され、Falcor のレンダリングに使用されます。
ヘッダーファイルを見ると、Gui の描画やリフレクションをサポートする関数、シーン情報にアクセスをするための setScene があります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    static SharedPtr create(RenderContext* pRenderContext = nullptr, const Dictionary&amp;amp; dict = {});

    virtual RenderPassReflection reflect(const CompileData&amp;amp; compileData) override;
    virtual void execute(RenderContext* pContext, const RenderData&amp;amp; renderData) override;
    virtual void setScene(RenderContext* pRenderContext, const Scene::SharedPtr&amp;amp; pScene) override;
    virtual void renderUI(Gui::Widgets&amp;amp; widget) override;
    virtual Dictionary getScriptingDictionary() override;
    virtual std::string getDesc() override { return kDesc; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;reflect()を見ると、レンダリングの出力として、2DのDepthStencilを出力することが分かります。入力は無いので、setSceneで設定されたシーンから取得できるカメラとジオメトリを用いてレンダリングすることが想像できます。
DepthBuffer のフォーマットはクラス内部に保持されて、Guiによる設定を介して変更できるようです。その結果がリフレクションの出力ピンに反映されます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RenderPassReflection DepthPass::reflect(const CompileData&amp;amp; compileData)
{
    RenderPassReflection reflector;
    reflector.addOutput(kDepth, &amp;quot;Depth-buffer&amp;quot;).bindFlags(Resource::BindFlags::DepthStencil).format(mDepthFormat).texture2D(0, 0, 0);
    return reflector;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;描画解像度の設定は無く、DLLの外部で用意されたDepthStencilバッファをBindしてレンダリングする仕組みになっています。シェーダーは、Slangで記述されたピクセルシェーダーが一つだけあります。
中を確認すると、prepareShadingDataを呼び出しています。これは、アルファが完全に透明だった場合に、この関数のなかでDiscardが呼ばれるためです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void main(VSOut vOut, uint triangleIndex : SV_PrimitiveID) : SV_TARGET
{
    // Calling prepareShadingData() to discard pixels that fail alpha test. The pixel shader has no other side effects.
    float3 viewDir = normalize(gScene.camera.getPosition() - vOut.posW);
    prepareShadingData(vOut, triangleIndex, viewDir);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ちなみに、描画解像度の設定は、Falcor の RenderGraph 側にあります。RenderGraphCompiler::allocateResources() が RenderGraph の変更や描画解像度変更をトリガーとして、使用されている出力ピンのリソースを ResourceCache に登録します。その時に、各種 RnederTarget の解像度の設定が行われます。&lt;/p&gt;
&lt;p&gt;実際に RenderGraph のノードを実装するならば、ぜひ Docs/
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/Falcor/blob/master/Docs/Tutorials/02-Implementing-a-Render-Pass.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorials&lt;/a&gt; をご一読する事をお勧めします。&lt;/p&gt;
&lt;h2 id=&#34;最後に&#34;&gt;最後に&lt;/h2&gt;
&lt;p&gt;ビルドして実行するだけではいまいち概要がつかみにくい Falcor ですが、リポジトリの
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/Falcor/blob/master/Docs/index.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ドキュメント&lt;/a&gt;を読めば、この記事に書いてあることを含めて記載があります。ソースコードの規模もあまり大きくないので、全体の把握も比較的容易だと思います。アセットもFBX形式が読み込めるので、手元のアセットでテストしたい場合なども比較的短時間でセットアップできるのではないでしょうか。今回は紹介していませんが、
&lt;a href=&#34;https://developer.nvidia.com/orca&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ORCA&lt;/a&gt;をはじめ、CC-BY等のオープンライセンスの元で公開されているアセットなどもあるので、これらを活用してレンダリングのテストを行う事も可能だと思います。&lt;/p&gt;
&lt;p&gt;今回は、簡単にですが Falcor を触ってみました。この手の軽量なレンダリングフレームワークというのは、自作含めて多数あると思いますが、RasterとDXRをシームレスにサポートしている軽量フレームワークはあまり見かけません。
そういう意味ではユニークな存在かもしれません。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Device Removalの処方箋 - 補足資料</title>
      <link>https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/</link>
      <pubDate>Fri, 04 Sep 2020 18:00:00 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/</guid>
      <description>&lt;h2 id=&#34;これは補完資料です&#34;&gt;これは補完資料です&lt;/h2&gt;
&lt;p&gt;この記事は、CEDEC2020での講演 &amp;ldquo;Direct3D 12 Device Removalの処方箋&amp;rdquo; において、時間内に説明することができなかった部分に関して解説するためのものです。
CEDEC2020で当該講演を聴講された方に向けて書いています。この記事単体では不完全です。タイムシフト視聴や、CEDiLにアクセス可能な方は、先にそちらをご覧になることをお勧めします。&lt;/p&gt;
&lt;h2 id=&#34;device_removedとは&#34;&gt;DEVICE_REMOVEDとは&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DXGIとD3D12API返すHRESULTに設定されるエラー&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正式にはDXGIのエラーコード。DXGI_ERROR_DEVICE_REMOVED&lt;/li&gt;
&lt;li&gt;殆どの場合は、IDXGISwapChain::Present()呼び出しの際に返される&lt;/li&gt;
&lt;li&gt;ID3D12DeviceD3D12の一部のメソッド、リソースの作成、Mapなどを実行した際にも返される&lt;/li&gt;
&lt;li&gt;ID3D12Device::GetDeviceRemovedReasonの呼び出しでも返される&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ID3D12Device::GetDeviceRemovedReasonを呼び出すことで以下の様な具体的なエラー原因が取得できる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_HUNG&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_REMOVED&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_RESET&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DRIVER_INTERNAL_ERROR&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_INVALID_CALL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;FormatMessage()や、_com_errorでエラーの意味を取得できる&lt;br&gt;
Device Removed Reason for 887a0006 DXGI_ERROR_DEVICE_HUNG
The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device_removedが発生する原因について&#34;&gt;DEVICE_REMOVEDが発生する原因について&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDは、D3D12APIを通じて、GPUやドライバーで発生したエラーの結果に過ぎない。OSやD3D12ランタイムが、コンテキストの実行を継続するべきでは無いと判断した場合に発生する。
ただ、
&lt;a href=&#34;https://www.youtube.com/watch?v=VaGcs5-W6S4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alex DunnがGDC2018で説明&lt;/a&gt;した通り、大きく分けて２つの種類にカテゴライズする事ができる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TDR（Timeout Detection and Recovery）によるDEVICE_REMOVED&lt;br&gt;
ドライバーやGPUがOSに対して一定時間内に応答しなかった場合に、OSが発生させるDEVICE_REMOVED。OSはシステム全体のHungを避けるため、DEVICE_REMOVEDを発生させてドライバーをリセットする。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ドライバーのコードパスで想定していない長時間の処理があった場合&lt;/li&gt;
&lt;li&gt;シェーダー内で長時間処理がかかった場合（シェーダー内無限ループ等）&lt;/li&gt;
&lt;li&gt;Signal,Waitの設定ミスで長時間Fenceが解決しなかった場合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;エラーの検出によるDEVICE_REMOVED&lt;br&gt;
何らかの看過できないエラーの発生に伴いOSやD3D12ランタイムが発生させるDEVICE_REMOVED。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPUで発生したPage Fault
存在しないリソースへのアクセスや、宣言した利用用途と異なるアクセス。&lt;/li&gt;
&lt;li&gt;不正な上書き等によるCommand Listの破損
結果的にドライバーやGPUが不正な実行コマンドを受け取る。&lt;/li&gt;
&lt;li&gt;D3D12ランタイムやドライバーによるエラーの検出
許可されていないリソースステートのリソースへのアクセス。各種リソースのアラインメント違反。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpuとcpuの時間のずれ&#34;&gt;GPUとCPUの時間のずれ&lt;/h2&gt;
&lt;p&gt;ここでは、CPUコードのデバッグと、DEVICE_REMOVEDの追跡の決定的な違いについて説明する。
CPUの実行コードは、デバッガがアタッチされている状況下では即時的であり、エラーが発生すれば直ちにプログラムの実行を停止して、デバッガに処理を返すことで、エラーが起きた瞬間の状況が分かる。&lt;br&gt;
これに対して、DEVICE_REMOVEDの発生は、CPUのコードと全く同期しないタイミングで発生する。そのため、CPUがDEVICE_REMOVEDを受け取った瞬間にデバッガで処理を止める事にはほとんど意味がない。&lt;/p&gt;
&lt;p&gt;以下のスクリーンショットはGPUViewというツールでCPUとGPUの処理時間を示したものになる。画面左から右に時間の経過を表している。中央の大きなスタックの中でハイライトされているのは、
あるGPU処理の塊となる、バケットである。ご覧の通り画面の左端で生成されたバケットは、画面の右側でスタックの最下段に到達している。この時点GPUの処理の対象となる。この間3フレーム分の時間が経過している。
もし、このGPU処理のなかでDEVICE_REMOVEDが発生したら、CPUがそのエラーを受け取る可能性があるのは、この時点以後となるので、CPUから見るとコマンド生成から3フレーム以上遅れてDEVICE_REMOVEDを受け取る事になる。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpuとcpuの処理時間のずれ&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/GPUView_Framelatency_clipped_hu8d16dffa687010e8cb8fe6da31428ef9_85614_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;GPUとCPUの処理時間のずれ&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/GPUView_Framelatency_clipped_hu8d16dffa687010e8cb8fe6da31428ef9_85614_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;870&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPUとCPUの処理時間のずれ
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;これが、DEVICE_REMOVEDの追跡が難しい原因の一つである。&lt;/p&gt;
&lt;h2 id=&#34;device_removedの対処法&#34;&gt;DEVICE_REMOVEDの対処法&lt;/h2&gt;
&lt;p&gt;GPU上で発生する様々なエラーをデバッグする方法として、D3D12APIは以下の方法を提供している&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debug Layer&lt;br&gt;
昔からあるが、DEVICE_REMOVEDの原因の追跡において最も有効な方法の一つ&lt;/li&gt;
&lt;li&gt;GPU Based Validation&lt;br&gt;
比較的新しく導入されたDebug Layerの拡張。CPU側のValidationでは追跡できない問題を検出する&lt;/li&gt;
&lt;li&gt;DRED1.2&lt;br&gt;
新しく導入されたDEVICE_REMOVEDの追跡方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上記3つのうち、先の二つは、DEVICE_REMOVEDが発生する前に起きているD3D12上のエラーの追跡に使うのに対して、
DREDは、DEVICE_REMOVEが発生した後に、発生した箇所を見つけ出すためのもので、用途が完全に異なる。どちらも有用なので組み合わせて使う。&lt;/p&gt;
&lt;h2 id=&#34;debug-layer&#34;&gt;Debug Layer&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDに対する処方の第一候補は、Debug Layerである。これを有効にすることにより、D3DのランタイムがValidationを積極的に行い、Debug Outputにメッセージを送出するようになる。
DEVICE_REMOVEDが発生する前に出力されるDebug Layerのメッセージは、DEVICE_REMOVEDの発生原因を調査する上での貴重な手がかりになる。&lt;/p&gt;
&lt;h3 id=&#34;debug-layerの有効化&#34;&gt;Debug Layerの有効化&lt;/h3&gt;
&lt;p&gt;Debug Layerはアプリケーション自身で有効にすることもできるし、外部から強制的に有効にすることもできる。&lt;br&gt;
外部から強制的に有効にする際は、dxcpl.exe(GUIツール)やd3dconfig.exe(コマンドラインツール)を用いる。インストールはWindows10の、Settings→Add an optional feature→ Add a feature→ Graphics Toolsを選択する事で行う。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-dxcplのインストール&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Graphics_tools_hud17edd7f0016c7970e8d79671c2245cb_50866_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;dxcplのインストール&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Graphics_tools_hud17edd7f0016c7970e8d79671c2245cb_50866_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;930&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    dxcplのインストール
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;外部からDebug Layerを有効にする際は、dxcpl.exeかd3dconfg.exeを用いて、ターゲットとなるアプリケーションの名前を事前に登録し、Debug Layerを強制的に有効にする設定にする。設定内容はdxcplとd3dconfigで共有され、システム全体で有効になるので注意が必要である。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Dxcpl_addname_hucbdb74109a3fd183c1975591731fc9c0_227302_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Dxcpl_addname_hucbdb74109a3fd183c1975591731fc9c0_227302_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;902&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    デバッグ対象アプリケーションを登録する
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/D3dConfg_hu66e5d0a7c318d4262e1366fb00f0e524_17980_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/D3dConfg_hu66e5d0a7c318d4262e1366fb00f0e524_17980_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;466&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    デバッグ対象アプリケーションを登録する
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;アプリケーション内部で設定する場合は、CreateDeviceを実行する前に、ID3D12Debugインターフェースを取得して、EnableDebugLayer()を呼び出す事で有効にできる。
この場合は、dxcpl.exeやd3dconfig.exeによるターゲットアプリケーション名の登録は必要ない。登録してある場合は、debug-layerの設定はApplication Controlledに設定することでAPIから明示的に有効にした場合のみDebug Layerが有効になる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Create Deviceの前に設定する
{
    ComPtr&amp;lt;ID3D12Debug1&amp;gt; debug1;
    if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;debug1))))
    {
        debug1-&amp;gt;EnableDebugLayer();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;debug-layerの出力&#34;&gt;Debug Layerの出力&lt;/h3&gt;
&lt;p&gt;Debug Layerが有効になっている状態では、アプリケーションのD3DAPIの使用において何らかの間違いが検出されれば、エラーの内容がデバッグ出力ストリームに文字列として出力される。出力メッセージはVisual StudioやDbgviewなどのツールを使って確認することができる。出力内容は、その深刻度に応じてグループ分けされている。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Info&lt;br&gt;
リソースの確保や開放などを通知する。デフォルトでMuteされている。&lt;/li&gt;
&lt;li&gt;Warning&lt;br&gt;
APIの仕様から逸脱していないが、パフォーマンスの問題や、バグの発生の原因になりそうな状況を通知する。&lt;/li&gt;
&lt;li&gt;Error&lt;br&gt;
APIの仕様から逸脱した状況が検出された場合に通知する。ただ、これが出力されるから、直ちにDEVICE＿REMOVALが発生するという訳ではない。&lt;/li&gt;
&lt;li&gt;Corruption&lt;br&gt;
リソースやオブジェクト（オブジェクト自身というよりは、多くはそのハンドル等）が破損していることが検出された場合に通知する。&lt;/li&gt;
&lt;li&gt;Message&lt;br&gt;
上記に当てはまらない情報を通知する（メモリ不足等）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、例としてResourceBarrierの遷移前リソースステートの指定が間違っていた場合に出力されたエラーである。ちなみにこのプログラムは、Debug Layerが無効な状態でも有効な状態でも正常に動作した。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D3D12 ERROR: ID3D12CommandList::ResourceBarrier: Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:&#39;MyColorTex&#39;) (subresource: 0) specified by transition barrier does not match with the current resource state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) (assumed at first use) [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH]
D3D12 ERROR: ID3D12CommandQueue::ExecuteCommandLists: Using ResourceBarrier on Command List (0x000001AE3B802060:&#39;MyCommandList_Direct&#39;): Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:&#39;MyColorTex&#39;) (subresource: 0) specified by transition barrier does not match with the state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) specified in the previous call to ResourceBarrier [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Debug Layerはこのエラーを二か所で検出した。一つはID3D12CommandList::ResourceBarrier()呼び出し時に、もう一つは、ID3D12CommandQueue::ExecuteCommandLists()呼び出し時に検出した。しかしこれは、この種のエラーは常に二か所で検出されるという意味ではない。コマンドリストは他のコマンドリストの生成タイミングと関係なく生成する事ができ、その際のコマンドリスト作成時のリソースのステートは未確定になる場合がある。そのためDebug Layerは複数の箇所で可能な限りエラーの特定を試みる。上記の場合では、コマンドリスト作成時の対象リソースの事前ステートが確定できたので、ID3D12CommandList::ResourceBarrier()の呼び出し時にエラーが出力出来たという事である。&lt;br&gt;
また、ステートが間違っていたリソースの名前が、&amp;lsquo;MyColorTex&amp;rsquo;といった様に表示されるが、これはアプリケーション自身が、ID3D12Object::SetName()を通じて設定したものである。D3D12アプリケーションを開発し、各種デバッグ機能を使う予定がある場合は、可能な限り全てのD3D12Objectに名前をつけるべきである。すると、上記の様にエラーが発生した際のメッセージによって原因となったリソースの特定が簡単に行えるようになる。Command ListやDescriptor Heapなどにもしっかりと名前を付けると、上記の様にエラーが発生したコマンドリスト名からエラーがどのレンダリングパスで発生したのかが特定できる場合もある。また、PIXやNSightといったフレームプロファイラを使う場合にもこれらの名前付けは有用である。&lt;/p&gt;
&lt;p&gt;次の例は、RenderTargetを設定したクリアカラー以外でクリア場合に発生する警告である。これはエラーではないので無視しても構わない。しかし、このようにパフォーマンスの向上を考える場合に有用なメッセージが得られる場合もある。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D3D12 WARNING: ID3D12CommandList::ClearRenderTargetView: The application did not pass any clear value to resource creation. The clear operation is typically slower as a result; but will still clear to the desired value. [ EXECUTION WARNING #820: CLEARRENDERTARGETVIEW_MISMATCHINGCLEARVALUE]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;id3d12infoqueueについて&#34;&gt;ID3D12InfoQueueについて&lt;/h3&gt;
&lt;p&gt;Debug Layerは、時にはアプリケーションが意図して記述しているコードに対してもメッセージを出力する場合がある。その場合は、アプリケーションが無視するべきと考えるメッセージを、D3D12InfoQueueを使ってフィルタリングできる。以下のコードスニペットは、GPUが書き込みしている可能性のあるリソースがCPUから読み込み可能な状態でMapされている場合に出力される警告を抑制するためのものである。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ComPtr&amp;lt;ID3D12InfoQueue&amp;gt; d3dInfoQueue;
if (SUCCEEDED(device-&amp;gt;QueryInterface(IID_PPV_ARGS(&amp;amp;d3dInfoQueue))))
{
    // Suppress individual messages by their ID.
    D3D12_MESSAGE_ID denyIds[] =
    {
        D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED,
    };

    D3D12_INFO_QUEUE_FILTER filter = {};
    filter.DenyList.NumIDs = _countof(denyIds);
    filter.DenyList.pIDList = denyIds;
    d3dInfoQueue-&amp;gt;AddStorageFilterEntries(&amp;amp;filter);
    OutputDebugString(L&amp;quot;Warning: GPUTimer is disabling an unwanted D3D12 debug layer warning: D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED.&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Microsoft DirectX SDK Sampleより引用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;メッセージのフィルタリングは、InfoQueueを通じてではなく、dxcpl/d3dconfigを使っても同様のフィルタリングの設定が可能だが、メッセージのフィルタリングはアプリケーションごとに行われるべきであるので、通常はアプリケーションのコードに記述されるべきである。ちなみに、InfoQueueの設定は、dxcpl/d3dconfigの設定でオーバーライドされるので、InfoQueueを使って制御したいときは、dxcpl/d3dconfigにアプリケーションを登録してはいけない。
以下はID3D12InfoQueueのその他の機能についてである。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;InfoQueueのデフォルト設定では、Infoレベルのメッセージはフィルタリングされているので、Infoレベルのメッセージを取得する必要がある場合はフィルタの設定を一旦クリアする必要がある。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;フィルターにはStorageFilterとRetrievalFilterの二種類がある。&lt;br&gt;
StorageFitlerは、エラーがメッセージキューにストアするときに適用されるフィルタ。フィルターを通過できなければ、メッセージキューにストアされない。
RetrievalFilterはメッセージを取得する際に適用されるフィルタ。メッセージキューにストアされているメッセージを破壊せずに、特定の種類のメッセージのみを抽出したいときなどに使う。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SetMuteDebugOutputでデバッグ出力ストリームへの出力を停止できる。
アプリケーション側で出力されるエラーのハンドリングを全て行う場合などで、デバッグ出力ストリームへの出力が不要な場合は抑止できる。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特定のエラーが検出された時や、エラーの深刻度によって、DebugBreakすることが可能。
Debug LayerはCPU側のD3D12ランタイムがエラーを検出しているので、エラーが発生するタイミングは、CPU処理と同期したタイミングが多い。したがって、DebugBreakすることは有効である。
しかし、DebugBreakがかかるのは、D3Dのランタイム側のスレッドでかかる場合もあるので、追跡するには、マルチスレッドのデバッギングが必要になる。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpu-based-validationの有効化&#34;&gt;GPU Based Validationの有効化&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDへの処方の第二候補は、GPU Based Validationの有効化である。GPU Based Validation(以下GBV)は、その名の通り、GPU側での実行時に行うValidationである。
GBVもアプリケーション自身で有効にすることもできるし、dxcplなどで強制的に有効にすることもできる。この点はDebug Layerと同様である。なお、Debug Layerが有効化されていないと動作しないので、Debug Layerの拡張機能と考える事もできる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    ComPtr&amp;lt;ID3D12Debug1&amp;gt; debug1;
    if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;debug1))))
    {
       debug1-&amp;gt;EnableDebugLayer();
       debug1-&amp;gt;SetEnableGPUBasedValidation(true);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;先ほど説明したDebug Layerは主にCommandListに命令を積み、ExecuteCommandListを呼び出すまでに行われるValidation。対してGBVはシェーダー実行時に行われるValidationになる。
未定義のDescriptorや、廃棄済みのリソースへのアクセス。不適切なリソースステートでのアクセスなど、CommandList作成時には、リソースの状況が未定で、検出できないエラーを実行時に検出する。
メッセージは既存のDebug Layerと同様に出力されるが、その出力のタイミングはコマンドリストを生成したCPU処理と同期しない。したがって、エラーメッセージが出力された瞬間のCPU処理を検証しても意味がない。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://docs.microsoft.com/sr-latn-rs/windows/win32/api/d3d12sdklayers/ne-d3d12sdklayers-d3d12_message_id&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D3D12_MESSAGE_ID enumeration&lt;/a&gt;を確認すれば、GBVで出力されるメッセージのIDには、
&amp;ldquo;GPU_BASED_VALIDATION&amp;quot;が含まれるのが分かる。これで実際にどのようなエラーが検出可能なのか分かる。&lt;/p&gt;
&lt;p&gt;GBVは、シェーダーコードとPSOにパッチを充てる形で実現する。これらには、いくつかのモードがあり選択することができる。GBVの設定は以下のAPIと構造体を通じて設定を行う。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ID3D12DebugCommandList1::SetDebugParameter()
typedef struct D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS {
  UINT                                                   MaxMessagesPerCommandList;
  D3D12_GPU_BASED_VALIDATION_SHADER_PATCH_MODE           DefaultShaderPatchMode;
  D3D12_GPU_BASED_VALIDATION_PIPELINE_STATE_CREATE_FLAGS PipelineStateCreateFlags;
} D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下はシェーダーのパッチモードの選択である&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;NONE&lt;br&gt;
シェーダーコードにValidationコードを挿入しないモード。
CommonStatePromotionによるリソースステートの遷移をトラッキングすることができない。そればかりかGBVを混乱させる恐れがある。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TRACKING_ONLY_SHADERS&lt;br&gt;
リソースステートの遷移のみをチェックするためのコードが挿入される。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CREATE_UNGUARDED_VALIDATION_SHADERS&lt;br&gt;
GBVのValidationコードが挿入される。Validationによるエラーが検出され、無効なリソースに対するアクセスや範囲外アクセスがあっても該当コードを実行する。結果、DEVICE_REMOVEDなどを引き起こすかもしれない。これがデフォルトのシェーダーパッチモード。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CREATE_GUARDED_VALIDATION_SHADERS&lt;br&gt;
GBVのValidationコードが挿入される。Validationによるエラーが検出された場合は、該当のリソースアクセスを避ける。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PipelineStateCreateFlagsでは、事前にPatchされたPSOを生成するかどうかを制御できる。
デフォルトでは、パッチがあてられたPSOの初回使用時にコンパイルされる挙動なので、CommandListのRecordingが遅くなる。FRONT_LOADを設定することで予めコンパイルされる設定になる。&lt;/p&gt;
&lt;p&gt;以下はGBVによって検出されたエラーの一例。UAVの範囲外にシェーダーがアクセスしたことで出力された。この種のバグは、CPU側のDebug Layerでは検出できないが、GBVならば検出できる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DescriptorTableのUAVに設定したUAVバッファに対する範囲外アクセス　(RootSignature1.1を使用。Range Flagは　D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTE)
D3D12 ERROR: GPU-BASED VALIDATION: Draw, Resource access out of bounds: Resource: 0x000001C6F8F91A60:&#39;DummyResource_256_bytes_UAV_buffer&#39;, Descriptor Type: UAV, Highest byte offset from view start accessed: [439737], Bytes available in view: 256. Results undefined because descriptor is declared static in root signature, which allows hardware/driver the option of converting the access to a root descriptor. Unlike descriptor heap descriptors, root descriptors do not have defined behavior for an out of bounds access. Index of Descriptor Range: 1, Shader Stage: PIXEL, Root Parameter Index: [0], Draw Index: [0], Shader Code: &amp;lt;debug info not available&amp;gt;, Asm Instruction Range: [0xbc-0xdf], Asm Operand Index: [2], Command List: 0x000001C6F8E6DA10:&#39;MyCommandList_Direct&#39;, SRV/UAV/CBV Descriptor Heap: 0x000001C6F8D8AB60:&#39;Unnamed ID3D12DescriptorHeap Object&#39;, Sampler Descriptor Heap: &amp;lt;not set&amp;gt;, Pipeline State: 0x000001C6F8BC81B0:&#39;Unnamed ID3D12PipelineState Object&#39;,  [ EXECUTION ERROR #1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ここで、GBVの話から少しそれるが、このエラーについて詳しく考えてみたいと思う。また、これらの出来事は私のローカル環境で観測されたに過ぎないことも明記しておく。
上記のエラーメッセージを要約すると以下の通りと思われる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;リソースへの範囲外アクセス。リソース：`ummyResource_256_bytes_UAV_buffer` デスクリプタタイプ:UAV 最高でオフセット[439737]にアクセスした。Viewでアクセス可能なのは 256. 
アクセスの結果は未定義です。なぜなら、デスクリプタはRootSignatureで`static`として宣言されており、ハードウェアやドライバーはこの（メモリ）アクセスをルートデスクリプタにコンバートする選択肢が許されているからです。
デスクリプタヒープのデスクリプタと異なり、ルートでスクリプタには範囲外アクセスの挙動の定義がありません。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このUAVはDescriptorTableに定義したが、RangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTEを設定した。このフラグが設定されたものはドライバーの最適化対象になる可能性があり、RootDescriptor（RootTableに直接定義するDescriptor）にコンバートされる可能性がある。
実際にコンバートされた場合は、範囲外アクセスは未定義動作となるので、エラーになっているという訳である。しかし、実際はリソースのアクセス範囲チェックがされていた（つまり、RootDescriptorへのコンバートは行われていなかった）ので、DEVICE_REMOVEDが発生するような致命的な事態にはならなかった。&lt;/p&gt;
&lt;p&gt;次に、このUAVが設定されているDescriptorTableのRangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定するとどうなるかというと、エラーが全く出力されなくなった。これは、DirectXの仕様として、RootSignature1.1のDescriptorTableに定義されたUAVで、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定された場合、もしくはRootSignature1.0で定義されたUAVの場合は、リソースアクセスの範囲チェックが行われる決まりがある。範囲外の読み出しはゼロを返され、範囲外への書き込みは行われない。DirectXの仕様に則った動作なのでエラーが発生しないというわけである。&lt;/p&gt;
&lt;p&gt;次は、DescriptorTableを介さずに、直接RootTableにUAVを定義して、範囲外アクセスを起こすと以下のメッセージが出力された。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RootTableに設定したUAVバッファに対する範囲外アクセス
D3D12 ERROR: GPU-BASED VALIDATION: Draw, Root descriptor access out of bounds (results undefined): Resource: 0x000001A7600AF410:&#39;DummyResource_256_bytes_UAV_buffer&#39;, Root Descriptor Type: UAV, Highest byte offset from view start accessed: [803581], Bytes available from view start based on remaining resource size: 256. Shader Stage: PIXEL, Root Parameter Index: [1], Draw Index: [0], Shader Code: &amp;lt;debug info not available&amp;gt;, Asm Instruction Range: [0xc8-0xeb], Asm Operand Index: [2], Command List: 0x000001A75F82C5B0:&#39;MyCommandList_Direct&#39;, SRV/UAV/CBV Descriptor Heap: 0x000001A75F9DEA70:&#39;Unnamed ID3D12DescriptorHeap Object&#39;, Sampler Descriptor Heap: &amp;lt;not set&amp;gt;, Pipeline State: 0x000001A75FDC5DE0:&#39;Unnamed ID3D12PipelineState Object&#39;,  [ EXECUTION ERROR #961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS]

さらに、DEVICE_REMOVED発生した。
D3D12: Removing Device.
D3D12 ERROR: ID3D12Device::RemoveDevice: Device removal has been triggered for the following reason (DXGI_ERROR_DEVICE_HUNG: The Device took an unreasonable amount of time to execute its commands, or the hardware crashed/hung. As a result, the TDR (Timeout Detection and Recovery) mechanism has been triggered. The current Device Context was executing commands when the hang occurred. The application may want to respawn and fallback to less aggressive use of the display hardware). [ EXECUTION ERROR #232: DEVICE_REMOVAL_PROCESS_AT_FAULT]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;先ほどとエラーメッセージが異なり、エラーのIDが異なるので注意が必要である。以上の出来事をまとめると以下の様になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DescriptorTableに定義した場合&lt;br&gt;
#1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS&lt;br&gt;
こちらのエラーは、VOLATILEでないDescriptorTableに定義されたリソースに対する範囲外アクセスで発生したエラー。
ハードウェアやドライバーが、範囲外アクセスを未定義動作にすることが許されている状態だが、実際に範囲外アクセスをするかは実装次第。&lt;/li&gt;
&lt;li&gt;RootTableに直接定義した場合&lt;br&gt;
#961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS&lt;br&gt;
こちらは、DescriptorTableではなく、RootTableに定義されたリソースの範囲外アクセスで発生したエラー。
RootTableにUAVやSRVを定義した場合、リソースのサイズは格納されない事が知られており、通常は範囲外アクセスへのチェックも行われない事が知られている。しかし、GBVを有効にすることでこれらの範囲外アクセスがValidatorにより検出され、
エラーが出力されたという状態。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;このように、エラーメッセージから学べる事もあるので、Debug LayerやGBVを有効にするのはおすすめである。&lt;/p&gt;
&lt;h2 id=&#34;debug-layerのその他の機能&#34;&gt;Debug Layerのその他の機能&lt;/h2&gt;
&lt;h3 id=&#34;synchronized-command-queue-validation&#34;&gt;Synchronized Command Queue Validation&lt;/h3&gt;
&lt;p&gt;Debug Layerを有効にすることで、Synchronized Command Queue Validationという機能がでデフォルトで有効になる。
この機能によって、FenceのWaitが設定されたコマンドリストにおいて、Waitの条件が満たされるまで、GPUへのコマンド送出をしなくなる。
これにより、Waitが設定されている以降のコマンドにおけるリソースステートをCPU側でも確認することができ、結果として、コマンド送出時にリソースステートのValidationをより厳密に行う事ができる。
Disableにすることによって、FenceのSignalとWaitを多用したQueueの組み立てをしている場合に限り、Debug Layer使用時の若干のパフォーマンス向上が期待できるが、そもそもDebug Layerはパフォーマンスを追求するためのものでは無いのでDisableにするメリットは殆どない。&lt;/p&gt;
&lt;h3 id=&#34;debugdevice--debugcommandqueue--debugcommandlist&#34;&gt;DebugDevice / DebugCommandQueue / DebugCommandList&lt;/h3&gt;
&lt;p&gt;Debug Layerが有効な状態では、Device, CommandQueue, CommandListからQueryInterfaceすることで、表題のインターフェースが取得できる。
主な機能は以下の通り。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ID3D12DebugDevice::ReportLiveDeviceObjects()&lt;br&gt;
現在有効なオブジェクトをデバッグ出力ストリームに出力する。&lt;/li&gt;
&lt;li&gt;ID3D12DebugCommandList::AssertResourceState()&lt;br&gt;
リソースのステートが、呼び出し引数に与えたステートと等しいかを返す。&lt;br&gt;

&lt;a href=&#34;https://microsoft.github.io/DirectX-Specs/d3d/CPUEfficiency.html#common-state-promotion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Common State Promotion&lt;/a&gt;を使う場合は、これでState PromotionやDecayの確認をするとデバッグしやすい。&lt;/li&gt;
&lt;li&gt;ID3D12DebugCommandQueue::AssertResourceState()&lt;br&gt;
リソースのステートが、呼び出し引数に与えたステートと等しいかを返す。&lt;br&gt;
CommandQueuから直接リソースを操作するAPIがある関係上、CommandQueuからもリソースのステートが確認できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-removed-extended-data-12&#34;&gt;Device Removed Extended Data 1.2&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://microsoft.github.io/DirectX-Specs/d3d/DeviceRemovedExtendedData.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Device Removed Extended Data&lt;/a&gt;とは、実際にDEVICE_REMOVEDが発生した後に、発生のより詳しい状況を知るための機構である。通常はDEVICE_REMOVEDが発生しても、得られる情報はせいぜいHRESULTのエラーコードぐらいで、デバッグの指標となる情報はほとんどない。しかし、DREDを活用すれば、DEVICE_REMOVEDが発生した時にGPUが実行していたコマンドや、原因となったメモリアクセスについて知ることができる場合がある。
Debug Layerとは機能的に独立しているので、使用にあたりDebug Layerを有効にする必要はない。また、Debug Layerほど処理オーバーヘッドが大きくないので、常時有効にしてアプリケーションを開発することができる。
以下は、DREDの主要機能を有効にするためのコードスニペットである。DRED自体はWindowsSDKの10.0.18362.1より使用可能だが、一部重要な機能が未実装なので、WindowsSDKの10.0.19041.0以後の導入とWindows10 20H1の導入を推奨する。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Try enabling DRED even in release code
{
  ComPtr&amp;lt;ID3D12DeviceRemovedExtendedDataSettings1&amp;gt; d3dDredSettings1;
  if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;d3dDredSettings1)))) {
    // Turn on AutoBreadcrumbs and Page Fault reporting
    d3dDredSettings1-&amp;gt;SetAutoBreadcrumbsEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
    d3dDredSettings1-&amp;gt;SetBreadcrumbContextEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
    d3dDredSettings1-&amp;gt;SetPageFaultEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;auto-breadcrumbsとbreadcrumb-contextについて&#34;&gt;Auto BreadcrumbsとBreadcrumb Contextについて&lt;/h3&gt;
&lt;p&gt;Breadcrumbsは、パンくずのことで、所謂通ってきた道を見失わないためにパンくずを撒きながら森の中を歩いた童話にちなんでいる。Auto Breadcrumbsは、明示的にAPIを呼び出してパンを撒かなくても自動的に道標なるイベント（D3D12のAPI呼び出し）を自動的に記録するための機能である。
Auto Bredcrumbsが記録するのは、基本的には、CommandListを介して実行するコマンド群である。詳細は
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_auto_breadcrumb_op&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D3D12_AUTO_BREADCRUMB_OP enumeration&lt;/a&gt;で確認できる。
そして、DEVICE_REMOVEDが発生する直前に実行したメソッドを指し示すことで、DEVICE_REMOVEDが発生した瞬間にGPUが実行していたオペレーションが分かる仕組みになっている。&lt;/p&gt;
&lt;p&gt;しかし、Auto Bredcrumbsは実行したコマンドの種類を記録するだけなので、連続する一連のDrawなどでは、実際にどのDraｗコールが問題を引き起こしたか分からない。
Breadcrumb Contextは、Auto Breadcrumbによって記録されたオペレーションに関連する情報を記録した文字列が取得できるDRED1.2で導入された新しい機能である。
具体的には、Pixのマーカーがセットされた場合は、そのマーカーの文字列が記録される。これにより、大幅にレンダリング箇所の特定が行いやすくなった。&lt;/p&gt;
&lt;h3 id=&#34;gpu-page-faultについて&#34;&gt;GPU Page Faultについて&lt;/h3&gt;
&lt;p&gt;GPU Page Faultは、GPU上で発生する不正なメモリアクセスで、これが発生するとDEVICE_REMOVEDとなる。DREDはGPU Page Faultの情報を記録する。まずはGPU Page Faultを理解するためにGPU仮想アドレス空間について簡単に説明する。&lt;/p&gt;
&lt;h3 id=&#34;gpu仮想アドレス空間について&#34;&gt;GPU仮想アドレス空間について&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows-hardware/drivers/display/gpummu-model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GpuMmu&lt;/a&gt;は、WDDM2.0(Windows Display Driver Model 2.0)でサポートされている、主にディスクリートGPU（VRAMとシステムメモリが物理的に独立しているGPU）のための
仮想アドレスモデルである。このモデルでは、プロセスごとに、GPU仮想アドレス空間がCPUの仮想アドレス空間とは別に存在して、物理アドレスに変換するためのMMUも、CPUのMMUとは別に存在している。
GPU仮想アドレス空間は、その名の通りGPU上で実行されるシェーダー等からメモリアクセスをする際に使用されるアドレス空間である。CPU側(D3D12APIやドライバー)でのリソース確保や解放によって、物理メモリが確保または破棄されて、アドレス変換テーブルが更新される。
アドレス変換テーブルが更新される際にはGPU側と同期して、GPU側と同じアドレス変換情報を共有することで、GPU上での仮想アドレスにおけるメモリアクセスを実現している。
図にある通り、物理リソースへのアクセスはアドレステーブルによる変換を介して行う。また、マップされるメモリは、VRAMでもSysMemでも構わない。GPUはどちらに配置されているリソースでも、透過的にアクセスすることができる。&lt;/p&gt;
&lt;h3 id=&#34;gpu-page-faultが起きるケース&#34;&gt;GPU Page Faultが起きるケース&lt;/h3&gt;
&lt;p&gt;GPUがPage Faultを起こすのは、アクセスが許されないページにアクセスした場合や、そもそもメモリがマッピングされていないアドレスにアクセスした場合である。主に具体的なケースとして考えられるのは、以下の通りである。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DrawcallやDispatch,Copy処理などにおいて、すでに破棄したリソースを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatch,Copy処理などにおいて、Evictしたリソースや、Non-Regidentなタイルリソースを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchで、未初期状態のDescriptorTableや、誤ったDescriptorTableを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchで、可変長のDescriptorTableで、シェーダーが実際に配置されているテーブルの範囲を逸脱してアクセスした場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchでRootTableに配置したUAVやSRVに対して誤った範囲でアクセスした場合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gpu-page-faultで得られる情報について&#34;&gt;GPU Page Faultで得られる情報について&lt;/h3&gt;
&lt;p&gt;DREDは、PageFaultが発生したアドレス空間に確保されているオブジェクトが有れば、そのオブジェクト名（SetNameで付けた名前）が記録される。
またAllocationTypeとして、そのアドレス空間に配置されたオブジェクトが、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_dred_allocation_type&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;どのような種類であるか&lt;/a&gt;を知ることができる。
また、そのアドレス空間を使っていて、直近で解放されたリソースがあれば、そのリソースの情報が取得できる。これは、解放されたリソースに対して、シェーダー等がアクセスした場合に発生するPage Faultを知るのに特に有用である。
しかし、GPU Page Faultはあくまで、GPU仮想アドレス変換時のエラーでしかないので、アクセスしたアドレスに有効なページがあればアクセス自体が成立するため、GPU page faultにならない。したがって、すべての不正アクセスを検出するわけではない。
たとえば、EvictしたリソースはVRAMが特に逼迫した状況になるまではリソースのページアウトが起きないため、そのままVRAM上に配置されていることが多い。結果Page Faultも起きない上に、正しくレンダリングされるため、問題に気づけない。&lt;/p&gt;
&lt;h2 id=&#34;dredで得られる情報で何が分かるか&#34;&gt;DREDで得られる情報で何が分かるか&lt;/h2&gt;
&lt;p&gt;DREDは、一見するとDEVICE_REMOVEDの発生原因についての十分な情報を提供してくれるように思えるが実際は違う。
AutoBreadCrumbは、エラーが発生していた時に実行していたコンテキストに過ぎず、実際にエラーの原因がその中にあるとは限らない。
Page Faultも同様で、Page Faultは発生した一つのアクセス例外に過ぎず、何がアクセス例外の原因となったかは分からない。たとえば、それが古いDescriptor Tableを参照したことによるのか、
破損したDescriptor Tableを参照したことによるのか、参照しているリソースを開放してしまったことによるのかは分からない。&lt;/p&gt;
&lt;p&gt;しかし、DEVICE_REMOVEDが頻発する状況下では、DREDで複数のクラッシュの情報を集約することは非常に有効である。例えば、もしも、PageFaultがいつも同じリソースとアドレスで発生するとしたら、
プログラムのロジックが安定的な間違いを犯している可能性が高いと考えられる。また、そうではなく、PageFaultがいろいろなリソースやアドレスで発生するとしたら、リソースやDescritorTableを管理しているスレッドと
GPUの実行コンテキストのレースコンディションを調べる価値があると考えられる。AutoBreadCrumbも同様で、毎回同じドローコールでDEVICE_REMOVEDが発生しているならば、
該当ドローコールのロジックや、実行分岐制御に関わる変数やリソースを調べるべきだが、異なるドローコールでランダムにDEVICE_REMOVEDが発生するならば、コマンドリストの破損の可能性が考えられる。&lt;/p&gt;
&lt;p&gt;以下はCommandList作成時には存在していたTextureがExecuteCommandListsの前に解放された場合に発生するGPU Page Faultによって発生した、DEVICE_REMOVEDの際に取得できたDREDの情報である。なお、DREDの情報はデバッグ出力ストリームに自動的に出力されないので、
自身でデータにアクセスして、何らかの形で表示する必要がある。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DXGI_ERROR_DEVICE_HUNG
The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application.
==== Auto Breadcrubs ====
QueueNameW: MyCommandQueue
QueuePtr: 0x2bad9c40330
BreadcrumbCount: 0
BreadcrumbContextsCount: 0
LastBreadcrumbValues: 0
==== Auto Breadcrubs ====
QueueNameW: MyCommandQueue
QueuePtr: 0x2bad9c40330
CommandListNameW: MyCommandList_Direct
CommandListPtr: 0x2bad9e379f0
BreadcrumbCount: 7
BreadcrumbContextsCount: 3
LastBreadcrumbValues: 5
  0|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|==Frame Start==
  1|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Set viewport and render targets
  2|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER
  3|D3D12_AUTO_BREADCRUMB_OP_CLEARRENDERTARGETVIEW
  4|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Draw - Triangle
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;Something wrong happned here...&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
  5|D3D12_AUTO_BREADCRUMB_OP_DRAWINSTANCED
  6|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER
====Page fault information ====
PageFaultGPUVA: 0x70fc000
==Existing Allocation Node Info
==Recent Freeed Allocation Node Info
ObjectNameW: DummyResource_256_bytes_UAV_buffer
AllocationType: D3D12_DRED_ALLOCATION_TYPE_RESOURCE
IUnknownPtr: 0x0x2bad9e8f9c0
D3D12app.exe has triggered a breakpoint.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;dump-file-について&#34;&gt;Dump File について&lt;/h3&gt;
&lt;p&gt;DREDの情報はユーザーモードダンプからも抽出することができる。まずは、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/wer/collecting-user-mode-dumps&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;プロセスがCrashした際に、FullDumpが作られる様に事前に設定&lt;/a&gt;し、ダンプファイルをwindbgで読み込む。
windbg.exeはWindows10のSDKに同梱されている。通常は、&amp;ldquo;C:\Program Files (x86)\Windows Kits\10\Debuggers\x64\windbg.exe&amp;quot;に配置されるはずである。
そこで、
&lt;a href=&#34;https://github.com/Microsoft/DirectX-Debugging-Tools&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MicrosoftがGitHubで公開しているスクリプト&lt;/a&gt;を読み込むことで、DREDの情報に容易にアクセスできる。
手順は該当のリポジトリでも確認できるが非常に簡単である。プロセスがクラッシュした際のフルダンプを読み込み、以下のコマンドを実行するだけである。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.scriptload &amp;lt;&amp;lt;path to script file&amp;gt;&amp;gt;\d3ddred.js
!d3ddred
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下が、Windbg上で実際にDRED情報を表示した例である。取得できる情報は、DREDのAPIで取得できる情報と同一である。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-windbg上でdred12の情報を確認する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/WinDbg_hu91d4c8ada4e4ee2168dbdfb94cdee135_75072_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Windbg上で、DRED1.2の情報を確認する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/WinDbg_hu91d4c8ada4e4ee2168dbdfb94cdee135_75072_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1011&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Windbg上で、DRED1.2の情報を確認する
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;最後に&#34;&gt;最後に&lt;/h3&gt;
&lt;p&gt;これら全てを駆使しても簡単に判明しないDEVICE_REMOVEDも存在すると思うが、DEVICE_REMOVEDを手さぐり的に解決する時代は終わりを迎えようとしていると言えると思う。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HLSLのWave Intrinsicsについて</title>
      <link>https://shikihuiku.github.io/post/wave_intrinsics1/</link>
      <pubDate>Sun, 16 Aug 2020 20:00:32 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/wave_intrinsics1/</guid>
      <description>&lt;h2 id=&#34;hlslのwave-intrinsicsについて&#34;&gt;HLSLのWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsは、HLSLのShader Model6.0から導入された新しい組み込み関数群です。
従来の他のHLSL組み込み関数が、単一スレッド内での変数のみを動作の対象するのに対して、
Wave Intrinsicsは、Waveと呼ばれる複数のスレッド間でのデータの交換や演算を行うための組み込み関数となります。
従来は、Compute Shaderなどで、他のスレッドの変数（演算用のレジスタ）が保持する値を参照するには、groupsharedで宣言された変数やUAVなどで宣言されたバッファーに情報を一旦ストアする必要があったうえ、スレッド間の同期命令が必要でした。
Wave Intrinsicsは、Wave内のスレッド間に限定されますが、他のスレッドの変数（演算用のレジスタ）の値を参照したり演算することが出来ます。
これにより、スレッド間のレジスタ空間の共有が可能になり、複数のスレッドで協調的に動作するシェーダーコードが、より記述しやすくなりました。
また、Wave内は命令実行のタイミングが同じであることが（論理上において）保証されていることから、スレッド間同期命令を必要としないのも大きな利点です。
一点注意が必要なのは、Wave IntrinsicsはShader Model 6.0以上に存在する組み込み関数ですが、実際に使用できるかどうかは、&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;で、&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;を調べる必要があります。&lt;/p&gt;
&lt;h2 id=&#34;用語&#34;&gt;用語&lt;/h2&gt;
&lt;p&gt;ここではWave Intrinsicsに関連する用語を説明します。&lt;/p&gt;
&lt;h4 id=&#34;wave&#34;&gt;Wave&lt;/h4&gt;
&lt;p&gt;NVIDIAの用語で&amp;quot;warp&amp;quot;とよばれ、AMDの用語では、&amp;ldquo;wavefront&amp;quot;と呼ばれてきたものです。命令発行が、同時に行われれるスレッドのグループのことです。&lt;/p&gt;
&lt;h4 id=&#34;lane&#34;&gt;Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドを指します。&lt;/p&gt;
&lt;p&gt;以下の図は、一つのWaveの中に32Lane分のスレッドが存在する場合の図になります。この図式を使って様々なWave Intrinsicsについて説明していきたいと思います。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-waveとlane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wave_hu550fc97d8560033e52f050ac0d549368_13159_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;WaveとLane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wave_hu550fc97d8560033e52f050ac0d549368_13159_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;441&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    WaveとLane
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;inactive-lane&#34;&gt;Inactive Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドのうち、命令を実行しないスレッドを指します。&lt;/p&gt;
&lt;h4 id=&#34;active-lane&#34;&gt;Active Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドのうち、命令を実行するスレッドを指します。&lt;/p&gt;
&lt;p&gt;以下の図は、左側のシェーダーコードの実行に伴って変化する、Active LaneとInactive Laneの変化の例を表した図です。右側の3 Laneは、スレッド起動数等の初期条件によるInactive Laneです。
Pixel ShaderやCompute Shaderで必要とされるスレッド数が、Waveの倍数でなかった場合は、Inactive Laneの存在するWaveが起動されます。このようなInactive Laneは、状態が動的に変更されることは無く、終始Inactive Laneのままです。
3行目のIf()による分岐の条件を満たさなかったLaneは、If()ステートで囲まれたコードブロックが終了するまでInactive Laneとなります。Wave内では命令実行は暗黙的に同期する決まりになっているので、Inactive Laneはその間なにも実行せず、他のLaneが該当コードブロックの実行を完了するまで待ちます。
図にはありませんが、If()ステートのコードブロックの実行が終了すれば、条件分岐によってInactive Laneとなったスレッドは、再びActive Laneへと復帰します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-active-laneとinactive-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/active_inactive_hu6f4caf7822c3e8aa1ace8fd32f3899a3_110070_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Active LaneとInactive Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/active_inactive_hu6f4caf7822c3e8aa1ace8fd32f3899a3_110070_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;965&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Active LaneとInactive Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;quad&#34;&gt;Quad&lt;/h4&gt;
&lt;p&gt;先頭から連続する4Lane分づつのスレッドのグループを指します。特にPixel Shaderでは、RenderTargetにおける2x2ピクセルブロックが一つのQuadにアサインされます。
Pixel Shaderにおけるddx/ddyなどのGradient命令や、テクスチャーのLoDの計算は、Quad内の変数の差分によって実現されており、Gradientの計算のみに寄与してPixelを塗らないLane（スレッド）をHelper Laneと呼びます。&lt;/p&gt;
&lt;p&gt;以下の図は、とあるプリミティブをレンダリングする際の、QuadとHelper LaneのRenderTarget上での表現とWaveとしての表現の対応図です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-quadとhelper-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;QuadとHelper Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    QuadとHelper Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;waveのサイズについて&#34;&gt;Waveのサイズについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsを使う上で、Waveのサイズというは非常に重要なファクターで、これを理解すること無しに、効率的な処理をデザインすることは難しいと思います。
NVIDIAのWarpは、伝統的に32 Lane/Waveです。対して、AMDのGCNアーキテクチャは64 Lane/Waveで動作しています。
同じくAMDのRDNAアーキテクチャは、Wave32とWave64の二つの動作モードを持ち、それぞれが、32, 64 Lane/Waveで動作しています。
どちらのモードでシェーダーが実行されるかは、ドライバーが決定するようなので、シェーダーは両モードで正しく動く必要があります。結局のところ、32 Lane/Wave、64 Lane/Waveの両方をサポートすることができれば、NVIDIA, AMDの両GPUに対応したアプリケーションとなるはずです。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-32-lanewaveと64-lanewave&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/32_64_lane_hu55f4de2178e3ca0a112fe7c34fbabb49_24264_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;32 Lane/Waveと64 Lane/Wave&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/32_64_lane_hu55f4de2178e3ca0a112fe7c34fbabb49_24264_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;630&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    32 Lane/Waveと64 Lane/Wave
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;の&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;では、Wave Intrinsicsの使用の可否についてとともに、使用される可能性のあるWaveのサイズの上限値と下限値が返されます。
したがって先のRDNAの様に、単一のアーキテクチャでも、Waveのサイズは可変であると考える必要があるのかもしれません。しかし、WaveのサイズのAPI仕様としての上限値と下限値である 4 と 128 はあまりにもかけ離れているため、Waveのサイズに依存するコードを記述する際に、すべてのWaveのサイズをサポートすることは非現実的です。また、実際には使用されないWaveのサイズのためにコードを書くのも無駄だと思います。したがって、現実的な実装方法としては&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;でWaveのサイズの上限値と下限値をチェックし、32と64の範囲ならば、Wave Intrinsicsを使ったシェーダーコードを使用し、そうでない場合はWave Intrinsicsを使用していないフォールバックのシェーダーコードを実行するか、エラーを出力して動作を終了するべきだと思います。&lt;/p&gt;
&lt;p&gt;Waveのサイズは、&lt;code&gt;WaveGetLaneCount&lt;/code&gt;というWave Intrinsicsを使って取得できます。しかし、これは裏を返せば、&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;のWaveの上限値と下限値に幅がある場合は、HLSLのシェーダーコードを実行するまで、Waveのサイズが分からないという事になります。（これはAPIのデザインの問題だと思います。）&lt;/p&gt;
&lt;h2 id=&#34;waveのサイズとthread-groupのサイズについて&#34;&gt;WaveのサイズとThread Groupのサイズについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsは、あくまでWaveのサイズを基準とした動作になっていて、Compute Shaderのnumthreadsの大きさは、Waveのサイズとは関係ありません。ただし、Wave Intrinsicsを使う場合は、numthreadsの大きさはWaveのサイズを意識したものが良いと思います。
WaveのThread Group内でのマッピングは、Row Oriented　(X軸優先）です。（ただし、これを明記しているドキュメントが見当たらなかったので注意が必要です。）numthreadsの大きさが、Waveのサイズの倍数でなかった場合は、シェーダーが実行される前からInactive Laneが存在するWaveが起動されます。この場合、Waveのサイズ分のスレッドがすべて動作していることを前提として記述されたシェーダーは、動作が破綻するので注意が必要です。
現状では、&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;の&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;の返すWaveのサイズの上限値の倍数をnumthreadsの大きさとすることで、このような事態を回避する事ができると思います。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-numthreadとwave&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/numthread_wave_hu87309c82afe6bdb07430f9b22f94f645_45303_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;numthreadとWave&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/numthread_wave_hu87309c82afe6bdb07430f9b22f94f645_45303_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    numthreadとWave
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;pixelshaderとwave-intrinsicsについて&#34;&gt;PixelShaderとWave Intrinsicsについて&lt;/h3&gt;
&lt;p&gt;（これも明記しているドキュメントが見当たらなかったので注意してください）&lt;br&gt;
Pixel Shaderでは、すべてのWave Intrinsicsの使用が許されています。しかし、Pixel Shaderにおける描画ピクセルとWaveやLaneの対応は、描画されるプリミティブの位置と、GPUとドライバー、そしてPixel Shaderのソースコードによって決まると考えられます。
シンプルな例では、ピクセルシェーダーのスレッドは描画されるプリミティブのピクセルと一対一の関係で起動されると思います。ただし、ピクセルシェーダー内で、Gradinet命令（ddx/ddy）を使用したり、テクスチャーのサンプリングにおいて、LoDを明示的に指定しなかった場合は、スレッド間の値（テクスチャサンプリングにおいてはUV値）の差分を計算する必要があるため、起動されるスレッドは2x2ピクセル単位となります。そして、プリミティブとして描画されるピクセルを担当しているスレッドのみがRenderTargetへの出力を行います。残りのスレッドは、Helper Laneとなり、スレッドとして動作しますがRenderTargetへの出力を行いません。
プリミティブの描画においては、必要なスレッド数は必ずしもWaveのサイズの倍数とならないので、シェーダー内で条件分岐を行っていない状態でも、Inactive Laneが存在しているWaveが起動される可能性があります。また、複数のプリミティブが同一のWaveにパッキングされる可能性もあります。Pixel Shader内でWave Intrinsicsを使う場合は、これらの点について考慮する必要があると思います。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-quadとhelper-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;QuadとHelper Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    QuadとHelper Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;shader-model-60のwave-intrinsicsについて&#34;&gt;Shader Model 6.0のWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Shader Model 6.0のWave Intrinsicsは以下のカテゴリに分類することができます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wave Query&lt;br&gt;
WaveやLaneの状態取得&lt;/li&gt;
&lt;li&gt;Wave Vote&lt;br&gt;
Wave内でのbooleanステート確認&lt;/li&gt;
&lt;li&gt;Wave Broadcast&lt;br&gt;
Wave内で特定のLaneの変数値の取得&lt;/li&gt;
&lt;li&gt;Wave Reduction&lt;br&gt;
Wave内での変数の演算&lt;/li&gt;
&lt;li&gt;Wave Scan and Prefix&lt;br&gt;
Wave内での変数の演算(自身より小さいLane Indexに限る)&lt;/li&gt;
&lt;li&gt;Quad-wide Shuffle operations&lt;br&gt;
Quadを動作対象とした、変数値の取得&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wave-query&#34;&gt;Wave Query&lt;/h3&gt;
&lt;p&gt;WaveのLane数と、Lane Indexを調べるためのIntrinsicsです。&lt;br&gt;
加えて、Wave内で自身が先頭のActive Laneかどうかを返す、&lt;code&gt;WaveIsFirstLane&lt;/code&gt;が含まれます。&lt;/p&gt;
&lt;h4 id=&#34;wavegetlanecount&#34;&gt;&lt;code&gt;WaveGetLaneCount&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;WaveのLaneの数を返します。全てのLaneで同じ値を受け取ります。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetcount_hu017ff3431e51e38ea7691ac81e49e3c2_14763_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetcount_hu017ff3431e51e38ea7691ac81e49e3c2_14763_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;382&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;wavegetlaneindex&#34;&gt;&lt;code&gt;WaveGetLaneIndex&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Wave内での該当LaneのIndexを返します。個々のLaneで異なる値を受け取ります。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetlaneindex_hue63fa13725fdb66d601d5d878c1d0ae3_26912_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetlaneindex_hue63fa13725fdb66d601d5d878c1d0ae3_26912_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;520&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;waveisfirstlane&#34;&gt;&lt;code&gt;WaveIsFirstLane&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;bool値を返します。ActiveLaneの中で最小のLane IndexのLaneのみ&lt;code&gt;true&lt;/code&gt;が返されます。残りのLaneは&lt;code&gt;false&lt;/code&gt;が返されます。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveisfirstlane_huafbbbf3a8be6235948052771404a6e1b_51220_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveisfirstlane_huafbbbf3a8be6235948052771404a6e1b_51220_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;571&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;wave-vote&#34;&gt;Wave Vote&lt;/h3&gt;
&lt;p&gt;Wave内の他のActive Laneのboolのステータスを確認するためのIntrinsicsです。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveanytrue&#34;&gt;&lt;code&gt;WaveActiveAnyTrue&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。そして、いずれかのActive Laneが&lt;code&gt;true&lt;/code&gt;を渡せば、全てのActive Laneに&lt;code&gt;true&lt;/code&gt;が返されます。そうでない場合は、全てのActive Laneに&lt;code&gt;false&lt;/code&gt;が返されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveanytrue_hue78662cc8f443afcaa688bcef7c43ea2_59746_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveanytrue_hue78662cc8f443afcaa688bcef7c43ea2_59746_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;697&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivealltrue&#34;&gt;&lt;code&gt;WaveActiveAllTrue&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。全てのActive Laneが&lt;code&gt;true&lt;/code&gt;を渡せば、全てのActive Laneに&lt;code&gt;true&lt;/code&gt;が返されます。そうでない場合は、全てのActive Laneに&lt;code&gt;false&lt;/code&gt;が返されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivealltrue_hu3ee6171c79406bc5f05b75ba065dfffc_59680_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivealltrue_hu3ee6171c79406bc5f05b75ba065dfffc_59680_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;708&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactiveballot&#34;&gt;&lt;code&gt;WaveActiveBallot&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneが渡したbool値をビットマスクとして返します。Inacive Laneは暗黙的に0が設定されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveballot_hu441b454dd67f6c112671144c7a7d1adc_61292_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveballot_hu441b454dd67f6c112671144c7a7d1adc_61292_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;769&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-broadcast&#34;&gt;Wave Broadcast&lt;/h3&gt;
&lt;p&gt;Wave内で、特定のLaneの変数の値を、すべてのActive Laneで取得するためのIntrinsicsです。&lt;/p&gt;
&lt;h4 id=&#34;wavereadlaneat&#34;&gt;&lt;code&gt;WaveReadLaneAt&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数とLane Indexを指定します。Lane Indexで指定されたLaneの、引数で指定された変数の値を、全てのActive Laneに返します。引数で指定した変数の型と同じ型が返されます。&lt;br&gt;
他にも、引数に指定した変数の型と同じ変数型を返すタイプのWave Intrinsicsがありますが、これらはベクトル型を含め、組み込み型の整数型と浮動小数点型の殆どがサポートされています。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlaneat_hu2ce763e09dbd4548c9ca84ea0f16840b_96939_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlaneat_hu2ce763e09dbd4548c9ca84ea0f16840b_96939_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1120&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavereadlanefirst&#34;&gt;&lt;code&gt;WaveReadLaneFirst&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。Active Laneの中で、最小のLane IndexのLaneの、引数で指定された変数の値を、すべてのActive Laneに返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlanefirst_hu6d9eb6b7bdb5af52098e10c274550961_77137_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlanefirst_hu6d9eb6b7bdb5af52098e10c274550961_77137_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;930&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-reduction&#34;&gt;Wave Reduction&lt;/h3&gt;
&lt;p&gt;Wave内でのActive Laneの変数の値を用いて演算するためのIntrinsicsです。一つの演算結果がすべてのActive Laneに返されます。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveallequal&#34;&gt;&lt;code&gt;WaveActiveAllEqual&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値が等しい場合のみTrueを返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveallequal_hub0d81e969a1494ea62407696e116d131_41919_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveallequal_hub0d81e969a1494ea62407696e116d131_41919_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;886&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivebitand&#34;&gt;&lt;code&gt;WaveActiveBitAnd&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise AND(論理積)を演算した結果を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivebitor&#34;&gt;&lt;code&gt;WaveActiveBitOr&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise OR(論理和)を演算した結果を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivebitxor&#34;&gt;&lt;code&gt;WaveActiveBitXor&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise XOR(排他的論理和)を演算した結果を返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivebitop_hu8c00d785c0bd006675ed4159e86102d6_54165_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivebitop_hu8c00d785c0bd006675ed4159e86102d6_54165_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1045&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivecountbits&#34;&gt;&lt;code&gt;WaveActiveCountBits&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、boolを指定します。引数に&lt;code&gt;true&lt;/code&gt;を指定したLaneの数を、すべてのActive Laneに返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivecountbits_hu45ba85d97c3b69abe8f3e4ff68f45109_54517_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivecountbits_hu45ba85d97c3b69abe8f3e4ff68f45109_54517_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;756&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivemax&#34;&gt;&lt;code&gt;WaveActiveMax&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最大値を、全てのActive Laneに返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivemin&#34;&gt;&lt;code&gt;WaveActiveMin&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最小値を、全てのActive Laneに返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveproduct&#34;&gt;&lt;code&gt;WaveActiveProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数をの値を乗算した結果を、全てのActive Laneに返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;/p&gt;
&lt;h4 id=&#34;waveactivesum&#34;&gt;&lt;code&gt;WaveActiveSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値を加算した結果を、全てのActive Laneに返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveminmaxop_huc07e0fb502a11709116c047263e24c8f_56203_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveminmaxop_huc07e0fb502a11709116c047263e24c8f_56203_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1097&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-scan-and-prefix&#34;&gt;Wave Scan and Prefix&lt;/h3&gt;
&lt;p&gt;Wave Reduction系に似ていますが、演算の対象が自身のLane Index未満のActive Laneのみです。自身のLaneは演算の対象に含みません。
演算の結果は、基本的にはLaneごとに異なる値が返されることになります。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixcountbits&#34;&gt;&lt;code&gt;WavePrefixCountBits&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にboolを指定します。自身のLane Index未満のActive Laneで、引数に&lt;code&gt;true&lt;/code&gt;を指定した個数を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixsum&#34;&gt;&lt;code&gt;WavePrefixSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を加算した結果を返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;code&gt;[precise]&lt;/code&gt;フラグは無視されます。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixproduct&#34;&gt;&lt;code&gt;WavePrefixProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を乗算した結果を返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;code&gt;[precise]&lt;/code&gt;フラグは無視されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveprefixop_hu36665e6520788b3009382913080bbf2c_71179_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveprefixop_hu36665e6520788b3009382913080bbf2c_71179_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;742&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;quad-wide-shuffle-operations&#34;&gt;Quad-wide Shuffle operations&lt;/h3&gt;
&lt;p&gt;Pixel Shaderでのみ使用可能なWave Intrinsicsです。
(これについては、2020/08現在ドキュメントの表記と実装に食い違いがあります。ドキュメントにはCompute Shaderでも使用可能と表記されており、その場合、Lane Indexの0より4 Laneごとに区切ったLaneがQuadとして扱われるとされています。
しかし実際には、Quad系を使用したCompute Shaderのコンパイル時に&lt;code&gt;opcode &#39;QuadReadAcross&#39; should only be used in &#39;Pixel Shader&#39;&lt;/code&gt;というメッセージが出力されます。そして、シェーダーの生成にも失敗します。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadlaneat&#34;&gt;&lt;code&gt;QuadReadLaneAt&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、Quad内のローカルのLane Indexと、読み取り対象となる変数を指定します。Quad内で同じ値が返されます。
読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。
Pixel ShaderにおけるQuad内のローカルのLane Indexは、下図に示した通りRow Orientedとなっています。&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossdiagonal&#34;&gt;&lt;code&gt;QuadReadAcrossDiagonal&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに対角の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossx&#34;&gt;&lt;code&gt;QuadReadAcrossX&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに水平の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:1の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossy&#34;&gt;&lt;code&gt;QuadReadAcrossY&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに垂直の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavequadop_hudda5976e667c4f4ea513984d01905e77_110927_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavequadop_hudda5976e667c4f4ea513984d01905e77_110927_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;916&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;shader-model-65のwave-intrinsicsについて&#34;&gt;Shader Model 6.5のWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Model 6.5で、いくつかの新しいWaveIntrinsicsが導入されています。&lt;/p&gt;
&lt;h4 id=&#34;wavematch&#34;&gt;&lt;code&gt;WaveMatch&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。&lt;br&gt;
戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneの引数で指定された変数の値が、自身のLaneの変数の値と等しい場合に、ビットがセットされます。Inacive Laneは暗黙的に0が設定されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavematch_hu0c1f58aae92c4965302c5d4274ad6622_58909_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavematch_hu0c1f58aae92c4965302c5d4274ad6622_58909_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;707&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavemultiprefixsum&#34;&gt;&lt;code&gt;WaveMultiPrefixSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなる uint4 を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveSum&lt;/code&gt;と動作は似ていますが、加算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。
ビットマスクは、Laneごとに設定を変更出来ますが、一つのLaneは1種類のビットマスクにしか所属する事ができません。
つまり、ビットマスクによって、Laneをパーティショニングしてサブセット化する事が出来ますが、各々のLaneが完全に自由にビットマスクを指定できるわけではありません。一つのLaneが複数の種類のビットマスクに所属した場合の動作は未定義です。&lt;br&gt;
Waveのサイズを超えるBitやInactive Laneのビットは無視されます。(ビットがゼロとして扱います。)
このビットマスクの仕様は他のWaveMultiPrefix系と共通です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavemultiprefixsum_hue9d268744f4c6ffd484f30d798dfb5fc_135719_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavemultiprefixsum_hue9d268744f4c6ffd484f30d798dfb5fc_135719_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1182&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavemultiprefixproduct&#34;&gt;&lt;code&gt;WaveMultiPrefixProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveProduct&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixcountbit&#34;&gt;&lt;code&gt;WaveMultiPrefixCountBit&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、bool値を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveCountBit&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitand&#34;&gt;&lt;code&gt;WaveMultiPrefixBitAnd&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitAnd&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitor&#34;&gt;&lt;code&gt;WaveMultiPrefixBitOr&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitOr&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitxor&#34;&gt;&lt;code&gt;WaveMultiPrefixBitXor&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitXor&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに&lt;/h2&gt;
&lt;p&gt;今回は、Wawve Intrinsicsの動作を理解するための基本的な内容となっているので、実際の使用ケースについては言及しませんでした。
次回は、もう少し実際の利用ケースについて触れたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugo&#43;Academicでブログを構築</title>
      <link>https://shikihuiku.github.io/post/hello_hugo_and_academic/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://shikihuiku.github.io/post/hello_hugo_and_academic/</guid>
      <description>&lt;h3 id=&#34;動機とか&#34;&gt;動機とか&lt;/h3&gt;
&lt;p&gt;タイトルの画像は、今まで運用してきたWordpress上のサイトのスクリーンショットです。記念に撮ってきました。&lt;br&gt;
別にWordpressがいやになったという訳ではないのですが、Github pagesに移行したほうが制約も少なく扱いやすい気がしたので引っ越しすることにしました。Wordpressに書いた記事は、簡単に移行するのは難しそうなので、そのままにしておきます。&lt;/p&gt;
&lt;h3 id=&#34;hugoacademic&#34;&gt;Hugo＋Academic&lt;/h3&gt;
&lt;p&gt;別に十分な検討をしてこの組み合わせに至ったわけでは無く、静的サイト生成ツール＋なんか都合の良いTheme程度の認識で選択しました。今後変えるかもしれません。
ただ、コンテンツは多少特殊な要素があったとしても、基本的にMarkdownで記述できるので、今後もしサイトを移行しようと思っても、記事の移行をあきらめたくなるような事はないのではないでしょうか。&lt;/p&gt;
&lt;h3 id=&#34;導入手順&#34;&gt;導入手順&lt;/h3&gt;
&lt;p&gt;せかっくなので自分なりの導入手順を記しておきます。環境はWindows10を使用しています。Hugoは導入済です。&lt;/p&gt;
&lt;h4 id=&#34;academicの導入&#34;&gt;Academicの導入&lt;/h4&gt;
&lt;p&gt;まず、Hugoのテーマとして、Academicを導入しようとして、以下の様にファイルを配置しましたが、上手くいきませんでした。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git submodule add https://github.com/gcushen/hugo-academic.git themes/academic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academicのドキュメント&lt;/a&gt;を参照すると、Hugoの新規サイトの状態に加えて、いろいろなファイルが正しい位置に配置されている必要があるようで、
&lt;a href=&#34;https://github.com/sourcethemes/academic-kickstart.git&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;academic-kickstart.git&lt;/a&gt;をクローンすることがおすすめのようです。
初めはプライベートリポジトリとして扱いたいですし、リポジトリの名前も変えたいので、cloneしてmirrorします。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --bare https://github.com/sourcethemes/academic-kickstart.git
cd academic-kickstart.git
git push --mirror https://github.com/shikihuiku/blog.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;早速ローカルで初期状態を確認しようと思ったら、ビルドエラーが出ました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; hugo server
Building sites … ERROR 2020/07/25 17:30:35 render of &amp;quot;term&amp;quot; failed: execute of template failed: template: authors/list.html:5:3: executing &amp;quot;authors/list.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;section&amp;quot; failed: execute of template failed: template: section/publication.html:5:3: executing &amp;quot;section/publication.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;home&amp;quot; failed: execute of template failed: template: index.html:5:3: executing &amp;quot;index.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;taxonomy&amp;quot; failed: execute of template failed: template: authors/terms.html:5:3: executing &amp;quot;authors/terms.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 failed to render pages: render of &amp;quot;section&amp;quot; failed: execute of template failed: template: section/talk.html:5:3: executing &amp;quot;section/talk.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
Built in 84 ms
Error: Error building site: TOCSS: failed to transform &amp;quot;main_parsed.scss&amp;quot; (text/x-scss): resource &amp;quot;scss/scss/main.scss_76ac6956597c32fec7ddf60d408db3ab&amp;quot; not found in file cache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;調べてみると、Academicには、hugo_extendedが必要だという事が分かりましたので、
&lt;a href=&#34;https://github.com/gohugoio/hugo/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo_extendedのビルド済バイナリ&lt;/a&gt;をDLします。
再びローカルサーバーを立ち上げると、今回は上手くビルドできました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hugo server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ローカルホストのポート1313にアクセスすると、おしゃれなサイトが表示されました。BiographyやProjectsやPublicationsなど、かなりハイスペック人材向けのテンプレートで尻込みしますが、どんどん削っていくことにします。&lt;/p&gt;
&lt;h4 id=&#34;academicのカスタマイズ&#34;&gt;Academicのカスタマイズ&lt;/h4&gt;
&lt;p&gt;ここで先人の知恵をお借りします&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hugo + Academic テーマを使ったブログの作り方

&lt;a href=&#34;https://qiita.com/harumaxy/items/58e7e4273c61e7e260b3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://qiita.com/harumaxy/items/58e7e4273c61e7e260b3&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;/config/_default/フォルダに格納されている以下のtomlファイルを編集していきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;config.toml&lt;/li&gt;
&lt;li&gt;language.toml&lt;/li&gt;
&lt;li&gt;menus.toml&lt;/li&gt;
&lt;li&gt;params.toml&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;その他諸々の変更を行って、シンプルにBlogのポストができるページにしました。言語設定はenのまま使用する事にします。&lt;/p&gt;
&lt;h4 id=&#34;フォントの設定&#34;&gt;フォントの設定&lt;/h4&gt;
&lt;p&gt;デフォルトでは、GoogleのWebフォントがいろいろ指定されていますが、フォントの設定はシンプルな方が良いと思っています。
フォントのプリセットにNativeという設定があり、こちらを使うとrootのfont-familyの設定を、殆どの要素で使うようになるようです。config/_default/params.tomlでこれを指定します。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;font=&amp;ldquo;Native&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;rootにある、フォントの設定はとりあえず変更せずに使ってみます。&lt;/p&gt;
&lt;h4 id=&#34;customscssの設定&#34;&gt;custom.scssの設定&lt;/h4&gt;
&lt;p&gt;デフォルトではブラウザの横幅に対してページの表示領域が酷く狭いです。&lt;br&gt;
blog/assets/scss/custom.scssというファイルを配置することで、自身で記述したcssをページに読み込ませる事が出来るようです。生成されたHTMLの要素のクラス名を確認して適当に設定しました。なんだか横幅を変えるだけで泥臭い作業になりました。もっと簡単にスタイルを変更する方法があるかもしれません。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/*width for top page*/
.container {
    max-width: 90%;
}
/*width for posts.*/
.article-container{
    max-width:90%
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;また、見出しのフォントのWeightが一定では無いので変更します。ついでにマージンも変更します。
この辺りは素人なので、あまり参考になりませんが。
しかし、CSSを書いて変更できると結局楽だなってなって思ってきました&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h1, h2, h3, h4, h5, h6 {
    margin-top: 1.7rem;
    margin-bottom: 0.3rem;
    font-weight: 700;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;アイコンの設定&#34;&gt;アイコンの設定&lt;/h4&gt;
&lt;p&gt;それから、Webサイトのアイコン、所謂ファビコンがデフォルトの設定では、Academicのアイコンになっているので変更します。&lt;br&gt;
assets/images/フォルダに、解像度512x512のicon.pngを配置します。&lt;/p&gt;
&lt;h4 id=&#34;github-pagesの設定&#34;&gt;Github Pagesの設定&lt;/h4&gt;
&lt;p&gt;最後に、実際にビルドされたページをGithub Pagesでホスティングする方法ですが、一番簡単な方法はHugoの出力先をdocsフォルダにして、それをそのままリポジトリにPushして、GithubPagesで公開する方法だと思います。
Hugoはデフォルトではpublicフォルダにファイルが生成されるので、これを変更します。&lt;/p&gt;
&lt;p&gt;config/_default/config.tomlに以下の様に設定することで、docsフォルダにサイトが生成されるようになります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;publishdir= &amp;quot;docs&amp;quot;  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;あとは、baseurlを設定しサイトを生成してエラーがでなければOKです。リポジトリにPushして、github pagesの設定をすれば公開されます。&lt;/p&gt;
&lt;h4 id=&#34;github-pagesの設定---やっぱりprivateリポジトリで&#34;&gt;Github Pagesの設定 - やっぱりPrivateリポジトリで&lt;/h4&gt;
&lt;p&gt;構築履歴が閲覧可能な状態なのは別に構わないですし、大抵の場合はDraft記事が閲覧可能な状態でも構わないのですが、一部のCEDECセッションの補間資料とかのDraftは会期以前に公開状態になるのはまずいので、
publishしたべージのコンテンツのみを公開状態にする必要があります。結局Hugoのpublishdirのディレクトリ以下を別のリポジトリにして、こちらだけPublicに設定して、ビルド環境はPrivateリポジトリにすることにしました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>フォートナイトの入力遅延を観測してみた</title>
      <link>https://shikihuiku.github.io/post/check_input_latency_of_fortnite/</link>
      <pubDate>Tue, 16 Jun 2020 01:33:02 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/check_input_latency_of_fortnite/</guid>
      <description>&lt;pre&gt;&lt;code&gt;この記事は、旧サイトからテスト用に移植しました。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;入力遅延の問題はゲーム開発において悩ましい問題の一つです。特にPCでは、他のプロセスが勝手な都合で動作しますし、リソースの競合も発生します。また、PC本体のCPU/GPUパフォーマンスの違いも大きいです。ここでは一般的なデスクトップPC上で、フォートナイトの描画がどのように実行されているかをソフトウェアの見地から、GPUViewを用いて観測してみます。ここで言う入力遅延は、Windows上のゲームのプロセスがキーやマウスのステートを取得すると思われるタイミングから、描画された画面が、ディスプレイへの出力対象になるまでを指します。実際には、マウスやキーボードのハードウェアとドライバにも遅延がありますし、ディスプレイにも実際に輝点として可視化されるまでに遅延がありますが、これらは今回は考慮しません。またゲームのプロセスが正確にいつ入力デバイスの情報を取得しているかは考慮しません。あるフレームのCPU処理の開始を入力取得時間として考えます。&lt;br&gt;
ちなみに今回使用したデスクトップPCは、Core-i7 7700KとGeForce RTX2080Tiが搭載されています。モニタは一般的な60Hzの4Kディスプレイです。&lt;br&gt;
テストに使ったシーンは、クリエイティブの島です。描画としては極めて軽い状態がテスト対象です。&lt;/p&gt;
&lt;p&gt;UE4の開発者の方は、すでにご存じかと思いますが、以下の資料に入力遅延に関する詳しい解説がご覧いただけると思います。&lt;/p&gt;
&lt;p align=&#34;center&#34; style=&#34;text-align:center&#34;&gt;
&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/k13Vz8lkoluqKW&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt;&lt;br&gt;
&lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/EpicGamesJapan/ue4input-latency&#34; title=&#34;UE4のスレッドの流れと Input Latency改善の仕組み&#34; target=&#34;_blank&#34;&gt;UE4のスレッドの流れと Input Latency改善の仕組み&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;https://www.slideshare.net/EpicGamesJapan&#34; target=&#34;_blank&#34;&gt;エピック・ゲームズ・ジャパン Epic Games Japan&lt;/a&gt;&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;今回は、フォートナイトをプレイする上でどのような設定が一番自分にとって好ましいかを調べる過程で分かったことを説明していきます。フォートナイトの描画設定で、入力遅延に関係のある設定は、フレームレートの上限値、VSync、それから、マルチスレッドレンダリングです。描画APIはD3D11と12に対応していますが、D3D12にすることによる利点があまり感じられなかったため、今回はD3D11のみをテストしています。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-off-フレームレート上限-60&#34;&gt;VSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 60&lt;/h2&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mtoff_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_60_hu33bc11a1f895fdcc3ac8673383111945_278989_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mtoff_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_60_hu33bc11a1f895fdcc3ac8673383111945_278989_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1435&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mtoff_60
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;おなじみのGPUViewのログです。詳しく見たい方はクリックして拡大してください。まずは、スレッドのアクティビティを理解するために一番簡単な例を示します。VSyncがOffなので、青い縦線で示されたVSyncのタイミングとは全く関係なく描画されています。描画スレッドが、D3D11の描画APIを呼び出して、Present()を呼び出し、GPUが描画を完了するのとほぼ同時にフロントバッファへのFlipが行われ、ディスプレイへの表示対象になります。ドライバのスレッドに描画命令を発行しているスレッドが、UE4のRHIスレッドと思われますが、マルチスレッドレンダリングをOffにしているので、Renderのスレッドが、直接RHIを呼び出しているのではないかと思われます。それに先立ち動作しているスレッドがゲームのメインスレッドと思われます。ゲームのメインスレッドは、Render/RHIスレッドに渡す描画情報を構築するタイミングと思われるところで、フレームレートのペーシングを行っていると思われます。計測された入力遅延は、12.8msですが、CPUもGPUもアイドル時間が長いので、処理クロックを落としていると思われます。実際の場合も何も小細工しなければ、ユーザーの知らないところでクロックが下がるので、今回はこの設定の入力遅延は12ms前後と考えます。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-on-フレームレート上限-60&#34;&gt;VSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 60&lt;/h2&gt;
&lt;p&gt;次は、先ほどの設定から、マルチスレッドレンダリングを有効にしてみます。他の設定は同じです。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mton_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_60_hu1169490fbcbadeadc14156a6fb3266a4_276171_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mton_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_60_hu1169490fbcbadeadc14156a6fb3266a4_276171_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1640&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mton_60
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;見た目ががらりと変わっていますが、アイドリングしているWorkerスレッドにRenderと思われるスレッドが埋もれてしまったため、このような見た目になっています。実際は、どの設定でも多数のWorkerスレッドやサウンドのスレッドが立ち上げられていますが、描画に関係ないものは省略しています。先ほどの例と異なり、RHIのスレッドと思われるスレッドと、Renderと思われるスレッドが別になりました。基本的な仕組みや、遅延の状況はほぼ同じです。こちらもおそらく動作クロックが下がっているので、本来の描画パフォーマンスと比べると処理時間がかかっています。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-off-フレームレート上限-120&#34;&gt;VSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 120&lt;/h2&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mtoff_120&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_120_hu577993647c8741ecb07125375c0cb93a_249296_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mtoff_120&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_120_hu577993647c8741ecb07125375c0cb93a_249296_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1071&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mtoff_120
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;次は、再びマルチスレッドレンダリングをOFFに戻しました。そして、フレームレート上限を120にしてみました。基本的な動作は一番初めの例と同じですが、フレームのペーシングが8.3msになったことで、120FPSのレンダリングになりました。そして、アイドリングのデューティ比が変わったことにより、動作クロックが引き上げられた関係で、入力遅延も短縮され、9.5ms程度になりました。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-on-フレームレート上限-120&#34;&gt;VSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 120&lt;/h2&gt;
&lt;p&gt;次は、上記の設定でマルチスレッドレンダリングをONにします。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mton_120&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_120_hucb7e813ec08e0a34392eae9da6d7a916_251387_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mton_120&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_120_hucb7e813ec08e0a34392eae9da6d7a916_251387_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1018&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mton_120
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;やはり、RenderスレッドとRHIスレッドが分かれました。今回のテスト対象になっているシーンは軽いので、マルチスレッドレンダリングの恩恵は少ないですが、もっと複雑なシーンでは、これらのスレッドが並列動作することにより、Renderスレッドの描画命令発行によるストールが軽減され、より顕著な差になると思われます。少なくとも遅くなることはなさそうなので、私はこの設定でプレイすることにします。&lt;/p&gt;
&lt;h2 id=&#34;vsync-on-マルチスレッドレンダリング-off-フレームレート上限-制限なし&#34;&gt;VSync: ON マルチスレッドレンダリング: OFF フレームレート上限: 制限なし&lt;/h2&gt;
&lt;p&gt;次は、いわゆる、VSyncを守って、画面のティアリングを起こさない描画になります。見た目は一番スムーズなのですが、入力遅延の観点からはあまりお勧めできない設定となりそうです。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncon_mtoff_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncon_mtoff_60_hu1e8bb69aa4e2d9153699b0a96e4ee908_517763_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncon_mtoff_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncon_mtoff_60_hu1e8bb69aa4e2d9153699b0a96e4ee908_517763_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1619&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncon_mtoff_60
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;まず、VSyncを取ると、メインスレッドの動作がかなり変わります。およそ2ms単位でスレッドをポーリングしながら、処理開始のタイミングを計っているようです。rhi.SyncSlackMSのデフォルト設定と思われる、VSyncの10ms前に、メインスレッドの処理を開始しています。Renderスレッドは、前の前のフレームのGPU描画処理が完了してから、RHIの呼び出しを開始しているようです。そして、RHIが呼び出すD3DAPIによって生成されたGPUタスクは、ドライバのGPUタスクキューに積み上げられます。そのフレームのGPU描画処理がGPU上で実行されるのは、Renderスレッドが動作したフレームの次の次のフレームです。そして、ディスプレイの出力対象になるFlipが行われるのは、VSyncに同期しているので、実際の表示はその次のフレームとなります。メインスレッドが動作を開始してから、ディスプレイの出力対象になるまでの入力遅延は60msほどとなります。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;まとめ&lt;/h3&gt;
&lt;p&gt;少なくとも私の環境では、VSyncをOFFにして、CPUのフレームペーシングがボトルネックになる状態（つまりGPUの処理時間には余裕がある状態）で、なるべく高いフレームレートが入力遅延が一番小さくなる状態だといえると思います。入力遅延を最短にするという目的ならば、私のPCでは、おそらく200フレーム以上の設定の方が短くなると思われます。しかし、使用しているディスプレイも60Hzですし、描画解像度など他の設定に妥協が必要になります。
また、これらの状況は、個々のPCの、CPUとGPUの処理能力のバランスによって変動するので、皆さんに一概にこの設定がおすすめですとはなりません。しかし、VSyncはOff、なるべく早いCPU、なるべく早いGPU、なるべく軽い描画が、入力遅延低減につながると思われます。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
