<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</title>
    <link>https://shikihuiku.github.io/post/</link>
      <atom:link href="https://shikihuiku.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 20 Jun 2022 14:54:40 +0900</lastBuildDate>
    <image>
      <url>https://shikihuiku.github.io/images/icon_hu127225d7ed9c50974404790b7c221374_401884_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://shikihuiku.github.io/post/</link>
    </image>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(2)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_second_step/</link>
      <pubDate>Mon, 20 Jun 2022 14:54:40 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_second_step/</guid>
      <description>&lt;p&gt;前提知識として、
&lt;a href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/&#34; title=&#34;About Us&#34;&gt;RTXDIのminimal-sampleをSpatioTemporal Resamplingなしの場合の動作&lt;/a&gt;について理解する必要があります。&lt;/p&gt;
&lt;h1 id=&#34;risとrestir&#34;&gt;RISとReSTIR&lt;/h1&gt;
&lt;p&gt;minimal-sampleは、まず初めに、現在レンダリングしているフレーム内でLight SampleとBRDF SampleをMISで結合したRservoirを生成します。この時点でもReservoirの結合を行いますが、基本的には Resampled Importance Sampling: RISのアルゴリズムに基づいて最適なライトパスの選択が行われます。&lt;br&gt;
加えて、&amp;ldquo;Enable Resampling&amp;quot;チェックボックスを有効にした場合は、現在のフレームで生成したReservoirと、前のフレームで生成されたReservoirを結合することで、さらに良質なライトパスの選択を行うことが出来ます。この処理を、Reservoir-based SpatioTemporal Importance Resampling: ReSTIRと呼びます。&lt;/p&gt;
&lt;h2 id=&#34;restirの効果&#34;&gt;ReSTIRの効果&lt;/h2&gt;
&lt;p&gt;端的にReSTIRの効果の有無を比較すると以下のようになります。ReSTIRの処理が追加されるので処理負荷は大きくなりますが、もしもReSTIRを使わずに、これと同等のレンダリングを達成するためには、ずっと多くの処理時間が必要となるでしょう。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-risrestir&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&amp;#43;ReSTIR&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS+ReSTIR
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ris&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;rtxdi_spatiotemporalresamplingの処理&#34;&gt;RTXDI_SpatioTemporalResampling()の処理&lt;/h2&gt;
&lt;p&gt;RTXDI SDKのReSTIRの処理は、&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数で行われます。minimal-sampleではRender.hlslから呼ばれています。引数には、以下の情報を渡します。返り値として、ReSTIRで結合されたReservoirが返されます。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reservoir = RTXDI_SpatioTemporalResampling(pixelPosition, primary.surface, reservoir, rng, stparams, params, temporalSamplePixelPos, lightSample);&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pixelPosition&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelの位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;surface&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelのサーフェース情報（位置, 法線 tec..）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;curSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在のフレームで生成したReservoir&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rng&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;乱数生成用のステート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stparams&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理に関するのパラメーター（後述)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;params&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI SDKの定数パラメーター（バッファのオフセット情報など）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;temporalSamplePixelPos&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに成功した場合は、そのピクセル位置が格納されます。失敗すれば(-1,-1)が格納されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selectedLightSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理でReservoirの選択サンプルが更新された場合は、このライトサンプルの情報が更新されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdi_spatiotemporalresamplingparameters-構造体&#34;&gt;RTXDI_SpatioTemporalResamplingParameters 構造体&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数を呼び出す際の引数にあるこの構造体には、 ReSTIRの制御に関する様々なパラメーターが格納されています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;screenSpaceMotion&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理しているピクセルのモーションベクトルです&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sourceBufferIndex&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoirバッファのフレームごとの参照オフセットを計算するためのインデックスです。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxHistoryLength&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合されたReservoirのウエイトの上限を決めます。この値が大きいほど、過去に多数のReservoirと結合されたサンプルのウエイトが高くなります。&lt;/li&gt;
&lt;li&gt;また、逆を言えば、シーンの変化への追従が悪くなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;biasCorrectionMode&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoir結合時のBiasの補正方法です。&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_OFF
&lt;ul&gt;
&lt;li&gt;Biasの補正をしない結合方法を使います。処理は一番軽いですが、レンダリング結果にBiasを導入します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_BASIC
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正しますが基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_PAIRWISE
&lt;ul&gt;
&lt;li&gt;pairwise MISという方法でBiasを補正します。基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。今回の記事では説明しません。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正したうえで、レイトレースを行い結合されたReservoirが有効かどうかをチェックします。基本的にBiasを導入しない方法です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;depthThreshold, normalThreshold&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionをしたときに、法線とデプスの相似度をチェックする際の閾値です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合を試みるReservoirの数です。最低1必要で、最初の一つは、TemporalResamplingとなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numDisocclusionBoostSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに失敗した場合に、SpartialSampleの数を増やす場合のサンプル数です&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;samplingRadius&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;SpartialSampleのサンプリング半径（ピクセル単位）です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enableVisibilityShortcut&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACEDの時のみ有効です。&lt;/li&gt;
&lt;li&gt;Reservoir結合後に、Visibilityテストを行う際にTemporalSampleが選択された場合はVisibilityテストをスキップします。
&lt;ul&gt;
&lt;li&gt;（ここのIfの判定は不明。おそらくだが、選択されたサンプルのReservoirのVisibilityテストをスキップするのが正しいと思う。（なぜならそれは前フレームで行ったから。））&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enablePermutationSampling&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;BackprojectionとSpartialSamplingの位置にに小さいオフセットを適用します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;backprojectionの処理&#34;&gt;Backprojectionの処理&lt;/h4&gt;
&lt;p&gt;まず、前のフレームのReservoirと結合するためには、Backprojectionの処理を行う必要があります。この処理自体は、通常我々が行っているものと違いはありません。モーションベクトルを基に、過去フレームのサンプル位置を算出し、その近傍で、法線やDepthの類似性が高いサンプルを探します。&lt;/p&gt;
&lt;h4 id=&#34;temporal-sampleの読み出し&#34;&gt;Temporal Sampleの読み出し&lt;/h4&gt;
&lt;p&gt;Backprojectionが成功したら、Reservoirバッファより、前フレームのPixel位置に対応するReservoirを読み出して&lt;code&gt;prevSample&lt;/code&gt;に格納します。読み出されるのは前のフレームに保存されたReservoirの情報になります。読み出したReservoirに対して以下の処理を行います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;をhistoryLimitでクランプ&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spartialDistance&lt;/code&gt;にピクセルオフセットを加算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;age&lt;/code&gt;をインクリメント&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightID&lt;/code&gt;を現在のフレームのライトバッファに対応するIDに変換
&lt;ul&gt;
&lt;li&gt;lightIDの変換では、もし該当するライトが、現在のフレームになければ読み出したReservoirを破棄します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;temporal-sampleの結合&#34;&gt;Temporal Sampleの結合&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;prevSample&lt;/code&gt;が有効なReservoirだった場合は、現在のフレームで生成されたReservoirと結合します。
まず、&lt;code&gt;prevSample&lt;/code&gt;のReservoirの情報を基に、Light Sampleを構築します。ここで構築されるLight Sampleは、読み出し時に、ligtIDを変換したので、現在のフレームにおける光源サンプルの位置になります。そして、現在処理をしているSurfaceとそのLight Sampleで、&lt;code&gt;targetPDF&lt;/code&gt;を計算します。（つまりシェーディングの計算をします。）この値は、前のフレームのReservoirを結合する際の、ウエイトの補正に使います。&lt;/p&gt;
&lt;p&gt;結合の計算の詳細:&lt;br&gt;
まず、&lt;code&gt;prevSample&lt;/code&gt;はFinalizeされて格納されているので、そのメンバー変数&lt;code&gt;weightSum&lt;/code&gt;は意味的には、(1/targetPDF * 1/M * weightSum)の値になっています。
そして、&lt;code&gt;prevSample&lt;/code&gt;のRIS Weightは、プログラム上では(&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;呼び出しの引数の&lt;code&gt;targetPdf&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;weightSum&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;M&lt;/code&gt;)で計算されます。&lt;br&gt;
これを意味的に解釈すると(引数のtargetPDF)/(元のtargetPDF) * weightSum となります。
つまり本来の意味でのweightSumに、新旧のtargetPDFの比を乗算したものがRISWeightとして使われることになります。
結合後は、MとRISWeightはそれぞれ結合先のReservoirに加算され、乱数によるサンプルの選択が行われることで結合が完了します。&lt;/p&gt;
&lt;h4 id=&#34;spartial-sampleの読み出しと結合&#34;&gt;Spartial Sampleの読み出しと結合&lt;/h4&gt;
&lt;p&gt;minimal-sampleにおいて、Spartial SampleはTemporal Sampleと同様に、前フレームのGBufferとReservoirバッファから読み出されます。
テストするサンプル数は、デバッグUI上の&lt;code&gt;Spartial Sample&lt;/code&gt;のスライダーで調整できます。Temporal Sampleとの主な違いは、Backprojectionした位置から、さらに、&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;から取得した値でオフセットを適用するところにあります。&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;はSDK側からその内容があらかじめ提供されている静的なバッファで、Spartial Sampleのサンプリングパターンが格納されています。読み出したサンプルは、Normal, Dpethそして、GbuffのMaterialの相似度をみて、サンプルが有効かを判定します。&lt;br&gt;
有効な場合は、Temporal Sampleの場合と同様にReservoirを結合行います。結合の計算は、Temporal Sampleの場合と同じです。&lt;/p&gt;
&lt;h4 id=&#34;biasの補正とreservoirのfinalize処理&#34;&gt;Biasの補正とReservoirのFinalize処理&lt;/h4&gt;
&lt;p&gt;隣接ピクセルや、過去のフレームのReservoirとの結合はBiasを発生させることがあります。例えば、異なるピクセルで生成した複数のReservoirを結合した場合、個々のピクセルの積分範囲（法線を中心とした半球）は異なるため、もし、結合後に選択したLight Sampleが、結合された、とあるReservoirの積分範囲の外であったり、不可視な状態だったなら、このReservoirから&lt;code&gt;M&lt;/code&gt;の値を、Fianlize処理するときの分母に含めてはいけません。そうしないと、Biasが発生してしまいます。（詳しくはReSTIRの論文を参照）&lt;/p&gt;
&lt;p&gt;可視状態の確認は、&lt;code&gt;biasCorrectionMode&lt;/code&gt;に&lt;code&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED&lt;/code&gt;が設定された場合に実行されます。具体的には、選択されたLight Sampleの位置と、各Reservoirの位置を、過去のフレームのBVHでレイトレースして、可視状態を確認します。（ただし、サンプル内の実際の処理では、シーンがスタティックであると仮定して、単純に現在のフレームのBVHでレイトレースするように実装されています。）&lt;/p&gt;
&lt;p&gt;次にFinazlieの処理についてです。&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数の正規化部分では、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;という変数が、Finalizeする際の係数の分子と分母になるように記述されています。もしも、ここがもっと単純な記述だったら、&lt;code&gt;pi&lt;/code&gt;は常に1で、&lt;code&gt;piSum&lt;/code&gt;には、選択したLight SampleがそのReservoirの積分範囲内で、かつ可視状態の、有効なReservoirの&lt;code&gt;M&lt;/code&gt;のみを加算することで、Finalize処理の係数を算出する形になります。（ReSTIR論文における1/Zに相当）&lt;br&gt;
しかし、RTXDIでは、MISのように正規化の係数を計算しています。具体的には、選択されたLight Sampleと各Reservoirの位置で、&lt;code&gt;targetPDF&lt;/code&gt;を計算し、可視状態ならば(&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;)という値を分母側の&lt;code&gt;piSum&lt;/code&gt;に蓄積しています。分子側の&lt;code&gt;pi&lt;/code&gt;は選択されたLight Sampleを保持していたReservoirとの&lt;code&gt;targetPDF&lt;/code&gt;です。つまり、選択されたLight Sampleを保持していたReservoirの&lt;code&gt;targetPDF&lt;/code&gt;(つまりはシェーディングの輝度）が相対的に他のReservoirと計算した輝度よりも高ければ、Finalizeする際の係数が大きくなるように計算されています。&lt;/p&gt;
&lt;p&gt;また、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;の初期値は、Temporal SampleやSpatial Sampleとの結合前の、現在のフレームで計算されたReservoirの値を設定します(&lt;code&gt;curSample.M&lt;/code&gt;)。これのMISのウエイトとして&lt;code&gt;state.targetPdf&lt;/code&gt;を使っています。これは、現在選択されているLight Sampleと、現在処理中のサーフェースで計算された&lt;code&gt;targetPDF&lt;/code&gt;で、この値は、他のTemporal SampleやSpatial Sampleのために計算する&lt;code&gt;targetPdf&lt;/code&gt;に対応する値です。（この値は、現在のフレームのデータで計算しています。他のTemporal SampleやSpatial SampleのReservoirの&lt;code&gt;targetPdf&lt;/code&gt;は前フレームのデータで計算しているという点は異なります。）&lt;/p&gt;
&lt;p&gt;ループ処理が完了すれば、結合されたすべてのReservoirのBiasの除外のチェックが完了したことになります。そして、&lt;code&gt;pi&lt;/code&gt;には選択されたサンプルの&lt;code&gt;targetPDF&lt;/code&gt;が格納され、&lt;code&gt;piSum&lt;/code&gt;には&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;の総和が格納されています。 &lt;code&gt;pi&lt;/code&gt;/&lt;code&gt;piSum&lt;/code&gt;を正規化係数としてFinalize処理を行うことで、Biasの補正をした結合ができます。&lt;/p&gt;
&lt;h5 id=&#34;biasの補正をしない場合のreservoirのfinalize処理&#34;&gt;Biasの補正をしない場合のReservoirのFinalize処理&lt;/h5&gt;
&lt;p&gt;Biasの補正をしない場合は、単純に結合されたReservoirを1/Mを正規化係数として、Finalize処理します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(1)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_first_step/</link>
      <pubDate>Tue, 07 Jun 2022 19:30:28 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_first_step/</guid>
      <description>&lt;h1 id=&#34;rtxdiとは&#34;&gt;RTXDIとは？&lt;/h1&gt;
&lt;p&gt;GPU上かどうかにかかわらずレイトレーシングやパストレーシングを行う際の重要な課題の一つは、追跡する光線の軌跡（パスもしくはレイと呼ばれるもの）をどのように構築するかです。これはレンダラーの性能や画質などの特性に直結する問題です。たとえば、物体表面からの反射に限定すれば、最も簡単なパスの構築方法は、物体の表面から半球状ににランダムな方向を選択してパスを構築する方法があると思います。また、物体表面の反射特性に合わせて、より反射率の高い方向を高確率で選択する方法や、シーン上に存在する光源の方向にパスを構築する方法もあります。&lt;br&gt;
このように、いろいろなパスの選択戦略があり、実際のレンダリングでは、これらを組み合わせて使うことがよくある思います。そして、最も理想的なパスの確率分布は、その物体表面から、観測者の方向へのRadianceに比例した確率分布といわれています。しかしこれは、一般的には解析的に解くことが極めて困難であることがほとんどです。なぜなら、物体表面の反射特性は分かっても、どの方向から強い光が差し込んでくるかはわかりません。その光も、シーン上に設定された光源からの直接光なのか、それとも何かほかの物体から反射された光なのかわかりません。&lt;br&gt;
RTXDIは、光源からの直接光によって形成されるRadianceに対して、最適なパスの確率分布を形成するようにパスの選択をするためのNVIDIAのSDKです。名前の由来は、おそらくRTX Direct Illuminationです。&lt;/p&gt;
&lt;h4 id=&#34;リポジトリ&#34;&gt;リポジトリ&lt;/h4&gt;
&lt;p&gt;GitHubのリポジトリがあるので、さっそくCloneしてみましょう。&lt;br&gt;
以降の説明では基本的にCloneしたソースを読める状態にある前提で書いています。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;ドキュメント&#34;&gt;ドキュメント&lt;/h4&gt;
&lt;p&gt;RTXDIのSDKのドキュメントを見る前に、前提知識として、Resampled Importance Sampling(RIS)のアルゴリズムの基礎部分を理解した方がよいと思います。（これより先は、Resampled Importance SamplingをRISと省略します。）&lt;br&gt;

&lt;a href=&#34;https://www.google.com/search?q=Importance&amp;#43;Resampling&amp;#43;for&amp;#43;Global&amp;#43;Illumination&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Importance Resampling for Global Illumination&amp;rdquo; by J. Talbot et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RTXDIのSDKには、その概要を把握するのに下記のドキュメントがありますが、これを読んで理解できる人は、この記事はここで読むのを終了していただいて、SDKのドキュメントやソースコードを直接参照した方が良いでしょう。

&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;rtxdi-sampleとminimal-sample&#34;&gt;rtxdi-sampleとminimal-sample&lt;/h4&gt;
&lt;p&gt;このSDKにはサンプルプロジェクトが二つ付いています。&lt;br&gt;
rtxdi-sampleは、RTXDIをパス選択の核として、RTXGIやNRDやDLSSを用いてレンダリングしています。またReGIRという、ワールド空間におけるRISも行っているので、かなり実践的なサンプルになっている一方で、初めのステップとして、RTXDIの動作を理解したい場合には不向きなサンプルです。&lt;br&gt;
一方で、minimal-sampleは、設定を変更することで時間方向のRISや、BRDFに基づくサンプリングも無効にすることが出来ます。また、NRDによるデノイズも行っておらず、レンダリングは極力単純な形で留めてあります。そのため、RTXDIの核であるRISの仕組みや、その効果をわかりやすく見せてくれるサンプルになっています。本記事ではこちらのサンプルプログラムの動作を見ていきます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleのスクリーンショット&#34;&gt;minimal-sampleのスクリーンショット&lt;/h1&gt;
&lt;p&gt;端的にRTXDIの効果の一端を見るためにいくつかのスクリーンショットを用意しました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-1サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;1サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    1サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-8サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;8サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    8サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

まずは上記3枚は、RTXDIのパス選択候補を、8サンプル、16サンプルと増加させたものです。選択候補は増やしているのですが、実際にれらのサンプルでレイトレースを行った訳ではありません。レイトレースはあくまで1回のみ行います。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプルbrdf2サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル＋BRDF2サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル＋BRDF2サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

次は、16サンプル+BRDF2サンプルの場合です。こちらはレイトレース回数は、合計3回となります。BRDFサンプルによって、良い選択候補が見つかるサーフェースでの変化が顕著に見られます。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-4サンプルbrdf1サンプルspatio-temporal-resample&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;4サンプル＋BRDF1サンプル&amp;#43;Spatio-Temporal Resample&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    4サンプル＋BRDF1サンプル+Spatio-Temporal Resample
  &lt;/figcaption&gt;


&lt;/figure&gt;

今回の記事では説明しませんが、Spatio-Temporalのパス選択候補を導入すると、上記のようになります。上記の16サンプルと同等の処理時間ですが、結果は圧倒的にこちらが優れています。デノイズ処理は一切入っていない状態でここまでレンダリングできれば、かなり高画質なレンダリングが期待できます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleを読む前に前提知識&#34;&gt;minimal-sampleを読む前に（前提知識）&lt;/h1&gt;
&lt;p&gt;ここでサンプルプログラムのレンダリングを見る前に、簡単に触れておいた方が良い前提知識について説明します。&lt;/p&gt;
&lt;h4 id=&#34;nvrhiとdonutフレームワーク&#34;&gt;NVRHIとDonutフレームワーク&lt;/h4&gt;
&lt;p&gt;RTXDI SDKのほかに、minimal-sampleが依存している主なライブラリとして、DonutとNVRHIがあります。&lt;br&gt;
NVRHIは、D3D12とVulkanを抽象化するためのグラフィックスAPIの抽象化レイヤーです。とはいえそれほど深い抽象化が行われているわけではありません。&lt;br&gt;
Donutは、サンプルアプリケーションのフレームワークに相当する部分になります。シーンのロードやシェーダーの管理、デバッグUIの表示などを行っています。こちらもサンプル向けのフレームワークなので、シンプルに記述されています。今回のサンプルプログラムでは、それほど多数のDispatchが呼び出されるわけではないので、動作の理解に苦しむことはないかと思います。&lt;/p&gt;
&lt;h4 id=&#34;rab_プレフィックスについて&#34;&gt;RAB_プレフィックスについて&lt;/h4&gt;
&lt;p&gt;RTXDIのサンプルを見ると、RTXDI_プレフィックスの関数や構造体とは別に、RAB_プレフィックスの関数や構造体がたくさんあります。RABの意味はRTXDI Application Bridgeという意味で、その名の通り、RTXDIとアプリケーションの橋渡しの役目があります。&lt;br&gt;
RTXDIがRISを行うときに必要になる情報は、アプリケーションのレンダラーと密接に関係しています。そのため、RTXDIがアプリケーション由来の情報と思われるものを取得する際は、RAB_プレフィックスのついた関数を呼び出します。RTXDIが呼び出している、RABプレフィックスのついた関数を実装するのは、アプリケーション側の責任となります。
しかし実際は、サンプルアプリケーションのRAB実装である、RtxdiApplicationBridge.hlslを改変する形で自身のアプリケーションに組み込む形になると思います。このようにすることで、アプリケーションごとに改変の必要な部分と不要な部分の切り分けを実現しています。&lt;/p&gt;
&lt;h4 id=&#34;rtxdi特有のリソース&#34;&gt;RTXDI特有のリソース&lt;/h4&gt;
&lt;p&gt;通常のG-Bufferなどに加えて、minimal-sampleでRTXDI SDKを導入したことで必要となるリソースは以下の通りです。RTXDIは、SDKの内部でリソースを確保することはありません。リソースの管理は、生成、破棄を含め、すべてアプリケーション側の管理となります。  SDK側からは必要に応じて、リソースのサイズやその中身がAPIを通じて提供されるので、アプリケーションはそれらを正しく管理しなくてはなりません。
以下のリソースは、ソースコード全体の把握では大切な要素ですが、RISのアルゴリズム部分ではあまり関わりが無いので読み飛ばしても問題ありません。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TaskBuffer&lt;br&gt;
RTXDIは、毎フレーム直接光源情報のテーブルの更新を行っています。これはPrepareLightというGPU処理マーカーの中でComputeShaderとして行われています。この処理の入力として TaskBufferが必要となります。このバッファはPrepareLightsTask構造体の配列となっています。
このサンプルでは、シーン上でEmissiveサーフェースを持ったGeometry Instanceの個数分のバッファを確保しています。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightBuffer&lt;br&gt;
RTXDIがアクセスする光源の情報はすべてこのバッファに格納されます。個々の光源は、RAB_LightInfo構造体に格納されます。
このサンプルでは、Emmisiveのマテリアルが設定されたポリゴン一つ一つがEmissiveTriangleの光源としてこの配列に設定されます。
TaskBufferによって入力された情報をもとに、このバッファが構築されます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GeometryInstanceToLightBuffer&lt;br&gt;
Geometry Instanceごとに、そのInstanceに含まれるEmissiveTriangleの光源としてのLightBufferにおける先頭のインデックスを格納します。つまり、GeometryInstanceのインデックスからLightBufferを参照するときに使われるテーブルです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeighborOffsetBuffer&lt;br&gt;
RTXDIがサイズを提供しと内容を指定します。スクリーンスペースでRISを行うときに参照するべきPixelへのオフセットになる値が格納されます。EvenとOddのフィールドがあるのでRTXDIが提供するNeighborOffsetCountの2倍の数で、RG8_SNORMのTypedBufferを確保します。
レンダリングの前に、RTXDIのFillNeighborOffsetBuffer()で取得できるバイト列をこのバッファに書き込む必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightReservoirBuffer&lt;br&gt;
RTXDIがサイズを提供し内容はComputeShaderで算出されます。
ReservoirBuffer一つあたりのサイズはsizeof(RTXDI_PackedReservoir) * context.GetReservoirBufferElementCount()で、RTXDIから提供されます。
これをアプリケーション側の好きな数だけ確保します。サンプルの初期値では3セット分のサイズのバッファを確保しています。
時間方向でRISを行う場合のためのバッファになります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdiのreservoirについて&#34;&gt;RTXDIのReservoirについて&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;（ここより以下、RTXDIもしくはRISの文脈で、&amp;ldquo;サンプル&amp;quot;と言っている場合は、レイトレーシングにおけるサーフェースと光源を結ぶパスを構築するためのLight Sampleを指します。サンプルアプリケーションのことでもなければ、テクスチャのサンプリングのことでもありません。）&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;
RTXDI_Reservoir構造体はRISのReservoirとしての情報を保持します。Reservoirとは、RISをするためのサンプルの集合です。ただし、サンプルの集合の情報をすべて保持していたら、GPU上ではメモリが足りません。したがって、Reservoirは今まで生成してきたサンプルによる確率の計算と、現在そのReservoirで選択されているサンプルの情報を格納しています。具体的には、サンプルの選択確率に関する情報と、パスの接続対象なる光源のインデックス、その光源の表面における位置情報にあたるUVです。これがあれば、ワールド空間でパスを接続するべき位置（つまりは光源の表面位置）が計算でき、シェーディングを行った後にサンプルの確率密度を適用することができます。&lt;br&gt;
Reservoirに関して全くイメージがわかないという場合は、まず初めに紹介した論文を軽く読んで、ReSTIRに関する論文、

&lt;a href=&#34;https://research.nvidia.com/sites/default/files/pubs/2020-07_Spatiotemporal-reservoir-resampling/ReSTIR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting&amp;rdquo;, Bitterli et al. 2020&lt;/a&gt;&lt;br&gt;
を読むとイメージできると思います。（もしこの二つを読んだならば、本記事は、この先読む必要がないでしょう）&lt;/p&gt;
&lt;h4 id=&#34;reservoirを操作する関数群&#34;&gt;Reservoirを操作する関数群&lt;/h4&gt;
&lt;p&gt;ここではRTXDIがReservoirを操作する関数群のなかで、最も基本的なものをザックリと説明します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RTXDI_Reservoir RTXDI_Reservoir RTXDI_EmptyReservoir()&lt;/code&gt;&lt;br&gt;
有効なサンプルが一つも格納されていない、初期化された&lt;code&gt;RTXDI_Reservoir&lt;/code&gt;構造体を返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_StreamSample( inout RTXDI_Reservoir reservoir, uint lightIndex, float2 uv, float random, float targetPdf, float invSourcePdf)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reservoir&lt;/code&gt; - 格納するReservoir&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightIndex&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; - 追加するLight Sampleの情報&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random&lt;/code&gt; - Light Sampleを更新するかどうかをDraw（選択）するときに使う乱数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPdf&lt;/code&gt; - RISにおけるTarget PDF&lt;/li&gt;
&lt;li&gt;&lt;code&gt;invSourcePdf&lt;/code&gt; - 追加するサンプルを生成する確率の逆数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一つのサンプルをReservoirに追加して、現在このReservoirの中で選択されているサンプルを更新します。&lt;br&gt;
&lt;code&gt;targetPDF&lt;/code&gt;は実際は正規化されたPDFである必要はなく、単なるウエイト値で問題ありません。一方で、&lt;code&gt;invSourcePdf&lt;/code&gt;は、サンプルの発生確率に基づいたPDFである必要があります。関数内部では、RIS Weightが &lt;code&gt;targetPdf * invSourcePdf&lt;/code&gt; で計算され、Reservoir構造体の &lt;code&gt;weightSum&lt;/code&gt; に加算されます。Reservoirの保持サンプル数&lt;code&gt;M&lt;/code&gt;もインクリメントされます。また、与えられた &lt;code&gt;random&lt;/code&gt;でサンプルの選択を行い、新たに追加されたサンプルが選択された場合はReservoir内部の選択サンプルの情報を更新します。その場合は、返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;void RTXDI_FinalizeResampling( inout RTXDI_Reservoir reservoir, float normalizationNumerator, float normalizationDenominator) &lt;/code&gt;&lt;br&gt;
通常は、Reservoirへのサンプル追加が終わった段階で呼び出す処理で、Reservoirに蓄積されたサンプルの確率と、現在選択されているサンプルの確率から、選択されているサンプルの評価値（つまりはシェーディング結果）に乗算するべき値 (Importance Samplingにおける 1/PDF) を計算します。&lt;br&gt;
&lt;code&gt;normalizationNumerator&lt;/code&gt;, &lt;code&gt;normalizationDenominator&lt;/code&gt;は蓄積されたサンプルの&lt;code&gt;weightSum&lt;/code&gt;を正規化するときの係数です。単独のReservoirであれば、Reservoirに蓄積されたサンプル数の逆数である、1/&lt;code&gt;M&lt;/code&gt;が係数として適切です。この場合、1/&lt;code&gt;targetPDF&lt;/code&gt; * (1/&lt;code&gt;M&lt;/code&gt; * &lt;code&gt;weightSum&lt;/code&gt;)を計算し、これを &lt;code&gt;weightSum&lt;/code&gt; に代入します。&lt;br&gt;
したがって、この関数を呼び出す前と後では構造体メンバーの&lt;code&gt;weightSum&lt;/code&gt;の値の意味が変わります。呼び出す前はReservoirに蓄積されたサンプルのウエイトの合算で、呼び出した後は、選択されたサンプルの評価値に乗算するべき値となります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float RTXDI_GetReservoirInvPdf(const RTXDI_Reservoir reservoir)&lt;/code&gt;&lt;br&gt;
Sampleの評価値に乗算するべき係数（Importance Samplingにおける1/PDF）を返します。&lt;br&gt;
内部の処理は&lt;code&gt;weightSum&lt;/code&gt;の値を返すだけです。事前に&lt;code&gt;FinalizeResampling()&lt;/code&gt;を呼ぶ必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_CombineReservoirs( inout RTXDI_Reservoir reservoir, const RTXDI_Reservoir newReservoir, float random, float targetPdf)&lt;/code&gt;&lt;br&gt;
二つのReservoirを結合します。&lt;br&gt;
まず、結合前に結合される側の&lt;code&gt;newReservoir&lt;/code&gt;は&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;で正規化されている必要があります。&lt;br&gt;
引数&lt;code&gt;targetPdf&lt;/code&gt;は、結合される&lt;code&gt;newReservoir&lt;/code&gt;で選択されているサンプルの、結合先Reservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;になります。結合される側と結合先でのtargetPdfが同じ場合は、引数の&lt;code&gt;targetPdf&lt;/code&gt;は、&lt;code&gt;newReservoir&lt;/code&gt;に保存されているサンプルのtargetPdfを指定すればよいです。&lt;br&gt;
結合後は、現在どちらかのReservoirで選択されているサンプルが選択サンプルになります。これを&lt;code&gt;random&lt;/code&gt;を用いて決めます。選択サンプルが変更される場合は返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;minimal-sampleの中身brfont-size1spatio-temporalでrisを行わない場合のレンダリングfont&#34;&gt;minimal-sampleの中身&lt;br&gt;&lt;font size=&#34;+1&#34;&gt;~Spatio-TemporalでRISを行わない場合のレンダリング~&lt;/font&gt;&lt;/h1&gt;
&lt;p&gt;レンダリングを理解するうえでの前提知識が整ったので、さっそく一番簡単なケースのレンダリングを見たいと思います。
Spatio-TemporalでのRISは、RTXDIの大きな特長の一つですが、今回は単純化のために無効化した状態でサンプルコードを読み、
RTXDIの最もシンプルな形を理解するこにします。このサンプルアプリケーションは、&amp;ldquo;Enable Resampling&amp;quot;というDebugUIが用意されているのでこれをDisableにします。しかしこれはSpatio-TemporalのRISを行うかどうかを切り替えるためのフラグで、RTXDIを完全にDisableにするためのものではありません。また、BRDF Cutoffも、簡単のため0.0が設定されていると仮定します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-settings&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Settings&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;30%&#34; height=&#34;351&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Settings
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;レイトレーサー本体の概要&#34;&gt;レイトレーサー本体の概要&lt;/h4&gt;
&lt;p&gt;Renderer.hlslのmain()がレイトレーサー本体のシェーダーコードです。カメラからレイを飛ばして、GBuffer相当の情報を取得している部分は特に難しい部分はないと思います。サーフェースにヒットした場合は、乱数シーケンスを初期化して、RTXDI_SampleParamterにサンプリングの設定をしています。その後の主な処理の流れは以下の通りです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空のReservoirに、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;でReservoirの正規化を行う&lt;/li&gt;
&lt;li&gt;選択パスが、RTXDI_SampleLocalLights()だったら、ShadowRayをキャストして、Visibilityをチェック&lt;/li&gt;
&lt;li&gt;ShadeSurfaceWithLightSample()で、Reservoirで選択されたサンプルを使ってシェーディングを行う&lt;/li&gt;
&lt;li&gt;再びShadowRayをキャストしてVisibilityをチェック&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Spatio-TemporalのRISが無効化されている場合は、最後の2度目のVisibilityチェックは必要ないはずです。しかし、大まかな処理の流れとしてはこのようになっています。以上を簡単に言い換えれば、1バウンスのライトサンプル(NEE)と、BRDFサンプルのMulti Importance Samplingのレイトレーサーが実装されているといえると思います。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplelocallights&#34;&gt;RTXDI_SampleLocalLights()&lt;/h3&gt;
&lt;p&gt;さっそくですが、1番めの処理についてです。この関数は&lt;code&gt;ResamplingFunctions.hlsli&lt;/code&gt;に実装されています。
この関数は、&lt;code&gt;numLocalLightSamples&lt;/code&gt;で指定された数だけ、サンプルを構築してReservoirに蓄積する処理を行います。このサンプルアプリケーションの中の様々な個所で行われているRISの最も基本的な形になっています。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;RTXSDKは事前にLight DataバッファにLocal Light (つまりは Emissive Triangle)のリストを構築しています。まず、このリストから、単純に乱数でLocal Lightを選択します。さらに乱数を2つ生成して、光源の三角形上の点を決定して、その位置に向けて、プライマリレイがヒットしたサーフェースからパスを構築します。&lt;br&gt;
構築されたパスのPDFは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;で計算され、&lt;code&gt;blendedSroucePdf&lt;/code&gt;に代入されます。&lt;/p&gt;
&lt;h5 id=&#34;blendedsourcepdfの計算&#34;&gt;blendedSourcePdfの計算&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;blendedSourcePdf&lt;/code&gt;は、RISにおけるsourcePDFなので、実際のパス生成確率に即したものでなければなりません。
この計算を行っているのは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数です。&lt;br&gt;
まず、ライトサンプルの確率は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ライトの選択確率（単なる乱数選択なので、ライトの個数の逆数）&lt;/li&gt;
&lt;li&gt;ライト上の特定の方向に向けたレイを選択する確率（サーフェースから見たLocal Lightの見かけの立体角の逆数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;の乗算で計算できます。&lt;/p&gt;
&lt;p&gt;そして、BRDFサンプルの確率は、&lt;code&gt;RAB_GetSurfaceBrdfPdf()&lt;/code&gt;で計算されるので、アプリケーション側の処理となりますが、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DiffuseRayの場合、CosineWeightedのPDF&lt;/li&gt;
&lt;li&gt;SpecularRayの場合、GGX_VNDFのPDF&lt;/li&gt;
&lt;li&gt;上記いずれかをDiffuseProbabilityで選択&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、&lt;br&gt;
DiffuseProbablity * CosineWeightedPDF + (1 - DiffuseProbability) * GGX_VNDF_PDF&lt;br&gt;
でBRDFサンプルの確率が計算できます。&lt;/p&gt;
&lt;p&gt;1ピクセルあたりで、RISで検討されるライトサンプル数とBRDFサンプル数はDebug UIの設定で決まっていて、&lt;code&gt;numLocalLightSamples&lt;/code&gt;と&lt;code&gt;numBrdfSamples&lt;/code&gt;に設定されます。このサンプル数を用いて、これらはバランスヒューリスティックで結合されます。これは通常のMulti Importance Samplingと同様の考え方です。&lt;/p&gt;
&lt;p&gt;注意点なのですが、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数の最後では、&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;に設定された&amp;quot;ライト上の特定の方向に向けたレイを選択する確率&amp;quot;で除算しています。ここはRTXDIのトリッキーな部分です。あくまで、実際の&amp;quot;sourcePdf&amp;quot;は、この除算の前の値です。
しかし、RTXDIでは&lt;code&gt;targetPdf&lt;/code&gt;も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算するので、計算のつじつまが合うようになっています。また、&lt;code&gt;taregetPdf&lt;/code&gt;は、シェーディング結果を除算しますが、シェーディング結果も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されるので、こちらも計算のつじつまが合う仕組みになっています。&lt;/p&gt;
&lt;h5 id=&#34;targetpdfの計算&#34;&gt;targetPdfの計算&lt;/h5&gt;
&lt;p&gt;説明が多少前後しましたが、&lt;code&gt;targetPdf&lt;/code&gt;の計算についてです。&lt;code&gt;targetPdf&lt;/code&gt;はRISにおいて、積分可能ではないが、理想的なサンプルの確率密度です。(この値は、簡単には積分できず大きさが正規化できないので、PDFと呼ぶべきではなく、単にWeightと呼ぶべきかもしれません。）
&lt;code&gt;targetPdf&lt;/code&gt;はレンダリングの文脈では、サーフェースがカメラ方向に出すRadianceに比例したレイの分布になるのが一番望ましいです。言い換えれば、カメラの方に最も強く反射される光源へのレイを重点的にサンプリングする分布です。これは、光源のサーフェースでのカメラ方向への反射を計算すればわかります。しかし、光源とサーフェースがVisibleかどうかの判断は、実際にShadow Rayをトレースしなくては分かりません。しかし、これを行えば、実際にレイトレースを行ってシェーディングする処理とまったく変わらなくなり、単にレイのサンプル数を増やすことと同義です。これでは、RISの意味がなくなってしまいまいます。&lt;br&gt;
&lt;code&gt;targetPdf&lt;/code&gt;の計算では、シェーディングの中で最も処理負荷の高いShadow Rayのテスト処理を省略した値（つまりい光源とサーフェースがVisibleかどうかの判断をせずにシェーディングした結果）が用いられます。&lt;/p&gt;
&lt;p&gt;実際の計算は、&lt;code&gt;RtxdiApplicationBridge.hlsli&lt;/code&gt;の&lt;code&gt;RAB_GetLightSampleTargetPdfForSurface()&lt;/code&gt;に実装されています。この関数は&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;という関数を呼び出して、シェーディングの計算を行っています。算出された値の輝度値が、そのまま&lt;code&gt;targetPDF&lt;/code&gt;として扱われます。また、&lt;code&gt;blendedSourcePdf&lt;/code&gt;の項で説明した通り、シェーディングの計算の最後で、値は&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されます。&lt;/p&gt;
&lt;h5 id=&#34;reservoirにサンプルを追加する計算&#34;&gt;Reservoirにサンプルを追加する計算&lt;/h5&gt;
&lt;p&gt;上記の通り、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;の計算が完了すれば、Reservoirにサンプルを追加する処理は簡単です。
&lt;code&gt;RTXDI_StreamSample()&lt;/code&gt;に、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;を乱数と共に渡して、渡したサンプルが選択された場合は、現在選択中のサンプルの情報を更新します。&lt;/p&gt;
&lt;h5 id=&#34;サンプル構築後の処理&#34;&gt;サンプル構築後の処理&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;numLocalLightSamples&lt;/code&gt;の数だけサンプルを構築し、Reservoirに蓄積した後は、現在Reservoirが選択中のサンプルの情報と、Reservoirに蓄積されたRISの情報のみが残ります。ここまでで複数のサンプルを検討していますが、実際にレイトレース処理は行っていません。しかし、Reservoirには、一番選択するべきサンプルの情報が残っています。&lt;br&gt;
サンプルを構築するループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;と思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で正規化されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplebrdf&#34;&gt;RTXDI_SampleBrdf()&lt;/h3&gt;
&lt;p&gt;この関数は、numBrdfSamplesで指定された数だけ、サーフェースのBRDFをもとにサンプルを構築してReservoir蓄積する処理を行います。&lt;br&gt;
この処理は、上記で説明した&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の処理と対を成す処理です。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築-1&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RAB_GetSurfaceBrdfSample()&lt;/code&gt;を呼び出して、BRDFに基づいたサンプルを構築します。そして、実際にレイトレースを行い、Local Light（Emissive Triangle）にHitするかをテストします。Hitしなかった場合は、このサンプルの処理は終了しReservoirに関する処理は行われません。（しかし、このサンプルがReservoirに蓄積されないというわけではなく、正確にはtargetPDF=0として蓄積された扱いになります。これはReservoirの結合時の処理を見ると判明します。）&lt;br&gt;
一方でLocal LightにHitした場合は、&lt;code&gt;targetPdf&lt;/code&gt;と&lt;code&gt;blendedSourcePdf&lt;/code&gt;をそれぞれ計算します。計算は、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と全く同じ計算になります。&lt;/p&gt;
&lt;h5 id=&#34;サンプルの構築後の処理&#34;&gt;サンプルの構築後の処理&lt;/h5&gt;
&lt;p&gt;ここも、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と基本的に同じ計算になります。
サンプル構築のループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、Shadow Rayによって棄却されたサンプルを含めるなら、&lt;code&gt;1.0/numBrdfSamples&lt;/code&gt;であるべきと思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;light-sampleとbrdf-sampleのreservoirの結合処理&#34;&gt;Light SampleとBRDF SampleのReservoirの結合処理&lt;/h3&gt;
&lt;p&gt;再び、&lt;code&gt;main()&lt;/code&gt;の処理に戻ります。&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;によって構築された&lt;code&gt;localReservoir&lt;/code&gt;と、&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;によって構築された、&lt;code&gt;brdfReservoir&lt;/code&gt;を結合する処理を見ていきます。&lt;/p&gt;
&lt;h5 id=&#34;rtxdi_combinereservoirsの処理&#34;&gt;RTXDI_CombineReservoirs()の処理&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;を呼ぶ前に、結合される側のReservoirは、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;が呼ばれている約束になっています。したがって、結合される側の&lt;code&gt;weightSum&lt;/code&gt;は、Finalize前の変数で解釈すると&lt;code&gt;1/targetPDF * 1/M * weightSum&lt;/code&gt;
に相当する値が設定されています。（ただし&lt;code&gt;1/M&lt;/code&gt;はFinalize時に引数で渡す正規化係数）&lt;br&gt;
これに、構造体に格納されている&lt;code&gt;M&lt;/code&gt;と、引数で渡された&lt;code&gt;targetPdf&lt;/code&gt;を乗算したものが、&lt;code&gt;risWeight&lt;/code&gt;という変数に設定されます。逆算すれば、&lt;code&gt;risWeight&lt;/code&gt;は、元の&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;(引数の)targetPdf / (構造体に保存されている)targetPdf&lt;/code&gt;を乗算したものですから、もしも、&lt;code&gt;1/M&lt;/code&gt;で正規化されていて、&lt;code&gt;targetPdf&lt;/code&gt;が同じならば、結局のところ元の&lt;code&gt;weightSum&lt;/code&gt;ということになります。&lt;br&gt;
しかし、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の引数に渡す&lt;code&gt;targetPdf&lt;/code&gt;は、結合元のReservoirで現在選択されているサンプルの、結合先のReservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;なので、もしも、結合先で&lt;code&gt;targetPdf&lt;/code&gt;が異なる場合は、その比が&lt;code&gt;weightSum&lt;/code&gt;に乗算されることになります。しかし、今回のサンプルプログラムでは、Spatio-TemporalなRISの結合を行わないので、&lt;code&gt;targetPdf&lt;/code&gt;は結合の前後で変化しないので、この計算について深く考える必要はありません。&lt;/p&gt;
&lt;p&gt;計算された&lt;code&gt;risWeight&lt;/code&gt;は、結合されるReservoir全体の、結合先Reservoirにおけるウエイトに相当する値です。&lt;br&gt;
後は、サンプル数&lt;code&gt;M&lt;/code&gt;を合算し、&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;risWeight&lt;/code&gt;を加算して、選択サンプルを乱数で決定することで、Reservoirの結合が完了します。&lt;/p&gt;
&lt;h5 id=&#34;localreservoir-と-brdfreservoir-の結合&#34;&gt;localReservoir と brdfReservoir の結合&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の項で説明したとおり、&lt;code&gt;localReservoir&lt;/code&gt;は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;で除算して正規化するところを、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算したうえに、サンプル数 &lt;code&gt;M&lt;/code&gt; を1に設定していました。
これを、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の結合される側のReservoirとして処理をすると、&lt;code&gt;risWeight&lt;/code&gt;は、Finalize前の変数で解釈すると以下のようになります。&lt;br&gt;
&lt;code&gt;1/numMisSamples * weightSum&lt;/code&gt;&lt;br&gt;
この式をわかりやすく書き換えると、以下のようになります。&lt;br&gt;
&lt;code&gt;numLocalLightSamples/numMisSamples * 1/numLocalLightSamples * weightSum&lt;/code&gt;&lt;br&gt;
つまり、&lt;code&gt;localReservoir&lt;/code&gt;の正規化処理と、&lt;code&gt;localReservoir&lt;/code&gt;と&lt;code&gt;brdfReservoir&lt;/code&gt;の、それぞれのサンプル数に基づくバランスヒューリスティックによる結合を同時に処理しているわけです。&lt;/p&gt;
&lt;p&gt;同様に、&lt;code&gt;brdfReservoir&lt;/code&gt;の結合時の&lt;code&gt;risWeight&lt;/code&gt;は、&lt;br&gt;
&lt;code&gt;numBrdfSamples/numMisSamples * 1/numBrdfSamples * weightSum&lt;/code&gt;&lt;br&gt;
と解釈できます。（ここで、&lt;code&gt;brdfReservoir&lt;/code&gt;の生成時に、Shadow RayがMissしてサンプルが破棄されているにも関わらず&lt;code&gt;targetPdf&lt;/code&gt;がゼロのサンプルとして扱われているという解釈ができるわけです。）&lt;/p&gt;
&lt;p&gt;最後に、両者の結合後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を正規化係数1.0で呼び出していますが、両者の正規化はMISのウエイトによって行われているので、計算のつじつまが合うわけです。&lt;/p&gt;
&lt;h2 id=&#34;最後のレイトレースとシェーディング処理&#34;&gt;最後のレイトレースとシェーディング処理&lt;/h2&gt;
&lt;p&gt;ついに、最終的に採用すべきサンプルが確定し、乗算すべきPDFの算出も完了しました。&lt;br&gt;
あとはShadow Rayをキャストして、Visibilityを確認すればよいのですが、&lt;code&gt;brdfReservoir&lt;/code&gt;のサンプルはその生成過程ですでにShadow Rayを使ってVisibilityを確認しているので、もし、こちらのReservoirからサンプルが採用された場合は、この作業は不要なのでスキップするように処理が書かれています。&lt;code&gt;localReservoir&lt;/code&gt;側からからサンプルが選択された場合のみShadow Rayのトレースを行います。&lt;/p&gt;
&lt;p&gt;シェーディング関数の&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;は、RISの過程で何度も呼び出しているので説明不要ですが、ここでも&lt;code&gt;solidAndlePDF&lt;/code&gt;が除算されているので、PDFとの計算のつじつまが合うわけです。
&lt;code&gt;RTXDI_GetReservoirInvPdf()&lt;/code&gt;は、既にFinalizeされているReservoirに対して呼び出す関数で、単に&lt;code&gt;weightSum&lt;/code&gt;を返します。Finalizeが行われていればそこには、PDFの逆数に相当する値が格納されているはずです。
シェーディングが終われば、TonemappingをかけてUAVに書き出すと、全体の処理が完了します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projection Matrixについて</title>
      <link>https://shikihuiku.github.io/post/projection_matrix/</link>
      <pubDate>Sun, 27 Dec 2020 00:09:34 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/projection_matrix/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;Projection Matrixは何となくややこしいイメージが強い。実際ややこしい。自分でも勘違いすることがある。
なのでいったんまとめることにする。&lt;/p&gt;
&lt;h2 id=&#34;row-major-column-major-ベクトルとの乗算の順序&#34;&gt;Row Major, Column Major, ベクトルとの乗算の順序&lt;/h2&gt;
&lt;p&gt;Projection Matrixは4x4の正方行列で、メモリに格納するときに行要素を優先して格納すればRow-Major、列要素を優先して格納すればColumn-Majorと呼ばれる。&lt;/p&gt;
&lt;p&gt;Row-Majorは以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} a_1    &amp;amp; a_2    &amp;amp; a_3    &amp;amp; a_4    \\ a_5    &amp;amp; a_6    &amp;amp; a_7    &amp;amp; a_8    \\ a_9    &amp;amp; a_{10} &amp;amp; a_{11} &amp;amp; a_{12} \\ a_{13} &amp;amp; a_{14} &amp;amp; a_{15} &amp;amp; a_{16}  \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;対してColumn-Majorは、以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;\begin{pmatrix} a_1 &amp;amp; a_5 &amp;amp; a_9    &amp;amp; a_{13} \\ a_2 &amp;amp; a_6 &amp;amp; a_{10} &amp;amp; a_{14} \\ a_3 &amp;amp; a_7 &amp;amp; a_{11} &amp;amp; a_{15} \\ a_4 &amp;amp; a_8 &amp;amp; a_{12} &amp;amp; a_{16} \end{pmatrix}&lt;/p&gt;
&lt;p&gt;また、行列の積は可換ではない。たとえば、4次元ベクトルを行列の右から掛けるか左から掛けるかによって演算が変わるので、これには2通りの演算が存在する。&lt;br&gt;
$$
\begin{pmatrix} x^{\prime} \\ y^{\prime} \\ z^{\prime} \\ w^{\prime} \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix} \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x^{\prime} &amp;amp; y^{\prime} &amp;amp; z^{\prime} &amp;amp; w^{\prime} \end{pmatrix} = \begin{pmatrix} x &amp;amp; y &amp;amp; z &amp;amp; w \end{pmatrix} \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;シェーダーを記述する場合は、これらの解釈は実装者に委ねられる。一方で、グラフィックスAPIがこれらの演算を提供する場合もある。
OpenGLのCompatibility Profileでは、Column-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算はベクトルに対して左側からである。
Direct3D 9では、Row-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算は、ベクトルに対して右側からである。&lt;/p&gt;
&lt;h2 id=&#34;座標変換の過程について&#34;&gt;座標変換の過程について&lt;/h2&gt;
&lt;p&gt;次に座標変換の過程について簡単に説明する。頂点シェーダーが出力する4次元ベクトルは、一般的にはView座標系の位置にProjection Matrixを乗算した結果が出力される。
この座標は同次座標と呼ばれ、W成分で(X,Y,Z)を除算して正規化することで、Normalized Device Coordinate(正規化デバイス座標系)に変換される(Perspective Division)。次にViewport変換を行い、Normalized Device Coordinateを、描画用のバッファ（スクリーン）の領域にマッピングする。
多少の用語の違いがあるが、OpenGL、Vulkan、Direct3Dの3つのグラフィックスAPIは概ね同じ座標変換のステップを持っている。ただし各APIごとに座標軸の考え方や値の範囲が異なるので注意が必要である。&lt;/p&gt;
&lt;h2 id=&#34;y軸の反転について&#34;&gt;Y軸の反転について&lt;/h2&gt;
&lt;p&gt;一般的に3D空間上ではY軸を上向きと考える事が多い一方で、2Dスクリーン上では、ピクセルデータを画像の左上から格納する事が多い関係上、Y軸は下向きと考えることが多い。そのため、Projection Matrixによる投影変換、Perspective Division、そしてViewport変換の過程においてY軸を反転させることがある。ここではこれについて説明する。各種変換や用語に関する解説と前後するが、先にここにまとめておく。&lt;/p&gt;
&lt;h4 id=&#34;opengl&#34;&gt;OpenGL&lt;/h4&gt;
&lt;p&gt;OpenGLでは、元来Y軸の反転を行わないという思想の基にAPIが設計されていた。したがって、Viewport変換後のWindow座標系では、画像の左下を原点としてピクセルデータを取り扱う。そのため、Framebufferを画像として表示するときは垂直方向でデータを反転させて表示させるのが一般的である。しかし、現在のOpenGLでは、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective Divisionの際にY軸の符号を反転させる。これによって、Normalized Device CoordinateのY軸の上下が反転するので、Framebufferのデータが画像の左上を原点として格納されるようになる。Perspective Divisionについては、
&lt;a href=&#34;https://www.khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenGL 4.6 Core Pprofile&lt;/a&gt;の13.8に記載がある。&lt;/p&gt;
&lt;h4 id=&#34;direct3d&#34;&gt;Direct3D&lt;/h4&gt;
&lt;p&gt;Direct3Dの座標変換に関しては、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/the-direct3d-transformation-pipeline&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;このドキュメント&lt;/a&gt;に記述がある。これによれば、Perspective DivisionはViewport変換のスケーリングの後に行われており、Y軸の符号反転は、Viewportのスケーリングの係数の符号を逆転し、オフセットを調整することで実装されている。
また、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d9/projection-transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;他のドキュメント&lt;/a&gt;でも、Normalized Device CoordinateのY軸はView座標系と同じ向きに描写されている。したがって、Direct3DではViewport変換でY軸の符号の反転が行われていると解釈できる。
Viewport変換後のScreen座標系では、画像の左上を原点としてピクセルデータを取り扱う。&lt;/p&gt;
&lt;h4 id=&#34;vlukan&#34;&gt;Vlukan&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.khronos.org/registry/vulkan/specs/1.2/pdf/vkspec.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vulkan 1.2&lt;/a&gt;によれば、Perspective DivisionでY軸の符号を反転しない。また、Viewport変換時もY軸の符号を反転しない。そして、Viewport変換後のFramebuffer Coordinateの原点は、左上とされている。そのため、VulkanではProjection Matrixの演算でY軸を反転しない限り、Y軸を上向きとする空間を投影変換した像は上下が反転する。
また、Framebuffer Coordinateとの関連性を考えれば、VulkanのNormalized Device CoordinateのY軸は下向きと考えるのが自然である。&lt;/p&gt;
&lt;h2 id=&#34;perspective-division&#34;&gt;Perspective Division&lt;/h2&gt;
&lt;p&gt;Projection Matrixとの演算を終えた4次元ベクトルは、同次座標を表現する。これを正規化する($w=1$にする）作業は、プログラムなどで制御ができない固定された機能として、グラフィックスAPI側が行う作業となっている。
デフォルトの設定のOpenGL, Vulkan, Direct3Dでは、単純な$w$による除算が行われる。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ \frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;ただし、OpenGLでglClipControl()でGL_UPPER_LEFTが設定されているときは、Perspective Divisionの実行時に$Y$の符号が逆転される。
これは、3D空間上ではY軸を上向きと考えることが一般的である一方、画像フォーマットや、Microsoft Windows や X Window Systemでは、
垂直方向は画面の上から下に向かって座標軸を考えることが多いため、座標軸の向きを入れ替えるための計算である。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ -\frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;正規化された後の(X,Y,Z)はNormalized Device Coordinate（正規化デバイス座標系）を表現する&lt;/p&gt;
&lt;h2 id=&#34;normalized-device-coordinate-ndc&#34;&gt;Normalized Device Coordinate (NDC)&lt;/h2&gt;
&lt;p&gt;NDCは、シェーダーコードが出力した同次座標を、Perspective Divitionにより正規化した後の座標系となる。この座標系は$X,Y$は範囲が[-1, 1]と決まっており、
$Z$は[-1, 1]あるいは[0,1]と決まっている。この座標系は、$X,Y$はRenderTargetピクセル位置を表すスクリーン座標系と線形の関係にある。$Z$は深度バッファの値と線形の関係にある。&lt;/p&gt;
&lt;p&gt;OpenGLでは、glClipControl()でNDCのZ軸の範囲を[-1, 1]か[0, 1]のどちらかで選択することができる。デフォルトでは、GL_NEGATIVE_ONE_TO_ONE[-1, 1]が設定されており、GL_ZERO_TO_ONE[0, 1]を設定することで、Direct3D/Vulkanと同じ範囲になる。また、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective DivisionでY軸の符号が反転されるので、NDCのY軸が反転する。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ndc&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;NDC&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;631&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    NDC
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;viewport変換&#34;&gt;Viewport変換&lt;/h2&gt;
&lt;p&gt;NDCにおける$X,Y$の値の範囲は[-1, 1]だが、これをViewport変換によりRenderTargetのピクセル位置を表すスクリーン座標系に線形にマッピングする。RnederTarget上でのオフセットと幅と高さを指定する事でViewport変換が実現される。
一般的には、オフセットをゼロに設定し、幅と高さをRenderTargetの幅と高さとすることで、NDCの$X,Y$の[-1, 1]の範囲をRenderTargetの全ピクセルにマッピングすることが多いが、描画領域を分けて複数のViewportのレンダリング結果を一枚のRenderTargetにレンダリングする事もある。&lt;/p&gt;
&lt;p&gt;Direct3DはViewport変換時にY軸の上下が入れ替わるように計算される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1207&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;$Z$に関しては、Viewport変換後の深度値の値の範囲を$near, far$の二つの値で指定し、範囲は[0, 1]に収まる様にしなくてはならない。Viewportの$near, far$は深度バッファで使用する値の範囲の事で、
Projection Matrixの$near, far$とは全く意味が異なる。ほとんどの場合では、[0, 1]を指定して、深度バッファが表現できる全ての範囲を使用する。
OpenGLは、NDCのZの範囲を[-1, 1]としているときは、必ずViewport変換時に[near, far]への線形変換が行われる。対して、NDCの範囲が[0, 1]の場合は、Viewport変換の$near, far$が、[0, 1]に設定されている場合は、NDCの$Z$の値がそのまま深度バッファの値として格納される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;374&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;右手系左手系&#34;&gt;右手系、左手系&lt;/h2&gt;
&lt;p&gt;右手系、左手系とは、単位マトリクスのX,Y,Z軸の各ベクトルの、認識している空間におけるマッピングである。右手系は、右手の（親指,人差し指, 中指）を自然な形で直交させたとき、(X, Y, Z)の向きとなる空間を指す。
左手系も同様である。デフォルトのOpenGLとDirect3DのNDCは、はX軸が画面左から右、Y軸が画面下から上、Z軸が画面手前から奥なので、左手系である。
一方で、glClipControl()でGL_UPPER_LEFTを設定したOpenGLとVulkanのNDCは、X軸が画面左から右、Y軸が画面上から下、Z軸が画面手前から奥なので、右手系である。&lt;/p&gt;
&lt;p&gt;よく耳にする話として、OpenGLが右手系でDirect3Dが左手系という話があるが、OpenGLに関してはglFrustum()/glOrtho()という関数が、
右手系のViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するためのProjection Matrixを計算することに起因している。
実際にはProjection MatixにはglLoadMatrixで自由に値を設定することができるので、OpenGLは元来シェーダーを使わなくても、右手系でも左手系でも自在に描画できるはずである。
また、Direct3DにはProjection Matrixを計算するAPIは用意されていない。ただし、ユーティリティ関数群のD3DXには、D3DXMatrixPerspectiveRH()という関数が用意されている。
この関数は右手系ViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。同様に、D3DXMatrixPerspectiveLH()という関数も用意されており、
こちらは、左手系のViewMatrixの+Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。&lt;/p&gt;
&lt;p&gt;このように、ある特定のグラフィックスAPIの座標系が右手系左手系のいずれかに属していると考えること自体が誤りだといえる。&lt;/p&gt;
&lt;h2 id=&#34;projection-matrixの役割&#34;&gt;Projection Matrixの役割&lt;/h2&gt;
&lt;p&gt;さて、ここからが本題ののProjection Matrixに関する説明になる。View座標系からNDC座標系への変換を担うProjection Matrixには、主に4つの要素がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y軸の向きの入れ替え (Vulkan)&lt;/li&gt;
&lt;li&gt;Z軸の向きの入れ替え&lt;/li&gt;
&lt;li&gt;X,Y軸に関する透視投影変換&lt;/li&gt;
&lt;li&gt;Z軸のNDC座標へのマッピング&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透視投影変換を行わない正射影というProjection Matrixもあるが、ここでは割愛する。&lt;/p&gt;
&lt;h2 id=&#34;y軸の向きの入れ替え-vulkan&#34;&gt;Y軸の向きの入れ替え (Vulkan)&lt;/h2&gt;
&lt;p&gt;Vulkan特有の事なので一番最初に解説する。Vulkanは先に説明した通り、NDCのY軸は下向きでPerspective DivisionやViewport変換でY軸の符号反転を行わない。
したがって、Y軸が下向きとなる様に頂点シェーダーの出力を行わなければならない。そのため、View座標系でY軸が上向きになるように座標を扱っていた場合、Projection MatrixでY軸を反転させる必要がある。
具体的にはProjection Matrixの、Y成分のスケーリングとオフセットを担当する成分（以下の場合では$a_{22}, a_{23}$）の符号を入れ替える事で、NDCの上下が反転した結果を得る事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; -a_{22} &amp;amp; -a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44}  \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸の向きの入れ替え&#34;&gt;Z軸の向きの入れ替え&lt;/h2&gt;
&lt;p&gt;同次座標の$w$は、単にPerspective Divisionでの除算に使われるだけでなく、ポリゴン平面上の属性値補間でPerspective Correctionを行うときに使用されるので、$Z$軸に沿って正しく透視投影変換をするときは下記のどちらかの設定になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Z_{View}$の正の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのため、$Z_{View}$と乗算される位置に$1$を設定する。&lt;/li&gt;
&lt;li&gt;$Z_{View}$の負の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$-Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのために$Z_{View}$と乗算される位置に$-1$を設定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、それぞれ$Z_{View}$正負の方向にNDCのZ軸を設定し、透視投影変換をする場合のProjection Matrixである。殆どのProjection Matrixは下記のいずれかである。
余談だが、この、$w$と乗算される行（あるいは列）は特徴的なので、これを手がかりに、メモリにダンプされたマトリクスが、Row-MajorなのかColumn-Majorなのかを簡単に見分ける事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;xy軸に関する透視投影変換&#34;&gt;X,Y軸に関する透視投影変換&lt;/h2&gt;
&lt;p&gt;透視投影変換は、空間にある物体が視点から離れる程小さく投影される様に変換する役割がある。これにより遠近感が演出される。
視点からの距離が二倍になれば、物体は長さで二分の一の大きさで描画されるようにする。したがって$Z$軸向きに透視投影した$X,Y$座標は、$1/Z$に比例する。&lt;/p&gt;
&lt;p&gt;$X,Y$軸に関する透視投影変換は、つまるところ、以下の式の$a, b, c, d$を決定することにある。
$$
X_{NDC} = \frac{a * X_{View}}{Z_{View}} + b
$$
$$
Y_{NDC} = \frac{c * Y_{View}}{Z_{View}} + d
$$&lt;/p&gt;
&lt;p&gt;$a, c$の値が、水平、垂直視野角を決定し、$b, d$がView座標系からNDC座標系に変換するときのオフセットになる。$b, d$は、View座標のZ軸がNDC座標のX,Yの中心を通る場合はゼロになる。
水平、垂直視野角から$a,c$の値を計算する場合は、視野の両端がNDCにおける[-1, 1]になるように計算すれば良い。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;808&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

したがって係数$a,c$は、水平視野角を$\theta$、垂直視野角を$\phi$とすれば以下の様に計算できる。（注意：通常は水平視野角と垂直視野角はアスペクト比を通じた線形の関係ではない。通常は水平視野角か垂直視野角のいずれかを基準として正接を計算して、他方はアスペクト比を乗算することで他方の正接を計算するが、ここでは簡便のためそれぞれの視野角を使う。）
$$
a = \frac{1}{tan(\frac{\theta}{2})}
$$
$$
c = \frac{1}{tan(\frac{\phi}{2})}
$$&lt;/p&gt;
&lt;p&gt;もう一つの、係数$a,c$の計算方法として、$Z_{View}=near$平面上での視野の上下左右に相当する$left, right, top, bottom$を指定する方法である。以下の図には$left, right$による水平視野角を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;992&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

この場合の係数$a,c$は、$l, r, t, b$の値と、$near$平面までの距離$n$を用いて以下の様に表せる。
$$
a = \frac{2n}{r - l}
$$
$$
c = \frac{2n}{t-b}
$$
また、この指定方法の場合は、$l, r$の値がZ軸で対称でない場合は、オフセットの値が発生する。例として、$l, r$によるオフセットの図を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野のオフセットの計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu770a23a06793a884f7075f1eec4e4997_39058_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野のオフセットの計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu770a23a06793a884f7075f1eec4e4997_39058_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;893&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野のオフセットの計算
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上図はView座標系でのオフセット値になるので、NDC座標系に変換するには、$2/(r-l)$を乗算する必要がある。したがってオフセットの値は以下の様に計算できる。
$$b = -\frac{r+l}{r-l}$$
$$d = -\frac{t+b}{t-b}$$&lt;/p&gt;
&lt;p&gt;また、オフセットがない場合は、$near, left, right, top, bottom$と$\theta, \phi$に、以下のような関係が成り立つ。
$$
l = n \cdot tan(\frac{\theta}{2})
$$
$$
r = -n \cdot tan(\frac{\theta}{2})
$$
$$
t = n \cdot tan(\frac{\phi}{2})
$$
$$
b = -n \cdot tan(\frac{\phi}{2})
$$&lt;/p&gt;
&lt;p&gt;次に、Projection Matrixへの各係数の設定だが、$a, c$の値は、それぞれ$X_{View}$, $Y_{View}$と乗算されるように格納する。$Z_{View}$の除算の部分はPerspective Divisionで行われる。
$b, d$の値は、$Z_{View}$と乗算されるようにProjection Matrixに格納する。これは、のちにPerspective Divisionで相殺されることでオフセット値として機能する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;以下のマトリクスはD3DXMatrixPerspectiveOffCenterLHが算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; -\frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; -\frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;一方で、Z軸の向きの入れ替えるために、$a_{43}$に$-1$を設定している場合は、$Z_{View}$が乗算される時と、除算される時で符号が異なるため、オフセットの係数の符号が変わる。
以下のマトリクスはD3DXMatrixPerspectiveOffCenterRHが算出する係数や、glFrustum()が算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; \frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; \frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸のndc座標へのマッピング&#34;&gt;Z軸のNDC座標へのマッピング&lt;/h2&gt;
&lt;p&gt;Z軸に関する変換は透視変換ではなく、Z軸の値の一定の範囲をNDCで許されている値の範囲に、大小関係を損なわずに変換することである。通常は、View座標系の広大なZ軸の範囲を、NDCで許されている高々[0, 1]程度の範囲にマッピングする圧縮作業である。
簡単に考えれば、View座標系のZの値にオフセットとスケールを適用すれば実現できるが、これは残念ながら推奨されない。
$$Z_{NDC} = e * Z_{View}  + f$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一つ目の理由は、Projection Matrixを使った座標変換による制限によるものである。$X, Y$の値を透視投影変換するためには、同次座標系の$W$の値を$Z$（もしくは$-Z$)の値としなければ、$X,Y$軸に関する透視投影変換が実現できない。そのため$W$の値は決定されていると言える。
この条件では、Projection Matrixとの乗算では、View座標系の$Z$と1次比例の関係を作ることができない。一応ながら、Pixel Shader内で深度バッファに出力する値を直接計算することで実現可能だが、GPUの早期Zカリング機能が無効化されるので実際のアプリケーションの運用では現実的な方法とは言えない。&lt;/li&gt;
&lt;li&gt;二つ目の理由は、透視投影変換後のNDCでの$X,Y$平面（つまりはスクリーンスペース）では、$Z_{View}$は線形性を失う。代わりに$1/Z_{View}$が線形性を持つことになる。
投影変換されたポリゴン平面の深度値を高速に計算するならば、線形性を失った$Z_{View}$に比例した式で計算された値は単純な補間では計算出来ず、計算コストが高く効率が良くない。それよりも、大小関係を（反転しつつも）保ちつつ、スクリーンスペースで線形性を持つ$1/Z_{View}$を使う方が合理的だったという経緯がある。
（ちなみに、スクリーンスペースでテクスチャのU,Vなどの頂点属性値は、$attribute/W$と$1/W$をスクリーンスペースで線形補間し、その結果を除算することで補完された頂点属性値を計算している。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、一般的にGPUでは$Z_{View}$ではなく$1/Z_{View}$を線形変換した結果をNDCのZ座標として採用している。
$$Z_{NDC} = \frac{e}{Z_{View}}  + f$$&lt;/p&gt;
&lt;p&gt;また、このようにすると、深度バッファに整数の格納フォーマットを使った場合、$Z$の値が小さいときほど、多くのBitを使って表現することになる。
つまり、近くの物体ほど深度バッファの多くのBitが割り当てられるので、これは合理的であるとも考える事ができる。また、$1/Z$の線形変換であれば、Projection Matixで一元的に扱えるのも利点である。&lt;/p&gt;
&lt;p&gt;係数$e, f$の決定は、View座標系における、Z軸の範囲である$near, far$の値が、[0, 1] （もしくは[-1, 1]）になるように連立方程式を解くだけで計算できる。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;下記の式を解けば、D3DXMatrixPerspectiveFovLHに設定される係数と符合する。&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$0 = \frac{e}{near} + f$$
$$1 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{far \cdot near}{far-near}$$
$$f = \frac{far}{far - near}$$&lt;/p&gt;
&lt;p&gt;Projection Matrixに設定するときは、$Z_{View}$と乗算される位置に$f$を設定し、$W$(通常は1.0)と乗算される方に$e$を設定する。Perspective Divisionで$W$(この時点では$Z_{View}$)による除算が行われ、上記の式と等価な計算が行われる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{far - near} &amp;amp; -\frac{far \cdot near}{far-near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合は、Projection Matrixの乗算をよく観察する必要がある。$1/Z_{View}$の係数である$e$は、$W_{View}$と乗算して、$-Z_{View}$で除算される。$W_{View}$は通常$1.0$で$-Z_{View}$も正の数なので、上記で求めた$e$がそのまま使える。
一方で、オフセットの$f$は、$Z_{View}$と乗算して、$-Z_{View}$で除算される。したがって、上記で求めたものの符号を反転させたものを使う必要がある。こうして求めた結果は、D3DXMatrixPerspectiveFovRHの係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{near-far} &amp;amp; \frac{far \cdot near}{near -far} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同様の手順で係数$e, f$を求める事ができる&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$-1 = \frac{e}{near} + f$$
$$2 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{2(far \cdot near)}{far-near}$$
$$f = \frac{far + near}{far - near}$$&lt;/p&gt;
&lt;p&gt;それぞれをProjection Matrixに設定すると以下の様になる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合も先ほどと同様の手順となる。これはglFrustum()関数の係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;inverse-z&#34;&gt;Inverse Z&lt;/h2&gt;
&lt;p&gt;深度バッファに浮動小数点の格納フォーマットが使えるとき、NDCにおける深度のマッピングを、[Near, Far]を[0, 1]ではなく[1, 0]にマッピングすることで、$far$付近での深度バッファの精度不足を解消することができる。
NDCが[-1, 1]の場合や、深度バッファの格納フォーマットが整数表現の場合は、Inverse Zを使う利点はない。
精度については詳しくは以下に解説がある。&lt;br&gt;

&lt;a href=&#34;http://www.reedbeta.com/blog/depth-precision-visualized/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Depth Precision - Nathan Reed&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zの設定は簡単で、先ほどの連立方程式の$near$と$far$を入れ替えて解くだけで係数は求まる。レンダリングの際には、深度バッファのクリア値を、1ではなく0に設定し、ラスタライザーの深度テストの条件を反転させればよい。
$$1 = \frac{e}{near} + f$$
$$0 = \frac{e}{far} + f$$
$$e = \frac{far \cdot near}{far - near}$$
$$f = -\frac{near}{far-near}$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;infinite-far-plane&#34;&gt;Infinite Far Plane&lt;/h2&gt;
&lt;p&gt;$far$を無限遠に設定する事で、Far Clippingを実質無効化するとともに、浮動小数点の丸め誤差を低減することができる。Projection Matrixに設定する係数の計算は、今まで求めてきた係数の、$far$を無限大で極限を取れば算出される。
Infinite Far Planeのメリットは、非常に遠くのオブジェクトを描画してもクリッピングされることがないことと共に、空や星などを描画する際に、$W_{View}$をゼロとすることで、$(X_{View}, Y_{View}, Z_{View})$方向の無限遠を描画することができることである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-1&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$e = \lim_{far\to\infty} -\frac{far \cdot near}{far-near} = -near$$
$$f = \lim_{far\to\infty} \frac{far}{far - near} = 1$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いないInfinite Far Planeは、無限遠の深度値が1.0となるが、$Z_{View}$が極大化すると正確に描画できないことがあるので注意が必要である。これはProjection Matrixを使った演算とPerspective Divisionでオフセットを設定する場合に、$Z_{View}$による乗算と除算が行われるため、この値が非常に大きな値になれば、浮動小数点数としての精度を失ってしまうからである。&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-1&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;一方で、Inverse Zを用いた場合のInfinite Far Planeの係数は以下の様に計算される。
$$e = \lim_{far\to\infty} \frac{far \cdot near}{far - near} = near$$
$$f = \lim_{far\to\infty} -\frac{near}{far-near} = 0$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeは、オフセットの係数がゼロなので、$Z_{View}$が極大化する事によるProjection Matrixとの乗算による精度の問題を起こさない。以下は、Inverse Zを用いたInfinite Far PlaneのProjection Matrixである。$a_{43}$は$1$でも$-1$でも変わらない。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; near \\ 0 &amp;amp; 0 &amp;amp; a_{43} &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからz_viewの逆算&#34;&gt;深度バッファから$Z_{View}$の逆算&lt;/h2&gt;
&lt;p&gt;マルチパスレンダリング等を行っていると、描画された深度バッファより、$Z_{View}$を求めたい時がある。計算自体は単なる逆算なので簡単である。&lt;/p&gt;
&lt;p&gt;深度バッファから$Z_{View}$を逆算するためには、まず、Viewport変換を逆変換して$Z_{NDC}$を計算する必要がある。Viewportの$near, far$とNDCの$Z$軸の範囲が分かれば計算は簡単である。深度バッファとNDCの範囲が一致する場合は、この計算は不要である。
$$Z_{NDC}  = \frac{Depth - near_{Viewport}}{far_{Viewport} - near_{Viewport}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-2&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;Projection Matrixに設定した係数$e, f$を使って$Z_{NDC}$から$Z_{View}$を逆算する。$Z_{NDC}$が正の$Z_{View}$方向ならば以下の式で計算できる。
$$Z_{NDC} = \frac{e}{Z_{View}} + f$$
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は符合の操作が必要である。まず、オフセットの値$f$の符合を反転させてあるので、これを反転する必要がある。加えて$Z_{View}$は負の方向なので、最後に符合を反転する必要がある。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-2&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{near + Z_{NDC} (far - near)}$$
Inverse Zで、$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{near + Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeの場合は、式はもっと単純になる。ただし、$Z_{NDC}$がゼロの場合はゼロ除算になるので注意が必要である。
$$Z_{View}= \frac{e}{Z_{NDC}} = \frac{near}{Z_{NDC}}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= -\frac{e}{Z_{NDC}} = -\frac{near}{Z_{NDC}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合-1&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同じ手順で計算する。
Depthから$Z_{NDC}$は以下の通り。
$$Z_{NDC}  = \frac{2(Depth - near_{Viewport})}{far_{Viewport} - near_{Viewport}} -1$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$から$Z_{View}$は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は
$$Z_{View}= -\frac{e}{Z_{NDC} + f} = -\frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからlinear-depthの計算&#34;&gt;深度バッファからLinear Depthの計算&lt;/h2&gt;
&lt;p&gt;上記で示した通り、Projection MatrixのNearとFarが分かれば、深度バッファから$Z_{View}$を復元できるが、
実際には$Z_{View}$よりも、単に線形性がある深度値としてのLinear Depthが欲しいケースが多い。
ここでのLinear Depthは[near, far]が[0, 1]にマッピングされており、かつ線形性を保っているものを指す。
計算は先の式の[near, far]を[0, 1]に線形でマッピングするだけである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-3&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$Z_{Linear}= \{ \frac{far \cdot near}{far - Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{Z_{NDC} \cdot near}{far - Z_{NDC}(far - near)} = \frac{Z_{NDC}}{\frac{far}{near} - Z_{NDC}(\frac{far}{near}-1)} $$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-3&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。[near, far]を[0, 1]にマッピングするので、Inverse Zの大小関係は再び反転するので注意。
$$Z_{Linear}= \{ \frac{far \cdot near}{near + Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{near (1 - Z_{NDC})}{near + Z_{NDC}(far -near)} = \frac{1 - Z_{NDC}}{ 1 + Z_{NDC}(\frac{far}{near} - 1)}$$&lt;/p&gt;
&lt;h2 id=&#34;render-targetのピクセル位置から視線ベクトルの逆算&#34;&gt;Render Targetのピクセル位置から視線ベクトルの逆算&lt;/h2&gt;
&lt;p&gt;G-Buffer等を用いている場合は、Render Targetのピクセル位置から視線ベクトルを逆算したい事も多い。これも上記と同様で、Projection Matrixからの逆算で計算自体は簡単である。&lt;/p&gt;
&lt;p&gt;Render Targetのピクセル位置から視線ベクトルの逆算するためには、Viewport変換を逆変換して$X_{NDC}, Y_{NDC}$を計算する。
$$X_{NDC} = \frac{2(X_{Pixel} - OfsX_{Viewport})}{Width_{Viewport}}-1$$
$$Y_{NDC} = \frac{2(Y_{Pixel} - OfsY_{Viewport})}{Height_{Viewport}}-1$$&lt;/p&gt;
&lt;p&gt;また、Render Targetのピクセル位置ではなく、フルスクリーン描画したポリゴンのUV値から$X_{NDC}, Y_{NDC}$を逆算する方法も良く用いられる。いずれにせよ、範囲が明確なNDCの座標を再計算するのは簡単である。&lt;/p&gt;
&lt;p&gt;次に$Z_{View}=1$の場合の、$X_{View}, Y_{View}$を計算する。ここでの$a,b,c,d$は、先ほど透視投影変換で求めた値で、$\theta, \phi$は水平、垂直視野角である。
$$X_{View1} = \frac{X_{NDC} - b}{a} = tan(\frac{\theta}{2})X_{NDC}$$
$$Y_{View1} = \frac{Y_{NDC} - d}{c} = tan(\frac{\phi}{2})Y_{NDC}$$&lt;/p&gt;
&lt;p&gt;三次元ベクトル$(X_{View1}, Y_{View1}, 1)$は、View座標系の原点からピクセルへのベクトル：視線ベクトルを表すが、長さが1ではないのでライティングの計算をする場合は正規化する必要がある。
一方で、ピクセルのView座標系における位置を求める場合は、このベクトルに$Z_{View}$を乗算することで求める事ができる。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;もっと簡単にまとめたかったが、ダラダラと長くなってしまった。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NVIDIA Falcor を使ってみる</title>
      <link>https://shikihuiku.github.io/post/falcor_getting_started/</link>
      <pubDate>Sun, 08 Nov 2020 11:12:51 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/falcor_getting_started/</guid>
      <description>&lt;h2 id=&#34;nvidia-falcor-とは&#34;&gt;NVIDIA Falcor とは&lt;/h2&gt;
&lt;p&gt;D3D12 をバックエンドとした、リアルタイムレンダリングのフレームワークです。
昨今のゲームエンジンほどの手厚い機能はありませんが、レンダリングAPIの抽象化レイヤーが軽量なのでカスタマイズが容易です。
抽象化レイヤーは、ラスタライズのみならず DXR をサポートしているのが大きな特長で、DXR を使って何か試してみたいときには特に有用なフレームワークになります。
また、DepthPre パスや、GBuffer パス、SVGF パスなどが初めから用意されているので、Raster と RT のハイブリッドレンダリングをテストしたい場合や、RT のデノイザー開発にも対応できます。
また、今回は紹介しませんが、CUDA を使った処理もサポートされているので、必要に応じてこちらも使ってみると面白いかもしれません。&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;早速ですが、環境をセットアップします。とはいっても、基本的には GitHub のリポジトリを Clone してビルドするだけです。&lt;br&gt;

&lt;a href=&#34;https://github.com/nvidiagameworks/falcor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/nvidiagameworks/falcor&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2020/11現在の推奨されるビルド環境は以下の通りです&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows 10 version 1809 or newer&lt;/li&gt;
&lt;li&gt;Visual Studio 2019&lt;/li&gt;
&lt;li&gt;Microsoft Windows SDK version 1903 (10.0.18362.1)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;また、必須ではありませんが以下のパッケージや機材を準備することをおすすめします&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GeForce RTXシリーズ (もしくはDXRをサポートしたGPU)&lt;/li&gt;
&lt;li&gt;Windows 10 Graphics Tools (WindowsのOptional Featureからインストールするパッケージ。DebugLayerのために必要)&lt;/li&gt;
&lt;li&gt;NVAPI (NVAPIによる拡張機能を使用したい場合)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;gitのリポジトリをclone&#34;&gt;GitのリポジトリをClone&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;git clone --recursive -b master git@github.com:NVIDIAGameWorks/Falcor.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;nvapiのインストール&#34;&gt;NVAPIのインストール&lt;/h4&gt;
&lt;p&gt;NVAPIを使用する方は、
&lt;a href=&#34;https://developer.nvidia.com/nvapi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ここ&lt;/a&gt;より NVAPI の最新パッケージをダウンロードして、Externals/.packman/nvapi に配置します。
ダウンロードの際にNVIDIAの開発者登録アカウントが必要になります。
次にFalcorConfig.hを開き、_ENABLE_NVAPI を1に設定します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#define _ENABLE_NVAPI 1 // Set this to 1 to enable NVIDIA specific DX extensions. Make sure you have the NVAPI package in your &#39;Externals&#39; directory. View the readme for more information.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;falcortest-プロジェクトをビルド&#34;&gt;FalcorTest プロジェクトをビルド&lt;/h4&gt;
&lt;p&gt;Tools/FalcorTest をビルドすると、Falcor (Falcor本体。レンダリングのバックエンドになるDLL) と、FalcorTest（各種単機能テストのレンダリングが書かれたアプリ）がビルドされます。
実行すると、各種機能がテストされて結果がコンソールに表示されます。詳細なテストではありませんが、まずここで自分の使いたい機能が正しく動作しているかチェックしておきましょう。
幾つかの機能は無条件にスキップされるようになっているので、適宜ソースを書き換えてテストしましょう。&lt;/p&gt;
&lt;p&gt;たとえば、ShaderModel6.5 のサポートを確認したければ、このように書き換えます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if 0
    GPU_TEST(ShaderModel6_4, &amp;quot;Requires shader model 6.4&amp;quot;) { test(ctx, &amp;quot;6_4&amp;quot;); }
    GPU_TEST(ShaderModel6_5, &amp;quot;Requires shader model 6.5&amp;quot;) { test(ctx, &amp;quot;6_5&amp;quot;); }
#else
    GPU_TEST(ShaderModel6_4) { test(ctx, &amp;quot;6_4&amp;quot;); }
    GPU_TEST(ShaderModel6_5) { test(ctx, &amp;quot;6_5&amp;quot;); }
#endif
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;TraceRayInline は、2020/11現在は、Falcor内にはシェーダーのコンパイルが通るかのテストコードしかありませんが、とりあえずテストすることが出来ます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#if 0
    GPU_TEST(testTraceRayInlineAPI, &amp;quot;Requires shader model 6.5&amp;quot;)
#else
    GPU_TEST(testTraceRayInlineAPI)
#endif
    {
        // We don&#39;t actually run the program, just make sure it compiles.
        ctx.createProgram(&amp;quot;Tests/Slang/TraceRayInline.cs.slang&amp;quot;, &amp;quot;testTraceRayInlineAPI&amp;quot;, Program::DefineList(), Shader::CompilerFlags::None, &amp;quot;6_5&amp;quot;);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;サンプルコードに目を通す&#34;&gt;サンプルコードに目を通す&lt;/h2&gt;
&lt;h3 id=&#34;projecttemplate&#34;&gt;ProjectTemplate&lt;/h3&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-project-template&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ProjectTemplate_hu17968daff6882fcdd0a6eccf1134604b_25340_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Project Template&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ProjectTemplate_hu17968daff6882fcdd0a6eccf1134604b_25340_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Project Template
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Samples/ProjectTemplate をビルドして実行すると、ウィンドウが開き、緑の画面とGUIが表示されます。チュートリアルではよくあるお約束の RenderTarget をクリアしているだけのプログラムになります。
プログラム本体はほんの数行で、Guiにボタンを追加するのと画面を緑色でクリアするコードが記述されているだけです。D3D12のAPIは抽象化されており、Render Target のクリアはこの一行で行われます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    pRenderContext-&amp;gt;clearFbo(pTargetFbo.get(), clearColor, 1.0f, 0, FboAttachmentType::All);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;RenderingContext は、メンバーに LowLevelContextData クラスを保持しており、これが D3D12 の CommandAllocator / CommandList / CommandQueue などを保持しています。
D3D12Device はグローバル変数としてアクセス可能で、一通りのAPIの抽象化レイヤーが提供されていますが、ネイティブ API へのアクセスも簡単なものになっています。
一方で、Guiのクラスを覗くと、Dear ImGui がGUIのバックエンドとして使われているのが分かります。&lt;/p&gt;
&lt;h3 id=&#34;shadertoy&#34;&gt;ShaderToy&lt;/h3&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-shadertoy&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ShaderToy_hu2b3746a333fae861e5f641d80618c199_316717_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ShaderToy&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ShaderToy_hu2b3746a333fae861e5f641d80618c199_316717_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;759&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ShaderToy
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Samples/ShaderToy プロジェクトをビルドすると、フルスクリーンの PixelShader のパスで、シェーダー Samples/ShaderToy/Toy.ps.slang が実行されます。
初期化処理の OnLoad で幾つかのステートを作成していますが全部不要な処理です。初期化処理で実際に必要とされる処理は下記の一行のみです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Load shaders
mpMainPass = FullScreenPass::create(&amp;quot;Samples/ShaderToy/Toy.ps.slang&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;描画時の onFrameRender では、初期化した mpMainPass のConstant Buffer の値を設定して execute を呼び出して描画しているだけです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mpMainPass[&amp;quot;ToyCB&amp;quot;][&amp;quot;iResolution&amp;quot;] = float2(width, height);
mpMainPass[&amp;quot;ToyCB&amp;quot;][&amp;quot;iGlobalTime&amp;quot;] = (float)gpFramework-&amp;gt;getGlobalClock().getTime();
mpMainPass-&amp;gt;execute(pRenderContext, pTargetFbo);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このように FullScreenPass クラスを使うと、ポストプロセス処理などで使うフルスクリーンのPixelShaderパスを簡単に構築することができます。Falcor には、FullScreenPass 以外にも極めて基本的な Dispatch や Draw を呼び出す機能がクラスとして標準で用意されています。これらは、Falcor プロジェクトの RenderGraph/BasePasses にあるので、興味があれば参照してください。&lt;/p&gt;
&lt;h3 id=&#34;modelviewer&#34;&gt;ModelViewer&lt;/h3&gt;
&lt;p&gt;Samples/ModelViewerをビルドして実行します。Gui の Load Model をクリックして、Falcor/Media/teapot.obj を読みます。（他にも、Media/Arcade/Arcade.fbxも読み込むことができます）
Falcor のアセット読み込みのバックエンドは、
&lt;a href=&#34;https://github.com/assimp/assimp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;assimp&lt;/a&gt; を使用しています。ライトとカメラの設定が無いので、初期状態ではカメラはteapotの中にありますし、レンダリングが真っ黒ですが、ASWDでカメラを動かせば、とりあえずジオメトリが読み込まれていることが分かります。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer01_hua46a1c90710a4eb0b2f7280e44c59e65_49694_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer01_hua46a1c90710a4eb0b2f7280e44c59e65_49694_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ModelViewer.ps.slang をチェックすると、単純にシーン上のライトをイテレーションして、マテリアルを評価しています。したがって、ライトさえ配置されていれば正しくレンダリングされるように書かれています。なので、ModelViewer.cpp の、SceneBuilder がファイルを読み終わった後の箇所で、以下の様にライトの数を確認してライトが無ければ DirectionalLight を追加するように処理を書き加えて実行します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (pBuilder-&amp;gt;getLightCount() == 0) {
    // no lights.
    pBuilder-&amp;gt;addLight(DirectionalLight::create());
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これで、シーン上にライトが無い場合はデフォルトのDirectionalLightが追加されるので、ライティングの様子が見れるようになりました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-with-a-light&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer02_hu4af4f192b6c567b25173183ebc184c2f_101873_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer with a light&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer02_hu4af4f192b6c567b25173183ebc184c2f_101873_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer with a light
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;次に、Media/Arcade/Arcade.fscene を読み込んでみます。fscene は、Json で記述された Falcorのシーン格納形式で、ライトとカメラの定義が含まれているので、特にソースコードを変更することなくライティングの様子を見ることができます。Arcade.fscene はリファレンスとして Arcade.fbx と Light.fbx を参照して、内部にライトとカメラの定義を保持しています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-fscene&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer03_hu0f84b7f164f683e83adc36f3959be573_2780056_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer fscene&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer03_hu0f84b7f164f683e83adc36f3959be573_2780056_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer fscene
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ModelViewer のプログラムを見てみると、初期化時に WireFrame描画用の RasterStateと、幾つかのCullModeの RasterStatreを作っています。DepthStencilStateも幾つか作っています。これらはGui上で選択して使用する事ができます。
シェーダープログラムは、アプリケーション側は PixelShader のみ指定して、頂点シェーダーと DrawCall の呼び出しは、Falcor 側の mpScene-&amp;gt;render() に任されています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-modelviewer-wire-frame&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer04_hucc614a67c5fbad2ebf671b0c2d57c68c_121887_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;ModelViewer wire frame&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/ModelViewer04_hucc614a67c5fbad2ebf671b0c2d57c68c_121887_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    ModelViewer wire frame
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;hellodxr&#34;&gt;HelloDXR&lt;/h4&gt;
&lt;p&gt;Samples/HelloDXRをビルドして実行します。先ほどの Arcade/Arcade.fscene が起動時から読み込まれています。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-hello-dxr-rtx-on&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR01_hu0dad088326deb0b53f9918ad0c5ed738_3254139_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Hello DXR (RTX ON)&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR01_hu0dad088326deb0b53f9918ad0c5ed738_3254139_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Hello DXR (RTX ON)
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-hello-dxr-rtx-off&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR02_hu3ace97392dbdea1ff721805c3675d6a4_2669467_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Hello DXR (RTX OFF)&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/HelloDXR02_hu3ace97392dbdea1ff721805c3675d6a4_2669467_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Hello DXR (RTX OFF)
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Ray Traceのチェックボックスで、DXRの有効/無効を切り替える事ができ、影と反射の効果の有無が違いとして見て取れます。
ソースコードを見ると、DXRが無効な時のレンダリングは、Falcorの組み込みレンダリングパスのRasterScenePassが使用されています。設定されているピクセルシェーダーは、ModelViewerとほぼ同じで、Falcorの組み込みシェーディング関数を使用しています。つまり、先の ModelViewer のサンプルプログラムは、RasterState の変更をしないのであれば、RasterScenePassを使って一行で記述できるという事です。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    mpRasterPass = RasterScenePass::create(mpScene, &amp;quot;Samples/HelloDXR/HelloDXR.ps.slang&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;main&amp;quot;);
    .
    .
    .
    mpRasterPass-&amp;gt;renderScene(pRenderContext, pTargetFbo);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DXR側は、HelloDXR.rt.slangに記述されている各シェーダーをShaderLibraryとしてコンパイルして、RtProgram::Descを使ってHitGroupの定義を行っています。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    RtProgram::Desc rtProgDesc;
    rtProgDesc.addShaderLibrary(&amp;quot;Samples/HelloDXR/HelloDXR.rt.slang&amp;quot;).setRayGen(&amp;quot;rayGen&amp;quot;);
    rtProgDesc.addHitGroup(0, &amp;quot;primaryClosestHit&amp;quot;, &amp;quot;primaryAnyHit&amp;quot;).addMiss(0, &amp;quot;primaryMiss&amp;quot;);
    rtProgDesc.addHitGroup(1, &amp;quot;&amp;quot;, &amp;quot;shadowAnyHit&amp;quot;).addMiss(1, &amp;quot;shadowMiss&amp;quot;);
    rtProgDesc.addDefines(mpScene-&amp;gt;getSceneDefines());
    rtProgDesc.setMaxTraceRecursionDepth(3); // 1 for calling TraceRay from RayGen, 1 for calling it from the primary-ray ClosestHitShader for reflections, 1 for reflection ray tracing a shadow ray

    mpRaytraceProgram = RtProgram::create(rtProgDesc);
    mpRtVars = RtProgramVars::create(mpRaytraceProgram, mpScene);
    mpRaytraceProgram-&amp;gt;setScene(mpScene);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Closest Hitのシェーディングの関数は、Rasterで使用しているものと同一で、prepareShadigData()でサーフェースの情報を取得して、envalMaterial()でシェーディングを行っています。
いる。ただし、ライトの評価の際に checkLightHit() で ShadowRay を飛ばして遮蔽のチェックをしています。また、リフレクションの Ray を飛ばしており、GGXのアルファ値（Roughness相当のパラメーター）で適当にブレンディングしています。（PBRではない） そのため、DXRを有効にした場合は、影と反射が追加されたレンダリングになります。&lt;/p&gt;
&lt;h2 id=&#34;mogwaiに目を通す&#34;&gt;Mogwaiに目を通す&lt;/h2&gt;
&lt;h4 id=&#34;注意&#34;&gt;注意&lt;/h4&gt;
&lt;p&gt;ビルドの際にコンパイルエラー等は発生しませんでしたが、実行時にPythonのBindingを設定している個所で例外が発生しました。この問題は、VisualStudioをアップデートすることで解決しました。動作確認は Microsoft Visual Studio Professional 2019 - Version 16.7.7 を用いて行いました。同様の問題が発生した場合は、VSのバージョンをチェックすると良いかもしれません。&lt;/p&gt;
&lt;h4 id=&#34;mogwai&#34;&gt;Mogwai&lt;/h4&gt;
&lt;p&gt;Falcorは Pybind11を使って、RenderGraph を Python で記述するための機構を持っています。Mogwaiはその機構を使ったフレームワークと呼べると思います。
ビルドすると、Pythonで記述されたいくつかの RenderGraph が、実行ファイルの出力先の Data フォルダに用意されます。
起動後に File-&amp;gt;Load Scriptで Data/FowardRenderer.py を読み込みます。これで Foward Rendering の RenderGraph が読み込まれて、使用できるようになります。
次にFile-&amp;gt;Load Sceneで、Falcor/Media/Arcade/Arcade.fsceneを読み込みます。
すると、サンプルの Model Viewerと同様にレンダリングが確認できると思います。しかし、ModelViewerとは異なり、先ほど読み込んだ Pythonのスクリプトに記述された RenderGraph によってレンダリングの動作が定義されています。&lt;/p&gt;
&lt;p&gt;ここで、File-&amp;gt;LoadScript で、MinimalPathTracer.py を読み込むことで、パストレーシングのRenderGraphを、追加で読み込むことができます。
HUD上でRenderGraphを切り替えると、MinimalPathTracerにレンダリングパスを切り替えることができます。このように、Mogwaiを使うと、python で記述された複数の RenderGraph を動的に切り替える事ができます。これはレンダリングの比較評価等を行う際に有用だと言えると思います。&lt;/p&gt;
&lt;p&gt;RenderGraph を ForwardRenderer に戻してEditボタンを押すと、RenderGraph の編集ができます。
基本的には FowardRenderer.py に書かれている内容そのままですが、RenderGraph を視覚的に確認してエディットすることもできます。ただ、オマケ的な要素が強く、実際の RenderGraph の構築では、Pythonスクリプトを直接編集したほうが早いです。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-mogwai-render-graph&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai01_hucf237075bdd7b9e9afe14ce554f09d70_147063_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Mogwai Render Graph&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai01_hucf237075bdd7b9e9afe14ce554f09d70_147063_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1119&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Mogwai Render Graph
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;rendergraphのノード&#34;&gt;RenderGraphのノード&lt;/h4&gt;
&lt;p&gt;RenderGraph の個々のノードは、Falcor の RenderPass クラスを継承したクラスです。
たとえば DepthPrePass ノードは DepthPass.dll として事前にビルドされており、これが ForwardRenderer.py の中でインポートされて、他のノードと接続されることでレンダリングパスが構築されています。他にも、GBuffer描画や、CascadedShadowMap, SSAO, Antialias, Tonemapping, SkyBox, それからレイトレーシング用に、MinimalPathTracer, AccumulatePass, SVGFPassなど、他にも幾つかの有用なノードが用意されています。これら RenderGraph のノードは個々のDLLとしてコンパイルされています。そのためのプロジェクトは、Falcor ソリューション内の RenderPasses フォルダに配置されているので確認してみてください。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-mogwai-render-graph&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai02_hu6c2dd509207f4d3927ccb0a42e7f7735_35792_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Mogwai Render Graph&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/falcor_getting_started/Mogwai02_hu6c2dd509207f4d3927ccb0a42e7f7735_35792_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;592&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Mogwai Render Graph
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;depthpassに目を通す&#34;&gt;DepthPassに目を通す&lt;/h4&gt;
&lt;p&gt;RenderGraph の一つのノードの例として、DepthPass ノードを見てみます。DepthPass ノードは RenderPass クラスを継承して実装され、DepthPass.dllとして配置され、Falcor のレンダリングに使用されます。
ヘッダーファイルを見ると、Gui の描画やリフレクションをサポートする関数、シーン情報にアクセスをするための setScene があります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    static SharedPtr create(RenderContext* pRenderContext = nullptr, const Dictionary&amp;amp; dict = {});

    virtual RenderPassReflection reflect(const CompileData&amp;amp; compileData) override;
    virtual void execute(RenderContext* pContext, const RenderData&amp;amp; renderData) override;
    virtual void setScene(RenderContext* pRenderContext, const Scene::SharedPtr&amp;amp; pScene) override;
    virtual void renderUI(Gui::Widgets&amp;amp; widget) override;
    virtual Dictionary getScriptingDictionary() override;
    virtual std::string getDesc() override { return kDesc; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;reflect()を見ると、レンダリングの出力として、2DのDepthStencilを出力することが分かります。入力は無いので、setSceneで設定されたシーンから取得できるカメラとジオメトリを用いてレンダリングすることが想像できます。
DepthBuffer のフォーマットはクラス内部に保持されて、Guiによる設定を介して変更できるようです。その結果がリフレクションの出力ピンに反映されます。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RenderPassReflection DepthPass::reflect(const CompileData&amp;amp; compileData)
{
    RenderPassReflection reflector;
    reflector.addOutput(kDepth, &amp;quot;Depth-buffer&amp;quot;).bindFlags(Resource::BindFlags::DepthStencil).format(mDepthFormat).texture2D(0, 0, 0);
    return reflector;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;描画解像度の設定は無く、DLLの外部で用意されたDepthStencilバッファをBindしてレンダリングする仕組みになっています。シェーダーは、Slangで記述されたピクセルシェーダーが一つだけあります。
中を確認すると、prepareShadingDataを呼び出しています。これは、アルファが完全に透明だった場合に、この関数のなかでDiscardが呼ばれるためです。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void main(VSOut vOut, uint triangleIndex : SV_PrimitiveID) : SV_TARGET
{
    // Calling prepareShadingData() to discard pixels that fail alpha test. The pixel shader has no other side effects.
    float3 viewDir = normalize(gScene.camera.getPosition() - vOut.posW);
    prepareShadingData(vOut, triangleIndex, viewDir);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ちなみに、描画解像度の設定は、Falcor の RenderGraph 側にあります。RenderGraphCompiler::allocateResources() が RenderGraph の変更や描画解像度変更をトリガーとして、使用されている出力ピンのリソースを ResourceCache に登録します。その時に、各種 RnederTarget の解像度の設定が行われます。&lt;/p&gt;
&lt;p&gt;実際に RenderGraph のノードを実装するならば、ぜひ Docs/
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/Falcor/blob/master/Docs/Tutorials/02-Implementing-a-Render-Pass.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tutorials&lt;/a&gt; をご一読する事をお勧めします。&lt;/p&gt;
&lt;h2 id=&#34;最後に&#34;&gt;最後に&lt;/h2&gt;
&lt;p&gt;ビルドして実行するだけではいまいち概要がつかみにくい Falcor ですが、リポジトリの
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/Falcor/blob/master/Docs/index.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ドキュメント&lt;/a&gt;を読めば、この記事に書いてあることを含めて記載があります。ソースコードの規模もあまり大きくないので、全体の把握も比較的容易だと思います。アセットもFBX形式が読み込めるので、手元のアセットでテストしたい場合なども比較的短時間でセットアップできるのではないでしょうか。今回は紹介していませんが、
&lt;a href=&#34;https://developer.nvidia.com/orca&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ORCA&lt;/a&gt;をはじめ、CC-BY等のオープンライセンスの元で公開されているアセットなどもあるので、これらを活用してレンダリングのテストを行う事も可能だと思います。&lt;/p&gt;
&lt;p&gt;今回は、簡単にですが Falcor を触ってみました。この手の軽量なレンダリングフレームワークというのは、自作含めて多数あると思いますが、RasterとDXRをシームレスにサポートしている軽量フレームワークはあまり見かけません。
そういう意味ではユニークな存在かもしれません。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Device Removalの処方箋 - 補足資料</title>
      <link>https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/</link>
      <pubDate>Fri, 04 Sep 2020 18:00:00 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/</guid>
      <description>&lt;h2 id=&#34;これは補完資料です&#34;&gt;これは補完資料です&lt;/h2&gt;
&lt;p&gt;この記事は、CEDEC2020での講演 &amp;ldquo;Direct3D 12 Device Removalの処方箋&amp;rdquo; において、時間内に説明することができなかった部分に関して解説するためのものです。
CEDEC2020で当該講演を聴講された方に向けて書いています。この記事単体では不完全です。タイムシフト視聴や、CEDiLにアクセス可能な方は、先にそちらをご覧になることをお勧めします。&lt;/p&gt;
&lt;h2 id=&#34;device_removedとは&#34;&gt;DEVICE_REMOVEDとは&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;DXGIとD3D12API返すHRESULTに設定されるエラー&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正式にはDXGIのエラーコード。DXGI_ERROR_DEVICE_REMOVED&lt;/li&gt;
&lt;li&gt;殆どの場合は、IDXGISwapChain::Present()呼び出しの際に返される&lt;/li&gt;
&lt;li&gt;ID3D12DeviceD3D12の一部のメソッド、リソースの作成、Mapなどを実行した際にも返される&lt;/li&gt;
&lt;li&gt;ID3D12Device::GetDeviceRemovedReasonの呼び出しでも返される&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ID3D12Device::GetDeviceRemovedReasonを呼び出すことで以下の様な具体的なエラー原因が取得できる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_HUNG&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_REMOVED&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DEVICE_RESET&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_DRIVER_INTERNAL_ERROR&lt;/li&gt;
&lt;li&gt;DXGI_ERROR_INVALID_CALL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;FormatMessage()や、_com_errorでエラーの意味を取得できる&lt;br&gt;
Device Removed Reason for 887a0006 DXGI_ERROR_DEVICE_HUNG
The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device_removedが発生する原因について&#34;&gt;DEVICE_REMOVEDが発生する原因について&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDは、D3D12APIを通じて、GPUやドライバーで発生したエラーの結果に過ぎない。OSやD3D12ランタイムが、コンテキストの実行を継続するべきでは無いと判断した場合に発生する。
ただ、
&lt;a href=&#34;https://www.youtube.com/watch?v=VaGcs5-W6S4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alex DunnがGDC2018で説明&lt;/a&gt;した通り、大きく分けて２つの種類にカテゴライズする事ができる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TDR（Timeout Detection and Recovery）によるDEVICE_REMOVED&lt;br&gt;
ドライバーやGPUがOSに対して一定時間内に応答しなかった場合に、OSが発生させるDEVICE_REMOVED。OSはシステム全体のHungを避けるため、DEVICE_REMOVEDを発生させてドライバーをリセットする。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ドライバーのコードパスで想定していない長時間の処理があった場合&lt;/li&gt;
&lt;li&gt;シェーダー内で長時間処理がかかった場合（シェーダー内無限ループ等）&lt;/li&gt;
&lt;li&gt;Signal,Waitの設定ミスで長時間Fenceが解決しなかった場合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;エラーの検出によるDEVICE_REMOVED&lt;br&gt;
何らかの看過できないエラーの発生に伴いOSやD3D12ランタイムが発生させるDEVICE_REMOVED。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPUで発生したPage Fault
存在しないリソースへのアクセスや、宣言した利用用途と異なるアクセス。&lt;/li&gt;
&lt;li&gt;不正な上書き等によるCommand Listの破損
結果的にドライバーやGPUが不正な実行コマンドを受け取る。&lt;/li&gt;
&lt;li&gt;D3D12ランタイムやドライバーによるエラーの検出
許可されていないリソースステートのリソースへのアクセス。各種リソースのアラインメント違反。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpuとcpuの時間のずれ&#34;&gt;GPUとCPUの時間のずれ&lt;/h2&gt;
&lt;p&gt;ここでは、CPUコードのデバッグと、DEVICE_REMOVEDの追跡の決定的な違いについて説明する。
CPUの実行コードは、デバッガがアタッチされている状況下では即時的であり、エラーが発生すれば直ちにプログラムの実行を停止して、デバッガに処理を返すことで、エラーが起きた瞬間の状況が分かる。&lt;br&gt;
これに対して、DEVICE_REMOVEDの発生は、CPUのコードと全く同期しないタイミングで発生する。そのため、CPUがDEVICE_REMOVEDを受け取った瞬間にデバッガで処理を止める事にはほとんど意味がない。&lt;/p&gt;
&lt;p&gt;以下のスクリーンショットはGPUViewというツールでCPUとGPUの処理時間を示したものになる。画面左から右に時間の経過を表している。中央の大きなスタックの中でハイライトされているのは、
あるGPU処理の塊となる、バケットである。ご覧の通り画面の左端で生成されたバケットは、画面の右側でスタックの最下段に到達している。この時点GPUの処理の対象となる。この間3フレーム分の時間が経過している。
もし、このGPU処理のなかでDEVICE_REMOVEDが発生したら、CPUがそのエラーを受け取る可能性があるのは、この時点以後となるので、CPUから見るとコマンド生成から3フレーム以上遅れてDEVICE_REMOVEDを受け取る事になる。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-gpuとcpuの処理時間のずれ&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/GPUView_Framelatency_clipped_hu8d16dffa687010e8cb8fe6da31428ef9_85614_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;GPUとCPUの処理時間のずれ&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/GPUView_Framelatency_clipped_hu8d16dffa687010e8cb8fe6da31428ef9_85614_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;870&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    GPUとCPUの処理時間のずれ
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;これが、DEVICE_REMOVEDの追跡が難しい原因の一つである。&lt;/p&gt;
&lt;h2 id=&#34;device_removedの対処法&#34;&gt;DEVICE_REMOVEDの対処法&lt;/h2&gt;
&lt;p&gt;GPU上で発生する様々なエラーをデバッグする方法として、D3D12APIは以下の方法を提供している&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debug Layer&lt;br&gt;
昔からあるが、DEVICE_REMOVEDの原因の追跡において最も有効な方法の一つ&lt;/li&gt;
&lt;li&gt;GPU Based Validation&lt;br&gt;
比較的新しく導入されたDebug Layerの拡張。CPU側のValidationでは追跡できない問題を検出する&lt;/li&gt;
&lt;li&gt;DRED1.2&lt;br&gt;
新しく導入されたDEVICE_REMOVEDの追跡方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上記3つのうち、先の二つは、DEVICE_REMOVEDが発生する前に起きているD3D12上のエラーの追跡に使うのに対して、
DREDは、DEVICE_REMOVEが発生した後に、発生した箇所を見つけ出すためのもので、用途が完全に異なる。どちらも有用なので組み合わせて使う。&lt;/p&gt;
&lt;h2 id=&#34;debug-layer&#34;&gt;Debug Layer&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDに対する処方の第一候補は、Debug Layerである。これを有効にすることにより、D3DのランタイムがValidationを積極的に行い、Debug Outputにメッセージを送出するようになる。
DEVICE_REMOVEDが発生する前に出力されるDebug Layerのメッセージは、DEVICE_REMOVEDの発生原因を調査する上での貴重な手がかりになる。&lt;/p&gt;
&lt;h3 id=&#34;debug-layerの有効化&#34;&gt;Debug Layerの有効化&lt;/h3&gt;
&lt;p&gt;Debug Layerはアプリケーション自身で有効にすることもできるし、外部から強制的に有効にすることもできる。&lt;br&gt;
外部から強制的に有効にする際は、dxcpl.exe(GUIツール)やd3dconfig.exe(コマンドラインツール)を用いる。インストールはWindows10の、Settings→Add an optional feature→ Add a feature→ Graphics Toolsを選択する事で行う。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-dxcplのインストール&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Graphics_tools_hud17edd7f0016c7970e8d79671c2245cb_50866_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;dxcplのインストール&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Graphics_tools_hud17edd7f0016c7970e8d79671c2245cb_50866_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;930&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    dxcplのインストール
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;外部からDebug Layerを有効にする際は、dxcpl.exeかd3dconfg.exeを用いて、ターゲットとなるアプリケーションの名前を事前に登録し、Debug Layerを強制的に有効にする設定にする。設定内容はdxcplとd3dconfigで共有され、システム全体で有効になるので注意が必要である。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Dxcpl_addname_hucbdb74109a3fd183c1975591731fc9c0_227302_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/Dxcpl_addname_hucbdb74109a3fd183c1975591731fc9c0_227302_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;902&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    デバッグ対象アプリケーションを登録する
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/D3dConfg_hu66e5d0a7c318d4262e1366fb00f0e524_17980_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;デバッグ対象アプリケーションを登録する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/D3dConfg_hu66e5d0a7c318d4262e1366fb00f0e524_17980_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;466&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    デバッグ対象アプリケーションを登録する
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;アプリケーション内部で設定する場合は、CreateDeviceを実行する前に、ID3D12Debugインターフェースを取得して、EnableDebugLayer()を呼び出す事で有効にできる。
この場合は、dxcpl.exeやd3dconfig.exeによるターゲットアプリケーション名の登録は必要ない。登録してある場合は、debug-layerの設定はApplication Controlledに設定することでAPIから明示的に有効にした場合のみDebug Layerが有効になる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Create Deviceの前に設定する
{
    ComPtr&amp;lt;ID3D12Debug1&amp;gt; debug1;
    if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;debug1))))
    {
        debug1-&amp;gt;EnableDebugLayer();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;debug-layerの出力&#34;&gt;Debug Layerの出力&lt;/h3&gt;
&lt;p&gt;Debug Layerが有効になっている状態では、アプリケーションのD3DAPIの使用において何らかの間違いが検出されれば、エラーの内容がデバッグ出力ストリームに文字列として出力される。出力メッセージはVisual StudioやDbgviewなどのツールを使って確認することができる。出力内容は、その深刻度に応じてグループ分けされている。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Info&lt;br&gt;
リソースの確保や開放などを通知する。デフォルトでMuteされている。&lt;/li&gt;
&lt;li&gt;Warning&lt;br&gt;
APIの仕様から逸脱していないが、パフォーマンスの問題や、バグの発生の原因になりそうな状況を通知する。&lt;/li&gt;
&lt;li&gt;Error&lt;br&gt;
APIの仕様から逸脱した状況が検出された場合に通知する。ただ、これが出力されるから、直ちにDEVICE＿REMOVALが発生するという訳ではない。&lt;/li&gt;
&lt;li&gt;Corruption&lt;br&gt;
リソースやオブジェクト（オブジェクト自身というよりは、多くはそのハンドル等）が破損していることが検出された場合に通知する。&lt;/li&gt;
&lt;li&gt;Message&lt;br&gt;
上記に当てはまらない情報を通知する（メモリ不足等）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、例としてResourceBarrierの遷移前リソースステートの指定が間違っていた場合に出力されたエラーである。ちなみにこのプログラムは、Debug Layerが無効な状態でも有効な状態でも正常に動作した。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D3D12 ERROR: ID3D12CommandList::ResourceBarrier: Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:&#39;MyColorTex&#39;) (subresource: 0) specified by transition barrier does not match with the current resource state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) (assumed at first use) [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH]
D3D12 ERROR: ID3D12CommandQueue::ExecuteCommandLists: Using ResourceBarrier on Command List (0x000001AE3B802060:&#39;MyCommandList_Direct&#39;): Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:&#39;MyColorTex&#39;) (subresource: 0) specified by transition barrier does not match with the state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) specified in the previous call to ResourceBarrier [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Debug Layerはこのエラーを二か所で検出した。一つはID3D12CommandList::ResourceBarrier()呼び出し時に、もう一つは、ID3D12CommandQueue::ExecuteCommandLists()呼び出し時に検出した。しかしこれは、この種のエラーは常に二か所で検出されるという意味ではない。コマンドリストは他のコマンドリストの生成タイミングと関係なく生成する事ができ、その際のコマンドリスト作成時のリソースのステートは未確定になる場合がある。そのためDebug Layerは複数の箇所で可能な限りエラーの特定を試みる。上記の場合では、コマンドリスト作成時の対象リソースの事前ステートが確定できたので、ID3D12CommandList::ResourceBarrier()の呼び出し時にエラーが出力出来たという事である。&lt;br&gt;
また、ステートが間違っていたリソースの名前が、&amp;lsquo;MyColorTex&amp;rsquo;といった様に表示されるが、これはアプリケーション自身が、ID3D12Object::SetName()を通じて設定したものである。D3D12アプリケーションを開発し、各種デバッグ機能を使う予定がある場合は、可能な限り全てのD3D12Objectに名前をつけるべきである。すると、上記の様にエラーが発生した際のメッセージによって原因となったリソースの特定が簡単に行えるようになる。Command ListやDescriptor Heapなどにもしっかりと名前を付けると、上記の様にエラーが発生したコマンドリスト名からエラーがどのレンダリングパスで発生したのかが特定できる場合もある。また、PIXやNSightといったフレームプロファイラを使う場合にもこれらの名前付けは有用である。&lt;/p&gt;
&lt;p&gt;次の例は、RenderTargetを設定したクリアカラー以外でクリア場合に発生する警告である。これはエラーではないので無視しても構わない。しかし、このようにパフォーマンスの向上を考える場合に有用なメッセージが得られる場合もある。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D3D12 WARNING: ID3D12CommandList::ClearRenderTargetView: The application did not pass any clear value to resource creation. The clear operation is typically slower as a result; but will still clear to the desired value. [ EXECUTION WARNING #820: CLEARRENDERTARGETVIEW_MISMATCHINGCLEARVALUE]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;id3d12infoqueueについて&#34;&gt;ID3D12InfoQueueについて&lt;/h3&gt;
&lt;p&gt;Debug Layerは、時にはアプリケーションが意図して記述しているコードに対してもメッセージを出力する場合がある。その場合は、アプリケーションが無視するべきと考えるメッセージを、D3D12InfoQueueを使ってフィルタリングできる。以下のコードスニペットは、GPUが書き込みしている可能性のあるリソースがCPUから読み込み可能な状態でMapされている場合に出力される警告を抑制するためのものである。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ComPtr&amp;lt;ID3D12InfoQueue&amp;gt; d3dInfoQueue;
if (SUCCEEDED(device-&amp;gt;QueryInterface(IID_PPV_ARGS(&amp;amp;d3dInfoQueue))))
{
    // Suppress individual messages by their ID.
    D3D12_MESSAGE_ID denyIds[] =
    {
        D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED,
    };

    D3D12_INFO_QUEUE_FILTER filter = {};
    filter.DenyList.NumIDs = _countof(denyIds);
    filter.DenyList.pIDList = denyIds;
    d3dInfoQueue-&amp;gt;AddStorageFilterEntries(&amp;amp;filter);
    OutputDebugString(L&amp;quot;Warning: GPUTimer is disabling an unwanted D3D12 debug layer warning: D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED.&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Microsoft DirectX SDK Sampleより引用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;メッセージのフィルタリングは、InfoQueueを通じてではなく、dxcpl/d3dconfigを使っても同様のフィルタリングの設定が可能だが、メッセージのフィルタリングはアプリケーションごとに行われるべきであるので、通常はアプリケーションのコードに記述されるべきである。ちなみに、InfoQueueの設定は、dxcpl/d3dconfigの設定でオーバーライドされるので、InfoQueueを使って制御したいときは、dxcpl/d3dconfigにアプリケーションを登録してはいけない。
以下はID3D12InfoQueueのその他の機能についてである。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;InfoQueueのデフォルト設定では、Infoレベルのメッセージはフィルタリングされているので、Infoレベルのメッセージを取得する必要がある場合はフィルタの設定を一旦クリアする必要がある。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;フィルターにはStorageFilterとRetrievalFilterの二種類がある。&lt;br&gt;
StorageFitlerは、エラーがメッセージキューにストアするときに適用されるフィルタ。フィルターを通過できなければ、メッセージキューにストアされない。
RetrievalFilterはメッセージを取得する際に適用されるフィルタ。メッセージキューにストアされているメッセージを破壊せずに、特定の種類のメッセージのみを抽出したいときなどに使う。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SetMuteDebugOutputでデバッグ出力ストリームへの出力を停止できる。
アプリケーション側で出力されるエラーのハンドリングを全て行う場合などで、デバッグ出力ストリームへの出力が不要な場合は抑止できる。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特定のエラーが検出された時や、エラーの深刻度によって、DebugBreakすることが可能。
Debug LayerはCPU側のD3D12ランタイムがエラーを検出しているので、エラーが発生するタイミングは、CPU処理と同期したタイミングが多い。したがって、DebugBreakすることは有効である。
しかし、DebugBreakがかかるのは、D3Dのランタイム側のスレッドでかかる場合もあるので、追跡するには、マルチスレッドのデバッギングが必要になる。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpu-based-validationの有効化&#34;&gt;GPU Based Validationの有効化&lt;/h2&gt;
&lt;p&gt;DEVICE_REMOVEDへの処方の第二候補は、GPU Based Validationの有効化である。GPU Based Validation(以下GBV)は、その名の通り、GPU側での実行時に行うValidationである。
GBVもアプリケーション自身で有効にすることもできるし、dxcplなどで強制的に有効にすることもできる。この点はDebug Layerと同様である。なお、Debug Layerが有効化されていないと動作しないので、Debug Layerの拡張機能と考える事もできる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
    ComPtr&amp;lt;ID3D12Debug1&amp;gt; debug1;
    if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;debug1))))
    {
       debug1-&amp;gt;EnableDebugLayer();
       debug1-&amp;gt;SetEnableGPUBasedValidation(true);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;先ほど説明したDebug Layerは主にCommandListに命令を積み、ExecuteCommandListを呼び出すまでに行われるValidation。対してGBVはシェーダー実行時に行われるValidationになる。
未定義のDescriptorや、廃棄済みのリソースへのアクセス。不適切なリソースステートでのアクセスなど、CommandList作成時には、リソースの状況が未定で、検出できないエラーを実行時に検出する。
メッセージは既存のDebug Layerと同様に出力されるが、その出力のタイミングはコマンドリストを生成したCPU処理と同期しない。したがって、エラーメッセージが出力された瞬間のCPU処理を検証しても意味がない。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://docs.microsoft.com/sr-latn-rs/windows/win32/api/d3d12sdklayers/ne-d3d12sdklayers-d3d12_message_id&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D3D12_MESSAGE_ID enumeration&lt;/a&gt;を確認すれば、GBVで出力されるメッセージのIDには、
&amp;ldquo;GPU_BASED_VALIDATION&amp;quot;が含まれるのが分かる。これで実際にどのようなエラーが検出可能なのか分かる。&lt;/p&gt;
&lt;p&gt;GBVは、シェーダーコードとPSOにパッチを充てる形で実現する。これらには、いくつかのモードがあり選択することができる。GBVの設定は以下のAPIと構造体を通じて設定を行う。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ID3D12DebugCommandList1::SetDebugParameter()
typedef struct D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS {
  UINT                                                   MaxMessagesPerCommandList;
  D3D12_GPU_BASED_VALIDATION_SHADER_PATCH_MODE           DefaultShaderPatchMode;
  D3D12_GPU_BASED_VALIDATION_PIPELINE_STATE_CREATE_FLAGS PipelineStateCreateFlags;
} D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下はシェーダーのパッチモードの選択である&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;NONE&lt;br&gt;
シェーダーコードにValidationコードを挿入しないモード。
CommonStatePromotionによるリソースステートの遷移をトラッキングすることができない。そればかりかGBVを混乱させる恐れがある。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TRACKING_ONLY_SHADERS&lt;br&gt;
リソースステートの遷移のみをチェックするためのコードが挿入される。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CREATE_UNGUARDED_VALIDATION_SHADERS&lt;br&gt;
GBVのValidationコードが挿入される。Validationによるエラーが検出され、無効なリソースに対するアクセスや範囲外アクセスがあっても該当コードを実行する。結果、DEVICE_REMOVEDなどを引き起こすかもしれない。これがデフォルトのシェーダーパッチモード。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CREATE_GUARDED_VALIDATION_SHADERS&lt;br&gt;
GBVのValidationコードが挿入される。Validationによるエラーが検出された場合は、該当のリソースアクセスを避ける。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PipelineStateCreateFlagsでは、事前にPatchされたPSOを生成するかどうかを制御できる。
デフォルトでは、パッチがあてられたPSOの初回使用時にコンパイルされる挙動なので、CommandListのRecordingが遅くなる。FRONT_LOADを設定することで予めコンパイルされる設定になる。&lt;/p&gt;
&lt;p&gt;以下はGBVによって検出されたエラーの一例。UAVの範囲外にシェーダーがアクセスしたことで出力された。この種のバグは、CPU側のDebug Layerでは検出できないが、GBVならば検出できる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DescriptorTableのUAVに設定したUAVバッファに対する範囲外アクセス　(RootSignature1.1を使用。Range Flagは　D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTE)
D3D12 ERROR: GPU-BASED VALIDATION: Draw, Resource access out of bounds: Resource: 0x000001C6F8F91A60:&#39;DummyResource_256_bytes_UAV_buffer&#39;, Descriptor Type: UAV, Highest byte offset from view start accessed: [439737], Bytes available in view: 256. Results undefined because descriptor is declared static in root signature, which allows hardware/driver the option of converting the access to a root descriptor. Unlike descriptor heap descriptors, root descriptors do not have defined behavior for an out of bounds access. Index of Descriptor Range: 1, Shader Stage: PIXEL, Root Parameter Index: [0], Draw Index: [0], Shader Code: &amp;lt;debug info not available&amp;gt;, Asm Instruction Range: [0xbc-0xdf], Asm Operand Index: [2], Command List: 0x000001C6F8E6DA10:&#39;MyCommandList_Direct&#39;, SRV/UAV/CBV Descriptor Heap: 0x000001C6F8D8AB60:&#39;Unnamed ID3D12DescriptorHeap Object&#39;, Sampler Descriptor Heap: &amp;lt;not set&amp;gt;, Pipeline State: 0x000001C6F8BC81B0:&#39;Unnamed ID3D12PipelineState Object&#39;,  [ EXECUTION ERROR #1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ここで、GBVの話から少しそれるが、このエラーについて詳しく考えてみたいと思う。また、これらの出来事は私のローカル環境で観測されたに過ぎないことも明記しておく。
上記のエラーメッセージを要約すると以下の通りと思われる。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;リソースへの範囲外アクセス。リソース：`ummyResource_256_bytes_UAV_buffer` デスクリプタタイプ:UAV 最高でオフセット[439737]にアクセスした。Viewでアクセス可能なのは 256. 
アクセスの結果は未定義です。なぜなら、デスクリプタはRootSignatureで`static`として宣言されており、ハードウェアやドライバーはこの（メモリ）アクセスをルートデスクリプタにコンバートする選択肢が許されているからです。
デスクリプタヒープのデスクリプタと異なり、ルートでスクリプタには範囲外アクセスの挙動の定義がありません。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;このUAVはDescriptorTableに定義したが、RangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTEを設定した。このフラグが設定されたものはドライバーの最適化対象になる可能性があり、RootDescriptor（RootTableに直接定義するDescriptor）にコンバートされる可能性がある。
実際にコンバートされた場合は、範囲外アクセスは未定義動作となるので、エラーになっているという訳である。しかし、実際はリソースのアクセス範囲チェックがされていた（つまり、RootDescriptorへのコンバートは行われていなかった）ので、DEVICE_REMOVEDが発生するような致命的な事態にはならなかった。&lt;/p&gt;
&lt;p&gt;次に、このUAVが設定されているDescriptorTableのRangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定するとどうなるかというと、エラーが全く出力されなくなった。これは、DirectXの仕様として、RootSignature1.1のDescriptorTableに定義されたUAVで、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定された場合、もしくはRootSignature1.0で定義されたUAVの場合は、リソースアクセスの範囲チェックが行われる決まりがある。範囲外の読み出しはゼロを返され、範囲外への書き込みは行われない。DirectXの仕様に則った動作なのでエラーが発生しないというわけである。&lt;/p&gt;
&lt;p&gt;次は、DescriptorTableを介さずに、直接RootTableにUAVを定義して、範囲外アクセスを起こすと以下のメッセージが出力された。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RootTableに設定したUAVバッファに対する範囲外アクセス
D3D12 ERROR: GPU-BASED VALIDATION: Draw, Root descriptor access out of bounds (results undefined): Resource: 0x000001A7600AF410:&#39;DummyResource_256_bytes_UAV_buffer&#39;, Root Descriptor Type: UAV, Highest byte offset from view start accessed: [803581], Bytes available from view start based on remaining resource size: 256. Shader Stage: PIXEL, Root Parameter Index: [1], Draw Index: [0], Shader Code: &amp;lt;debug info not available&amp;gt;, Asm Instruction Range: [0xc8-0xeb], Asm Operand Index: [2], Command List: 0x000001A75F82C5B0:&#39;MyCommandList_Direct&#39;, SRV/UAV/CBV Descriptor Heap: 0x000001A75F9DEA70:&#39;Unnamed ID3D12DescriptorHeap Object&#39;, Sampler Descriptor Heap: &amp;lt;not set&amp;gt;, Pipeline State: 0x000001A75FDC5DE0:&#39;Unnamed ID3D12PipelineState Object&#39;,  [ EXECUTION ERROR #961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS]

さらに、DEVICE_REMOVED発生した。
D3D12: Removing Device.
D3D12 ERROR: ID3D12Device::RemoveDevice: Device removal has been triggered for the following reason (DXGI_ERROR_DEVICE_HUNG: The Device took an unreasonable amount of time to execute its commands, or the hardware crashed/hung. As a result, the TDR (Timeout Detection and Recovery) mechanism has been triggered. The current Device Context was executing commands when the hang occurred. The application may want to respawn and fallback to less aggressive use of the display hardware). [ EXECUTION ERROR #232: DEVICE_REMOVAL_PROCESS_AT_FAULT]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;先ほどとエラーメッセージが異なり、エラーのIDが異なるので注意が必要である。以上の出来事をまとめると以下の様になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DescriptorTableに定義した場合&lt;br&gt;
#1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS&lt;br&gt;
こちらのエラーは、VOLATILEでないDescriptorTableに定義されたリソースに対する範囲外アクセスで発生したエラー。
ハードウェアやドライバーが、範囲外アクセスを未定義動作にすることが許されている状態だが、実際に範囲外アクセスをするかは実装次第。&lt;/li&gt;
&lt;li&gt;RootTableに直接定義した場合&lt;br&gt;
#961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS&lt;br&gt;
こちらは、DescriptorTableではなく、RootTableに定義されたリソースの範囲外アクセスで発生したエラー。
RootTableにUAVやSRVを定義した場合、リソースのサイズは格納されない事が知られており、通常は範囲外アクセスへのチェックも行われない事が知られている。しかし、GBVを有効にすることでこれらの範囲外アクセスがValidatorにより検出され、
エラーが出力されたという状態。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;このように、エラーメッセージから学べる事もあるので、Debug LayerやGBVを有効にするのはおすすめである。&lt;/p&gt;
&lt;h2 id=&#34;debug-layerのその他の機能&#34;&gt;Debug Layerのその他の機能&lt;/h2&gt;
&lt;h3 id=&#34;synchronized-command-queue-validation&#34;&gt;Synchronized Command Queue Validation&lt;/h3&gt;
&lt;p&gt;Debug Layerを有効にすることで、Synchronized Command Queue Validationという機能がでデフォルトで有効になる。
この機能によって、FenceのWaitが設定されたコマンドリストにおいて、Waitの条件が満たされるまで、GPUへのコマンド送出をしなくなる。
これにより、Waitが設定されている以降のコマンドにおけるリソースステートをCPU側でも確認することができ、結果として、コマンド送出時にリソースステートのValidationをより厳密に行う事ができる。
Disableにすることによって、FenceのSignalとWaitを多用したQueueの組み立てをしている場合に限り、Debug Layer使用時の若干のパフォーマンス向上が期待できるが、そもそもDebug Layerはパフォーマンスを追求するためのものでは無いのでDisableにするメリットは殆どない。&lt;/p&gt;
&lt;h3 id=&#34;debugdevice--debugcommandqueue--debugcommandlist&#34;&gt;DebugDevice / DebugCommandQueue / DebugCommandList&lt;/h3&gt;
&lt;p&gt;Debug Layerが有効な状態では、Device, CommandQueue, CommandListからQueryInterfaceすることで、表題のインターフェースが取得できる。
主な機能は以下の通り。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ID3D12DebugDevice::ReportLiveDeviceObjects()&lt;br&gt;
現在有効なオブジェクトをデバッグ出力ストリームに出力する。&lt;/li&gt;
&lt;li&gt;ID3D12DebugCommandList::AssertResourceState()&lt;br&gt;
リソースのステートが、呼び出し引数に与えたステートと等しいかを返す。&lt;br&gt;

&lt;a href=&#34;https://microsoft.github.io/DirectX-Specs/d3d/CPUEfficiency.html#common-state-promotion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Common State Promotion&lt;/a&gt;を使う場合は、これでState PromotionやDecayの確認をするとデバッグしやすい。&lt;/li&gt;
&lt;li&gt;ID3D12DebugCommandQueue::AssertResourceState()&lt;br&gt;
リソースのステートが、呼び出し引数に与えたステートと等しいかを返す。&lt;br&gt;
CommandQueuから直接リソースを操作するAPIがある関係上、CommandQueuからもリソースのステートが確認できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;device-removed-extended-data-12&#34;&gt;Device Removed Extended Data 1.2&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://microsoft.github.io/DirectX-Specs/d3d/DeviceRemovedExtendedData.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Device Removed Extended Data&lt;/a&gt;とは、実際にDEVICE_REMOVEDが発生した後に、発生のより詳しい状況を知るための機構である。通常はDEVICE_REMOVEDが発生しても、得られる情報はせいぜいHRESULTのエラーコードぐらいで、デバッグの指標となる情報はほとんどない。しかし、DREDを活用すれば、DEVICE_REMOVEDが発生した時にGPUが実行していたコマンドや、原因となったメモリアクセスについて知ることができる場合がある。
Debug Layerとは機能的に独立しているので、使用にあたりDebug Layerを有効にする必要はない。また、Debug Layerほど処理オーバーヘッドが大きくないので、常時有効にしてアプリケーションを開発することができる。
以下は、DREDの主要機能を有効にするためのコードスニペットである。DRED自体はWindowsSDKの10.0.18362.1より使用可能だが、一部重要な機能が未実装なので、WindowsSDKの10.0.19041.0以後の導入とWindows10 20H1の導入を推奨する。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Try enabling DRED even in release code
{
  ComPtr&amp;lt;ID3D12DeviceRemovedExtendedDataSettings1&amp;gt; d3dDredSettings1;
  if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&amp;amp;d3dDredSettings1)))) {
    // Turn on AutoBreadcrumbs and Page Fault reporting
    d3dDredSettings1-&amp;gt;SetAutoBreadcrumbsEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
    d3dDredSettings1-&amp;gt;SetBreadcrumbContextEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
    d3dDredSettings1-&amp;gt;SetPageFaultEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;auto-breadcrumbsとbreadcrumb-contextについて&#34;&gt;Auto BreadcrumbsとBreadcrumb Contextについて&lt;/h3&gt;
&lt;p&gt;Breadcrumbsは、パンくずのことで、所謂通ってきた道を見失わないためにパンくずを撒きながら森の中を歩いた童話にちなんでいる。Auto Breadcrumbsは、明示的にAPIを呼び出してパンを撒かなくても自動的に道標なるイベント（D3D12のAPI呼び出し）を自動的に記録するための機能である。
Auto Bredcrumbsが記録するのは、基本的には、CommandListを介して実行するコマンド群である。詳細は
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_auto_breadcrumb_op&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D3D12_AUTO_BREADCRUMB_OP enumeration&lt;/a&gt;で確認できる。
そして、DEVICE_REMOVEDが発生する直前に実行したメソッドを指し示すことで、DEVICE_REMOVEDが発生した瞬間にGPUが実行していたオペレーションが分かる仕組みになっている。&lt;/p&gt;
&lt;p&gt;しかし、Auto Bredcrumbsは実行したコマンドの種類を記録するだけなので、連続する一連のDrawなどでは、実際にどのDraｗコールが問題を引き起こしたか分からない。
Breadcrumb Contextは、Auto Breadcrumbによって記録されたオペレーションに関連する情報を記録した文字列が取得できるDRED1.2で導入された新しい機能である。
具体的には、Pixのマーカーがセットされた場合は、そのマーカーの文字列が記録される。これにより、大幅にレンダリング箇所の特定が行いやすくなった。&lt;/p&gt;
&lt;h3 id=&#34;gpu-page-faultについて&#34;&gt;GPU Page Faultについて&lt;/h3&gt;
&lt;p&gt;GPU Page Faultは、GPU上で発生する不正なメモリアクセスで、これが発生するとDEVICE_REMOVEDとなる。DREDはGPU Page Faultの情報を記録する。まずはGPU Page Faultを理解するためにGPU仮想アドレス空間について簡単に説明する。&lt;/p&gt;
&lt;h3 id=&#34;gpu仮想アドレス空間について&#34;&gt;GPU仮想アドレス空間について&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://docs.microsoft.com/ja-jp/windows-hardware/drivers/display/gpummu-model&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GpuMmu&lt;/a&gt;は、WDDM2.0(Windows Display Driver Model 2.0)でサポートされている、主にディスクリートGPU（VRAMとシステムメモリが物理的に独立しているGPU）のための
仮想アドレスモデルである。このモデルでは、プロセスごとに、GPU仮想アドレス空間がCPUの仮想アドレス空間とは別に存在して、物理アドレスに変換するためのMMUも、CPUのMMUとは別に存在している。
GPU仮想アドレス空間は、その名の通りGPU上で実行されるシェーダー等からメモリアクセスをする際に使用されるアドレス空間である。CPU側(D3D12APIやドライバー)でのリソース確保や解放によって、物理メモリが確保または破棄されて、アドレス変換テーブルが更新される。
アドレス変換テーブルが更新される際にはGPU側と同期して、GPU側と同じアドレス変換情報を共有することで、GPU上での仮想アドレスにおけるメモリアクセスを実現している。
図にある通り、物理リソースへのアクセスはアドレステーブルによる変換を介して行う。また、マップされるメモリは、VRAMでもSysMemでも構わない。GPUはどちらに配置されているリソースでも、透過的にアクセスすることができる。&lt;/p&gt;
&lt;h3 id=&#34;gpu-page-faultが起きるケース&#34;&gt;GPU Page Faultが起きるケース&lt;/h3&gt;
&lt;p&gt;GPUがPage Faultを起こすのは、アクセスが許されないページにアクセスした場合や、そもそもメモリがマッピングされていないアドレスにアクセスした場合である。主に具体的なケースとして考えられるのは、以下の通りである。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DrawcallやDispatch,Copy処理などにおいて、すでに破棄したリソースを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatch,Copy処理などにおいて、Evictしたリソースや、Non-Regidentなタイルリソースを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchで、未初期状態のDescriptorTableや、誤ったDescriptorTableを参照した場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchで、可変長のDescriptorTableで、シェーダーが実際に配置されているテーブルの範囲を逸脱してアクセスした場合。&lt;/li&gt;
&lt;li&gt;DrawcallやDispatchでRootTableに配置したUAVやSRVに対して誤った範囲でアクセスした場合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gpu-page-faultで得られる情報について&#34;&gt;GPU Page Faultで得られる情報について&lt;/h3&gt;
&lt;p&gt;DREDは、PageFaultが発生したアドレス空間に確保されているオブジェクトが有れば、そのオブジェクト名（SetNameで付けた名前）が記録される。
またAllocationTypeとして、そのアドレス空間に配置されたオブジェクトが、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/api/d3d12/ne-d3d12-d3d12_dred_allocation_type&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;どのような種類であるか&lt;/a&gt;を知ることができる。
また、そのアドレス空間を使っていて、直近で解放されたリソースがあれば、そのリソースの情報が取得できる。これは、解放されたリソースに対して、シェーダー等がアクセスした場合に発生するPage Faultを知るのに特に有用である。
しかし、GPU Page Faultはあくまで、GPU仮想アドレス変換時のエラーでしかないので、アクセスしたアドレスに有効なページがあればアクセス自体が成立するため、GPU page faultにならない。したがって、すべての不正アクセスを検出するわけではない。
たとえば、EvictしたリソースはVRAMが特に逼迫した状況になるまではリソースのページアウトが起きないため、そのままVRAM上に配置されていることが多い。結果Page Faultも起きない上に、正しくレンダリングされるため、問題に気づけない。&lt;/p&gt;
&lt;h2 id=&#34;dredで得られる情報で何が分かるか&#34;&gt;DREDで得られる情報で何が分かるか&lt;/h2&gt;
&lt;p&gt;DREDは、一見するとDEVICE_REMOVEDの発生原因についての十分な情報を提供してくれるように思えるが実際は違う。
AutoBreadCrumbは、エラーが発生していた時に実行していたコンテキストに過ぎず、実際にエラーの原因がその中にあるとは限らない。
Page Faultも同様で、Page Faultは発生した一つのアクセス例外に過ぎず、何がアクセス例外の原因となったかは分からない。たとえば、それが古いDescriptor Tableを参照したことによるのか、
破損したDescriptor Tableを参照したことによるのか、参照しているリソースを開放してしまったことによるのかは分からない。&lt;/p&gt;
&lt;p&gt;しかし、DEVICE_REMOVEDが頻発する状況下では、DREDで複数のクラッシュの情報を集約することは非常に有効である。例えば、もしも、PageFaultがいつも同じリソースとアドレスで発生するとしたら、
プログラムのロジックが安定的な間違いを犯している可能性が高いと考えられる。また、そうではなく、PageFaultがいろいろなリソースやアドレスで発生するとしたら、リソースやDescritorTableを管理しているスレッドと
GPUの実行コンテキストのレースコンディションを調べる価値があると考えられる。AutoBreadCrumbも同様で、毎回同じドローコールでDEVICE_REMOVEDが発生しているならば、
該当ドローコールのロジックや、実行分岐制御に関わる変数やリソースを調べるべきだが、異なるドローコールでランダムにDEVICE_REMOVEDが発生するならば、コマンドリストの破損の可能性が考えられる。&lt;/p&gt;
&lt;p&gt;以下はCommandList作成時には存在していたTextureがExecuteCommandListsの前に解放された場合に発生するGPU Page Faultによって発生した、DEVICE_REMOVEDの際に取得できたDREDの情報である。なお、DREDの情報はデバッグ出力ストリームに自動的に出力されないので、
自身でデータにアクセスして、何らかの形で表示する必要がある。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DXGI_ERROR_DEVICE_HUNG
The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application.
==== Auto Breadcrubs ====
QueueNameW: MyCommandQueue
QueuePtr: 0x2bad9c40330
BreadcrumbCount: 0
BreadcrumbContextsCount: 0
LastBreadcrumbValues: 0
==== Auto Breadcrubs ====
QueueNameW: MyCommandQueue
QueuePtr: 0x2bad9c40330
CommandListNameW: MyCommandList_Direct
CommandListPtr: 0x2bad9e379f0
BreadcrumbCount: 7
BreadcrumbContextsCount: 3
LastBreadcrumbValues: 5
  0|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|==Frame Start==
  1|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Set viewport and render targets
  2|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER
  3|D3D12_AUTO_BREADCRUMB_OP_CLEARRENDERTARGETVIEW
  4|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Draw - Triangle
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;Something wrong happned here...&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
  5|D3D12_AUTO_BREADCRUMB_OP_DRAWINSTANCED
  6|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER
====Page fault information ====
PageFaultGPUVA: 0x70fc000
==Existing Allocation Node Info
==Recent Freeed Allocation Node Info
ObjectNameW: DummyResource_256_bytes_UAV_buffer
AllocationType: D3D12_DRED_ALLOCATION_TYPE_RESOURCE
IUnknownPtr: 0x0x2bad9e8f9c0
D3D12app.exe has triggered a breakpoint.
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;dump-file-について&#34;&gt;Dump File について&lt;/h3&gt;
&lt;p&gt;DREDの情報はユーザーモードダンプからも抽出することができる。まずは、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/wer/collecting-user-mode-dumps&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;プロセスがCrashした際に、FullDumpが作られる様に事前に設定&lt;/a&gt;し、ダンプファイルをwindbgで読み込む。
windbg.exeはWindows10のSDKに同梱されている。通常は、&amp;ldquo;C:\Program Files (x86)\Windows Kits\10\Debuggers\x64\windbg.exe&amp;quot;に配置されるはずである。
そこで、
&lt;a href=&#34;https://github.com/Microsoft/DirectX-Debugging-Tools&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MicrosoftがGitHubで公開しているスクリプト&lt;/a&gt;を読み込むことで、DREDの情報に容易にアクセスできる。
手順は該当のリポジトリでも確認できるが非常に簡単である。プロセスがクラッシュした際のフルダンプを読み込み、以下のコマンドを実行するだけである。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.scriptload &amp;lt;&amp;lt;path to script file&amp;gt;&amp;gt;\d3ddred.js
!d3ddred
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下が、Windbg上で実際にDRED情報を表示した例である。取得できる情報は、DREDのAPIで取得できる情報と同一である。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-windbg上でdred12の情報を確認する&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/WinDbg_hu91d4c8ada4e4ee2168dbdfb94cdee135_75072_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;Windbg上で、DRED1.2の情報を確認する&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/WinDbg_hu91d4c8ada4e4ee2168dbdfb94cdee135_75072_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1011&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Windbg上で、DRED1.2の情報を確認する
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;最後に&#34;&gt;最後に&lt;/h3&gt;
&lt;p&gt;これら全てを駆使しても簡単に判明しないDEVICE_REMOVEDも存在すると思うが、DEVICE_REMOVEDを手さぐり的に解決する時代は終わりを迎えようとしていると言えると思う。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HLSLのWave Intrinsicsについて</title>
      <link>https://shikihuiku.github.io/post/wave_intrinsics1/</link>
      <pubDate>Sun, 16 Aug 2020 20:00:32 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/wave_intrinsics1/</guid>
      <description>&lt;h2 id=&#34;hlslのwave-intrinsicsについて&#34;&gt;HLSLのWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsは、HLSLのShader Model6.0から導入された新しい組み込み関数群です。
従来の他のHLSL組み込み関数が、単一スレッド内での変数のみを動作の対象するのに対して、
Wave Intrinsicsは、Waveと呼ばれる複数のスレッド間でのデータの交換や演算を行うための組み込み関数となります。
従来は、Compute Shaderなどで、他のスレッドの変数（演算用のレジスタ）が保持する値を参照するには、groupsharedで宣言された変数やUAVなどで宣言されたバッファーに情報を一旦ストアする必要があったうえ、スレッド間の同期命令が必要でした。
Wave Intrinsicsは、Wave内のスレッド間に限定されますが、他のスレッドの変数（演算用のレジスタ）の値を参照したり演算することが出来ます。
これにより、スレッド間のレジスタ空間の共有が可能になり、複数のスレッドで協調的に動作するシェーダーコードが、より記述しやすくなりました。
また、Wave内は命令実行のタイミングが同じであることが（論理上において）保証されていることから、スレッド間同期命令を必要としないのも大きな利点です。
一点注意が必要なのは、Wave IntrinsicsはShader Model 6.0以上に存在する組み込み関数ですが、実際に使用できるかどうかは、&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;で、&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;を調べる必要があります。&lt;/p&gt;
&lt;h2 id=&#34;用語&#34;&gt;用語&lt;/h2&gt;
&lt;p&gt;ここではWave Intrinsicsに関連する用語を説明します。&lt;/p&gt;
&lt;h4 id=&#34;wave&#34;&gt;Wave&lt;/h4&gt;
&lt;p&gt;NVIDIAの用語で&amp;quot;warp&amp;quot;とよばれ、AMDの用語では、&amp;ldquo;wavefront&amp;quot;と呼ばれてきたものです。命令発行が、同時に行われれるスレッドのグループのことです。&lt;/p&gt;
&lt;h4 id=&#34;lane&#34;&gt;Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドを指します。&lt;/p&gt;
&lt;p&gt;以下の図は、一つのWaveの中に32Lane分のスレッドが存在する場合の図になります。この図式を使って様々なWave Intrinsicsについて説明していきたいと思います。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-waveとlane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wave_hu550fc97d8560033e52f050ac0d549368_13159_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;WaveとLane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wave_hu550fc97d8560033e52f050ac0d549368_13159_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;441&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    WaveとLane
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;inactive-lane&#34;&gt;Inactive Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドのうち、命令を実行しないスレッドを指します。&lt;/p&gt;
&lt;h4 id=&#34;active-lane&#34;&gt;Active Lane&lt;/h4&gt;
&lt;p&gt;Waveを構成する個々のスレッドのうち、命令を実行するスレッドを指します。&lt;/p&gt;
&lt;p&gt;以下の図は、左側のシェーダーコードの実行に伴って変化する、Active LaneとInactive Laneの変化の例を表した図です。右側の3 Laneは、スレッド起動数等の初期条件によるInactive Laneです。
Pixel ShaderやCompute Shaderで必要とされるスレッド数が、Waveの倍数でなかった場合は、Inactive Laneの存在するWaveが起動されます。このようなInactive Laneは、状態が動的に変更されることは無く、終始Inactive Laneのままです。
3行目のIf()による分岐の条件を満たさなかったLaneは、If()ステートで囲まれたコードブロックが終了するまでInactive Laneとなります。Wave内では命令実行は暗黙的に同期する決まりになっているので、Inactive Laneはその間なにも実行せず、他のLaneが該当コードブロックの実行を完了するまで待ちます。
図にはありませんが、If()ステートのコードブロックの実行が終了すれば、条件分岐によってInactive Laneとなったスレッドは、再びActive Laneへと復帰します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-active-laneとinactive-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/active_inactive_hu6f4caf7822c3e8aa1ace8fd32f3899a3_110070_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Active LaneとInactive Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/active_inactive_hu6f4caf7822c3e8aa1ace8fd32f3899a3_110070_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;965&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Active LaneとInactive Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;quad&#34;&gt;Quad&lt;/h4&gt;
&lt;p&gt;先頭から連続する4Lane分づつのスレッドのグループを指します。特にPixel Shaderでは、RenderTargetにおける2x2ピクセルブロックが一つのQuadにアサインされます。
Pixel Shaderにおけるddx/ddyなどのGradient命令や、テクスチャーのLoDの計算は、Quad内の変数の差分によって実現されており、Gradientの計算のみに寄与してPixelを塗らないLane（スレッド）をHelper Laneと呼びます。&lt;/p&gt;
&lt;p&gt;以下の図は、とあるプリミティブをレンダリングする際の、QuadとHelper LaneのRenderTarget上での表現とWaveとしての表現の対応図です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-quadとhelper-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;QuadとHelper Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    QuadとHelper Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;waveのサイズについて&#34;&gt;Waveのサイズについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsを使う上で、Waveのサイズというは非常に重要なファクターで、これを理解すること無しに、効率的な処理をデザインすることは難しいと思います。
NVIDIAのWarpは、伝統的に32 Lane/Waveです。対して、AMDのGCNアーキテクチャは64 Lane/Waveで動作しています。
同じくAMDのRDNAアーキテクチャは、Wave32とWave64の二つの動作モードを持ち、それぞれが、32, 64 Lane/Waveで動作しています。
どちらのモードでシェーダーが実行されるかは、ドライバーが決定するようなので、シェーダーは両モードで正しく動く必要があります。結局のところ、32 Lane/Wave、64 Lane/Waveの両方をサポートすることができれば、NVIDIA, AMDの両GPUに対応したアプリケーションとなるはずです。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-32-lanewaveと64-lanewave&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/32_64_lane_hu55f4de2178e3ca0a112fe7c34fbabb49_24264_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;32 Lane/Waveと64 Lane/Wave&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/32_64_lane_hu55f4de2178e3ca0a112fe7c34fbabb49_24264_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;630&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    32 Lane/Waveと64 Lane/Wave
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;の&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;では、Wave Intrinsicsの使用の可否についてとともに、使用される可能性のあるWaveのサイズの上限値と下限値が返されます。
したがって先のRDNAの様に、単一のアーキテクチャでも、Waveのサイズは可変であると考える必要があるのかもしれません。しかし、WaveのサイズのAPI仕様としての上限値と下限値である 4 と 128 はあまりにもかけ離れているため、Waveのサイズに依存するコードを記述する際に、すべてのWaveのサイズをサポートすることは非現実的です。また、実際には使用されないWaveのサイズのためにコードを書くのも無駄だと思います。したがって、現実的な実装方法としては&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;でWaveのサイズの上限値と下限値をチェックし、32と64の範囲ならば、Wave Intrinsicsを使ったシェーダーコードを使用し、そうでない場合はWave Intrinsicsを使用していないフォールバックのシェーダーコードを実行するか、エラーを出力して動作を終了するべきだと思います。&lt;/p&gt;
&lt;p&gt;Waveのサイズは、&lt;code&gt;WaveGetLaneCount&lt;/code&gt;というWave Intrinsicsを使って取得できます。しかし、これは裏を返せば、&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;のWaveの上限値と下限値に幅がある場合は、HLSLのシェーダーコードを実行するまで、Waveのサイズが分からないという事になります。（これはAPIのデザインの問題だと思います。）&lt;/p&gt;
&lt;h2 id=&#34;waveのサイズとthread-groupのサイズについて&#34;&gt;WaveのサイズとThread Groupのサイズについて&lt;/h2&gt;
&lt;p&gt;Wave Intrinsicsは、あくまでWaveのサイズを基準とした動作になっていて、Compute Shaderのnumthreadsの大きさは、Waveのサイズとは関係ありません。ただし、Wave Intrinsicsを使う場合は、numthreadsの大きさはWaveのサイズを意識したものが良いと思います。
WaveのThread Group内でのマッピングは、Row Oriented　(X軸優先）です。（ただし、これを明記しているドキュメントが見当たらなかったので注意が必要です。）numthreadsの大きさが、Waveのサイズの倍数でなかった場合は、シェーダーが実行される前からInactive Laneが存在するWaveが起動されます。この場合、Waveのサイズ分のスレッドがすべて動作していることを前提として記述されたシェーダーは、動作が破綻するので注意が必要です。
現状では、&lt;code&gt;ID3D12Device::CheckFeatureSupport()&lt;/code&gt;の&lt;code&gt;D3D12_FEATURE_D3D12_OPTIONS1&lt;/code&gt;の返すWaveのサイズの上限値の倍数をnumthreadsの大きさとすることで、このような事態を回避する事ができると思います。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-numthreadとwave&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/numthread_wave_hu87309c82afe6bdb07430f9b22f94f645_45303_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;numthreadとWave&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/numthread_wave_hu87309c82afe6bdb07430f9b22f94f645_45303_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    numthreadとWave
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;pixelshaderとwave-intrinsicsについて&#34;&gt;PixelShaderとWave Intrinsicsについて&lt;/h3&gt;
&lt;p&gt;（これも明記しているドキュメントが見当たらなかったので注意してください）&lt;br&gt;
Pixel Shaderでは、すべてのWave Intrinsicsの使用が許されています。しかし、Pixel Shaderにおける描画ピクセルとWaveやLaneの対応は、描画されるプリミティブの位置と、GPUとドライバー、そしてPixel Shaderのソースコードによって決まると考えられます。
シンプルな例では、ピクセルシェーダーのスレッドは描画されるプリミティブのピクセルと一対一の関係で起動されると思います。ただし、ピクセルシェーダー内で、Gradinet命令（ddx/ddy）を使用したり、テクスチャーのサンプリングにおいて、LoDを明示的に指定しなかった場合は、スレッド間の値（テクスチャサンプリングにおいてはUV値）の差分を計算する必要があるため、起動されるスレッドは2x2ピクセル単位となります。そして、プリミティブとして描画されるピクセルを担当しているスレッドのみがRenderTargetへの出力を行います。残りのスレッドは、Helper Laneとなり、スレッドとして動作しますがRenderTargetへの出力を行いません。
プリミティブの描画においては、必要なスレッド数は必ずしもWaveのサイズの倍数とならないので、シェーダー内で条件分岐を行っていない状態でも、Inactive Laneが存在しているWaveが起動される可能性があります。また、複数のプリミティブが同一のWaveにパッキングされる可能性もあります。Pixel Shader内でWave Intrinsicsを使う場合は、これらの点について考慮する必要があると思います。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-quadとhelper-lane&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;QuadとHelper Lane&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/quad_helper_hu842ae506986670f32043d947253c500c_93104_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;755&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    QuadとHelper Lane
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;shader-model-60のwave-intrinsicsについて&#34;&gt;Shader Model 6.0のWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Shader Model 6.0のWave Intrinsicsは以下のカテゴリに分類することができます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wave Query&lt;br&gt;
WaveやLaneの状態取得&lt;/li&gt;
&lt;li&gt;Wave Vote&lt;br&gt;
Wave内でのbooleanステート確認&lt;/li&gt;
&lt;li&gt;Wave Broadcast&lt;br&gt;
Wave内で特定のLaneの変数値の取得&lt;/li&gt;
&lt;li&gt;Wave Reduction&lt;br&gt;
Wave内での変数の演算&lt;/li&gt;
&lt;li&gt;Wave Scan and Prefix&lt;br&gt;
Wave内での変数の演算(自身より小さいLane Indexに限る)&lt;/li&gt;
&lt;li&gt;Quad-wide Shuffle operations&lt;br&gt;
Quadを動作対象とした、変数値の取得&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wave-query&#34;&gt;Wave Query&lt;/h3&gt;
&lt;p&gt;WaveのLane数と、Lane Indexを調べるためのIntrinsicsです。&lt;br&gt;
加えて、Wave内で自身が先頭のActive Laneかどうかを返す、&lt;code&gt;WaveIsFirstLane&lt;/code&gt;が含まれます。&lt;/p&gt;
&lt;h4 id=&#34;wavegetlanecount&#34;&gt;&lt;code&gt;WaveGetLaneCount&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;WaveのLaneの数を返します。全てのLaneで同じ値を受け取ります。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetcount_hu017ff3431e51e38ea7691ac81e49e3c2_14763_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetcount_hu017ff3431e51e38ea7691ac81e49e3c2_14763_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;382&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;wavegetlaneindex&#34;&gt;&lt;code&gt;WaveGetLaneIndex&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Wave内での該当LaneのIndexを返します。個々のLaneで異なる値を受け取ります。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetlaneindex_hue63fa13725fdb66d601d5d878c1d0ae3_26912_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavegetlaneindex_hue63fa13725fdb66d601d5d878c1d0ae3_26912_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;520&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;waveisfirstlane&#34;&gt;&lt;code&gt;WaveIsFirstLane&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;bool値を返します。ActiveLaneの中で最小のLane IndexのLaneのみ&lt;code&gt;true&lt;/code&gt;が返されます。残りのLaneは&lt;code&gt;false&lt;/code&gt;が返されます。






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveisfirstlane_huafbbbf3a8be6235948052771404a6e1b_51220_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveisfirstlane_huafbbbf3a8be6235948052771404a6e1b_51220_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;571&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;wave-vote&#34;&gt;Wave Vote&lt;/h3&gt;
&lt;p&gt;Wave内の他のActive Laneのboolのステータスを確認するためのIntrinsicsです。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveanytrue&#34;&gt;&lt;code&gt;WaveActiveAnyTrue&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。そして、いずれかのActive Laneが&lt;code&gt;true&lt;/code&gt;を渡せば、全てのActive Laneに&lt;code&gt;true&lt;/code&gt;が返されます。そうでない場合は、全てのActive Laneに&lt;code&gt;false&lt;/code&gt;が返されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveanytrue_hue78662cc8f443afcaa688bcef7c43ea2_59746_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveanytrue_hue78662cc8f443afcaa688bcef7c43ea2_59746_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;697&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivealltrue&#34;&gt;&lt;code&gt;WaveActiveAllTrue&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。全てのActive Laneが&lt;code&gt;true&lt;/code&gt;を渡せば、全てのActive Laneに&lt;code&gt;true&lt;/code&gt;が返されます。そうでない場合は、全てのActive Laneに&lt;code&gt;false&lt;/code&gt;が返されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivealltrue_hu3ee6171c79406bc5f05b75ba065dfffc_59680_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivealltrue_hu3ee6171c79406bc5f05b75ba065dfffc_59680_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;708&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactiveballot&#34;&gt;&lt;code&gt;WaveActiveBallot&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にbool値を指定します。戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneが渡したbool値をビットマスクとして返します。Inacive Laneは暗黙的に0が設定されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveballot_hu441b454dd67f6c112671144c7a7d1adc_61292_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveballot_hu441b454dd67f6c112671144c7a7d1adc_61292_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;769&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-broadcast&#34;&gt;Wave Broadcast&lt;/h3&gt;
&lt;p&gt;Wave内で、特定のLaneの変数の値を、すべてのActive Laneで取得するためのIntrinsicsです。&lt;/p&gt;
&lt;h4 id=&#34;wavereadlaneat&#34;&gt;&lt;code&gt;WaveReadLaneAt&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数とLane Indexを指定します。Lane Indexで指定されたLaneの、引数で指定された変数の値を、全てのActive Laneに返します。引数で指定した変数の型と同じ型が返されます。&lt;br&gt;
他にも、引数に指定した変数の型と同じ変数型を返すタイプのWave Intrinsicsがありますが、これらはベクトル型を含め、組み込み型の整数型と浮動小数点型の殆どがサポートされています。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlaneat_hu2ce763e09dbd4548c9ca84ea0f16840b_96939_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlaneat_hu2ce763e09dbd4548c9ca84ea0f16840b_96939_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1120&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavereadlanefirst&#34;&gt;&lt;code&gt;WaveReadLaneFirst&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。Active Laneの中で、最小のLane IndexのLaneの、引数で指定された変数の値を、すべてのActive Laneに返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlanefirst_hu6d9eb6b7bdb5af52098e10c274550961_77137_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavereadlanefirst_hu6d9eb6b7bdb5af52098e10c274550961_77137_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;930&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-reduction&#34;&gt;Wave Reduction&lt;/h3&gt;
&lt;p&gt;Wave内でのActive Laneの変数の値を用いて演算するためのIntrinsicsです。一つの演算結果がすべてのActive Laneに返されます。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveallequal&#34;&gt;&lt;code&gt;WaveActiveAllEqual&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値が等しい場合のみTrueを返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveallequal_hub0d81e969a1494ea62407696e116d131_41919_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveallequal_hub0d81e969a1494ea62407696e116d131_41919_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;886&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivebitand&#34;&gt;&lt;code&gt;WaveActiveBitAnd&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise AND(論理積)を演算した結果を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivebitor&#34;&gt;&lt;code&gt;WaveActiveBitOr&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise OR(論理和)を演算した結果を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivebitxor&#34;&gt;&lt;code&gt;WaveActiveBitXor&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise XOR(排他的論理和)を演算した結果を返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivebitop_hu8c00d785c0bd006675ed4159e86102d6_54165_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivebitop_hu8c00d785c0bd006675ed4159e86102d6_54165_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1045&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivecountbits&#34;&gt;&lt;code&gt;WaveActiveCountBits&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、boolを指定します。引数に&lt;code&gt;true&lt;/code&gt;を指定したLaneの数を、すべてのActive Laneに返します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivecountbits_hu45ba85d97c3b69abe8f3e4ff68f45109_54517_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactivecountbits_hu45ba85d97c3b69abe8f3e4ff68f45109_54517_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;756&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;waveactivemax&#34;&gt;&lt;code&gt;WaveActiveMax&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最大値を、全てのActive Laneに返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactivemin&#34;&gt;&lt;code&gt;WaveActiveMin&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最小値を、全てのActive Laneに返します。&lt;/p&gt;
&lt;h4 id=&#34;waveactiveproduct&#34;&gt;&lt;code&gt;WaveActiveProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数をの値を乗算した結果を、全てのActive Laneに返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;/p&gt;
&lt;h4 id=&#34;waveactivesum&#34;&gt;&lt;code&gt;WaveActiveSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値を加算した結果を、全てのActive Laneに返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveminmaxop_huc07e0fb502a11709116c047263e24c8f_56203_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveactiveminmaxop_huc07e0fb502a11709116c047263e24c8f_56203_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1097&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;wave-scan-and-prefix&#34;&gt;Wave Scan and Prefix&lt;/h3&gt;
&lt;p&gt;Wave Reduction系に似ていますが、演算の対象が自身のLane Index未満のActive Laneのみです。自身のLaneは演算の対象に含みません。
演算の結果は、基本的にはLaneごとに異なる値が返されることになります。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixcountbits&#34;&gt;&lt;code&gt;WavePrefixCountBits&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数にboolを指定します。自身のLane Index未満のActive Laneで、引数に&lt;code&gt;true&lt;/code&gt;を指定した個数を返します。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixsum&#34;&gt;&lt;code&gt;WavePrefixSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を加算した結果を返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;code&gt;[precise]&lt;/code&gt;フラグは無視されます。&lt;/p&gt;
&lt;h4 id=&#34;waveprefixproduct&#34;&gt;&lt;code&gt;WavePrefixProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を乗算した結果を返します。
演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。&lt;code&gt;[precise]&lt;/code&gt;フラグは無視されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveprefixop_hu36665e6520788b3009382913080bbf2c_71179_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/waveprefixop_hu36665e6520788b3009382913080bbf2c_71179_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;742&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h3 id=&#34;quad-wide-shuffle-operations&#34;&gt;Quad-wide Shuffle operations&lt;/h3&gt;
&lt;p&gt;Pixel Shaderでのみ使用可能なWave Intrinsicsです。
(これについては、2020/08現在ドキュメントの表記と実装に食い違いがあります。ドキュメントにはCompute Shaderでも使用可能と表記されており、その場合、Lane Indexの0より4 Laneごとに区切ったLaneがQuadとして扱われるとされています。
しかし実際には、Quad系を使用したCompute Shaderのコンパイル時に&lt;code&gt;opcode &#39;QuadReadAcross&#39; should only be used in &#39;Pixel Shader&#39;&lt;/code&gt;というメッセージが出力されます。そして、シェーダーの生成にも失敗します。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadlaneat&#34;&gt;&lt;code&gt;QuadReadLaneAt&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、Quad内のローカルのLane Indexと、読み取り対象となる変数を指定します。Quad内で同じ値が返されます。
読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。
Pixel ShaderにおけるQuad内のローカルのLane Indexは、下図に示した通りRow Orientedとなっています。&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossdiagonal&#34;&gt;&lt;code&gt;QuadReadAcrossDiagonal&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに対角の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossx&#34;&gt;&lt;code&gt;QuadReadAcrossX&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに水平の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:1の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;
&lt;h4 id=&#34;quadreadacrossy&#34;&gt;&lt;code&gt;QuadReadAcrossY&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。Quad内で互いに垂直の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。)
(APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavequadop_hudda5976e667c4f4ea513984d01905e77_110927_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavequadop_hudda5976e667c4f4ea513984d01905e77_110927_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;916&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h2 id=&#34;shader-model-65のwave-intrinsicsについて&#34;&gt;Shader Model 6.5のWave Intrinsicsについて&lt;/h2&gt;
&lt;p&gt;Model 6.5で、いくつかの新しいWaveIntrinsicsが導入されています。&lt;/p&gt;
&lt;h4 id=&#34;wavematch&#34;&gt;&lt;code&gt;WaveMatch&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。&lt;br&gt;
戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneの引数で指定された変数の値が、自身のLaneの変数の値と等しい場合に、ビットがセットされます。Inacive Laneは暗黙的に0が設定されます。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavematch_hu0c1f58aae92c4965302c5d4274ad6622_58909_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavematch_hu0c1f58aae92c4965302c5d4274ad6622_58909_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;707&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavemultiprefixsum&#34;&gt;&lt;code&gt;WaveMultiPrefixSum&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなる uint4 を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveSum&lt;/code&gt;と動作は似ていますが、加算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。
ビットマスクは、Laneごとに設定を変更出来ますが、一つのLaneは1種類のビットマスクにしか所属する事ができません。
つまり、ビットマスクによって、Laneをパーティショニングしてサブセット化する事が出来ますが、各々のLaneが完全に自由にビットマスクを指定できるわけではありません。一つのLaneが複数の種類のビットマスクに所属した場合の動作は未定義です。&lt;br&gt;
Waveのサイズを超えるBitやInactive Laneのビットは無視されます。(ビットがゼロとして扱います。)
このビットマスクの仕様は他のWaveMultiPrefix系と共通です。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavemultiprefixsum_hue9d268744f4c6ffd484f30d798dfb5fc_135719_2000x2000_fit_lanczos_3.png&#34; &gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/wave_intrinsics1/wavemultiprefixsum_hue9d268744f4c6ffd484f30d798dfb5fc_135719_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;1182&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;h4 id=&#34;wavemultiprefixproduct&#34;&gt;&lt;code&gt;WaveMultiPrefixProduct&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveProduct&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixcountbit&#34;&gt;&lt;code&gt;WaveMultiPrefixCountBit&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、bool値を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveCountBit&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitand&#34;&gt;&lt;code&gt;WaveMultiPrefixBitAnd&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitAnd&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitor&#34;&gt;&lt;code&gt;WaveMultiPrefixBitOr&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitOr&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h4 id=&#34;wavemultiprefixbitxor&#34;&gt;&lt;code&gt;WaveMultiPrefixBitXor&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。&lt;br&gt;
&lt;code&gt;WaveActiveBitXor&lt;/code&gt;と動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。&lt;/p&gt;
&lt;h2 id=&#34;終わりに&#34;&gt;終わりに&lt;/h2&gt;
&lt;p&gt;今回は、Wawve Intrinsicsの動作を理解するための基本的な内容となっているので、実際の使用ケースについては言及しませんでした。
次回は、もう少し実際の利用ケースについて触れたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugo&#43;Academicでブログを構築</title>
      <link>https://shikihuiku.github.io/post/hello_hugo_and_academic/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://shikihuiku.github.io/post/hello_hugo_and_academic/</guid>
      <description>&lt;h3 id=&#34;動機とか&#34;&gt;動機とか&lt;/h3&gt;
&lt;p&gt;タイトルの画像は、今まで運用してきたWordpress上のサイトのスクリーンショットです。記念に撮ってきました。&lt;br&gt;
別にWordpressがいやになったという訳ではないのですが、Github pagesに移行したほうが制約も少なく扱いやすい気がしたので引っ越しすることにしました。Wordpressに書いた記事は、簡単に移行するのは難しそうなので、そのままにしておきます。&lt;/p&gt;
&lt;h3 id=&#34;hugoacademic&#34;&gt;Hugo＋Academic&lt;/h3&gt;
&lt;p&gt;別に十分な検討をしてこの組み合わせに至ったわけでは無く、静的サイト生成ツール＋なんか都合の良いTheme程度の認識で選択しました。今後変えるかもしれません。
ただ、コンテンツは多少特殊な要素があったとしても、基本的にMarkdownで記述できるので、今後もしサイトを移行しようと思っても、記事の移行をあきらめたくなるような事はないのではないでしょうか。&lt;/p&gt;
&lt;h3 id=&#34;導入手順&#34;&gt;導入手順&lt;/h3&gt;
&lt;p&gt;せかっくなので自分なりの導入手順を記しておきます。環境はWindows10を使用しています。Hugoは導入済です。&lt;/p&gt;
&lt;h4 id=&#34;academicの導入&#34;&gt;Academicの導入&lt;/h4&gt;
&lt;p&gt;まず、Hugoのテーマとして、Academicを導入しようとして、以下の様にファイルを配置しましたが、上手くいきませんでした。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git submodule add https://github.com/gcushen/hugo-academic.git themes/academic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academicのドキュメント&lt;/a&gt;を参照すると、Hugoの新規サイトの状態に加えて、いろいろなファイルが正しい位置に配置されている必要があるようで、
&lt;a href=&#34;https://github.com/sourcethemes/academic-kickstart.git&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;academic-kickstart.git&lt;/a&gt;をクローンすることがおすすめのようです。
初めはプライベートリポジトリとして扱いたいですし、リポジトリの名前も変えたいので、cloneしてmirrorします。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone --bare https://github.com/sourcethemes/academic-kickstart.git
cd academic-kickstart.git
git push --mirror https://github.com/shikihuiku/blog.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;早速ローカルで初期状態を確認しようと思ったら、ビルドエラーが出ました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; hugo server
Building sites … ERROR 2020/07/25 17:30:35 render of &amp;quot;term&amp;quot; failed: execute of template failed: template: authors/list.html:5:3: executing &amp;quot;authors/list.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;section&amp;quot; failed: execute of template failed: template: section/publication.html:5:3: executing &amp;quot;section/publication.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;home&amp;quot; failed: execute of template failed: template: index.html:5:3: executing &amp;quot;index.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 render of &amp;quot;taxonomy&amp;quot; failed: execute of template failed: template: authors/terms.html:5:3: executing &amp;quot;authors/terms.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
ERROR 2020/07/25 17:30:35 failed to render pages: render of &amp;quot;section&amp;quot; failed: execute of template failed: template: section/talk.html:5:3: executing &amp;quot;section/talk.html&amp;quot; at &amp;lt;partial &amp;quot;site_head&amp;quot; .&amp;gt;: error calling partial: &amp;quot;T:\GitHub\hugotest\blog\themes\academic\layouts\partials\site_head.html:131:56&amp;quot;: execute of template failed: template: partials/site_head.html:131:56: executing &amp;quot;partials/site_head.html&amp;quot; at &amp;lt;resources.Concat&amp;gt;: error calling Concat: resources in Concat must be of the same Media Type, got &amp;quot;text/x-scss&amp;quot; and &amp;quot;text/css&amp;quot;
Built in 84 ms
Error: Error building site: TOCSS: failed to transform &amp;quot;main_parsed.scss&amp;quot; (text/x-scss): resource &amp;quot;scss/scss/main.scss_76ac6956597c32fec7ddf60d408db3ab&amp;quot; not found in file cache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;調べてみると、Academicには、hugo_extendedが必要だという事が分かりましたので、
&lt;a href=&#34;https://github.com/gohugoio/hugo/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo_extendedのビルド済バイナリ&lt;/a&gt;をDLします。
再びローカルサーバーを立ち上げると、今回は上手くビルドできました。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hugo server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ローカルホストのポート1313にアクセスすると、おしゃれなサイトが表示されました。BiographyやProjectsやPublicationsなど、かなりハイスペック人材向けのテンプレートで尻込みしますが、どんどん削っていくことにします。&lt;/p&gt;
&lt;h4 id=&#34;academicのカスタマイズ&#34;&gt;Academicのカスタマイズ&lt;/h4&gt;
&lt;p&gt;ここで先人の知恵をお借りします&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hugo + Academic テーマを使ったブログの作り方

&lt;a href=&#34;https://qiita.com/harumaxy/items/58e7e4273c61e7e260b3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://qiita.com/harumaxy/items/58e7e4273c61e7e260b3&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;/config/_default/フォルダに格納されている以下のtomlファイルを編集していきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;config.toml&lt;/li&gt;
&lt;li&gt;language.toml&lt;/li&gt;
&lt;li&gt;menus.toml&lt;/li&gt;
&lt;li&gt;params.toml&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;その他諸々の変更を行って、シンプルにBlogのポストができるページにしました。言語設定はenのまま使用する事にします。&lt;/p&gt;
&lt;h4 id=&#34;フォントの設定&#34;&gt;フォントの設定&lt;/h4&gt;
&lt;p&gt;デフォルトでは、GoogleのWebフォントがいろいろ指定されていますが、フォントの設定はシンプルな方が良いと思っています。
フォントのプリセットにNativeという設定があり、こちらを使うとrootのfont-familyの設定を、殆どの要素で使うようになるようです。config/_default/params.tomlでこれを指定します。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;font=&amp;ldquo;Native&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;rootにある、フォントの設定はとりあえず変更せずに使ってみます。&lt;/p&gt;
&lt;h4 id=&#34;customscssの設定&#34;&gt;custom.scssの設定&lt;/h4&gt;
&lt;p&gt;デフォルトではブラウザの横幅に対してページの表示領域が酷く狭いです。&lt;br&gt;
blog/assets/scss/custom.scssというファイルを配置することで、自身で記述したcssをページに読み込ませる事が出来るようです。生成されたHTMLの要素のクラス名を確認して適当に設定しました。なんだか横幅を変えるだけで泥臭い作業になりました。もっと簡単にスタイルを変更する方法があるかもしれません。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/*width for top page*/
.container {
    max-width: 90%;
}
/*width for posts.*/
.article-container{
    max-width:90%
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;また、見出しのフォントのWeightが一定では無いので変更します。ついでにマージンも変更します。
この辺りは素人なので、あまり参考になりませんが。
しかし、CSSを書いて変更できると結局楽だなってなって思ってきました&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;h1, h2, h3, h4, h5, h6 {
    margin-top: 1.7rem;
    margin-bottom: 0.3rem;
    font-weight: 700;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;アイコンの設定&#34;&gt;アイコンの設定&lt;/h4&gt;
&lt;p&gt;それから、Webサイトのアイコン、所謂ファビコンがデフォルトの設定では、Academicのアイコンになっているので変更します。&lt;br&gt;
assets/images/フォルダに、解像度512x512のicon.pngを配置します。&lt;/p&gt;
&lt;h4 id=&#34;github-pagesの設定&#34;&gt;Github Pagesの設定&lt;/h4&gt;
&lt;p&gt;最後に、実際にビルドされたページをGithub Pagesでホスティングする方法ですが、一番簡単な方法はHugoの出力先をdocsフォルダにして、それをそのままリポジトリにPushして、GithubPagesで公開する方法だと思います。
Hugoはデフォルトではpublicフォルダにファイルが生成されるので、これを変更します。&lt;/p&gt;
&lt;p&gt;config/_default/config.tomlに以下の様に設定することで、docsフォルダにサイトが生成されるようになります。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;publishdir= &amp;quot;docs&amp;quot;  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;あとは、baseurlを設定しサイトを生成してエラーがでなければOKです。リポジトリにPushして、github pagesの設定をすれば公開されます。&lt;/p&gt;
&lt;h4 id=&#34;github-pagesの設定---やっぱりprivateリポジトリで&#34;&gt;Github Pagesの設定 - やっぱりPrivateリポジトリで&lt;/h4&gt;
&lt;p&gt;構築履歴が閲覧可能な状態なのは別に構わないですし、大抵の場合はDraft記事が閲覧可能な状態でも構わないのですが、一部のCEDECセッションの補間資料とかのDraftは会期以前に公開状態になるのはまずいので、
publishしたべージのコンテンツのみを公開状態にする必要があります。結局Hugoのpublishdirのディレクトリ以下を別のリポジトリにして、こちらだけPublicに設定して、ビルド環境はPrivateリポジトリにすることにしました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>フォートナイトの入力遅延を観測してみた</title>
      <link>https://shikihuiku.github.io/post/check_input_latency_of_fortnite/</link>
      <pubDate>Tue, 16 Jun 2020 01:33:02 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/check_input_latency_of_fortnite/</guid>
      <description>&lt;pre&gt;&lt;code&gt;この記事は、旧サイトからテスト用に移植しました。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;入力遅延の問題はゲーム開発において悩ましい問題の一つです。特にPCでは、他のプロセスが勝手な都合で動作しますし、リソースの競合も発生します。また、PC本体のCPU/GPUパフォーマンスの違いも大きいです。ここでは一般的なデスクトップPC上で、フォートナイトの描画がどのように実行されているかをソフトウェアの見地から、GPUViewを用いて観測してみます。ここで言う入力遅延は、Windows上のゲームのプロセスがキーやマウスのステートを取得すると思われるタイミングから、描画された画面が、ディスプレイへの出力対象になるまでを指します。実際には、マウスやキーボードのハードウェアとドライバにも遅延がありますし、ディスプレイにも実際に輝点として可視化されるまでに遅延がありますが、これらは今回は考慮しません。またゲームのプロセスが正確にいつ入力デバイスの情報を取得しているかは考慮しません。あるフレームのCPU処理の開始を入力取得時間として考えます。&lt;br&gt;
ちなみに今回使用したデスクトップPCは、Core-i7 7700KとGeForce RTX2080Tiが搭載されています。モニタは一般的な60Hzの4Kディスプレイです。&lt;br&gt;
テストに使ったシーンは、クリエイティブの島です。描画としては極めて軽い状態がテスト対象です。&lt;/p&gt;
&lt;p&gt;UE4の開発者の方は、すでにご存じかと思いますが、以下の資料に入力遅延に関する詳しい解説がご覧いただけると思います。&lt;/p&gt;
&lt;p align=&#34;center&#34; style=&#34;text-align:center&#34;&gt;
&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/k13Vz8lkoluqKW&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt;&lt;br&gt;
&lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/EpicGamesJapan/ue4input-latency&#34; title=&#34;UE4のスレッドの流れと Input Latency改善の仕組み&#34; target=&#34;_blank&#34;&gt;UE4のスレッドの流れと Input Latency改善の仕組み&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;https://www.slideshare.net/EpicGamesJapan&#34; target=&#34;_blank&#34;&gt;エピック・ゲームズ・ジャパン Epic Games Japan&lt;/a&gt;&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;今回は、フォートナイトをプレイする上でどのような設定が一番自分にとって好ましいかを調べる過程で分かったことを説明していきます。フォートナイトの描画設定で、入力遅延に関係のある設定は、フレームレートの上限値、VSync、それから、マルチスレッドレンダリングです。描画APIはD3D11と12に対応していますが、D3D12にすることによる利点があまり感じられなかったため、今回はD3D11のみをテストしています。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-off-フレームレート上限-60&#34;&gt;VSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 60&lt;/h2&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mtoff_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_60_hu33bc11a1f895fdcc3ac8673383111945_278989_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mtoff_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_60_hu33bc11a1f895fdcc3ac8673383111945_278989_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1435&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mtoff_60
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;おなじみのGPUViewのログです。詳しく見たい方はクリックして拡大してください。まずは、スレッドのアクティビティを理解するために一番簡単な例を示します。VSyncがOffなので、青い縦線で示されたVSyncのタイミングとは全く関係なく描画されています。描画スレッドが、D3D11の描画APIを呼び出して、Present()を呼び出し、GPUが描画を完了するのとほぼ同時にフロントバッファへのFlipが行われ、ディスプレイへの表示対象になります。ドライバのスレッドに描画命令を発行しているスレッドが、UE4のRHIスレッドと思われますが、マルチスレッドレンダリングをOffにしているので、Renderのスレッドが、直接RHIを呼び出しているのではないかと思われます。それに先立ち動作しているスレッドがゲームのメインスレッドと思われます。ゲームのメインスレッドは、Render/RHIスレッドに渡す描画情報を構築するタイミングと思われるところで、フレームレートのペーシングを行っていると思われます。計測された入力遅延は、12.8msですが、CPUもGPUもアイドル時間が長いので、処理クロックを落としていると思われます。実際の場合も何も小細工しなければ、ユーザーの知らないところでクロックが下がるので、今回はこの設定の入力遅延は12ms前後と考えます。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-on-フレームレート上限-60&#34;&gt;VSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 60&lt;/h2&gt;
&lt;p&gt;次は、先ほどの設定から、マルチスレッドレンダリングを有効にしてみます。他の設定は同じです。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mton_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_60_hu1169490fbcbadeadc14156a6fb3266a4_276171_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mton_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_60_hu1169490fbcbadeadc14156a6fb3266a4_276171_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1640&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mton_60
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;見た目ががらりと変わっていますが、アイドリングしているWorkerスレッドにRenderと思われるスレッドが埋もれてしまったため、このような見た目になっています。実際は、どの設定でも多数のWorkerスレッドやサウンドのスレッドが立ち上げられていますが、描画に関係ないものは省略しています。先ほどの例と異なり、RHIのスレッドと思われるスレッドと、Renderと思われるスレッドが別になりました。基本的な仕組みや、遅延の状況はほぼ同じです。こちらもおそらく動作クロックが下がっているので、本来の描画パフォーマンスと比べると処理時間がかかっています。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-off-フレームレート上限-120&#34;&gt;VSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 120&lt;/h2&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mtoff_120&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_120_hu577993647c8741ecb07125375c0cb93a_249296_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mtoff_120&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mtoff_120_hu577993647c8741ecb07125375c0cb93a_249296_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1071&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mtoff_120
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;次は、再びマルチスレッドレンダリングをOFFに戻しました。そして、フレームレート上限を120にしてみました。基本的な動作は一番初めの例と同じですが、フレームのペーシングが8.3msになったことで、120FPSのレンダリングになりました。そして、アイドリングのデューティ比が変わったことにより、動作クロックが引き上げられた関係で、入力遅延も短縮され、9.5ms程度になりました。&lt;/p&gt;
&lt;h2 id=&#34;vsync-off-マルチスレッドレンダリング-on-フレームレート上限-120&#34;&gt;VSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 120&lt;/h2&gt;
&lt;p&gt;次は、上記の設定でマルチスレッドレンダリングをONにします。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncoff_mton_120&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_120_hucb7e813ec08e0a34392eae9da6d7a916_251387_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncoff_mton_120&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncoff_mton_120_hucb7e813ec08e0a34392eae9da6d7a916_251387_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1018&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncoff_mton_120
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;やはり、RenderスレッドとRHIスレッドが分かれました。今回のテスト対象になっているシーンは軽いので、マルチスレッドレンダリングの恩恵は少ないですが、もっと複雑なシーンでは、これらのスレッドが並列動作することにより、Renderスレッドの描画命令発行によるストールが軽減され、より顕著な差になると思われます。少なくとも遅くなることはなさそうなので、私はこの設定でプレイすることにします。&lt;/p&gt;
&lt;h2 id=&#34;vsync-on-マルチスレッドレンダリング-off-フレームレート上限-制限なし&#34;&gt;VSync: ON マルチスレッドレンダリング: OFF フレームレート上限: 制限なし&lt;/h2&gt;
&lt;p&gt;次は、いわゆる、VSyncを守って、画面のティアリングを起こさない描画になります。見た目は一番スムーズなのですが、入力遅延の観点からはあまりお勧めできない設定となりそうです。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-vsyncon_mtoff_60&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncon_mtoff_60_hu1e8bb69aa4e2d9153699b0a96e4ee908_517763_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;vsyncon_mtoff_60&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/check_input_latency_of_fortnite/vsyncon_mtoff_60_hu1e8bb69aa4e2d9153699b0a96e4ee908_517763_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1619&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    vsyncon_mtoff_60
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;まず、VSyncを取ると、メインスレッドの動作がかなり変わります。およそ2ms単位でスレッドをポーリングしながら、処理開始のタイミングを計っているようです。rhi.SyncSlackMSのデフォルト設定と思われる、VSyncの10ms前に、メインスレッドの処理を開始しています。Renderスレッドは、前の前のフレームのGPU描画処理が完了してから、RHIの呼び出しを開始しているようです。そして、RHIが呼び出すD3DAPIによって生成されたGPUタスクは、ドライバのGPUタスクキューに積み上げられます。そのフレームのGPU描画処理がGPU上で実行されるのは、Renderスレッドが動作したフレームの次の次のフレームです。そして、ディスプレイの出力対象になるFlipが行われるのは、VSyncに同期しているので、実際の表示はその次のフレームとなります。メインスレッドが動作を開始してから、ディスプレイの出力対象になるまでの入力遅延は60msほどとなります。&lt;/p&gt;
&lt;h3 id=&#34;まとめ&#34;&gt;まとめ&lt;/h3&gt;
&lt;p&gt;少なくとも私の環境では、VSyncをOFFにして、CPUのフレームペーシングがボトルネックになる状態（つまりGPUの処理時間には余裕がある状態）で、なるべく高いフレームレートが入力遅延が一番小さくなる状態だといえると思います。入力遅延を最短にするという目的ならば、私のPCでは、おそらく200フレーム以上の設定の方が短くなると思われます。しかし、使用しているディスプレイも60Hzですし、描画解像度など他の設定に妥協が必要になります。
また、これらの状況は、個々のPCの、CPUとGPUの処理能力のバランスによって変動するので、皆さんに一概にこの設定がおすすめですとはなりません。しかし、VSyncはOff、なるべく早いCPU、なるべく早いGPU、なるべく軽い描画が、入力遅延低減につながると思われます。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
