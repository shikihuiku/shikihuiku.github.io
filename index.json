[{"authors":["admin"],"categories":null,"content":"このブログはあくまで会社もしくはその社員としての公式見解の場ではありません。全ての記事は個人としての発言です。このブログでは、リアルタイムグラフィックス関連で、興味のあることを取り扱っていきたいと思います。\n以前の記事はこちらにあります。 https://shikihuiku.wordpress.com/\nThis BLOG is a place to express things which I’m interested in, especially related to computer graphics, not for a place to discuss about my work or company. All things noted on this BLOG are based on my personal views.\nThank you.\nOld site is here, https://shikihuiku.wordpress.com/\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shikihuiku.github.io/author/shikihuiku/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shikihuiku/","section":"authors","summary":"このブログはあくまで会社もしくはその社員としての公式見解の場","tags":null,"title":"shikihuiku","type":"authors"},{"authors":[],"categories":[],"content":"NVIDIA Falcor とは D3D12 をバックエンドとした、リアルタイムレンダリングのフレームワークです。 昨今のゲームエンジンほどの手厚い機能はありませんが、レンダリングAPIの抽象化レイヤーが軽量なのでカスタマイズが容易です。 抽象化レイヤーは、ラスタライズのみならず DXR をサポートしているのが大きな特長で、DXR を使って何か試してみたいときには特に有用なフレームワークになります。 また、DepthPre パスや、GBuffer パス、SVGF パスなどが初めから用意されているので、Raster と RT のハイブリッドレンダリングをテストしたい場合や、RT のデノイザー開発にも対応できます。 また、今回は紹介しませんが、CUDA を使った処理もサポートされているので、必要に応じてこちらも使ってみると面白いかもしれません。\nGetting Started 早速ですが、環境をセットアップします。とはいっても、基本的には GitHub のリポジトリを Clone してビルドするだけです。\nhttps://github.com/nvidiagameworks/falcor\n2020/11現在の推奨されるビルド環境は以下の通りです\n Windows 10 version 1809 or newer Visual Studio 2019 Microsoft Windows SDK version 1903 (10.0.18362.1)  また、必須ではありませんが以下のパッケージや機材を準備することをおすすめします\n GeForce RTXシリーズ (もしくはDXRをサポートしたGPU) Windows 10 Graphics Tools (WindowsのOptional Featureからインストールするパッケージ。DebugLayerのために必要) NVAPI (NVAPIによる拡張機能を使用したい場合)  GitのリポジトリをClone git clone --recursive -b master git@github.com:NVIDIAGameWorks/Falcor.git  NVAPIのインストール NVAPIを使用する方は、 ここより NVAPI の最新パッケージをダウンロードして、Externals/.packman/nvapi に配置します。 ダウンロードの際にNVIDIAの開発者登録アカウントが必要になります。 次にFalcorConfig.hを開き、_ENABLE_NVAPI を1に設定します。\n#define _ENABLE_NVAPI 1 // Set this to 1 to enable NVIDIA specific DX extensions. Make sure you have the NVAPI package in your 'Externals' directory. View the readme for more information.  FalcorTest プロジェクトをビルド Tools/FalcorTest をビルドすると、Falcor (Falcor本体。レンダリングのバックエンドになるDLL) と、FalcorTest（各種単機能テストのレンダリングが書かれたアプリ）がビルドされます。 実行すると、各種機能がテストされて結果がコンソールに表示されます。詳細なテストではありませんが、まずここで自分の使いたい機能が正しく動作しているかチェックしておきましょう。 幾つかの機能は無条件にスキップされるようになっているので、適宜ソースを書き換えてテストしましょう。\nたとえば、ShaderModel6.5 のサポートを確認したければ、このように書き換えます。\n#if 0 GPU_TEST(ShaderModel6_4, \u0026quot;Requires shader model 6.4\u0026quot;) { test(ctx, \u0026quot;6_4\u0026quot;); } GPU_TEST(ShaderModel6_5, \u0026quot;Requires shader model 6.5\u0026quot;) { test(ctx, \u0026quot;6_5\u0026quot;); } #else GPU_TEST(ShaderModel6_4) { test(ctx, \u0026quot;6_4\u0026quot;); } GPU_TEST(ShaderModel6_5) { test(ctx, \u0026quot;6_5\u0026quot;); } #endif  TraceRayInline は、2020/11現在は、Falcor内にはシェーダーのコンパイルが通るかのテストコードしかありませんが、とりあえずテストすることが出来ます。\n#if 0 GPU_TEST(testTraceRayInlineAPI, \u0026quot;Requires shader model 6.5\u0026quot;) #else GPU_TEST(testTraceRayInlineAPI) #endif { // We don't actually run the program, just make sure it compiles. ctx.createProgram(\u0026quot;Tests/Slang/TraceRayInline.cs.slang\u0026quot;, \u0026quot;testTraceRayInlineAPI\u0026quot;, Program::DefineList(), Shader::CompilerFlags::None, \u0026quot;6_5\u0026quot;); }  サンプルコードに目を通す ProjectTemplate   Project Template   Samples/ProjectTemplate をビルドして実行すると、ウィンドウが開き、緑の画面とGUIが表示されます。チュートリアルではよくあるお約束の RenderTarget をクリアしているだけのプログラムになります。 プログラム本体はほんの数行で、Guiにボタンを追加するのと画面を緑色でクリアするコードが記述されているだけです。D3D12のAPIは抽象化されており、Render Target のクリアはこの一行で行われます。\n pRenderContext-\u0026gt;clearFbo(pTargetFbo.get(), clearColor, 1.0f, 0, FboAttachmentType::All);  RenderingContext は、メンバーに LowLevelContextData クラスを保持しており、これが D3D12 の CommandAllocator / CommandList / CommandQueue などを保持しています。 D3D12Device はグローバル変数としてアクセス可能で、一通りのAPIの抽象化レイヤーが提供されていますが、ネイティブ API へのアクセスも簡単なものになっています。 一方で、Guiのクラスを覗くと、Dear ImGui がGUIのバックエンドとして使われているのが分かります。\nShaderToy   ShaderToy   Samples/ShaderToy プロジェクトをビルドすると、フルスクリーンの PixelShader のパスで、シェーダー Samples/ShaderToy/Toy.ps.slang が実行されます。 初期化処理の OnLoad で幾つかのステートを作成していますが全部不要な処理です。初期化処理で実際に必要とされる処理は下記の一行のみです。\n// Load shaders mpMainPass = FullScreenPass::create(\u0026quot;Samples/ShaderToy/Toy.ps.slang\u0026quot;);  描画時の onFrameRender では、初期化した mpMainPass のConstant Buffer の値を設定して execute を呼び出して描画しているだけです。\nmpMainPass[\u0026quot;ToyCB\u0026quot;][\u0026quot;iResolution\u0026quot;] = float2(width, height); mpMainPass[\u0026quot;ToyCB\u0026quot;][\u0026quot;iGlobalTime\u0026quot;] = (float)gpFramework-\u0026gt;getGlobalClock().getTime(); mpMainPass-\u0026gt;execute(pRenderContext, pTargetFbo);  このように FullScreenPass クラスを使うと、ポストプロセス処理などで使うフルスクリーンのPixelShaderパスを簡単に構築することができます。Falcor には、FullScreenPass 以外にも極めて基本的な Dispatch や Draw を呼び出す機能がクラスとして標準で用意されています。これらは、Falcor プロジェクトの RenderGraph/BasePasses にあるので、興味があれば参照してください。\nModelViewer Samples/ModelViewerをビルドして実行します。Gui の Load Model をクリックして、Falcor/Media/teapot.obj を読みます。（他にも、Media/Arcade/Arcade.fbxも読み込むことができます） Falcor のアセット読み込みのバックエンドは、 assimp を使用しています。ライトとカメラの設定が無いので、初期状態ではカメラはteapotの中にありますし、レンダリングが真っ黒ですが、ASWDでカメラを動かせば、とりあえずジオメトリが読み込まれていることが分かります。   ModelViewer   ModelViewer.ps.slang をチェックすると、単純にシーン上のライトをイテレーションして、マテリアルを評価しています。したがって、ライトさえ配置されていれば正しくレンダリングされるように書かれています。なので、ModelViewer.cpp の、SceneBuilder がファイルを読み終わった後の箇所で、以下の様にライトの数を確認してライトが無ければ DirectionalLight を追加するように処理を書き加えて実行します。\nif (pBuilder-\u0026gt;getLightCount() == 0) { // no lights. pBuilder-\u0026gt;addLight(DirectionalLight::create()); }  これで、シーン上にライトが無い場合はデフォルトのDirectionalLightが追加されるので、ライティングの様子が見れるようになりました。   ModelViewer with a light   次に、Media/Arcade/Arcade.fscene を読み込んでみます。fscene は、Json で記述された Falcorのシーン格納形式で、ライトとカメラの定義が含まれているので、特にソースコードを変更することなくライティングの様子を見ることができます。Arcade.fscene はリファレンスとして Arcade.fbx と Light.fbx を参照して、内部にライトとカメラの定義を保持しています。   ModelViewer fscene   ModelViewer のプログラムを見てみると、初期化時に WireFrame描画用の RasterStateと、幾つかのCullModeの RasterStatreを作っています。DepthStencilStateも幾つか作っています。これらはGui上で選択して使用する事ができます。 シェーダープログラムは、アプリケーション側は PixelShader のみ指定して、頂点シェーダーと DrawCall の呼び出しは、Falcor 側の mpScene-\u0026gt;render() に任されています。   ModelViewer wire frame   HelloDXR Samples/HelloDXRをビルドして実行します。先ほどの Arcade/Arcade.fscene が起動時から読み込まれています。   Hello DXR (RTX ON)     Hello DXR (RTX OFF)   Ray Traceのチェックボックスで、DXRの有効/無効を切り替える事ができ、影と反射の効果の有無が違いとして見て取れます。 ソースコードを見ると、DXRが無効な時のレンダリングは、Falcorの組み込みレンダリングパスのRasterScenePassが使用されています。設定されているピクセルシェーダーは、ModelViewerとほぼ同じで、Falcorの組み込みシェーディング関数を使用しています。つまり、先の ModelViewer のサンプルプログラムは、RasterState の変更をしないのであれば、RasterScenePassを使って一行で記述できるという事です。\n mpRasterPass = RasterScenePass::create(mpScene, \u0026quot;Samples/HelloDXR/HelloDXR.ps.slang\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;main\u0026quot;); . . . mpRasterPass-\u0026gt;renderScene(pRenderContext, pTargetFbo);  DXR側は、HelloDXR.rt.slangに記述されている各シェーダーをShaderLibraryとしてコンパイルして、RtProgram::Descを使ってHitGroupの定義を行っています。\n RtProgram::Desc rtProgDesc; rtProgDesc.addShaderLibrary(\u0026quot;Samples/HelloDXR/HelloDXR.rt.slang\u0026quot;).setRayGen(\u0026quot;rayGen\u0026quot;); rtProgDesc.addHitGroup(0, \u0026quot;primaryClosestHit\u0026quot;, \u0026quot;primaryAnyHit\u0026quot;).addMiss(0, \u0026quot;primaryMiss\u0026quot;); rtProgDesc.addHitGroup(1, \u0026quot;\u0026quot;, \u0026quot;shadowAnyHit\u0026quot;).addMiss(1, \u0026quot;shadowMiss\u0026quot;); rtProgDesc.addDefines(mpScene-\u0026gt;getSceneDefines()); rtProgDesc.setMaxTraceRecursionDepth(3); // 1 for calling TraceRay from RayGen, 1 for calling it from the primary-ray ClosestHitShader for reflections, 1 for reflection ray tracing a shadow ray mpRaytraceProgram = RtProgram::create(rtProgDesc); mpRtVars = RtProgramVars::create(mpRaytraceProgram, mpScene); mpRaytraceProgram-\u0026gt;setScene(mpScene);  Closest Hitのシェーディングの関数は、Rasterで使用しているものと同一で、prepareShadigData()でサーフェースの情報を取得して、envalMaterial()でシェーディングを行っています。 いる。ただし、ライトの評価の際に checkLightHit() で ShadowRay を飛ばして遮蔽のチェックをしています。また、リフレクションの Ray を飛ばしており、GGXのアルファ値（Roughness相当のパラメーター）で適当にブレンディングしています。（PBRではない） そのため、DXRを有効にした場合は、影と反射が追加されたレンダリングになります。\nMogwaiに目を通す 注意 ビルドの際にコンパイルエラー等は発生しませんでしたが、実行時にPythonのBindingを設定している個所で例外が発生しました。この問題は、VisualStudioをアップデートすることで解決しました。動作確認は Microsoft Visual Studio Professional 2019 - Version 16.7.7 を用いて行いました。同様の問題が発生した場合は、VSのバージョンをチェックすると良いかもしれません。\nMogwai Falcorは Pybind11を使って、RenderGraph を Python で記述するための機構を持っています。Mogwaiはその機構を使ったフレームワークと呼べると思います。 ビルドすると、Pythonで記述されたいくつかの RenderGraph が、実行ファイルの出力先の Data フォルダに用意されます。 起動後に File-\u0026gt;Load Scriptで Data/FowardRenderer.py を読み込みます。これで Foward Rendering の RenderGraph が読み込まれて、使用できるようになります。 次にFile-\u0026gt;Load Sceneで、Falcor/Media/Arcade/Arcade.fsceneを読み込みます。 すると、サンプルの Model Viewerと同様にレンダリングが確認できると思います。しかし、ModelViewerとは異なり、先ほど読み込んだ Pythonのスクリプトに記述された RenderGraph によってレンダリングの動作が定義されています。\nここで、File-\u0026gt;LoadScript で、MinimalPathTracer.py を読み込むことで、パストレーシングのRenderGraphを、追加で読み込むことができます。 HUD上でRenderGraphを切り替えると、MinimalPathTracerにレンダリングパスを切り替えることができます。このように、Mogwaiを使うと、python で記述された複数の RenderGraph を動的に切り替える事ができます。これはレンダリングの比較評価等を行う際に有用だと言えると思います。\nRenderGraph を ForwardRenderer に戻してEditボタンを押すと、RenderGraph の編集ができます。 基本的には FowardRenderer.py に書かれている内容そのままですが、RenderGraph を視覚的に確認してエディットすることもできます。ただ、オマケ的な要素が強く、実際の RenderGraph の構築では、Pythonスクリプトを直接編集したほうが早いです。   Mogwai Render Graph   RenderGraphのノード RenderGraph の個々のノードは、Falcor の RenderPass クラスを継承したクラスです。 たとえば DepthPrePass ノードは DepthPass.dll として事前にビルドされており、これが ForwardRenderer.py の中でインポートされて、他のノードと接続されることでレンダリングパスが構築されています。他にも、GBuffer描画や、CascadedShadowMap, SSAO, Antialias, Tonemapping, SkyBox, それからレイトレーシング用に、MinimalPathTracer, AccumulatePass, SVGFPassなど、他にも幾つかの有用なノードが用意されています。これら RenderGraph のノードは個々のDLLとしてコンパイルされています。そのためのプロジェクトは、Falcor ソリューション内の RenderPasses フォルダに配置されているので確認してみてください。\n  Mogwai Render Graph   DepthPassに目を通す RenderGraph の一つのノードの例として、DepthPass ノードを見てみます。DepthPass ノードは RenderPass クラスを継承して実装され、DepthPass.dllとして配置され、Falcor のレンダリングに使用されます。 ヘッダーファイルを見ると、Gui の描画やリフレクションをサポートする関数、シーン情報にアクセスをするための setScene があります。\n static SharedPtr create(RenderContext* pRenderContext = nullptr, const Dictionary\u0026amp; dict = {}); virtual RenderPassReflection reflect(const CompileData\u0026amp; compileData) override; virtual void execute(RenderContext* pContext, const RenderData\u0026amp; renderData) override; virtual void setScene(RenderContext* pRenderContext, const Scene::SharedPtr\u0026amp; pScene) override; virtual void renderUI(Gui::Widgets\u0026amp; widget) override; virtual Dictionary getScriptingDictionary() override; virtual std::string getDesc() override { return kDesc; }  reflect()を見ると、レンダリングの出力として、2DのDepthStencilを出力することが分かります。入力は無いので、setSceneで設定されたシーンから取得できるカメラとジオメトリを用いてレンダリングすることが想像できます。 DepthBuffer のフォーマットはクラス内部に保持されて、Guiによる設定を介して変更できるようです。その結果がリフレクションの出力ピンに反映されます。\nRenderPassReflection DepthPass::reflect(const CompileData\u0026amp; compileData) { RenderPassReflection reflector; reflector.addOutput(kDepth, \u0026quot;Depth-buffer\u0026quot;).bindFlags(Resource::BindFlags::DepthStencil).format(mDepthFormat).texture2D(0, 0, 0); return reflector; }  描画解像度の設定は無く、DLLの外部で用意されたDepthStencilバッファをBindしてレンダリングする仕組みになっています。シェーダーは、Slangで記述されたピクセルシェーダーが一つだけあります。 中を確認すると、prepareShadingDataを呼び出しています。これは、アルファが完全に透明だった場合に、この関数のなかでDiscardが呼ばれるためです。\nvoid main(VSOut vOut, uint triangleIndex : SV_PrimitiveID) : SV_TARGET { // Calling prepareShadingData() to discard pixels that fail alpha test. The pixel shader has no other side effects. float3 viewDir = normalize(gScene.camera.getPosition() - vOut.posW); prepareShadingData(vOut, triangleIndex, viewDir); }  ちなみに、描画解像度の設定は、Falcor の RenderGraph 側にあります。RenderGraphCompiler::allocateResources() が RenderGraph の変更や描画解像度変更をトリガーとして、使用されている出力ピンのリソースを ResourceCache に登録します。その時に、各種 RnederTarget の解像度の設定が行われます。\n実際に RenderGraph のノードを実装するならば、ぜひ Docs/ Tutorials をご一読する事をお勧めします。\n最後に ビルドして実行するだけではいまいち概要がつかみにくい Falcor ですが、リポジトリの ドキュメントを読めば、この記事に書いてあることを含めて記載があります。ソースコードの規模もあまり大きくないので、全体の把握も比較的容易だと思います。アセットもFBX形式が読み込めるので、手元のアセットでテストしたい場合なども比較的短時間でセットアップできるのではないでしょうか。今回は紹介していませんが、 ORCAをはじめ、CC-BY等のオープンライセンスの元で公開されているアセットなどもあるので、これらを活用してレンダリングのテストを行う事も可能だと思います。\n今回は、簡単にですが Falcor を触ってみました。この手の軽量なレンダリングフレームワークというのは、自作含めて多数あると思いますが、RasterとDXRをシームレスにサポートしている軽量フレームワークはあまり見かけません。 そういう意味ではユニークな存在かもしれません。\n","date":1604801571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604801571,"objectID":"b23e5eafb2462b2afeefae474c42d193","permalink":"https://shikihuiku.github.io/post/falcor_getting_started/","publishdate":"2020-11-08T11:12:51+09:00","relpermalink":"/post/falcor_getting_started/","section":"post","summary":"Raster / Realtime Raytracing の Rapid Prototyping に使えるかも","tags":["DX12"],"title":"NVIDIA Falcor を使ってみる","type":"post"},{"authors":[],"categories":[],"content":"参考資料   Importance Resampling for Global Illumination\nhttps://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=1662\u0026amp;context=etd\n  Rendering Millions of Dynamic Lights in Real-Time\nhttps://news.developer.nvidia.com/rendering-millions-of-dynamics-lights-in-realtime/\n  Resampled Importance Sampling Importance Resamplingの概要  確率分布$p$に基づいたM個($(M \\ge 1$)のサンプル、$(X = \\langle X_1, X_2, \u0026hellip; , X_M \\rangle $を生成する 各サンプルのウエイト$ｗ_j$を計算する $X$のなかから、一つのサンプル$Y$を、ウエイト$\\langle w_1, w_2, \u0026hellip; , w_M \\rangle$に基づいて選ぶ  もし、$w_j = \\frac{g(X_j)}{p(X_j)}$としたならば、サンプル$Y$は、おおよそ$g$に基づいて分布する。 上記のリサンプリングの効果とは、密度$p$のソースのから、サンプルを取り出し、\u0026ldquo;filter\u0026quot;することで、 結果として、サンプル$Y$がおおよそ$g$の分布になるようにすることである。\nこれを図解した下記の例は、8個のサンプルを生成して、それぞれのウエイトを計算した場合のイメージになる。       サンプル数である$M$を分布の補間変数としてとらえることができる。 $M=1$のとき、$Y$は$p$に従って分布する。$M\\rightarrow\\infty$とすると、$Y$の分布は$g$に近づく。 一般的には、$M$が有限個である事によって導入されるバイアスを無視できる程度に小さくするためには、$M$は非常に大きくなけれならない。\n注釈：サンプル列$X$から、あるサンプル$Y$が選択される確率は $w_i / w_{sum}$で計算できるが、積分の範囲に対して、そのサンプルが選択される確率を考えると、 これに$M \\cdot p(X_i)$を乗算する必要がある。したがって、そのサンプルが選択される確率は$M \\cdot g(X_i) / w_{sum} $となる。これはそのまま次項でのImportance Samplingの確率となっている。また、$M / w_{sum} $は、サンプル列$X$において一定なので、$g(X_i)$に比例する関数で、選択が行われている事になる。\nResampled Importance Samplingの概要 Importance Resamplingの考え方をImporntace Samplingに導入したものをResampled Importance Sampling（RIS)と呼ぶ。\n下記の積分を求めたいとする。 $$ I = \\int_{\\Omega} f(x) d\\mu(x) $$\n二つの確率密度関数$p$と、確率に即した値を返す関数$g$を導入する。 $p$は、比較的簡単に計算でき、正規化することができるが、上記積分をImportance Samplingするのにあまり良い分布となっていないとする。 $g$は、良い分布特性を持っているが、計算が複雑で正規化されていない、またはするのが困難だとする。 通常のImportance Samplingでは、$p$を使う事しかできないが、RISを使うことで、$g$の分布特性をunbiasedな条件下で使うことができる。 $X$(Resamplingによって生成されたサンプル列)および$Y$(Xからウエイトに基づいて乱択されたサンプル)がImporntace Resamplingを用いて導出された場合の、RISのEstimatorは以下の通りとなる。\n$$ \\hat I_{ris} = \\frac{1}{N} \\sum^{N}_{i=1} w(X_i, Y_i) \\frac{f(Y_i)}{g(Y_i)} $$\nウエイト関数$w$は、$g$が正規化されていないことと、$Y$の分布が$g$を近似するようにする必要があることの二つを考慮して選択されなければならない。 そのための適切なウエイト関数$w$は実は非常に単純で、リサンプリングステップで計算された重みの平均である。\n$$ w(X_i, Y_i) = \\frac{1}{M} \\sum^{M}_ {j=1} w_ {ij} = \\frac{1}{M} \\sum^{M}_ {j=1} \\frac{g(X_{ij})}{p(X_{ij})}$$\n注釈：$X_i$, $Y_i$はそれぞれが、Importance Samplingの$i$番目の試行の時に作られた、M個のサンプル列$X_i$と、そこから選択された一つのサンプル$Y_i$を指す。 $w_{ij}$は、Importance Samplingの$i$番目の試行の時に作られた、M個のサンプル集合の、$j$番目のサンプルのウエイトを指す。\n注釈２：ウエイトは、結局のところ、二つの関数$p(x)$と$g(x)$のプロファイル（関数の形状および大きさ）の比になる。(例えば、$g(x)$が$p(x)$に対して、平均で2倍の値を持つ場合は、 $g(Y_i)$で除算すると、推定値が期待値の$1/2$に収束してしまう。$w$はその補正として2倍の補正を掛ける役割を担う。)\n上記の2式を合わせると下記の通りになる。 $$ \\hat I_{ris} = \\frac{1}{N} \\sum^{N}_ {i=1} \\left( \\frac{f(Y_i)}{g(Y_i)} \\cdot \\frac{1}{M} \\sum^{M}_ {j=1} \\frac{g(X_{ij})}{p(X_{ij})} \\right) $$\n$M=1$のときは、RISは$p$によるImportance Samplingになる。RISがunbiasedである条件は、$f$が非ゼロの領域では、$p, q$共に非ゼロである必要があるのと、$M,N$共にゼロより大きい必要がある。 RISがunbiasとすると、誤差は分散に起因するもののみとなる。ターゲット分布関数$g$と共に、パラメーター$M,N$を適切に選ぶことが分散の低減につながる。\nレンダリングにおいて、ライティングの関数を$f=F_s GVL_e$とするとき、ターゲット分布関数$g$を、$g=F_s GL_e$とすることができる。レイのトラバースが必要な$V$項を取り除いたものである。正規化されている必要がないのでそのまま使用できる。\n次は、適切な$M,N$の設定である。\nRobust Approximations of M and N 詳細は割愛するが、最適なM,Nを選ぶための計算には、実際のモンテカルロ法の試行が必要になる。しかし実際にはモンテカルロ法の試行の前に知りたい。 ここではサンプルの生成や実際の推定値の計算にかかる時間を基にして、$M,N$の導出を行う。 $T_x$を$p$に基づいてサンプルを生成してウエイトを計算するのにかかる時間とし、$T_y$をIRS Estimatorで推定値を計算する時間とすると、全体の計算時間は以下の様になる。 $$ T=MNT_x + N(r(M) + T_y) $$ $r$はリサンプリングにかかる時間で、離散的な分布からサンプルを選ぶ作業は高度に最適化されており、時間は無視できるとすると以下の様になる。 $$ T=MNT_x + NT_y　$$\nここで、リサンプリングの各ステップに同じ計算時間を割り当てるとすると、以下の様になる。 $$MNT_x = NT_y $$\nこの条件下では$M$は以下の様に求まる。 $$M=\\frac{T_y}{T_x} $$\n注釈：$N$は上式から求まらないが、総計算時間の関数として計算することができる。$M$は、$T_y$($V$項を含んだシェーディングの評価)が、他の項の計算に比べてどのくらい時間がかかるかによって 決定されるといえると思う。時間がかかればかかるほど$M$を大きくした方が良いという事になる。\nレンダリングするシーンの複雑度が均一であれば、この値は事前計算することができる。$T_x, T_y$を得るために数千のPrimaryRayをキャストして計算する。\n 参照論文  のレンダリングの例では、二つのポリゴンライトと環境マップを用いてライティングしている。この場合RISは同じ計算量で分散を70%低減できた。しかし、ライティングから環境マップを取り除くと、分散を10%しか低減出来なかった。 これは、$L_e$の成分にあった環境マップが分散を導入していたからで、これはターゲット分布関数$g$のウエイトとして計算されていた。(つまり$L_e$が導入した分散に効果的に作用した。) しかし、これが取り除かれると、$V$項による分散が支配的となり、通常のImportance Samplingとの差が得られなくなった。\nWeighted Reservoir Sampling 上記Resampled Importance Samplingは、計算時に$M$個のサンプルストリームを用意する必要があった。これを、実際にストレージを確保して保存することなく実現するための手法がWeighted Reservoir Samplingになる。 WRSではサンプルストリームに値を追加するたびにDraw（分布に基づく乱択）を行う代わりに、ストリームに何個要素を追加しても、ウエイトの合計値である$w_ {sum}$と現在の出力である$y$のみ記録することでRISと同等の機能を実現する。\nWeighted Reservoir Samplingの手法 以下はWRSのpuseudo codeである。サンプルストリームの要素の追加(update)のたびに、$w_ {sum}$を更新しつつ乱択を行う。Reservoirは常に選択候補となる一つのサンプルを保持する形となる。同じストリームから複数のサンプルを乱択することは出来ないが、必要なストレージが非常に少ないのが特徴。\nclass Reservoir y ← 0 // The output sample w ← 0 // The weight for the output stream wsum ← 0 // The sum of weights M ← 0 // The number of samples seen so far function p(x) return probability of x function g(x) return target distribution of x function update(xi, wi, cnt) wsum ← wsum + wi M ← M + cnt if rand() \u0026lt; (wi /wsum) then y ← xi function reservoirSampling() Reservoir r for i ← 1 to StreamLen do generate xi r.update(xi, g(xi)/p(xi), 1) w ← (1 / g(y))(wsum / M) return y, w  Combine Multiple Reservoirs WRSの特長として、個々のストリームにアクセスすることなく、生成された複数のストリームを結合することができることが挙げられる。結合の方法は以下の通りで新しいReservoirに、結合するReservoirを入力することで行う。 s.update()の第二引数のウエイトは、結合する際のReservoirのターゲット分布関数$g$が同じ場合は、r.wsumと等価である。しかし、結合する際のReservoirのターゲット分布関数が異なる場合、 $g(y)/g'(y)$をr.wsumに乗算する必要がある。 これはそのための計算である。\nfunction combineReservoirs(g, r1, r2, . . . , rk) Reservoir s // a new reservor foreach r ∈ {r1, . . . , rk } do s.update(r.y, g(r.y) · r.w · r.M, r.M) w ← (1 / g(s.y))(s.wsum / s.M) return s.y, w  注釈１：ウエイトのスケーリング(g(r.y) · r.w · r.M)について。\n結合元の$w$は、 $$\\frac{1}{g'(y')} \\frac{1}{M'} \\sum^{M'}_ {i=1} \\frac{g'(X_i)}{p'(X_i)} $$ なのだが、これは通常のImportance Samplingにおける確率密度関数の逆数に相当するものでなくてはならない。（通常1/p(x)で表すが本式のpとは意味が異なる。） したがって、これに$g(y')$ を乗算すると、以下の様になり、これは、通常のRISの一つのウエイトである、$g / p$と同義になる。（ただし、この場合のベースの確率密度関数（先ほどpと呼んでいたものに相当するもの）が実際にどんなプロファイルかは知らない） $$\\frac{g(y')}{g'(y')} \\frac{1}{M'} \\sum^{M'}_{i=1} \\frac{g'(X_i)}{p'(X_i)} $$ そして、この$y'$は、$M'$個のサンプルの中から選択されたサンプルなので、加重平均で確率計算するために、その分のウエイトに相当する$M'$を乗算する。 $$\\frac{g(y')}{g'(y')} \\sum^{1}_{M'} \\frac{g'(X_i)}{p'(X_i)} $$ このように、ウエイトのスケーリングを解釈する事ができる。\nまた、結合後のウエイトの計算部分((1 / g(s.y))(s.wsum / s.M))は、まず、(s.wsum / s.M)の部分は、全てのサンプルのg/pの平均値になり、関数pとgのプロファイルの比と考える事ができる。 また、この値は、全てのサンプルのg/pの平均値なので、候補となった全サンプルにおいて一定の値と解釈でき、最終的な確率密度の逆数は、1/gに比例していると考える事ができる。\n注釈２：バイアスについて。\n実際には、結合先と結合元で、確率密度関数や、ターゲット分布関数が異なれば、もとから一つのサンプル集合だった場合とは異なる演算になる。ただ、これによってBiasが導入されるかは別である。 実際は、結合結果として選択されたサンプルが、結合元の確率密度関数でゼロになる場合にBiasが導入されることになる。この場合は、無効なウエイト値が計算に入るので、実際の値より小さくなる方向にBiasがかかるはずである。 それ以外では、結果的に分散を大きくするかもしれないが、biasが導入されることはない。\nNaive Unbiased combine UnbiasedなWRSの結合をするためには、結合前のターゲット分布関数もしくは、確率密度関数が必要になる。（あるサンプルに対して正の値を返すかどうかチェックするだけなので、実際の関数のプロファイルは関係ない） Reservoirを結合してサンプルの選択をするところまでは同じだが、最後に、選択されたサンプルが、結合前のターゲット分布関数で有効であるかどうかを確認して、無効であればウエイトから除外するようにしている。\nfunction combineReservoirsUnbiased(g, r1, r2, . . . , rk, g1, g2, . . . , gk) Reservoir s // a new reservor s.combineReservoirs(g, r1, r2, . . . , rk) Z ← 0 foreach gi ∈ {g1, . . . , gk } do if gi(s.y) \u0026gt; 0 then Z ← Z + ri.M w ← (1 / g(s.y))(s.wsum / Z) return s.y, w  注釈３：安定性について。 上記のMの代わりにｚで割るのは、単純に有効なサンプルの平均を取っているからで、Unbiasedにすること自体は安定性に対して問題がない。 それよりも、結合元のベース確率密度関数とターゲット分布関数の比が大きい（$g/p$が大きい）サンプルが生成される、Resampleの過程で選択される確率が高く、wsumの値が大きくなる傾向がある。\n閑話休題 ReSTIR のFig7について まずは、グラフ(a)(b)について。 被積分関数については言及がないが$ f(x) = 2-2x$と仮定する。\n $ g(x) = 2 -2x$, $ p_1(x) = 1$ $ g(x) = 2 -2x$, $ p_2(x) = 2H(1/2 -x) $(p2(x)=0 if x \u0026gt; 0.5 otherwise =2)  としている。\n$1/p(y)$をVisualizeしているといってるが、この$1/p(y)$はRISのEffectivePDFの逆数、つまり、$\\frac{1}{g(y)} \\frac{1}{M} \\sum^{M}_ {i=1} \\frac{g(X_i)}{p(X_i)} $を指していると思われる。\n  一つは、サンプルのヒストグラムの逆数をプロットしたもの\nImportance Samplingを、$f(x)$に沿って行えたとするならば、生成されたサンプルのヒストグラムは、$f(x)$に比例しなくてはならない。 したがって、サンプルのヒストグラムを正規化して逆数をとれば、$1/f(x)$に沿うと考えられる。このグラフは、サンプル数に基づいて、ヒストグラムを正規化して逆数にしたグラフと思われる。 $p_2$が0.5以上のサンプルを生成しないので、そこに大きな境界が出来ている。（実際の運用なら単純によろしくない。)　0.5以上は、$p_1$の方で生成されるが、こちらのサンプル確率は単純に$g(x)$(つまりf(x))に比例しているため、 1に近づくにつれてサンプルの生成される確率が低下している。それに伴ってヒストグラムの乱れが顕著に見られる様になっていると思われる。また、0.5以下ではサンプル数が多い傾向があり、0.5以上ではサンプル数が少ない傾向があるが、これは$p_2$が偏った範囲でサンプルを生成することによる影響と思われる。\n  もう一つは、RISのウエイトの平均値\nこちらは単純に先のRISのウエイト（実質的なサンプルの確率としてのウエイト。Effective PDF）の逆数の平均だから解釈は簡単。サンプルの出現確率と、RISのウエイト値は、統計的に一致していない場合は、真値からのBiasが生じる事になる。 グラフ(a)は、0.5以上で、明らかな乖離が見られる。サンプルを発生させない$p_2$のウエイトを算入しているためBiasが発生しているのが分かる。\n  次に、グラフ(c)(d)について。 $ p_2(x) = max(1.9\u0026hellip;H(1/2 -x), 10^{-4}) $ (p2(x)=10^{-4} if x \u0026gt; 0.5 otherwise =1.9\u0026hellip;)\nに変更し、$p_2$で非常に低確率で0.5以上のサンプルが生成されるように変更したもの。\n  0.5以上のサンプルが生成されるとき、$p_2=10^{-4}$なので、$\\frac{g(X_i)}{p(X_i)} $の部分は値が非常に大きくなると思われる。すると、$p_2$内でのResamplingで選択される可能性が高く、 また、$p_2$の$w_{sum}$も大きくなることから、$p_1,p_2$を結合する時に選択される可能性が高くなる。 また結合後の$w_{sum}$への影響も大きいので、選択の可否に関わらず、$p_2$側で、0.5以上のサンプルが生成されることにより、最終的なウエイト値に大きな乱れを導入する原因になっている。(c)\n  MIS（バランスヒューリスティック）で結合する場合、各サンプリング戦略（この場合は、結合対象の各RISのこと。いわゆる$p_1,p_2$）におけるサンプルの確率が計算出来なくてはならない。しかし、RISでは、自身のサンプル戦略の結果として出たサンプルのウエイト値（サンプルの確率）は計算されるるが、任意のサンプルの確率を計算する術がない。しかしここでは何らかのサンプルの確率に相当するものが計算できるものとして話を進める。\n$p_2$で非常に低確率な0.5以上のサンプルが出た場合は、RISのウエイトは極大化して、その逆数であるサンプル出現確率は極小化するはずである。そして、例えば、バランスヒューリスティックで結合すれば、極小化した出現確率による除算は相殺されて、代わりに、各サンプル戦略のサンプル確率の加重平均による除算になるので、$p_2$側のサンプル戦略で極大化したRISウエイトを保持する事による影響は軽微となるはずである。(d)\n  ReSTIRのSupplementary Filesの方に記載があるMISに関する議論  こちら のSupplementary Documentでは、RISを結合する際のMISのウエイトの計算方法について 言及している。この手法にとってとても重要な部分なのだが、とにかくこちらに記載がある。\n二つの手法が紹介され、一つはTalbot et alの手法と、本論文の提案手法である、Bitterli et alの手法を比較している。MISを計算するには、任意のサンプルの、個々のサンプル戦略に於けるPDFが計算できる必要があるが、RISは、自身が選出したサンプルのウエイト値を計算することしかできない。そこで、PDFの代替となる値を計算する必要がある。重要なのは、この値はMISのウエイトを計算するためのもので、各サンプリング戦略(各RIS)におけるPDFと必ずしも一致する必要がない。 ただ、unbiasedなウエイトを算出するだけなら、\n あるサンプルに於ける各サンプリング戦略のウエイトの合計値が1 ある戦略で、あるサンプルのPDFがゼロならば、そのウエイトはゼロ の二つを守れば良い。  Talbot et alの方法は、各RISを結合の際に、結合対象サンプルを、全てのRISのターゲット分布関数:$g$で評価してウエイト$g_i / g_{sum}$を計算し、正規化（$m$の平均が1.0になるように）して、これをサンプルのウエイト値に乗算して結合している。直感的で分かりやすいが、ターゲット分布関数:$g$の評価回数が2次的に増大するのがこの方法の大きな欠点である。\nfunction combineReservoirsTalbotMIS(g, r1, r2, . . . , rk, g1, g2, . . . , gk) Reservoir s // a new reservor foreach r_i ∈ {r1, . . . , rk } do // calculate normalized MIS weight using g() g_sum ← 0 foreach g_j ∈ {g1, . . . , gk } do g_sum ← g_sum + g_j(r.y) m ← g_i(r.y) / (g_sum / k) s.update(r.y, g(r.y) · r.w · r.M · m, r.M) w ← (1 / g(s.y))(s.wsum / s.M) return s.y, w  本論文の提案手法であるBitterli et alの手法では、結合して、最終的に選択されたサンプルが使っていた戦略のMISウエイトを計算している。 最終的に$1/M$の代わりにこれを乗算している。この手法では、ターゲット分布関数の評価回数はサンプリング戦略数（結合するRISの数）なので、 Talbot et alの方法に比べたら、明らかに計算量が少ない。\n注釈：この式はまだ理解できてない。例えば一つの戦略で、Mに非常に大きな数を使った場合、s.wsumはそれに準じて大きな数になる。 一方でmは、ターゲット分布関数に変化が無い場合、サンプリング戦略数が増えればそれに準じて小さな値になっていくはずである。 これら両者は直交したパラメーターで、直接の関係がない。しかし、s.wsum · mは、1/gを正規化するために作用する必要があるが、これでは正規化できないはずだ。\nもし、全てのサンプリング戦略でMが1であると仮定すると、g(r.y) · r.wの部分はg/pに相当して、s.wsumは、サンプリング戦略数分の$\\sum{g/p}$で、サンプリング戦略数で割ればg/pの平均値として解釈できる。 一方でmは、各サンプリング戦略のターゲット分布関数が同じものだった場合は、サンプリング戦略数の逆数となる。選択されたサンプルのターゲット分布関数が、 他の戦略に対して相対的に大きければ、ウエイトが大きくなり、逆ならば小さくなるようなMISウエイトとして解釈できる。\nfunction combineReservoirsMIS(g, r1, r2, . . . , rk, g1, g2, . . . , gk) Reservoir s // a new reservor foreach r ∈ {r1, . . . , rk } do s.update(r.y, g(r.y) · r.w · r.M, r.M) // calculate normalized MIS weight using g() g_sum ← 0 foreach g_j ∈ {g1, . . . , gk } do g_sum ← g_sum + g_j(r.y) m ← g_*(r.y) / g_sum // g_* : target distribution that contributed s.y w ← (1 / g(s.y))(s.wsum · m) return s.y, w  ","date":1599793175,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599793175,"objectID":"9b6cdab9a0fae2185d4774220e711a0e","permalink":"https://shikihuiku.github.io/memo/restir/","publishdate":"2020-09-11T11:59:35+09:00","relpermalink":"/memo/restir/","section":"memo","summary":"ReSTIRのためのメモ書き","tags":[],"title":"Importance Resampling 関連","type":"memo"},{"authors":[],"categories":[],"content":"これは補完資料です この記事は、CEDEC2020での講演 \u0026ldquo;Direct3D 12 Device Removalの処方箋\u0026rdquo; において、時間内に説明することができなかった部分に関して解説するためのものです。 CEDEC2020で当該講演を聴講された方に向けて書いています。この記事単体では不完全です。タイムシフト視聴や、CEDiLにアクセス可能な方は、先にそちらをご覧になることをお勧めします。\nDEVICE_REMOVEDとは   DXGIとD3D12API返すHRESULTに設定されるエラー\n 正式にはDXGIのエラーコード。DXGI_ERROR_DEVICE_REMOVED 殆どの場合は、IDXGISwapChain::Present()呼び出しの際に返される ID3D12DeviceD3D12の一部のメソッド、リソースの作成、Mapなどを実行した際にも返される ID3D12Device::GetDeviceRemovedReasonの呼び出しでも返される    ID3D12Device::GetDeviceRemovedReasonを呼び出すことで以下の様な具体的なエラー原因が取得できる。\n DXGI_ERROR_DEVICE_HUNG DXGI_ERROR_DEVICE_REMOVED DXGI_ERROR_DEVICE_RESET DXGI_ERROR_DRIVER_INTERNAL_ERROR DXGI_ERROR_INVALID_CALL    FormatMessage()や、_com_errorでエラーの意味を取得できる\nDevice Removed Reason for 887a0006 DXGI_ERROR_DEVICE_HUNG The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application.\n  DEVICE_REMOVEDが発生する原因について DEVICE_REMOVEDは、D3D12APIを通じて、GPUやドライバーで発生したエラーの結果に過ぎない。OSやD3D12ランタイムが、コンテキストの実行を継続するべきでは無いと判断した場合に発生する。 ただ、 Alex DunnがGDC2018で説明した通り、大きく分けて２つの種類にカテゴライズする事ができる。\n  TDR（Timeout Detection and Recovery）によるDEVICE_REMOVED\nドライバーやGPUがOSに対して一定時間内に応答しなかった場合に、OSが発生させるDEVICE_REMOVED。OSはシステム全体のHungを避けるため、DEVICE_REMOVEDを発生させてドライバーをリセットする。\n ドライバーのコードパスで想定していない長時間の処理があった場合 シェーダー内で長時間処理がかかった場合（シェーダー内無限ループ等） Signal,Waitの設定ミスで長時間Fenceが解決しなかった場合    エラーの検出によるDEVICE_REMOVED\n何らかの看過できないエラーの発生に伴いOSやD3D12ランタイムが発生させるDEVICE_REMOVED。\n GPUで発生したPage Fault 存在しないリソースへのアクセスや、宣言した利用用途と異なるアクセス。 不正な上書き等によるCommand Listの破損 結果的にドライバーやGPUが不正な実行コマンドを受け取る。 D3D12ランタイムやドライバーによるエラーの検出 許可されていないリソースステートのリソースへのアクセス。各種リソースのアラインメント違反。    GPUとCPUの時間のずれ ここでは、CPUコードのデバッグと、DEVICE_REMOVEDの追跡の決定的な違いについて説明する。 CPUの実行コードは、デバッガがアタッチされている状況下では即時的であり、エラーが発生すれば直ちにプログラムの実行を停止して、デバッガに処理を返すことで、エラーが起きた瞬間の状況が分かる。\nこれに対して、DEVICE_REMOVEDの発生は、CPUのコードと全く同期しないタイミングで発生する。そのため、CPUがDEVICE_REMOVEDを受け取った瞬間にデバッガで処理を止める事にはほとんど意味がない。\n以下のスクリーンショットはGPUViewというツールでCPUとGPUの処理時間を示したものになる。画面左から右に時間の経過を表している。中央の大きなスタックの中でハイライトされているのは、 あるGPU処理の塊となる、バケットである。ご覧の通り画面の左端で生成されたバケットは、画面の右側でスタックの最下段に到達している。この時点GPUの処理の対象となる。この間3フレーム分の時間が経過している。 もし、このGPU処理のなかでDEVICE_REMOVEDが発生したら、CPUがそのエラーを受け取る可能性があるのは、この時点以後となるので、CPUから見るとコマンド生成から3フレーム以上遅れてDEVICE_REMOVEDを受け取る事になる。\n  GPUとCPUの処理時間のずれ   これが、DEVICE_REMOVEDの追跡が難しい原因の一つである。\nDEVICE_REMOVEDの対処法 GPU上で発生する様々なエラーをデバッグする方法として、D3D12APIは以下の方法を提供している\n Debug Layer\n昔からあるが、DEVICE_REMOVEDの原因の追跡において最も有効な方法の一つ GPU Based Validation\n比較的新しく導入されたDebug Layerの拡張。CPU側のValidationでは追跡できない問題を検出する DRED1.2\n新しく導入されたDEVICE_REMOVEDの追跡方法  上記3つのうち、先の二つは、DEVICE_REMOVEDが発生する前に起きているD3D12上のエラーの追跡に使うのに対して、 DREDは、DEVICE_REMOVEが発生した後に、発生した箇所を見つけ出すためのもので、用途が完全に異なる。どちらも有用なので組み合わせて使う。\nDebug Layer DEVICE_REMOVEDに対する処方の第一候補は、Debug Layerである。これを有効にすることにより、D3DのランタイムがValidationを積極的に行い、Debug Outputにメッセージを送出するようになる。 DEVICE_REMOVEDが発生する前に出力されるDebug Layerのメッセージは、DEVICE_REMOVEDの発生原因を調査する上での貴重な手がかりになる。\nDebug Layerの有効化 Debug Layerはアプリケーション自身で有効にすることもできるし、外部から強制的に有効にすることもできる。\n外部から強制的に有効にする際は、dxcpl.exe(GUIツール)やd3dconfig.exe(コマンドラインツール)を用いる。インストールはWindows10の、Settings→Add an optional feature→ Add a feature→ Graphics Toolsを選択する事で行う。\n  dxcplのインストール   外部からDebug Layerを有効にする際は、dxcpl.exeかd3dconfg.exeを用いて、ターゲットとなるアプリケーションの名前を事前に登録し、Debug Layerを強制的に有効にする設定にする。設定内容はdxcplとd3dconfigで共有され、システム全体で有効になるので注意が必要である。\n  デバッグ対象アプリケーションを登録する     デバッグ対象アプリケーションを登録する   アプリケーション内部で設定する場合は、CreateDeviceを実行する前に、ID3D12Debugインターフェースを取得して、EnableDebugLayer()を呼び出す事で有効にできる。 この場合は、dxcpl.exeやd3dconfig.exeによるターゲットアプリケーション名の登録は必要ない。登録してある場合は、debug-layerの設定はApplication Controlledに設定することでAPIから明示的に有効にした場合のみDebug Layerが有効になる。\n// Create Deviceの前に設定する { ComPtr\u0026lt;ID3D12Debug1\u0026gt; debug1; if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(\u0026amp;debug1)))) { debug1-\u0026gt;EnableDebugLayer(); } }  Debug Layerの出力 Debug Layerが有効になっている状態では、アプリケーションのD3DAPIの使用において何らかの間違いが検出されれば、エラーの内容がデバッグ出力ストリームに文字列として出力される。出力メッセージはVisual StudioやDbgviewなどのツールを使って確認することができる。出力内容は、その深刻度に応じてグループ分けされている。\n Info\nリソースの確保や開放などを通知する。デフォルトでMuteされている。 Warning\nAPIの仕様から逸脱していないが、パフォーマンスの問題や、バグの発生の原因になりそうな状況を通知する。 Error\nAPIの仕様から逸脱した状況が検出された場合に通知する。ただ、これが出力されるから、直ちにDEVICE＿REMOVALが発生するという訳ではない。 Corruption\nリソースやオブジェクト（オブジェクト自身というよりは、多くはそのハンドル等）が破損していることが検出された場合に通知する。 Message\n上記に当てはまらない情報を通知する（メモリ不足等）  以下は、例としてResourceBarrierの遷移前リソースステートの指定が間違っていた場合に出力されたエラーである。ちなみにこのプログラムは、Debug Layerが無効な状態でも有効な状態でも正常に動作した。\nD3D12 ERROR: ID3D12CommandList::ResourceBarrier: Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:'MyColorTex') (subresource: 0) specified by transition barrier does not match with the current resource state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) (assumed at first use) [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH] D3D12 ERROR: ID3D12CommandQueue::ExecuteCommandLists: Using ResourceBarrier on Command List (0x000001AE3B802060:'MyCommandList_Direct'): Before state (0x0: D3D12_RESOURCE_STATE_[COMMON|PRESENT]) of resource (0x000001AE3B886890:'MyColorTex') (subresource: 0) specified by transition barrier does not match with the state (0x400: D3D12_RESOURCE_STATE_COPY_DEST) specified in the previous call to ResourceBarrier [ RESOURCE_MANIPULATION ERROR #527: RESOURCE_BARRIER_BEFORE_AFTER_MISMATCH]  Debug Layerはこのエラーを二か所で検出した。一つはID3D12CommandList::ResourceBarrier()呼び出し時に、もう一つは、ID3D12CommandQueue::ExecuteCommandLists()呼び出し時に検出した。しかしこれは、この種のエラーは常に二か所で検出されるという意味ではない。コマンドリストは他のコマンドリストの生成タイミングと関係なく生成する事ができ、その際のコマンドリスト作成時のリソースのステートは未確定になる場合がある。そのためDebug Layerは複数の箇所で可能な限りエラーの特定を試みる。上記の場合では、コマンドリスト作成時の対象リソースの事前ステートが確定できたので、ID3D12CommandList::ResourceBarrier()の呼び出し時にエラーが出力出来たという事である。\nまた、ステートが間違っていたリソースの名前が、\u0026lsquo;MyColorTex\u0026rsquo;といった様に表示されるが、これはアプリケーション自身が、ID3D12Object::SetName()を通じて設定したものである。D3D12アプリケーションを開発し、各種デバッグ機能を使う予定がある場合は、可能な限り全てのD3D12Objectに名前をつけるべきである。すると、上記の様にエラーが発生した際のメッセージによって原因となったリソースの特定が簡単に行えるようになる。Command ListやDescriptor Heapなどにもしっかりと名前を付けると、上記の様にエラーが発生したコマンドリスト名からエラーがどのレンダリングパスで発生したのかが特定できる場合もある。また、PIXやNSightといったフレームプロファイラを使う場合にもこれらの名前付けは有用である。\n次の例は、RenderTargetを設定したクリアカラー以外でクリア場合に発生する警告である。これはエラーではないので無視しても構わない。しかし、このようにパフォーマンスの向上を考える場合に有用なメッセージが得られる場合もある。\nD3D12 WARNING: ID3D12CommandList::ClearRenderTargetView: The application did not pass any clear value to resource creation. The clear operation is typically slower as a result; but will still clear to the desired value. [ EXECUTION WARNING #820: CLEARRENDERTARGETVIEW_MISMATCHINGCLEARVALUE]  ID3D12InfoQueueについて Debug Layerは、時にはアプリケーションが意図して記述しているコードに対してもメッセージを出力する場合がある。その場合は、アプリケーションが無視するべきと考えるメッセージを、D3D12InfoQueueを使ってフィルタリングできる。以下のコードスニペットは、GPUが書き込みしている可能性のあるリソースがCPUから読み込み可能な状態でMapされている場合に出力される警告を抑制するためのものである。\nComPtr\u0026lt;ID3D12InfoQueue\u0026gt; d3dInfoQueue; if (SUCCEEDED(device-\u0026gt;QueryInterface(IID_PPV_ARGS(\u0026amp;d3dInfoQueue)))) { // Suppress individual messages by their ID. D3D12_MESSAGE_ID denyIds[] = { D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED, }; D3D12_INFO_QUEUE_FILTER filter = {}; filter.DenyList.NumIDs = _countof(denyIds); filter.DenyList.pIDList = denyIds; d3dInfoQueue-\u0026gt;AddStorageFilterEntries(\u0026amp;filter); OutputDebugString(L\u0026quot;Warning: GPUTimer is disabling an unwanted D3D12 debug layer warning: D3D12_MESSAGE_ID_EXECUTECOMMANDLISTS_GPU_WRITTEN_READBACK_RESOURCE_MAPPED.\u0026quot;); }   Microsoft DirectX SDK Sampleより引用\n メッセージのフィルタリングは、InfoQueueを通じてではなく、dxcpl/d3dconfigを使っても同様のフィルタリングの設定が可能だが、メッセージのフィルタリングはアプリケーションごとに行われるべきであるので、通常はアプリケーションのコードに記述されるべきである。ちなみに、InfoQueueの設定は、dxcpl/d3dconfigの設定でオーバーライドされるので、InfoQueueを使って制御したいときは、dxcpl/d3dconfigにアプリケーションを登録してはいけない。 以下はID3D12InfoQueueのその他の機能についてである。\n  InfoQueueのデフォルト設定では、Infoレベルのメッセージはフィルタリングされているので、Infoレベルのメッセージを取得する必要がある場合はフィルタの設定を一旦クリアする必要がある。\n  フィルターにはStorageFilterとRetrievalFilterの二種類がある。\nStorageFitlerは、エラーがメッセージキューにストアするときに適用されるフィルタ。フィルターを通過できなければ、メッセージキューにストアされない。 RetrievalFilterはメッセージを取得する際に適用されるフィルタ。メッセージキューにストアされているメッセージを破壊せずに、特定の種類のメッセージのみを抽出したいときなどに使う。\n  SetMuteDebugOutputでデバッグ出力ストリームへの出力を停止できる。 アプリケーション側で出力されるエラーのハンドリングを全て行う場合などで、デバッグ出力ストリームへの出力が不要な場合は抑止できる。\n  特定のエラーが検出された時や、エラーの深刻度によって、DebugBreakすることが可能。 Debug LayerはCPU側のD3D12ランタイムがエラーを検出しているので、エラーが発生するタイミングは、CPU処理と同期したタイミングが多い。したがって、DebugBreakすることは有効である。 しかし、DebugBreakがかかるのは、D3Dのランタイム側のスレッドでかかる場合もあるので、追跡するには、マルチスレッドのデバッギングが必要になる。\n  GPU Based Validationの有効化 DEVICE_REMOVEDへの処方の第二候補は、GPU Based Validationの有効化である。GPU Based Validation(以下GBV)は、その名の通り、GPU側での実行時に行うValidationである。 GBVもアプリケーション自身で有効にすることもできるし、dxcplなどで強制的に有効にすることもできる。この点はDebug Layerと同様である。なお、Debug Layerが有効化されていないと動作しないので、Debug Layerの拡張機能と考える事もできる。\n{ ComPtr\u0026lt;ID3D12Debug1\u0026gt; debug1; if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(\u0026amp;debug1)))) { debug1-\u0026gt;EnableDebugLayer(); debug1-\u0026gt;SetEnableGPUBasedValidation(true); } }  先ほど説明したDebug Layerは主にCommandListに命令を積み、ExecuteCommandListを呼び出すまでに行われるValidation。対してGBVはシェーダー実行時に行われるValidationになる。 未定義のDescriptorや、廃棄済みのリソースへのアクセス。不適切なリソースステートでのアクセスなど、CommandList作成時には、リソースの状況が未定で、検出できないエラーを実行時に検出する。 メッセージは既存のDebug Layerと同様に出力されるが、その出力のタイミングはコマンドリストを生成したCPU処理と同期しない。したがって、エラーメッセージが出力された瞬間のCPU処理を検証しても意味がない。\n D3D12_MESSAGE_ID enumerationを確認すれば、GBVで出力されるメッセージのIDには、 \u0026ldquo;GPU_BASED_VALIDATION\u0026quot;が含まれるのが分かる。これで実際にどのようなエラーが検出可能なのか分かる。\nGBVは、シェーダーコードとPSOにパッチを充てる形で実現する。これらには、いくつかのモードがあり選択することができる。GBVの設定は以下のAPIと構造体を通じて設定を行う。\nID3D12DebugCommandList1::SetDebugParameter() typedef struct D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS { UINT MaxMessagesPerCommandList; D3D12_GPU_BASED_VALIDATION_SHADER_PATCH_MODE DefaultShaderPatchMode; D3D12_GPU_BASED_VALIDATION_PIPELINE_STATE_CREATE_FLAGS PipelineStateCreateFlags; } D3D12_DEBUG_DEVICE_GPU_BASED_VALIDATION_SETTINGS;  以下はシェーダーのパッチモードの選択である\n  NONE\nシェーダーコードにValidationコードを挿入しないモード。 CommonStatePromotionによるリソースステートの遷移をトラッキングすることができない。そればかりかGBVを混乱させる恐れがある。\n  TRACKING_ONLY_SHADERS\nリソースステートの遷移のみをチェックするためのコードが挿入される。\n  CREATE_UNGUARDED_VALIDATION_SHADERS\nGBVのValidationコードが挿入される。Validationによるエラーが検出され、無効なリソースに対するアクセスや範囲外アクセスがあっても該当コードを実行する。結果、DEVICE_REMOVEDなどを引き起こすかもしれない。これがデフォルトのシェーダーパッチモード。\n  CREATE_GUARDED_VALIDATION_SHADERS\nGBVのValidationコードが挿入される。Validationによるエラーが検出された場合は、該当のリソースアクセスを避ける。\n  PipelineStateCreateFlagsでは、事前にPatchされたPSOを生成するかどうかを制御できる。 デフォルトでは、パッチがあてられたPSOの初回使用時にコンパイルされる挙動なので、CommandListのRecordingが遅くなる。FRONT_LOADを設定することで予めコンパイルされる設定になる。\n以下はGBVによって検出されたエラーの一例。UAVの範囲外にシェーダーがアクセスしたことで出力された。この種のバグは、CPU側のDebug Layerでは検出できないが、GBVならば検出できる。\nDescriptorTableのUAVに設定したUAVバッファに対する範囲外アクセス　(RootSignature1.1を使用。Range Flagは　D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTE) D3D12 ERROR: GPU-BASED VALIDATION: Draw, Resource access out of bounds: Resource: 0x000001C6F8F91A60:'DummyResource_256_bytes_UAV_buffer', Descriptor Type: UAV, Highest byte offset from view start accessed: [439737], Bytes available in view: 256. Results undefined because descriptor is declared static in root signature, which allows hardware/driver the option of converting the access to a root descriptor. Unlike descriptor heap descriptors, root descriptors do not have defined behavior for an out of bounds access. Index of Descriptor Range: 1, Shader Stage: PIXEL, Root Parameter Index: [0], Draw Index: [0], Shader Code: \u0026lt;debug info not available\u0026gt;, Asm Instruction Range: [0xbc-0xdf], Asm Operand Index: [2], Command List: 0x000001C6F8E6DA10:'MyCommandList_Direct', SRV/UAV/CBV Descriptor Heap: 0x000001C6F8D8AB60:'Unnamed ID3D12DescriptorHeap Object', Sampler Descriptor Heap: \u0026lt;not set\u0026gt;, Pipeline State: 0x000001C6F8BC81B0:'Unnamed ID3D12PipelineState Object', [ EXECUTION ERROR #1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS]  ここで、GBVの話から少しそれるが、このエラーについて詳しく考えてみたいと思う。また、これらの出来事は私のローカル環境で観測されたに過ぎないことも明記しておく。 上記のエラーメッセージを要約すると以下の通りと思われる。\nリソースへの範囲外アクセス。リソース：`ummyResource_256_bytes_UAV_buffer` デスクリプタタイプ:UAV 最高でオフセット[439737]にアクセスした。Viewでアクセス可能なのは 256. アクセスの結果は未定義です。なぜなら、デスクリプタはRootSignatureで`static`として宣言されており、ハードウェアやドライバーはこの（メモリ）アクセスをルートデスクリプタにコンバートする選択肢が許されているからです。 デスクリプタヒープのデスクリプタと異なり、ルートでスクリプタには範囲外アクセスの挙動の定義がありません。  このUAVはDescriptorTableに定義したが、RangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DATA_STATIC_WHILE_SET_AT_EXECUTEを設定した。このフラグが設定されたものはドライバーの最適化対象になる可能性があり、RootDescriptor（RootTableに直接定義するDescriptor）にコンバートされる可能性がある。 実際にコンバートされた場合は、範囲外アクセスは未定義動作となるので、エラーになっているという訳である。しかし、実際はリソースのアクセス範囲チェックがされていた（つまり、RootDescriptorへのコンバートは行われていなかった）ので、DEVICE_REMOVEDが発生するような致命的な事態にはならなかった。\n次に、このUAVが設定されているDescriptorTableのRangeFlagに、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定するとどうなるかというと、エラーが全く出力されなくなった。これは、DirectXの仕様として、RootSignature1.1のDescriptorTableに定義されたUAVで、D3D12_DESCRIPTOR_RANGE_FLAG_DESCRIPTORS_VOLATILEを設定された場合、もしくはRootSignature1.0で定義されたUAVの場合は、リソースアクセスの範囲チェックが行われる決まりがある。範囲外の読み出しはゼロを返され、範囲外への書き込みは行われない。DirectXの仕様に則った動作なのでエラーが発生しないというわけである。\n次は、DescriptorTableを介さずに、直接RootTableにUAVを定義して、範囲外アクセスを起こすと以下のメッセージが出力された。\nRootTableに設定したUAVバッファに対する範囲外アクセス D3D12 ERROR: GPU-BASED VALIDATION: Draw, Root descriptor access out of bounds (results undefined): Resource: 0x000001A7600AF410:'DummyResource_256_bytes_UAV_buffer', Root Descriptor Type: UAV, Highest byte offset from view start accessed: [803581], Bytes available from view start based on remaining resource size: 256. Shader Stage: PIXEL, Root Parameter Index: [1], Draw Index: [0], Shader Code: \u0026lt;debug info not available\u0026gt;, Asm Instruction Range: [0xc8-0xeb], Asm Operand Index: [2], Command List: 0x000001A75F82C5B0:'MyCommandList_Direct', SRV/UAV/CBV Descriptor Heap: 0x000001A75F9DEA70:'Unnamed ID3D12DescriptorHeap Object', Sampler Descriptor Heap: \u0026lt;not set\u0026gt;, Pipeline State: 0x000001A75FDC5DE0:'Unnamed ID3D12PipelineState Object', [ EXECUTION ERROR #961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS] さらに、DEVICE_REMOVED発生した。 D3D12: Removing Device. D3D12 ERROR: ID3D12Device::RemoveDevice: Device removal has been triggered for the following reason (DXGI_ERROR_DEVICE_HUNG: The Device took an unreasonable amount of time to execute its commands, or the hardware crashed/hung. As a result, the TDR (Timeout Detection and Recovery) mechanism has been triggered. The current Device Context was executing commands when the hang occurred. The application may want to respawn and fallback to less aggressive use of the display hardware). [ EXECUTION ERROR #232: DEVICE_REMOVAL_PROCESS_AT_FAULT]  先ほどとエラーメッセージが異なり、エラーのIDが異なるので注意が必要である。以上の出来事をまとめると以下の様になる。\n DescriptorTableに定義した場合\n#1005: GPU_BASED_VALIDATION_RESOURCE_ACCESS_OUT_OF_BOUNDS\nこちらのエラーは、VOLATILEでないDescriptorTableに定義されたリソースに対する範囲外アクセスで発生したエラー。 ハードウェアやドライバーが、範囲外アクセスを未定義動作にすることが許されている状態だが、実際に範囲外アクセスをするかは実装次第。 RootTableに直接定義した場合\n#961: GPU_BASED_VALIDATION_ROOT_DESCRIPTOR_ACCESS_OUT_OF_BOUNDS\nこちらは、DescriptorTableではなく、RootTableに定義されたリソースの範囲外アクセスで発生したエラー。 RootTableにUAVやSRVを定義した場合、リソースのサイズは格納されない事が知られており、通常は範囲外アクセスへのチェックも行われない事が知られている。しかし、GBVを有効にすることでこれらの範囲外アクセスがValidatorにより検出され、 エラーが出力されたという状態。  このように、エラーメッセージから学べる事もあるので、Debug LayerやGBVを有効にするのはおすすめである。\nDebug Layerのその他の機能 Synchronized Command Queue Validation Debug Layerを有効にすることで、Synchronized Command Queue Validationという機能がでデフォルトで有効になる。 この機能によって、FenceのWaitが設定されたコマンドリストにおいて、Waitの条件が満たされるまで、GPUへのコマンド送出をしなくなる。 これにより、Waitが設定されている以降のコマンドにおけるリソースステートをCPU側でも確認することができ、結果として、コマンド送出時にリソースステートのValidationをより厳密に行う事ができる。 Disableにすることによって、FenceのSignalとWaitを多用したQueueの組み立てをしている場合に限り、Debug Layer使用時の若干のパフォーマンス向上が期待できるが、そもそもDebug Layerはパフォーマンスを追求するためのものでは無いのでDisableにするメリットは殆どない。\nDebugDevice / DebugCommandQueue / DebugCommandList Debug Layerが有効な状態では、Device, CommandQueue, CommandListからQueryInterfaceすることで、表題のインターフェースが取得できる。 主な機能は以下の通り。\n ID3D12DebugDevice::ReportLiveDeviceObjects()\n現在有効なオブジェクトをデバッグ出力ストリームに出力する。 ID3D12DebugCommandList::AssertResourceState()\nリソースのステートが、呼び出し引数に与えたステートと等しいかを返す。\nCommon State Promotionを使う場合は、これでState PromotionやDecayの確認をするとデバッグしやすい。 ID3D12DebugCommandQueue::AssertResourceState()\nリソースのステートが、呼び出し引数に与えたステートと等しいかを返す。\nCommandQueuから直接リソースを操作するAPIがある関係上、CommandQueuからもリソースのステートが確認できる。  Device Removed Extended Data 1.2  Device Removed Extended Dataとは、実際にDEVICE_REMOVEDが発生した後に、発生のより詳しい状況を知るための機構である。通常はDEVICE_REMOVEDが発生しても、得られる情報はせいぜいHRESULTのエラーコードぐらいで、デバッグの指標となる情報はほとんどない。しかし、DREDを活用すれば、DEVICE_REMOVEDが発生した時にGPUが実行していたコマンドや、原因となったメモリアクセスについて知ることができる場合がある。 Debug Layerとは機能的に独立しているので、使用にあたりDebug Layerを有効にする必要はない。また、Debug Layerほど処理オーバーヘッドが大きくないので、常時有効にしてアプリケーションを開発することができる。 以下は、DREDの主要機能を有効にするためのコードスニペットである。DRED自体はWindowsSDKの10.0.18362.1より使用可能だが、一部重要な機能が未実装なので、WindowsSDKの10.0.19041.0以後の導入とWindows10 20H1の導入を推奨する。\n// Try enabling DRED even in release code { ComPtr\u0026lt;ID3D12DeviceRemovedExtendedDataSettings1\u0026gt; d3dDredSettings1; if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(\u0026amp;d3dDredSettings1)))) { // Turn on AutoBreadcrumbs and Page Fault reporting d3dDredSettings1-\u0026gt;SetAutoBreadcrumbsEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON); d3dDredSettings1-\u0026gt;SetBreadcrumbContextEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON); d3dDredSettings1-\u0026gt;SetPageFaultEnablement(D3D12_DRED_ENABLEMENT_FORCED_ON); } }  Auto BreadcrumbsとBreadcrumb Contextについて Breadcrumbsは、パンくずのことで、所謂通ってきた道を見失わないためにパンくずを撒きながら森の中を歩いた童話にちなんでいる。Auto Breadcrumbsは、明示的にAPIを呼び出してパンを撒かなくても自動的に道標なるイベント（D3D12のAPI呼び出し）を自動的に記録するための機能である。 Auto Bredcrumbsが記録するのは、基本的には、CommandListを介して実行するコマンド群である。詳細は D3D12_AUTO_BREADCRUMB_OP enumerationで確認できる。 そして、DEVICE_REMOVEDが発生する直前に実行したメソッドを指し示すことで、DEVICE_REMOVEDが発生した瞬間にGPUが実行していたオペレーションが分かる仕組みになっている。\nしかし、Auto Bredcrumbsは実行したコマンドの種類を記録するだけなので、連続する一連のDrawなどでは、実際にどのDraｗコールが問題を引き起こしたか分からない。 Breadcrumb Contextは、Auto Breadcrumbによって記録されたオペレーションに関連する情報を記録した文字列が取得できるDRED1.2で導入された新しい機能である。 具体的には、Pixのマーカーがセットされた場合は、そのマーカーの文字列が記録される。これにより、大幅にレンダリング箇所の特定が行いやすくなった。\nGPU Page Faultについて GPU Page Faultは、GPU上で発生する不正なメモリアクセスで、これが発生するとDEVICE_REMOVEDとなる。DREDはGPU Page Faultの情報を記録する。まずはGPU Page Faultを理解するためにGPU仮想アドレス空間について簡単に説明する。\nGPU仮想アドレス空間について  GpuMmuは、WDDM2.0(Windows Display Driver Model 2.0)でサポートされている、主にディスクリートGPU（VRAMとシステムメモリが物理的に独立しているGPU）のための 仮想アドレスモデルである。このモデルでは、プロセスごとに、GPU仮想アドレス空間がCPUの仮想アドレス空間とは別に存在して、物理アドレスに変換するためのMMUも、CPUのMMUとは別に存在している。 GPU仮想アドレス空間は、その名の通りGPU上で実行されるシェーダー等からメモリアクセスをする際に使用されるアドレス空間である。CPU側(D3D12APIやドライバー)でのリソース確保や解放によって、物理メモリが確保または破棄されて、アドレス変換テーブルが更新される。 アドレス変換テーブルが更新される際にはGPU側と同期して、GPU側と同じアドレス変換情報を共有することで、GPU上での仮想アドレスにおけるメモリアクセスを実現している。 図にある通り、物理リソースへのアクセスはアドレステーブルによる変換を介して行う。また、マップされるメモリは、VRAMでもSysMemでも構わない。GPUはどちらに配置されているリソースでも、透過的にアクセスすることができる。\nGPU Page Faultが起きるケース GPUがPage Faultを起こすのは、アクセスが許されないページにアクセスした場合や、そもそもメモリがマッピングされていないアドレスにアクセスした場合である。主に具体的なケースとして考えられるのは、以下の通りである。\n DrawcallやDispatch,Copy処理などにおいて、すでに破棄したリソースを参照した場合。 DrawcallやDispatch,Copy処理などにおいて、Evictしたリソースや、Non-Regidentなタイルリソースを参照した場合。 DrawcallやDispatchで、未初期状態のDescriptorTableや、誤ったDescriptorTableを参照した場合。 DrawcallやDispatchで、可変長のDescriptorTableで、シェーダーが実際に配置されているテーブルの範囲を逸脱してアクセスした場合。 DrawcallやDispatchでRootTableに配置したUAVやSRVに対して誤った範囲でアクセスした場合。  GPU Page Faultで得られる情報について DREDは、PageFaultが発生したアドレス空間に確保されているオブジェクトが有れば、そのオブジェクト名（SetNameで付けた名前）が記録される。 またAllocationTypeとして、そのアドレス空間に配置されたオブジェクトが、 どのような種類であるかを知ることができる。 また、そのアドレス空間を使っていて、直近で解放されたリソースがあれば、そのリソースの情報が取得できる。これは、解放されたリソースに対して、シェーダー等がアクセスした場合に発生するPage Faultを知るのに特に有用である。 しかし、GPU Page Faultはあくまで、GPU仮想アドレス変換時のエラーでしかないので、アクセスしたアドレスに有効なページがあればアクセス自体が成立するため、GPU page faultにならない。したがって、すべての不正アクセスを検出するわけではない。 たとえば、EvictしたリソースはVRAMが特に逼迫した状況になるまではリソースのページアウトが起きないため、そのままVRAM上に配置されていることが多い。結果Page Faultも起きない上に、正しくレンダリングされるため、問題に気づけない。\nDREDで得られる情報で何が分かるか DREDは、一見するとDEVICE_REMOVEDの発生原因についての十分な情報を提供してくれるように思えるが実際は違う。 AutoBreadCrumbは、エラーが発生していた時に実行していたコンテキストに過ぎず、実際にエラーの原因がその中にあるとは限らない。 Page Faultも同様で、Page Faultは発生した一つのアクセス例外に過ぎず、何がアクセス例外の原因となったかは分からない。たとえば、それが古いDescriptor Tableを参照したことによるのか、 破損したDescriptor Tableを参照したことによるのか、参照しているリソースを開放してしまったことによるのかは分からない。\nしかし、DEVICE_REMOVEDが頻発する状況下では、DREDで複数のクラッシュの情報を集約することは非常に有効である。例えば、もしも、PageFaultがいつも同じリソースとアドレスで発生するとしたら、 プログラムのロジックが安定的な間違いを犯している可能性が高いと考えられる。また、そうではなく、PageFaultがいろいろなリソースやアドレスで発生するとしたら、リソースやDescritorTableを管理しているスレッドと GPUの実行コンテキストのレースコンディションを調べる価値があると考えられる。AutoBreadCrumbも同様で、毎回同じドローコールでDEVICE_REMOVEDが発生しているならば、 該当ドローコールのロジックや、実行分岐制御に関わる変数やリソースを調べるべきだが、異なるドローコールでランダムにDEVICE_REMOVEDが発生するならば、コマンドリストの破損の可能性が考えられる。\n以下はCommandList作成時には存在していたTextureがExecuteCommandListsの前に解放された場合に発生するGPU Page Faultによって発生した、DEVICE_REMOVEDの際に取得できたDREDの情報である。なお、DREDの情報はデバッグ出力ストリームに自動的に出力されないので、 自身でデータにアクセスして、何らかの形で表示する必要がある。\nDXGI_ERROR_DEVICE_HUNG The GPU will not respond to more commands, most likely because of an invalid command passed by the calling application. ==== Auto Breadcrubs ==== QueueNameW: MyCommandQueue QueuePtr: 0x2bad9c40330 BreadcrumbCount: 0 BreadcrumbContextsCount: 0 LastBreadcrumbValues: 0 ==== Auto Breadcrubs ==== QueueNameW: MyCommandQueue QueuePtr: 0x2bad9c40330 CommandListNameW: MyCommandList_Direct CommandListPtr: 0x2bad9e379f0 BreadcrumbCount: 7 BreadcrumbContextsCount: 3 LastBreadcrumbValues: 5 0|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|==Frame Start== 1|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Set viewport and render targets 2|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER 3|D3D12_AUTO_BREADCRUMB_OP_CLEARRENDERTARGETVIEW 4|D3D12_AUTO_BREADCRUMB_OP_SETMARKER|Draw - Triangle \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;Something wrong happned here...\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 5|D3D12_AUTO_BREADCRUMB_OP_DRAWINSTANCED 6|D3D12_AUTO_BREADCRUMB_OP_RESOURCEBARRIER ====Page fault information ==== PageFaultGPUVA: 0x70fc000 ==Existing Allocation Node Info ==Recent Freeed Allocation Node Info ObjectNameW: DummyResource_256_bytes_UAV_buffer AllocationType: D3D12_DRED_ALLOCATION_TYPE_RESOURCE IUnknownPtr: 0x0x2bad9e8f9c0 D3D12app.exe has triggered a breakpoint.  Dump File について DREDの情報はユーザーモードダンプからも抽出することができる。まずは、 プロセスがCrashした際に、FullDumpが作られる様に事前に設定し、ダンプファイルをwindbgで読み込む。 windbg.exeはWindows10のSDKに同梱されている。通常は、\u0026ldquo;C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe\u0026quot;に配置されるはずである。 そこで、 MicrosoftがGitHubで公開しているスクリプトを読み込むことで、DREDの情報に容易にアクセスできる。 手順は該当のリポジトリでも確認できるが非常に簡単である。プロセスがクラッシュした際のフルダンプを読み込み、以下のコマンドを実行するだけである。\n.scriptload \u0026lt;\u0026lt;path to script file\u0026gt;\u0026gt;\\d3ddred.js !d3ddred  以下が、Windbg上で実際にDRED情報を表示した例である。取得できる情報は、DREDのAPIで取得できる情報と同一である。\n  Windbg上で、DRED1.2の情報を確認する   最後に これら全てを駆使しても簡単に判明しないDEVICE_REMOVEDも存在すると思うが、DEVICE_REMOVEDを手さぐり的に解決する時代は終わりを迎えようとしていると言えると思う。\n","date":1599210000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599210000,"objectID":"a9db3b9f69d28f3162320077074647b1","permalink":"https://shikihuiku.github.io/post/cedec2020_prescriptions_for_deviceremoval/","publishdate":"2020-09-04T18:00:00+09:00","relpermalink":"/post/cedec2020_prescriptions_for_deviceremoval/","section":"post","summary":"CEDEC2020のショートセッションで説明しきれなかった部分についての補足資料になります","tags":["DX12","Debug Layer","GBV","DRED"],"title":"Device Removalの処方箋 - 補足資料","type":"post"},{"authors":[],"categories":[],"content":"HLSLのWave Intrinsicsについて Wave Intrinsicsは、HLSLのShader Model6.0から導入された新しい組み込み関数群です。 従来の他のHLSL組み込み関数が、単一スレッド内での変数のみを動作の対象するのに対して、 Wave Intrinsicsは、Waveと呼ばれる複数のスレッド間でのデータの交換や演算を行うための組み込み関数となります。 従来は、Compute Shaderなどで、他のスレッドの変数（演算用のレジスタ）が保持する値を参照するには、groupsharedで宣言された変数やUAVなどで宣言されたバッファーに情報を一旦ストアする必要があったうえ、スレッド間の同期命令が必要でした。 Wave Intrinsicsは、Wave内のスレッド間に限定されますが、他のスレッドの変数（演算用のレジスタ）の値を参照したり演算することが出来ます。 これにより、スレッド間のレジスタ空間の共有が可能になり、複数のスレッドで協調的に動作するシェーダーコードが、より記述しやすくなりました。 また、Wave内は命令実行のタイミングが同じであることが（論理上において）保証されていることから、スレッド間同期命令を必要としないのも大きな利点です。 一点注意が必要なのは、Wave IntrinsicsはShader Model 6.0以上に存在する組み込み関数ですが、実際に使用できるかどうかは、ID3D12Device::CheckFeatureSupport()で、D3D12_FEATURE_D3D12_OPTIONS1を調べる必要があります。\n用語 ここではWave Intrinsicsに関連する用語を説明します。\nWave NVIDIAの用語で\u0026quot;warp\u0026quot;とよばれ、AMDの用語では、\u0026ldquo;wavefront\u0026quot;と呼ばれてきたものです。命令発行が、同時に行われれるスレッドのグループのことです。\nLane Waveを構成する個々のスレッドを指します。\n以下の図は、一つのWaveの中に32Lane分のスレッドが存在する場合の図になります。この図式を使って様々なWave Intrinsicsについて説明していきたいと思います。   WaveとLane   Inactive Lane Waveを構成する個々のスレッドのうち、命令を実行しないスレッドを指します。\nActive Lane Waveを構成する個々のスレッドのうち、命令を実行するスレッドを指します。\n以下の図は、左側のシェーダーコードの実行に伴って変化する、Active LaneとInactive Laneの変化の例を表した図です。右側の3 Laneは、スレッド起動数等の初期条件によるInactive Laneです。 Pixel ShaderやCompute Shaderで必要とされるスレッド数が、Waveの倍数でなかった場合は、Inactive Laneの存在するWaveが起動されます。このようなInactive Laneは、状態が動的に変更されることは無く、終始Inactive Laneのままです。 3行目のIf()による分岐の条件を満たさなかったLaneは、If()ステートで囲まれたコードブロックが終了するまでInactive Laneとなります。Wave内では命令実行は暗黙的に同期する決まりになっているので、Inactive Laneはその間なにも実行せず、他のLaneが該当コードブロックの実行を完了するまで待ちます。 図にはありませんが、If()ステートのコードブロックの実行が終了すれば、条件分岐によってInactive Laneとなったスレッドは、再びActive Laneへと復帰します。\n  Active LaneとInactive Lane   Quad 先頭から連続する4Lane分づつのスレッドのグループを指します。特にPixel Shaderでは、RenderTargetにおける2x2ピクセルブロックが一つのQuadにアサインされます。 Pixel Shaderにおけるddx/ddyなどのGradient命令や、テクスチャーのLoDの計算は、Quad内の変数の差分によって実現されており、Gradientの計算のみに寄与してPixelを塗らないLane（スレッド）をHelper Laneと呼びます。\n以下の図は、とあるプリミティブをレンダリングする際の、QuadとHelper LaneのRenderTarget上での表現とWaveとしての表現の対応図です。\n  QuadとHelper Lane   Waveのサイズについて Wave Intrinsicsを使う上で、Waveのサイズというは非常に重要なファクターで、これを理解すること無しに、効率的な処理をデザインすることは難しいと思います。 NVIDIAのWarpは、伝統的に32 Lane/Waveです。対して、AMDのGCNアーキテクチャは64 Lane/Waveで動作しています。 同じくAMDのRDNAアーキテクチャは、Wave32とWave64の二つの動作モードを持ち、それぞれが、32, 64 Lane/Waveで動作しています。 どちらのモードでシェーダーが実行されるかは、ドライバーが決定するようなので、シェーダーは両モードで正しく動く必要があります。結局のところ、32 Lane/Wave、64 Lane/Waveの両方をサポートすることができれば、NVIDIA, AMDの両GPUに対応したアプリケーションとなるはずです。\n  32 Lane/Waveと64 Lane/Wave   ID3D12Device::CheckFeatureSupport()のD3D12_FEATURE_D3D12_OPTIONS1では、Wave Intrinsicsの使用の可否についてとともに、使用される可能性のあるWaveのサイズの上限値と下限値が返されます。 したがって先のRDNAの様に、単一のアーキテクチャでも、Waveのサイズは可変であると考える必要があるのかもしれません。しかし、WaveのサイズのAPI仕様としての上限値と下限値である 4 と 128 はあまりにもかけ離れているため、Waveのサイズに依存するコードを記述する際に、すべてのWaveのサイズをサポートすることは非現実的です。また、実際には使用されないWaveのサイズのためにコードを書くのも無駄だと思います。したがって、現実的な実装方法としてはD3D12_FEATURE_D3D12_OPTIONS1でWaveのサイズの上限値と下限値をチェックし、32と64の範囲ならば、Wave Intrinsicsを使ったシェーダーコードを使用し、そうでない場合はWave Intrinsicsを使用していないフォールバックのシェーダーコードを実行するか、エラーを出力して動作を終了するべきだと思います。\nWaveのサイズは、WaveGetLaneCountというWave Intrinsicsを使って取得できます。しかし、これは裏を返せば、D3D12_FEATURE_D3D12_OPTIONS1のWaveの上限値と下限値に幅がある場合は、HLSLのシェーダーコードを実行するまで、Waveのサイズが分からないという事になります。（これはAPIのデザインの問題だと思います。）\nWaveのサイズとThread Groupのサイズについて Wave Intrinsicsは、あくまでWaveのサイズを基準とした動作になっていて、Compute Shaderのnumthreadsの大きさは、Waveのサイズとは関係ありません。ただし、Wave Intrinsicsを使う場合は、numthreadsの大きさはWaveのサイズを意識したものが良いと思います。 WaveのThread Group内でのマッピングは、Row Oriented　(X軸優先）です。（ただし、これを明記しているドキュメントが見当たらなかったので注意が必要です。）numthreadsの大きさが、Waveのサイズの倍数でなかった場合は、シェーダーが実行される前からInactive Laneが存在するWaveが起動されます。この場合、Waveのサイズ分のスレッドがすべて動作していることを前提として記述されたシェーダーは、動作が破綻するので注意が必要です。 現状では、ID3D12Device::CheckFeatureSupport()のD3D12_FEATURE_D3D12_OPTIONS1の返すWaveのサイズの上限値の倍数をnumthreadsの大きさとすることで、このような事態を回避する事ができると思います。\n  numthreadとWave   PixelShaderとWave Intrinsicsについて （これも明記しているドキュメントが見当たらなかったので注意してください）\nPixel Shaderでは、すべてのWave Intrinsicsの使用が許されています。しかし、Pixel Shaderにおける描画ピクセルとWaveやLaneの対応は、描画されるプリミティブの位置と、GPUとドライバー、そしてPixel Shaderのソースコードによって決まると考えられます。 シンプルな例では、ピクセルシェーダーのスレッドは描画されるプリミティブのピクセルと一対一の関係で起動されると思います。ただし、ピクセルシェーダー内で、Gradinet命令（ddx/ddy）を使用したり、テクスチャーのサンプリングにおいて、LoDを明示的に指定しなかった場合は、スレッド間の値（テクスチャサンプリングにおいてはUV値）の差分を計算する必要があるため、起動されるスレッドは2x2ピクセル単位となります。そして、プリミティブとして描画されるピクセルを担当しているスレッドのみがRenderTargetへの出力を行います。残りのスレッドは、Helper Laneとなり、スレッドとして動作しますがRenderTargetへの出力を行いません。 プリミティブの描画においては、必要なスレッド数は必ずしもWaveのサイズの倍数とならないので、シェーダー内で条件分岐を行っていない状態でも、Inactive Laneが存在しているWaveが起動される可能性があります。また、複数のプリミティブが同一のWaveにパッキングされる可能性もあります。Pixel Shader内でWave Intrinsicsを使う場合は、これらの点について考慮する必要があると思います。\n  QuadとHelper Lane   Shader Model 6.0のWave Intrinsicsについて Shader Model 6.0のWave Intrinsicsは以下のカテゴリに分類することができます。\n Wave Query\nWaveやLaneの状態取得 Wave Vote\nWave内でのbooleanステート確認 Wave Broadcast\nWave内で特定のLaneの変数値の取得 Wave Reduction\nWave内での変数の演算 Wave Scan and Prefix\nWave内での変数の演算(自身より小さいLane Indexに限る) Quad-wide Shuffle operations\nQuadを動作対象とした、変数値の取得  Wave Query WaveのLane数と、Lane Indexを調べるためのIntrinsicsです。\n加えて、Wave内で自身が先頭のActive Laneかどうかを返す、WaveIsFirstLaneが含まれます。\nWaveGetLaneCount WaveのLaneの数を返します。全てのLaneで同じ値を受け取ります。   WaveGetLaneIndex Wave内での該当LaneのIndexを返します。個々のLaneで異なる値を受け取ります。   WaveIsFirstLane bool値を返します。ActiveLaneの中で最小のLane IndexのLaneのみtrueが返されます。残りのLaneはfalseが返されます。   Wave Vote Wave内の他のActive Laneのboolのステータスを確認するためのIntrinsicsです。\nWaveActiveAnyTrue 引数にbool値を指定します。そして、いずれかのActive Laneがtrueを渡せば、全てのActive Laneにtrueが返されます。そうでない場合は、全てのActive Laneにfalseが返されます。\n  WaveActiveAllTrue 引数にbool値を指定します。全てのActive Laneがtrueを渡せば、全てのActive Laneにtrueが返されます。そうでない場合は、全てのActive Laneにfalseが返されます。\n  WaveActiveBallot 引数にbool値を指定します。戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneが渡したbool値をビットマスクとして返します。Inacive Laneは暗黙的に0が設定されます。\n  Wave Broadcast Wave内で、特定のLaneの変数の値を、すべてのActive Laneで取得するためのIntrinsicsです。\nWaveReadLaneAt 引数に、読み取りの対象となる変数とLane Indexを指定します。Lane Indexで指定されたLaneの、引数で指定された変数の値を、全てのActive Laneに返します。引数で指定した変数の型と同じ型が返されます。\n他にも、引数に指定した変数の型と同じ変数型を返すタイプのWave Intrinsicsがありますが、これらはベクトル型を含め、組み込み型の整数型と浮動小数点型の殆どがサポートされています。\n  WaveReadLaneFirst 引数に、読み取りの対象となる変数を指定します。Active Laneの中で、最小のLane IndexのLaneの、引数で指定された変数の値を、すべてのActive Laneに返します。\n  Wave Reduction Wave内でのActive Laneの変数の値を用いて演算するためのIntrinsicsです。一つの演算結果がすべてのActive Laneに返されます。\nWaveActiveAllEqual 引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値が等しい場合のみTrueを返します。\n  WaveActiveBitAnd 引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise AND(論理積)を演算した結果を返します。\nWaveActiveBitOr 引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise OR(論理和)を演算した結果を返します。\nWaveActiveBitXor 引数に、読み取りの対象となる整数型の変数を指定します。すべてのActive Laneの変数の値のBitwise XOR(排他的論理和)を演算した結果を返します。\n  WaveActiveCountBits 引数に、boolを指定します。引数にtrueを指定したLaneの数を、すべてのActive Laneに返します。\n  WaveActiveMax 引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最大値を、全てのActive Laneに返します。\nWaveActiveMin 引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値の中で、最小値を、全てのActive Laneに返します。\nWaveActiveProduct 引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数をの値を乗算した結果を、全てのActive Laneに返します。 演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。\nWaveActiveSum 引数に、読み取りの対象となる変数を指定します。すべてのActive Laneの変数の値を加算した結果を、全てのActive Laneに返します。 演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。\n  Wave Scan and Prefix Wave Reduction系に似ていますが、演算の対象が自身のLane Index未満のActive Laneのみです。自身のLaneは演算の対象に含みません。 演算の結果は、基本的にはLaneごとに異なる値が返されることになります。\nWavePrefixCountBits 引数にboolを指定します。自身のLane Index未満のActive Laneで、引数にtrueを指定した個数を返します。\nWavePrefixSum 引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を加算した結果を返します。 演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。[precise]フラグは無視されます。\nWavePrefixProduct 引数に、読み取りの対象となる変数を指定します。自身のLane Index未満のActive Laneの、変数の値を乗算した結果を返します。 演算の順序については、API仕様としての明確な定義が無いので、扱う変数の型や、値の範囲について注意が必要です。[precise]フラグは無視されます。\n  Quad-wide Shuffle operations Pixel Shaderでのみ使用可能なWave Intrinsicsです。 (これについては、2020/08現在ドキュメントの表記と実装に食い違いがあります。ドキュメントにはCompute Shaderでも使用可能と表記されており、その場合、Lane Indexの0より4 Laneごとに区切ったLaneがQuadとして扱われるとされています。 しかし実際には、Quad系を使用したCompute Shaderのコンパイル時にopcode 'QuadReadAcross' should only be used in 'Pixel Shader'というメッセージが出力されます。そして、シェーダーの生成にも失敗します。)\nQuadReadLaneAt 引数に、Quad内のローカルのLane Indexと、読み取り対象となる変数を指定します。Quad内で同じ値が返されます。 読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。 Pixel ShaderにおけるQuad内のローカルのLane Indexは、下図に示した通りRow Orientedとなっています。\nQuadReadAcrossDiagonal 引数に、読み取り対象となる変数を指定します。Quad内で互いに対角の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。) (APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)\nQuadReadAcrossX 引数に、読み取り対象となる変数を指定します。Quad内で互いに水平の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:1の値を受け取ります。) (APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)\nQuadReadAcrossY 引数に、読み取り対象となる変数を指定します。Quad内で互いに垂直の位置にあるLaneの値を読み取ります。(例えば、Lane:0はLane:3の値を受け取ります。) (APIドキュメントに明記がありませんが、読み取り対象LaneがInactive Laneだった場合の読み取り結果は未定義なので注意が必要です。)\n  Shader Model 6.5のWave Intrinsicsについて Model 6.5で、いくつかの新しいWaveIntrinsicsが導入されています。\nWaveMatch 引数に、読み取り対象となる変数を指定します。\n戻り値にuint4を返します。戻り値のuint4は、128bit-wideのビットマスクとなっており、各Active Laneの引数で指定された変数の値が、自身のLaneの変数の値と等しい場合に、ビットがセットされます。Inacive Laneは暗黙的に0が設定されます。\n  WaveMultiPrefixSum 引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなる uint4 を指定します。\nWaveActiveSumと動作は似ていますが、加算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。 ビットマスクは、Laneごとに設定を変更出来ますが、一つのLaneは1種類のビットマスクにしか所属する事ができません。 つまり、ビットマスクによって、Laneをパーティショニングしてサブセット化する事が出来ますが、各々のLaneが完全に自由にビットマスクを指定できるわけではありません。一つのLaneが複数の種類のビットマスクに所属した場合の動作は未定義です。\nWaveのサイズを超えるBitやInactive Laneのビットは無視されます。(ビットがゼロとして扱います。) このビットマスクの仕様は他のWaveMultiPrefix系と共通です。\n  WaveMultiPrefixProduct 引数に、読み取り対象となる変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。\nWaveActiveProductと動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。\nWaveMultiPrefixCountBit 引数に、bool値を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。\nWaveActiveCountBitと動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。\nWaveMultiPrefixAnd 引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。\nWaveActiveBitAndと動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。\nWaveMultiPrefixOr 引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。\nWaveActiveBitOrと動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。\nWaveMultiPrefixXor 引数に、読み取り対象となる整数型の変数を指定します。また、引数に128bit-wideのビットマスクとなるuint4を指定します。\nWaveActiveBitXorと動作は似ていますが、乗算の対象となるLaneがビットマスクで指定されたLaneに限定される点が異なります。\n終わりに 今回は、Wawve Intrinsicsの動作を理解するための基本的な内容となっているので、実際の使用ケースについては言及しませんでした。 次回は、もう少し実際の利用ケースについて触れたいと思います。\n","date":1597575632,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597575632,"objectID":"d26efcbc36e3445c1245aed40fbb6ffc","permalink":"https://shikihuiku.github.io/post/wave_intrinsics1/","publishdate":"2020-08-16T20:00:32+09:00","relpermalink":"/post/wave_intrinsics1/","section":"post","summary":"Wave Intrinsicsの動作を理解しよう","tags":["D3D12","WaveIntrinsics"],"title":"HLSLのWave Intrinsicsについて","type":"post"},{"authors":[],"categories":[],"content":"動機とか タイトルの画像は、今まで運用してきたWordpress上のサイトのスクリーンショットです。記念に撮ってきました。\n別にWordpressがいやになったという訳ではないのですが、Github pagesに移行したほうが制約も少なく扱いやすい気がしたので引っ越しすることにしました。Wordpressに書いた記事は、簡単に移行するのは難しそうなので、そのままにしておきます。\nHugo＋Academic 別に十分な検討をしてこの組み合わせに至ったわけでは無く、静的サイト生成ツール＋なんか都合の良いTheme程度の認識で選択しました。今後変えるかもしれません。 ただ、コンテンツは多少特殊な要素があったとしても、基本的にMarkdownで記述できるので、今後もしサイトを移行しようと思っても、記事の移行をあきらめたくなるような事はないのではないでしょうか。\n導入手順 せかっくなので自分なりの導入手順を記しておきます。環境はWindows10を使用しています。Hugoは導入済です。\nAcademicの導入 まず、Hugoのテーマとして、Academicを導入しようとして、以下の様にファイルを配置しましたが、上手くいきませんでした。\ngit submodule add https://github.com/gcushen/hugo-academic.git themes/academic   Academicのドキュメントを参照すると、Hugoの新規サイトの状態に加えて、いろいろなファイルが正しい位置に配置されている必要があるようで、 academic-kickstart.gitをクローンすることがおすすめのようです。 初めはプライベートリポジトリとして扱いたいですし、リポジトリの名前も変えたいので、cloneしてmirrorします。\ngit clone --bare https://github.com/sourcethemes/academic-kickstart.git cd academic-kickstart.git git push --mirror https://github.com/shikihuiku/blog.git  早速ローカルで初期状態を確認しようと思ったら、ビルドエラーが出ました。\n\u0026gt; hugo server Building sites … ERROR 2020/07/25 17:30:35 render of \u0026quot;term\u0026quot; failed: execute of template failed: template: authors/list.html:5:3: executing \u0026quot;authors/list.html\u0026quot; at \u0026lt;partial \u0026quot;site_head\u0026quot; .\u0026gt;: error calling partial: \u0026quot;T:\\GitHub\\hugotest\\blog\\themes\\academic\\layouts\\partials\\site_head.html:131:56\u0026quot;: execute of template failed: template: partials/site_head.html:131:56: executing \u0026quot;partials/site_head.html\u0026quot; at \u0026lt;resources.Concat\u0026gt;: error calling Concat: resources in Concat must be of the same Media Type, got \u0026quot;text/x-scss\u0026quot; and \u0026quot;text/css\u0026quot; ERROR 2020/07/25 17:30:35 render of \u0026quot;section\u0026quot; failed: execute of template failed: template: section/publication.html:5:3: executing \u0026quot;section/publication.html\u0026quot; at \u0026lt;partial \u0026quot;site_head\u0026quot; .\u0026gt;: error calling partial: \u0026quot;T:\\GitHub\\hugotest\\blog\\themes\\academic\\layouts\\partials\\site_head.html:131:56\u0026quot;: execute of template failed: template: partials/site_head.html:131:56: executing \u0026quot;partials/site_head.html\u0026quot; at \u0026lt;resources.Concat\u0026gt;: error calling Concat: resources in Concat must be of the same Media Type, got \u0026quot;text/x-scss\u0026quot; and \u0026quot;text/css\u0026quot; ERROR 2020/07/25 17:30:35 render of \u0026quot;home\u0026quot; failed: execute of template failed: template: index.html:5:3: executing \u0026quot;index.html\u0026quot; at \u0026lt;partial \u0026quot;site_head\u0026quot; .\u0026gt;: error calling partial: \u0026quot;T:\\GitHub\\hugotest\\blog\\themes\\academic\\layouts\\partials\\site_head.html:131:56\u0026quot;: execute of template failed: template: partials/site_head.html:131:56: executing \u0026quot;partials/site_head.html\u0026quot; at \u0026lt;resources.Concat\u0026gt;: error calling Concat: resources in Concat must be of the same Media Type, got \u0026quot;text/x-scss\u0026quot; and \u0026quot;text/css\u0026quot; ERROR 2020/07/25 17:30:35 render of \u0026quot;taxonomy\u0026quot; failed: execute of template failed: template: authors/terms.html:5:3: executing \u0026quot;authors/terms.html\u0026quot; at \u0026lt;partial \u0026quot;site_head\u0026quot; .\u0026gt;: error calling partial: \u0026quot;T:\\GitHub\\hugotest\\blog\\themes\\academic\\layouts\\partials\\site_head.html:131:56\u0026quot;: execute of template failed: template: partials/site_head.html:131:56: executing \u0026quot;partials/site_head.html\u0026quot; at \u0026lt;resources.Concat\u0026gt;: error calling Concat: resources in Concat must be of the same Media Type, got \u0026quot;text/x-scss\u0026quot; and \u0026quot;text/css\u0026quot; ERROR 2020/07/25 17:30:35 failed to render pages: render of \u0026quot;section\u0026quot; failed: execute of template failed: template: section/talk.html:5:3: executing \u0026quot;section/talk.html\u0026quot; at \u0026lt;partial \u0026quot;site_head\u0026quot; .\u0026gt;: error calling partial: \u0026quot;T:\\GitHub\\hugotest\\blog\\themes\\academic\\layouts\\partials\\site_head.html:131:56\u0026quot;: execute of template failed: template: partials/site_head.html:131:56: executing \u0026quot;partials/site_head.html\u0026quot; at \u0026lt;resources.Concat\u0026gt;: error calling Concat: resources in Concat must be of the same Media Type, got \u0026quot;text/x-scss\u0026quot; and \u0026quot;text/css\u0026quot; Built in 84 ms Error: Error building site: TOCSS: failed to transform \u0026quot;main_parsed.scss\u0026quot; (text/x-scss): resource \u0026quot;scss/scss/main.scss_76ac6956597c32fec7ddf60d408db3ab\u0026quot; not found in file cache  調べてみると、Academicには、hugo_extendedが必要だという事が分かりましたので、 Hugo_extendedのビルド済バイナリをDLします。 再びローカルサーバーを立ち上げると、今回は上手くビルドできました。\nhugo server  ローカルホストのポート1313にアクセスすると、おしゃれなサイトが表示されました。BiographyやProjectsやPublicationsなど、かなりハイスペック人材向けのテンプレートで尻込みしますが、どんどん削っていくことにします。\nAcademicのカスタマイズ ここで先人の知恵をお借りします\n Hugo + Academic テーマを使ったブログの作り方 https://qiita.com/harumaxy/items/58e7e4273c61e7e260b3\n /config/_default/フォルダに格納されている以下のtomlファイルを編集していきます。\n config.toml language.toml menus.toml params.toml  その他諸々の変更を行って、シンプルにBlogのポストができるページにしました。言語設定はenのまま使用する事にします。\nフォントの設定 デフォルトでは、GoogleのWebフォントがいろいろ指定されていますが、フォントの設定はシンプルな方が良いと思っています。 フォントのプリセットにNativeという設定があり、こちらを使うとrootのfont-familyの設定を、殆どの要素で使うようになるようです。config/_default/params.tomlでこれを指定します。\n font=\u0026ldquo;Native\u0026rdquo;\n rootにある、フォントの設定はとりあえず変更せずに使ってみます。\ncustom.scssの設定 デフォルトではブラウザの横幅に対してページの表示領域が酷く狭いです。\nblog/assets/scss/custom.scssというファイルを配置することで、自身で記述したcssをページに読み込ませる事が出来るようです。生成されたHTMLの要素のクラス名を確認して適当に設定しました。なんだか横幅を変えるだけで泥臭い作業になりました。もっと簡単にスタイルを変更する方法があるかもしれません。\n/*width for top page*/ .container { max-width: 90%; } /*width for posts.*/ .article-container{ max-width:90% }  また、見出しのフォントのWeightが一定では無いので変更します。ついでにマージンも変更します。 この辺りは素人なので、あまり参考になりませんが。 しかし、CSSを書いて変更できると結局楽だなってなって思ってきました\u0026hellip;\nh1, h2, h3, h4, h5, h6 { margin-top: 1.7rem; margin-bottom: 0.3rem; font-weight: 700; }  アイコンの設定 それから、Webサイトのアイコン、所謂ファビコンがデフォルトの設定では、Academicのアイコンになっているので変更します。\nassets/images/フォルダに、解像度512x512のicon.pngを配置します。\nGithub Pagesの設定 最後に、実際にビルドされたページをGithub Pagesでホスティングする方法ですが、一番簡単な方法はHugoの出力先をdocsフォルダにして、それをそのままリポジトリにPushして、GithubPagesで公開する方法だと思います。 Hugoはデフォルトではpublicフォルダにファイルが生成されるので、これを変更します。\nconfig/_default/config.tomlに以下の様に設定することで、docsフォルダにサイトが生成されるようになります。\npublishdir= \u0026quot;docs\u0026quot;  あとは、baseurlを設定しサイトを生成してエラーがでなければOKです。リポジトリにPushして、github pagesの設定をすれば公開されます。\nGithub Pagesの設定 - やっぱりPrivateリポジトリで 構築履歴が閲覧可能な状態なのは別に構わないですし、大抵の場合はDraft記事が閲覧可能な状態でも構わないのですが、一部のCEDECセッションの補間資料とかのDraftは会期以前に公開状態になるのはまずいので、 publishしたべージのコンテンツのみを公開状態にする必要があります。結局Hugoのpublishdirのディレクトリ以下を別のリポジトリにして、こちらだけPublicに設定して、ビルド環境はPrivateリポジトリにすることにしました。\n","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595462400,"objectID":"1a9a117957ea8d71e8aeec5a04f15ce9","permalink":"https://shikihuiku.github.io/post/hello_hugo_and_academic/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/post/hello_hugo_and_academic/","section":"post","summary":"永らくWordpressでダラダラと記事をPostしてきましたが、Wordpressであることのメリットがほとんど活かせてない状況です。自分は静的サイトが作れれば十分なので、引っ越すことにしました。","tags":["Hugo","Academic"],"title":"Hugo+Academicでブログを構築","type":"post"},{"authors":[],"categories":[],"content":"この記事は、旧サイトからテスト用に移植しました。  入力遅延の問題はゲーム開発において悩ましい問題の一つです。特にPCでは、他のプロセスが勝手な都合で動作しますし、リソースの競合も発生します。また、PC本体のCPU/GPUパフォーマンスの違いも大きいです。ここでは一般的なデスクトップPC上で、フォートナイトの描画がどのように実行されているかをソフトウェアの見地から、GPUViewを用いて観測してみます。ここで言う入力遅延は、Windows上のゲームのプロセスがキーやマウスのステートを取得すると思われるタイミングから、描画された画面が、ディスプレイへの出力対象になるまでを指します。実際には、マウスやキーボードのハードウェアとドライバにも遅延がありますし、ディスプレイにも実際に輝点として可視化されるまでに遅延がありますが、これらは今回は考慮しません。またゲームのプロセスが正確にいつ入力デバイスの情報を取得しているかは考慮しません。あるフレームのCPU処理の開始を入力取得時間として考えます。\nちなみに今回使用したデスクトップPCは、Core-i7 7700KとGeForce RTX2080Tiが搭載されています。モニタは一般的な60Hzの4Kディスプレイです。\nテストに使ったシーンは、クリエイティブの島です。描画としては極めて軽い状態がテスト対象です。\nUE4の開発者の方は、すでにご存じかと思いますが、以下の資料に入力遅延に関する詳しい解説がご覧いただけると思います。\n\n UE4のスレッドの流れと Input Latency改善の仕組み  from エピック・ゲームズ・ジャパン Epic Games Japan 今回は、フォートナイトをプレイする上でどのような設定が一番自分にとって好ましいかを調べる過程で分かったことを説明していきます。フォートナイトの描画設定で、入力遅延に関係のある設定は、フレームレートの上限値、VSync、それから、マルチスレッドレンダリングです。描画APIはD3D11と12に対応していますが、D3D12にすることによる利点があまり感じられなかったため、今回はD3D11のみをテストしています。\nVSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 60   vsyncoff_mtoff_60   おなじみのGPUViewのログです。詳しく見たい方はクリックして拡大してください。まずは、スレッドのアクティビティを理解するために一番簡単な例を示します。VSyncがOffなので、青い縦線で示されたVSyncのタイミングとは全く関係なく描画されています。描画スレッドが、D3D11の描画APIを呼び出して、Present()を呼び出し、GPUが描画を完了するのとほぼ同時にフロントバッファへのFlipが行われ、ディスプレイへの表示対象になります。ドライバのスレッドに描画命令を発行しているスレッドが、UE4のRHIスレッドと思われますが、マルチスレッドレンダリングをOffにしているので、Renderのスレッドが、直接RHIを呼び出しているのではないかと思われます。それに先立ち動作しているスレッドがゲームのメインスレッドと思われます。ゲームのメインスレッドは、Render/RHIスレッドに渡す描画情報を構築するタイミングと思われるところで、フレームレートのペーシングを行っていると思われます。計測された入力遅延は、12.8msですが、CPUもGPUもアイドル時間が長いので、処理クロックを落としていると思われます。実際の場合も何も小細工しなければ、ユーザーの知らないところでクロックが下がるので、今回はこの設定の入力遅延は12ms前後と考えます。\nVSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 60 次は、先ほどの設定から、マルチスレッドレンダリングを有効にしてみます。他の設定は同じです。\n  vsyncoff_mton_60   見た目ががらりと変わっていますが、アイドリングしているWorkerスレッドにRenderと思われるスレッドが埋もれてしまったため、このような見た目になっています。実際は、どの設定でも多数のWorkerスレッドやサウンドのスレッドが立ち上げられていますが、描画に関係ないものは省略しています。先ほどの例と異なり、RHIのスレッドと思われるスレッドと、Renderと思われるスレッドが別になりました。基本的な仕組みや、遅延の状況はほぼ同じです。こちらもおそらく動作クロックが下がっているので、本来の描画パフォーマンスと比べると処理時間がかかっています。\nVSync: OFF マルチスレッドレンダリング: OFF フレームレート上限: 120   vsyncoff_mtoff_120   次は、再びマルチスレッドレンダリングをOFFに戻しました。そして、フレームレート上限を120にしてみました。基本的な動作は一番初めの例と同じですが、フレームのペーシングが8.3msになったことで、120FPSのレンダリングになりました。そして、アイドリングのデューティ比が変わったことにより、動作クロックが引き上げられた関係で、入力遅延も短縮され、9.5ms程度になりました。\nVSync: OFF マルチスレッドレンダリング: ON フレームレート上限: 120 次は、上記の設定でマルチスレッドレンダリングをONにします。   vsyncoff_mton_120   やはり、RenderスレッドとRHIスレッドが分かれました。今回のテスト対象になっているシーンは軽いので、マルチスレッドレンダリングの恩恵は少ないですが、もっと複雑なシーンでは、これらのスレッドが並列動作することにより、Renderスレッドの描画命令発行によるストールが軽減され、より顕著な差になると思われます。少なくとも遅くなることはなさそうなので、私はこの設定でプレイすることにします。\nVSync: ON マルチスレッドレンダリング: OFF フレームレート上限: 制限なし 次は、いわゆる、VSyncを守って、画面のティアリングを起こさない描画になります。見た目は一番スムーズなのですが、入力遅延の観点からはあまりお勧めできない設定となりそうです。   vsyncon_mtoff_60   まず、VSyncを取ると、メインスレッドの動作がかなり変わります。およそ2ms単位でスレッドをポーリングしながら、処理開始のタイミングを計っているようです。rhi.SyncSlackMSのデフォルト設定と思われる、VSyncの10ms前に、メインスレッドの処理を開始しています。Renderスレッドは、前の前のフレームのGPU描画処理が完了してから、RHIの呼び出しを開始しているようです。そして、RHIが呼び出すD3DAPIによって生成されたGPUタスクは、ドライバのGPUタスクキューに積み上げられます。そのフレームのGPU描画処理がGPU上で実行されるのは、Renderスレッドが動作したフレームの次の次のフレームです。そして、ディスプレイの出力対象になるFlipが行われるのは、VSyncに同期しているので、実際の表示はその次のフレームとなります。メインスレッドが動作を開始してから、ディスプレイの出力対象になるまでの入力遅延は60msほどとなります。\nまとめ 少なくとも私の環境では、VSyncをOFFにして、CPUのフレームペーシングがボトルネックになる状態（つまりGPUの処理時間には余裕がある状態）で、なるべく高いフレームレートが入力遅延が一番小さくなる状態だといえると思います。入力遅延を最短にするという目的ならば、私のPCでは、おそらく200フレーム以上の設定の方が短くなると思われます。しかし、使用しているディスプレイも60Hzですし、描画解像度など他の設定に妥協が必要になります。 また、これらの状況は、個々のPCの、CPUとGPUの処理能力のバランスによって変動するので、皆さんに一概にこの設定がおすすめですとはなりません。しかし、VSyncはOff、なるべく早いCPU、なるべく早いGPU、なるべく軽い描画が、入力遅延低減につながると思われます。\n","date":1592238782,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592238782,"objectID":"117dad02d1f9ebb737d4f2c72538fd7f","permalink":"https://shikihuiku.github.io/post/check_input_latency_of_fortnite/","publishdate":"2020-06-16T01:33:02+09:00","relpermalink":"/post/check_input_latency_of_fortnite/","section":"post","summary":"タイトルは緩いですけど、ゲーム開発者向けの話です。プラットフォームはPC限定です。","tags":["DX11","GPUView","UE4","Fortnite"],"title":"フォートナイトの入力遅延を観測してみた","type":"post"}]