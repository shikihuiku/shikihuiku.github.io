<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Direct3D | shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</title>
    <link>https://shikihuiku.github.io/tag/direct3d/</link>
      <atom:link href="https://shikihuiku.github.io/tag/direct3d/index.xml" rel="self" type="application/rss+xml" />
    <description>Direct3D</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 19 Aug 2024 19:00:41 +0900</lastBuildDate>
    <image>
      <url>https://shikihuiku.github.io/images/icon_hu127225d7ed9c50974404790b7c221374_401884_512x512_fill_lanczos_center_3.png</url>
      <title>Direct3D</title>
      <link>https://shikihuiku.github.io/tag/direct3d/</link>
    </image>
    
    <item>
      <title>Work Graph in HLSL</title>
      <link>https://shikihuiku.github.io/post/workgraph_in_hlsl/</link>
      <pubDate>Mon, 19 Aug 2024 19:00:41 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/workgraph_in_hlsl/</guid>
      <description>&lt;p&gt;基本的な機能に関する説明は割愛。自分が Work Graph を書くときに、度忘れしたときに参照するもののつもりで書いた。描画系はあとで書き足すかも。&lt;/p&gt;
&lt;h2 id=&#34;hlsl関数のattribute&#34;&gt;HLSL関数のAttribute&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[Shader(&amp;quot;node&amp;quot;)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;この属性をつけたHLSL関数は Work Graph のノードとして宣言。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeIsProgramEntry]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Work Graph のエントリポイントとなれる。つまり、Input RecordをCommand Listや外部のGPUメモリから受け取ることができる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeLaunch(&amp;quot;mode&amp;quot;)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;“broadcasting”&lt;/code&gt;&lt;br&gt;
一つの Input Record を、複数の Dispatch Grid で共有して処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“coalescing”&lt;/code&gt;&lt;br&gt;
複数の Input Redcord を、一つの Dispatch Grid で処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“thread”&lt;/code&gt;&lt;br&gt;
一つの Input Record を、一つのスレッドで処理するノードとして宣言。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;“mesh”&lt;/code&gt;&lt;br&gt;
&lt;code&gt;“broadcasting”&lt;/code&gt;ノードと同様の起動方式だが、Work Graph の末端でしか使用できない。&lt;br&gt;
Mesh shaderとして動作する。（Amplification Shader は Work Graph ではサポートされていない）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NumThreads(x,y,z)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group のサイズ。通常の Compute Shader と同じ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeDispatchGrid(x,y,z)]&lt;/code&gt; or &lt;code&gt;[NodeMaxDispatchGrid(x,y,z)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;NodeLaunch&lt;/code&gt;が&lt;code&gt;“broadcasting”&lt;/code&gt;の場合は、上記のいずれかが宣言されている必要がある。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeMaxDispatchGrid&lt;/code&gt;が宣言されている場合は、Input Record 内の&lt;code&gt;SV_DispatchGrid&lt;/code&gt;セマンティクスの変数で Dispatch Grid のサイズが指定される必要がある。&lt;br&gt;
この場合は、Disapatch Grid サイズが Input Record ごとに変更できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;,arrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;ノードとしての識別名の定義。これを省略すると、関数名がノードの識別名になる。&lt;/li&gt;
&lt;li&gt;複数のHLSL関数で、Work Graph のノード配列を定義する場合は、同一の&lt;code&gt;”nodeName”&lt;/code&gt;で、異なる&lt;code&gt;arrayIndex&lt;/code&gt;を指定する。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;arrayIndex&lt;/code&gt; は省略可能で、省略した場合は０番を宣言したとみなされる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrayIndex&lt;/code&gt; は、必ずしも連続して、隙間なく宣言されている必要はない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ノード配列として定義されるノード要素に相当するHLSL関数は、以下の項目が同一でなければならない。
&lt;ul&gt;
&lt;li&gt;Input Record の宣言&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeLaunch&lt;/code&gt;属性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeDispatchGrid&lt;/code&gt;属性、もしくは&lt;code&gt;NodeMaxDispatchGrid&lt;/code&gt;属性で定義された Dispatch Grid のサイズ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeLocalRootArgumentsTableIndex(index)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;このノードが実行されるとき、&lt;code&gt;index&lt;/code&gt;で指定した Local Root Table がバインドされる。&lt;/li&gt;
&lt;li&gt;この属性を定義しない場合や、&lt;code&gt;index&lt;/code&gt;に-1を設定した場合は、Work Graph がコンパイルされる時に自動で割り振られたインデックスがアサインされる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeShareInputOf(&amp;quot;nodeIDWhoseInputToShare&amp;quot;, optionalArrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;同一の Input Record で、異なる種類のノードを起動する場合は、同時に起動するノードには、この属性で、Input Record を共有するノードが示されている必要がある。&lt;/li&gt;
&lt;li&gt;異なる種類のノードが Input Record を共有する場合は、一つの代表する&lt;code&gt;NodeID&lt;/code&gt;を他のすべてのノードが指すように宣言する。&lt;/li&gt;
&lt;li&gt;最高で256種類のノードが同一の Input Record で起動できる。&lt;/li&gt;
&lt;li&gt;RW Input Record（書き込み可能な Input Record）は、異なる種類のノードで共有することはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeMaxRecursionDepth(count)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;このノードの最大再帰呼び出し回数を宣言する。&lt;/li&gt;
&lt;li&gt;参考：現在のWork Graphでは複数ノードを介した再帰呼び出しグラフはサポートされていない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeMaxInputRecordsPerGraphEntryRecord(count, sharedAcrossNodeArray)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;この&lt;code&gt;”mesh&amp;quot;&lt;/code&gt;ノードが一度に受け取ることのできる Input Record の最大数を宣言する。&lt;/li&gt;
&lt;li&gt;この最大数は、&lt;code&gt;DispatchGrid()&lt;/code&gt;呼び出し時の、一つの Input Record によって動作する全ての Work Graph ノードが出力する、このノードに対する Input Record の総数という意味。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sharedAcrossNodeArray&lt;/code&gt;が&lt;code&gt;true&lt;/code&gt;の場合は、Input Record を受け取るノード配列全体で、この最大数を共有する。&lt;/li&gt;
&lt;li&gt;参考：GPUのアーキテクチャによっては、コンピュートシェーダーを実行するときと、描画用のシェーダーを実行するときに、実行コンテキストのスイッチが必要なものがある。&lt;br&gt;
頻繁な実行コンテキストスイッチを避けるため、&lt;code&gt;”mesh”&lt;/code&gt;ノードへの Input Record は可能な限り蓄積される必要があるが、その上限を定義することで、Backing Memory のサイズと実行性能を適切にバランスすることができるようになると思われる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;input-record&#34;&gt;Input Record&lt;/h2&gt;
&lt;p&gt;Input Recordは、自身の&lt;code&gt;NodeLaunch&lt;/code&gt;属性で受け取れる型が決まる。&lt;/p&gt;
&lt;h4 id=&#34;broadcasting-launch&#34;&gt;Broadcasting Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み出し専用の Input Record。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書きが可能な Input Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;前者と基本的に同じだが、&lt;code&gt;Barrier()&lt;/code&gt;と&lt;code&gt;FinishedCrossGroupSharing()&lt;/code&gt;メソッドを適切に使うことで、&lt;br&gt;
Input Record のメモリ領域を、同時に起動した Dispatch Grid の他の Thread Group とのコミュニケーションにつかうことができる。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;FinishedCrossGroupSharing()&lt;/code&gt;メソッドを使うときは、Input Recordの構造体に、&lt;code&gt;[NodeTrackRWInputSharing]&lt;/code&gt;属性をつけなくてはいけない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;coalescing-launch&#34;&gt;Coalescing Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] GroupNodeInputRecords&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;1 ～ &lt;code&gt;maxCount&lt;/code&gt;数の、読み出し専用の Input Record。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] RWGroupNodeInputRecords&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書き可能なInput Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;li&gt;参考：この Input Record にアクセスできるのは、Coalescing Launch の特性上、一つの Thread Group なので、あまり使い道がないかもしれない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(maxCount)] EmptyNodeInput&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;データの受け渡しはない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Count()&lt;/code&gt;メソッドで、受け渡された Input Record の配列の長さがわかる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;thread-launch&#34;&gt;Thread Launch&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ThreadNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み出し専用の Input Record。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWThreadNodeInputRecord&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;読み書きが可能な Input Record。一時的なUAVバッファのように扱える。&lt;/li&gt;
&lt;li&gt;ただし、Thread Launch なので、他のスレッドとのデータのやり取りなどには使えない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;node-outputとoutput-record&#34;&gt;Node OutputとOutput Record&lt;/h2&gt;
&lt;p&gt;Input Record は、ノード関数の引数で直接受け取る形になっているが、Output Record は、NodeOutput 型が Output Record を抽象化して保持している形になっているので注意。
Input Record とは異なり、呼び出し先のノードの &lt;code&gt;NodeLaunch&lt;/code&gt;属性にかかわらず、同じ型を使用する。&lt;/p&gt;
&lt;h4 id=&#34;node-output&#34;&gt;Node Output&lt;/h4&gt;
&lt;p&gt;配列型かどうかと、Empty型かどうかを選択する形で、計４種類がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;attribute-list NodeOutput&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;単一の Node Output を出力する場合。&lt;/li&gt;
&lt;li&gt;注意：Output Record 自体が、基本的には可変長の配列のようなものなので、Output Record が一つしか出力できないという意味ではない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list NodeOutputArray&amp;lt;recordType&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;配列型の Node Output を出力する場合。&lt;/li&gt;
&lt;li&gt;この出力を受け取るノードは、配列で宣言されていることが期待される。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operator []&lt;/code&gt; で、上記の&lt;code&gt;NodeOutput&lt;/code&gt;型が取得できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list EmptyNodeOutput&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を出力しない場合の Node Output。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attribute-list EmptyNodeOutputArray&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;配列型の&lt;code&gt;EmptyNodeOutput&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operator []&lt;/code&gt; で、上記の&lt;code&gt;EmptyNodeOutput&lt;/code&gt;型が取得できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;上記の-attribute-list-について&#34;&gt;上記の &lt;code&gt;attribute-list&lt;/code&gt; について&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[MaxRecords(count)]&lt;/code&gt; or &lt;code&gt;[MaxRecordsSharedWith(nameInShader)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;count&lt;/code&gt;で、出力する Output Record の最大数を宣言する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MaxRecordsSharedWith&lt;/code&gt;は、このノードの関数の引数宣言で、先に宣言された&lt;code&gt;nameInShader&lt;/code&gt;引数と同じ最大数を、宣言として使う場合に使用する。
&lt;ul&gt;
&lt;li&gt;同じ最大数を、複数の下流ノードに出力する場合に有用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配列型の Node Output は、配列のすべての要素に対してこの最大数が適用される。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;)]&lt;/code&gt; or &lt;code&gt;[NodeID(&amp;quot;nodeName&amp;quot;,baseArrayIndex)]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;出力先のノード名を明示的に宣言する。&lt;/li&gt;
&lt;li&gt;この属性をつけない場合は、宣言した変数名が出力先のノードとみなされる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[AllowSparseNodes]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;出力先のノードが存在しないことを許可する。&lt;/li&gt;
&lt;li&gt;特に配列型の Node Output では、いくつかの配列要素に対する出力ノードが存在しないことを許可する。
&lt;ul&gt;
&lt;li&gt;参考：&lt;code&gt;IsValid()&lt;/code&gt;メソッドで、Work Graph に有効な出力ノードが存在するかを確認することができる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[NodeArraySize(count)]&lt;/code&gt; or &lt;code&gt;[UnboundedSparseNodes]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;count&lt;/code&gt;で、配列型の Node Output の最大要素数を宣言する。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UnboundedSparseNodes&lt;/code&gt;は、&lt;code&gt;[NodeArraySize(0xffffffff)] [AllowSparseNodes]&lt;/code&gt;と宣言するのと同義。
&lt;ul&gt;
&lt;li&gt;参考：実際には、Work Graphをコンパイルするときに、存在する有効な出力ノードの数と範囲は検出されるので、このサイズの Output Record が作られるわけではない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;output-record-の生成と取得操作など&#34;&gt;Output Record の生成と取得、操作など。&lt;/h4&gt;
&lt;p&gt;基本的には、Output Record を、スレッド単位で確保するか、Therad Group 単位で確保するかで分かれている。&lt;br&gt;
各メソッドの呼び出し時には、Thread Group が Uniform でなくてはならないというルールがある。&lt;br&gt;
（つまり、すべてのスレッドがその命令を通過するか、すべてのスレッドがその命令を通過しないかのいずれかでなくてはならない。）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ThreadNodeOutputRecords&amp;lt;recordType&amp;gt; NodeOutput&amp;lt;recordType&amp;gt;::GetThreadNodeOutputRecords(uint numRecordsForThisThread)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を個々のスレッド単位で確保する。&lt;/li&gt;
&lt;li&gt;呼び出しは Unfirom だが、確保する Output Record の数や、配列型 Output Record の場合の、確保する要素のインデックスは、各スレッドで可変でよい。&lt;/li&gt;
&lt;li&gt;Output Record のハンドルの配列が返される。&lt;code&gt;Get(int index=0)&lt;/code&gt;メソッドが、Output Record の配列の先頭に対する簡単なアクセスを提供する。&lt;/li&gt;
&lt;li&gt;すべての書き込み処理が終了したら、呼び出しが Uniform な状態で、取得した &lt;code&gt;ThreadNodeOutputRecords&amp;lt;&amp;gt;&lt;/code&gt; に対して&lt;code&gt;OutputComplete()&lt;/code&gt;メソッドを必ず呼び出さなければならない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupNodeOutputRecords&amp;lt;recordType&amp;gt; NodeOutput&amp;lt;recordType&amp;gt;.GetGroupNodeOutputRecords(uint numRecords)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Output Record を Thread Group 全体で&lt;code&gt;numRecord&lt;/code&gt;数確保する。&lt;/li&gt;
&lt;li&gt;呼び出しは Unfirom で、確保数や、配列型 Output Record の場合の確保する要素のインデックスも Uniform でなくてはならない。&lt;/li&gt;
&lt;li&gt;すべての書き込み処理が終了したら、呼び出しが Uniform な状態で、取得した&lt;code&gt;GroupNodeOutputRecords&amp;lt;&amp;gt;&lt;/code&gt;に対して&lt;code&gt;OutputComplete()&lt;/code&gt;メソッドを必ず呼び出さなければならない。&lt;/li&gt;
&lt;li&gt;Thread Launch のノードではこのメソッドを呼び出すことはできない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EmptyNodeOutput::ThreadIncrementOutputCount(uint count)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;スレッド単位で（Emptyな）Output Record の数をインクリメントする。&lt;/li&gt;
&lt;li&gt;呼び出しは Uniform である必要があるが、個々のスレッドが指定するインクリメント数は可変でよい。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EmptyNodeOutput::GroupIncrementOutputCount(uint count)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group 単位で（Emptyな）Output Recordを&lt;code&gt;count&lt;/code&gt;数インクリメントする。&lt;/li&gt;
&lt;li&gt;呼び出しは Uniform で、インクリメント数も Uniform でなければならない。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;barrier組み込み関数&#34;&gt;&lt;code&gt;Barrier()&lt;/code&gt;組み込み関数&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Barrier()&lt;/code&gt;組み込み関数は、Work Graphの導入に伴いShader Model 6.8から新しく導入されたが、Work Graphに関係なく使える。&lt;br&gt;
以下の３つの型がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;void Barrier(uint MemoryTypeFlags, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MemoryTypeFlags&lt;/code&gt;で指定したタイプの、すべてのリソースの同期をとる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MemoryTypeFlags&lt;/code&gt; は ビットマスクになっていて下記を組み合わせて指定できる。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;UAV_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GROUP_SHARED_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NODE_INPUT_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NODE_OUTPUT_MEMORY&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ALL_MEMORY&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;これはすべてのビットマスクの組み合わせ。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;template&amp;lt;typename UAVResource&amp;gt; void Barrier(UAVResource, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;引数で指定した&lt;code&gt;UAVResource&lt;/code&gt;を同期の対象とする。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;template&amp;lt;typename NodeRecordObject&amp;gt; void Barrier(NodeRecordObject o, uint SemanticFlags)&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;引数で指定した&lt;code&gt;NodeRecordObject&lt;/code&gt;の同期をとる。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NodeRecordObject&lt;/code&gt;は、&lt;code&gt;RW{Dispatch|Group|Thread}NodeInputRecords&lt;/code&gt; or &lt;code&gt;{Group|Thread}NodeOutputRecords&lt;/code&gt;を指定できる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;semanticflagsについて&#34;&gt;&lt;code&gt;SemanticFlags&lt;/code&gt;について&lt;/h4&gt;
&lt;p&gt;どのような同期をとるかを指定するのが&lt;code&gt;SemanticFlags&lt;/code&gt;。以下の３つがある。&lt;code&gt;_SYNC&lt;/code&gt;と&lt;code&gt;_SCOPE&lt;/code&gt;は論理和で組み合わせて指定できる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GROUP_SYNC&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thread Group 内のすべてのスレッドが、このバリア命令の直前の命令まで発行し終わるまで、ここですべてのスレッドが待つことを指示する。&lt;/li&gt;
&lt;li&gt;他の２つはメモリアクセスの完了に関連する制御だが、これはシェーダーの命令発行の制御。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;GROUP_SCOPE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このバリア命令の前に発行された、メモリアクセス処理が完了するまで、ここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;と組み合わせて指定した場合は、Thread Group 内のすべてのスレッドが、&lt;br&gt;
このバリア命令の前に記述されたすべてのメモリアクセス処理が、完了するまでここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;がない場合は、Thread Group が複数の Wave に分かれている場合は、Wave 間での同期は保証されない。&lt;/li&gt;
&lt;li&gt;例として、以下のオブジェクトに対してのメモリアクセスを同期したい場合に使う。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;groupshared&lt;/code&gt;で修飾されたオブジェクト&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RWGroupNodeInputRecords&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GroupNodeOutputRecords&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;DEVICE_SCOPE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このバリア命令の前に発行された、メモリアクセス処理が完了するまで、ここで待つことを指示する。&lt;br&gt;
加えて、&lt;code&gt;globallycoherent&lt;/code&gt;で修飾されたオブジェクトに対するメモリアクセス処理と、&lt;code&gt;Interlocked&lt;/code&gt;系の命令によるメモリアクセス処理が完了して、&lt;br&gt;
GPUの他の処理ユニットからその処理結果が正しく読み出せるようになるまで、ここで待つことを指示する。&lt;/li&gt;
&lt;li&gt;参考：&lt;code&gt;GROUP_SYNC&lt;/code&gt;と組み合わせた場合の効果は、&lt;code&gt;GROUP_SCOPE&lt;/code&gt;の項で説明したのと同じ。&lt;/li&gt;
&lt;li&gt;具体的には、以下のオブジェクトに対してのメモリアクセスを同期したい場合に使う。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾されたUAV&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾された&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;work-graphにおけるgloballycoherent修飾について&#34;&gt;Work Graphにおける&lt;code&gt;globallycoherent&lt;/code&gt;修飾について。&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;globallycoherent&lt;/code&gt;修飾されたUAVについて&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Work Graph の上流ノードと下流ノードでのデータの受け渡しは、基本的に{Input|Output} Record を使うが、データの格納形式や、必要とされるデータの寿命などによって、UAVを使うのが適切な場合がある。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;globallycoherent&lt;/code&gt;修飾されたUAVを介して、上流ノードと下流ノードでデータを受け渡す場合は、上流ノードにおいて、UAVに対する処理と、下流ノードを起動するための Output Record の生成完了（つまり、&lt;code&gt;OutputComplete()&lt;/code&gt;の呼び出しや、&lt;code&gt;IncrementOutputCount()&lt;/code&gt;の呼び出し）の間に、&lt;code&gt;DEVICE_SCOPE&lt;/code&gt;のバリアを設定することで、両ノードの、UAVへのデータ競合を避けることができる。
&lt;ul&gt;
&lt;li&gt;注意：Work Graphの実行順序は、必ずしもグラフの上流ノードから下流ノードと順番が決まっているわけではなく、{Input|Output} Recordの依存関係で決まっている。&lt;/li&gt;
&lt;li&gt;上流ノードの、複数の Thread Group が同一のUAVを処理し、全ての処理の完了を待ってから下流ノードの処理を始めたい場合は、&lt;code&gt;InterlockedAdd()&lt;/code&gt;などを駆使して、上流ノードの Thread Group の中で、最後に処理が完了した Thread Groupを検出して、その Thread Group が下流ノードを起動するための Output Record を生成する必要がある。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;globallycoherent&lt;/code&gt;で修飾された&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;について&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Broadcasting Launch では、複数のThread Group が、一つの Input Recordを読み書きすることができる。&lt;br&gt;
&lt;code&gt;globallycoherent&lt;/code&gt;修飾をつけておけば、&lt;code&gt;globallycoherent&lt;/code&gt;修飾のついた短期的なUAVバッファとして扱うことができるので、  &lt;code&gt;Interlocked&lt;/code&gt;系の命令やバリアを適切に使用すれば Thread Group 間で、データのやり取りおよび同期をとることができる。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RWDispatchNodeInputRecord&amp;lt;recordType&amp;gt;::FinishedCrossGroupSharing()&lt;/code&gt;を使えば、最後にこのメソッドを呼び出した Thread Group にのみ、&lt;code&gt;true&lt;/code&gt;が返されるので、複数の Therad Group で行った処理全体の終了を知ることができる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;このメソッドを使用するInput Recordの宣言には、&lt;code&gt;[NodeTrackRWInputSharing]&lt;/code&gt;属性がついてる必要がある。この属性をつけると、Input Recordのサイズが4byte大きくなる。
&lt;ul&gt;
&lt;li&gt;参考：結局のところ、この4byteの領域を上流ノードでゼロに設定しておき、各Therad Groupが&lt;code&gt;RWDispatchNodeInputRecord&lt;/code&gt;に対する処理が終了した時点で、その4byte領域に&lt;code&gt;InterlockedAdd()&lt;/code&gt;を実行していると思われる。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rwthreadnodeinputrecord-threadnodeoutputrecordsオブジェクトとbarrierについて&#34;&gt;&lt;code&gt;RWThreadNodeInputRecord&lt;/code&gt;, &lt;code&gt;ThreadNodeOutputRecords&lt;/code&gt;オブジェクトと&lt;code&gt;Barrier()&lt;/code&gt;について&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;この二つのオブジェクトは、いずれもスレッドローカルなので、&lt;code&gt;GROUP_SCOPE&lt;/code&gt;, &lt;code&gt;DEVICE_SCOPE&lt;/code&gt;いずれも適用できない。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Barrier()&lt;/code&gt;命令を跨いで、対象オブジェクトに対するメモリアクセス命令を、コンパイラによる命令スケジューリングで移動することを抑制する。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(2)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_second_step/</link>
      <pubDate>Mon, 20 Jun 2022 14:54:40 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_second_step/</guid>
      <description>&lt;p&gt;前提知識として、
&lt;a href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/&#34; title=&#34;About Us&#34;&gt;RTXDIのminimal-sampleをSpatioTemporal Resamplingなしの場合の動作&lt;/a&gt;について理解する必要があります。&lt;/p&gt;
&lt;h1 id=&#34;risとrestir&#34;&gt;RISとReSTIR&lt;/h1&gt;
&lt;p&gt;minimal-sampleは、まず初めに、現在レンダリングしているフレーム内でLight SampleとBRDF SampleをMISで結合したRservoirを生成します。この時点でもReservoirの結合を行いますが、基本的には Resampled Importance Sampling: RISのアルゴリズムに基づいて最適なライトパスの選択が行われます。&lt;br&gt;
加えて、&amp;ldquo;Enable Resampling&amp;quot;チェックボックスを有効にした場合は、現在のフレームで生成したReservoirと、前のフレームで生成されたReservoirを結合することで、さらに良質なライトパスの選択を行うことが出来ます。この処理を、Reservoir-based SpatioTemporal Importance Resampling: ReSTIRと呼びます。&lt;/p&gt;
&lt;h2 id=&#34;restirの効果&#34;&gt;ReSTIRの効果&lt;/h2&gt;
&lt;p&gt;端的にReSTIRの効果の有無を比較すると以下のようになります。ReSTIRの処理が追加されるので処理負荷は大きくなりますが、もしもReSTIRを使わずに、これと同等のレンダリングを達成するためには、ずっと多くの処理時間が必要となるでしょう。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-risrestir&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&amp;#43;ReSTIR&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_2_hud1dfaec533456fc1d766fb3b64615f0b_640919_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS+ReSTIR
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ris&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;RIS&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_second_step/RTXDI_SecondStep_1_hud1dfaec533456fc1d766fb3b64615f0b_949905_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    RIS
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;rtxdi_spatiotemporalresamplingの処理&#34;&gt;RTXDI_SpatioTemporalResampling()の処理&lt;/h2&gt;
&lt;p&gt;RTXDI SDKのReSTIRの処理は、&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数で行われます。minimal-sampleではRender.hlslから呼ばれています。引数には、以下の情報を渡します。返り値として、ReSTIRで結合されたReservoirが返されます。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reservoir = RTXDI_SpatioTemporalResampling(pixelPosition, primary.surface, reservoir, rng, stparams, params, temporalSamplePixelPos, lightSample);&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pixelPosition&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelの位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;surface&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理をしているPixelのサーフェース情報（位置, 法線 tec..）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;curSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在のフレームで生成したReservoir&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rng&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;乱数生成用のステート&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stparams&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理に関するのパラメーター（後述)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;params&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI SDKの定数パラメーター（バッファのオフセット情報など）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;temporalSamplePixelPos&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに成功した場合は、そのピクセル位置が格納されます。失敗すれば(-1,-1)が格納されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selectedLightSample&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Spatio Temporal Resamplingの処理でReservoirの選択サンプルが更新された場合は、このライトサンプルの情報が更新されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdi_spatiotemporalresamplingparameters-構造体&#34;&gt;RTXDI_SpatioTemporalResamplingParameters 構造体&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数を呼び出す際の引数にあるこの構造体には、 ReSTIRの制御に関する様々なパラメーターが格納されています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;screenSpaceMotion&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;現在処理しているピクセルのモーションベクトルです&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sourceBufferIndex&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoirバッファのフレームごとの参照オフセットを計算するためのインデックスです。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;maxHistoryLength&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合されたReservoirのウエイトの上限を決めます。この値が大きいほど、過去に多数のReservoirと結合されたサンプルのウエイトが高くなります。&lt;/li&gt;
&lt;li&gt;また、逆を言えば、シーンの変化への追従が悪くなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;biasCorrectionMode&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Reservoir結合時のBiasの補正方法です。&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_OFF
&lt;ul&gt;
&lt;li&gt;Biasの補正をしない結合方法を使います。処理は一番軽いですが、レンダリング結果にBiasを導入します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_BASIC
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正しますが基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_PAIRWISE
&lt;ul&gt;
&lt;li&gt;pairwise MISという方法でBiasを補正します。基本的に結合されたReservoirはすべて有効であると仮定します。異なる場合はBiasが導入されます。今回の記事では説明しません。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED
&lt;ul&gt;
&lt;li&gt;TargetPDFを再計算してBiasを補正したうえで、レイトレースを行い結合されたReservoirが有効かどうかをチェックします。基本的にBiasを導入しない方法です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;depthThreshold, normalThreshold&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionをしたときに、法線とデプスの相似度をチェックする際の閾値です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;結合を試みるReservoirの数です。最低1必要で、最初の一つは、TemporalResamplingとなります。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numDisocclusionBoostSamples&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Backprojectionに失敗した場合に、SpartialSampleの数を増やす場合のサンプル数です&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;samplingRadius&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;SpartialSampleのサンプリング半径（ピクセル単位）です。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enableVisibilityShortcut&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;RTXDI_BIAS_CORRECTION_RAY_TRACEDの時のみ有効です。&lt;/li&gt;
&lt;li&gt;Reservoir結合後に、Visibilityテストを行う際にTemporalSampleが選択された場合はVisibilityテストをスキップします。
&lt;ul&gt;
&lt;li&gt;（ここのIfの判定は不明。おそらくだが、選択されたサンプルのReservoirのVisibilityテストをスキップするのが正しいと思う。（なぜならそれは前フレームで行ったから。））&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;enablePermutationSampling&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;BackprojectionとSpartialSamplingの位置にに小さいオフセットを適用します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;backprojectionの処理&#34;&gt;Backprojectionの処理&lt;/h4&gt;
&lt;p&gt;まず、前のフレームのReservoirと結合するためには、Backprojectionの処理を行う必要があります。この処理自体は、通常我々が行っているものと違いはありません。モーションベクトルを基に、過去フレームのサンプル位置を算出し、その近傍で、法線やDepthの類似性が高いサンプルを探します。&lt;/p&gt;
&lt;h4 id=&#34;temporal-sampleの読み出し&#34;&gt;Temporal Sampleの読み出し&lt;/h4&gt;
&lt;p&gt;Backprojectionが成功したら、Reservoirバッファより、前フレームのPixel位置に対応するReservoirを読み出して&lt;code&gt;prevSample&lt;/code&gt;に格納します。読み出されるのは前のフレームに保存されたReservoirの情報になります。読み出したReservoirに対して以下の処理を行います。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt;をhistoryLimitでクランプ&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spartialDistance&lt;/code&gt;にピクセルオフセットを加算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;age&lt;/code&gt;をインクリメント&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightID&lt;/code&gt;を現在のフレームのライトバッファに対応するIDに変換
&lt;ul&gt;
&lt;li&gt;lightIDの変換では、もし該当するライトが、現在のフレームになければ読み出したReservoirを破棄します。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;temporal-sampleの結合&#34;&gt;Temporal Sampleの結合&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;prevSample&lt;/code&gt;が有効なReservoirだった場合は、現在のフレームで生成されたReservoirと結合します。
まず、&lt;code&gt;prevSample&lt;/code&gt;のReservoirの情報を基に、Light Sampleを構築します。ここで構築されるLight Sampleは、読み出し時に、ligtIDを変換したので、現在のフレームにおける光源サンプルの位置になります。そして、現在処理をしているSurfaceとそのLight Sampleで、&lt;code&gt;targetPDF&lt;/code&gt;を計算します。（つまりシェーディングの計算をします。）この値は、前のフレームのReservoirを結合する際の、ウエイトの補正に使います。&lt;/p&gt;
&lt;p&gt;結合の計算の詳細:&lt;br&gt;
まず、&lt;code&gt;prevSample&lt;/code&gt;はFinalizeされて格納されているので、そのメンバー変数&lt;code&gt;weightSum&lt;/code&gt;は意味的には、(1/targetPDF * 1/M * weightSum)の値になっています。
そして、&lt;code&gt;prevSample&lt;/code&gt;のRIS Weightは、プログラム上では(&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;呼び出しの引数の&lt;code&gt;targetPdf&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;weightSum&lt;/code&gt;) * (Reservoirのメンバー変数の&lt;code&gt;M&lt;/code&gt;)で計算されます。&lt;br&gt;
これを意味的に解釈すると(引数のtargetPDF)/(元のtargetPDF) * weightSum となります。
つまり本来の意味でのweightSumに、新旧のtargetPDFの比を乗算したものがRISWeightとして使われることになります。
結合後は、MとRISWeightはそれぞれ結合先のReservoirに加算され、乱数によるサンプルの選択が行われることで結合が完了します。&lt;/p&gt;
&lt;h4 id=&#34;spartial-sampleの読み出しと結合&#34;&gt;Spartial Sampleの読み出しと結合&lt;/h4&gt;
&lt;p&gt;minimal-sampleにおいて、Spartial SampleはTemporal Sampleと同様に、前フレームのGBufferとReservoirバッファから読み出されます。
テストするサンプル数は、デバッグUI上の&lt;code&gt;Spartial Sample&lt;/code&gt;のスライダーで調整できます。Temporal Sampleとの主な違いは、Backprojectionした位置から、さらに、&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;から取得した値でオフセットを適用するところにあります。&lt;code&gt;NeighborOffsetBuffer&lt;/code&gt;はSDK側からその内容があらかじめ提供されている静的なバッファで、Spartial Sampleのサンプリングパターンが格納されています。読み出したサンプルは、Normal, Dpethそして、GbuffのMaterialの相似度をみて、サンプルが有効かを判定します。&lt;br&gt;
有効な場合は、Temporal Sampleの場合と同様にReservoirを結合行います。結合の計算は、Temporal Sampleの場合と同じです。&lt;/p&gt;
&lt;h4 id=&#34;biasの補正とreservoirのfinalize処理&#34;&gt;Biasの補正とReservoirのFinalize処理&lt;/h4&gt;
&lt;p&gt;隣接ピクセルや、過去のフレームのReservoirとの結合はBiasを発生させることがあります。例えば、異なるピクセルで生成した複数のReservoirを結合した場合、個々のピクセルの積分範囲（法線を中心とした半球）は異なるため、もし、結合後に選択したLight Sampleが、結合された、とあるReservoirの積分範囲の外であったり、不可視な状態だったなら、このReservoirから&lt;code&gt;M&lt;/code&gt;の値を、Fianlize処理するときの分母に含めてはいけません。そうしないと、Biasが発生してしまいます。（詳しくはReSTIRの論文を参照）&lt;/p&gt;
&lt;p&gt;可視状態の確認は、&lt;code&gt;biasCorrectionMode&lt;/code&gt;に&lt;code&gt;RTXDI_BIAS_CORRECTION_RAY_TRACED&lt;/code&gt;が設定された場合に実行されます。具体的には、選択されたLight Sampleの位置と、各Reservoirの位置を、過去のフレームのBVHでレイトレースして、可視状態を確認します。（ただし、サンプル内の実際の処理では、シーンがスタティックであると仮定して、単純に現在のフレームのBVHでレイトレースするように実装されています。）&lt;/p&gt;
&lt;p&gt;次にFinazlieの処理についてです。&lt;code&gt;RTXDI_SpatioTemporalResampling()&lt;/code&gt;関数の正規化部分では、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;という変数が、Finalizeする際の係数の分子と分母になるように記述されています。もしも、ここがもっと単純な記述だったら、&lt;code&gt;pi&lt;/code&gt;は常に1で、&lt;code&gt;piSum&lt;/code&gt;には、選択したLight SampleがそのReservoirの積分範囲内で、かつ可視状態の、有効なReservoirの&lt;code&gt;M&lt;/code&gt;のみを加算することで、Finalize処理の係数を算出する形になります。（ReSTIR論文における1/Zに相当）&lt;br&gt;
しかし、RTXDIでは、MISのように正規化の係数を計算しています。具体的には、選択されたLight Sampleと各Reservoirの位置で、&lt;code&gt;targetPDF&lt;/code&gt;を計算し、可視状態ならば(&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;)という値を分母側の&lt;code&gt;piSum&lt;/code&gt;に蓄積しています。分子側の&lt;code&gt;pi&lt;/code&gt;は選択されたLight Sampleを保持していたReservoirとの&lt;code&gt;targetPDF&lt;/code&gt;です。つまり、選択されたLight Sampleを保持していたReservoirの&lt;code&gt;targetPDF&lt;/code&gt;(つまりはシェーディングの輝度）が相対的に他のReservoirと計算した輝度よりも高ければ、Finalizeする際の係数が大きくなるように計算されています。&lt;/p&gt;
&lt;p&gt;また、&lt;code&gt;pi&lt;/code&gt;と&lt;code&gt;piSum&lt;/code&gt;の初期値は、Temporal SampleやSpatial Sampleとの結合前の、現在のフレームで計算されたReservoirの値を設定します(&lt;code&gt;curSample.M&lt;/code&gt;)。これのMISのウエイトとして&lt;code&gt;state.targetPdf&lt;/code&gt;を使っています。これは、現在選択されているLight Sampleと、現在処理中のサーフェースで計算された&lt;code&gt;targetPDF&lt;/code&gt;で、この値は、他のTemporal SampleやSpatial Sampleのために計算する&lt;code&gt;targetPdf&lt;/code&gt;に対応する値です。（この値は、現在のフレームのデータで計算しています。他のTemporal SampleやSpatial SampleのReservoirの&lt;code&gt;targetPdf&lt;/code&gt;は前フレームのデータで計算しているという点は異なります。）&lt;/p&gt;
&lt;p&gt;ループ処理が完了すれば、結合されたすべてのReservoirのBiasの除外のチェックが完了したことになります。そして、&lt;code&gt;pi&lt;/code&gt;には選択されたサンプルの&lt;code&gt;targetPDF&lt;/code&gt;が格納され、&lt;code&gt;piSum&lt;/code&gt;には&lt;code&gt;targetPDF&lt;/code&gt;*&lt;code&gt;M&lt;/code&gt;の総和が格納されています。 &lt;code&gt;pi&lt;/code&gt;/&lt;code&gt;piSum&lt;/code&gt;を正規化係数としてFinalize処理を行うことで、Biasの補正をした結合ができます。&lt;/p&gt;
&lt;h5 id=&#34;biasの補正をしない場合のreservoirのfinalize処理&#34;&gt;Biasの補正をしない場合のReservoirのFinalize処理&lt;/h5&gt;
&lt;p&gt;Biasの補正をしない場合は、単純に結合されたReservoirを1/Mを正規化係数として、Finalize処理します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する(1)</title>
      <link>https://shikihuiku.github.io/post/rtxdi_first_step/</link>
      <pubDate>Tue, 07 Jun 2022 19:30:28 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_first_step/</guid>
      <description>&lt;h1 id=&#34;rtxdiとは&#34;&gt;RTXDIとは？&lt;/h1&gt;
&lt;p&gt;GPU上かどうかにかかわらずレイトレーシングやパストレーシングを行う際の重要な課題の一つは、追跡する光線の軌跡（パスもしくはレイと呼ばれるもの）をどのように構築するかです。これはレンダラーの性能や画質などの特性に直結する問題です。たとえば、物体表面からの反射に限定すれば、最も簡単なパスの構築方法は、物体の表面から半球状ににランダムな方向を選択してパスを構築する方法があると思います。また、物体表面の反射特性に合わせて、より反射率の高い方向を高確率で選択する方法や、シーン上に存在する光源の方向にパスを構築する方法もあります。&lt;br&gt;
このように、いろいろなパスの選択戦略があり、実際のレンダリングでは、これらを組み合わせて使うことがよくある思います。そして、最も理想的なパスの確率分布は、その物体表面から、観測者の方向へのRadianceに比例した確率分布といわれています。しかしこれは、一般的には解析的に解くことが極めて困難であることがほとんどです。なぜなら、物体表面の反射特性は分かっても、どの方向から強い光が差し込んでくるかはわかりません。その光も、シーン上に設定された光源からの直接光なのか、それとも何かほかの物体から反射された光なのかわかりません。&lt;br&gt;
RTXDIは、光源からの直接光によって形成されるRadianceに対して、最適なパスの確率分布を形成するようにパスの選択をするためのNVIDIAのSDKです。名前の由来は、おそらくRTX Direct Illuminationです。&lt;/p&gt;
&lt;h4 id=&#34;リポジトリ&#34;&gt;リポジトリ&lt;/h4&gt;
&lt;p&gt;GitHubのリポジトリがあるので、さっそくCloneしてみましょう。&lt;br&gt;
以降の説明では基本的にCloneしたソースを読める状態にある前提で書いています。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;ドキュメント&#34;&gt;ドキュメント&lt;/h4&gt;
&lt;p&gt;RTXDIのSDKのドキュメントを見る前に、前提知識として、Resampled Importance Sampling(RIS)のアルゴリズムの基礎部分を理解した方がよいと思います。（これより先は、Resampled Importance SamplingをRISと省略します。）&lt;br&gt;

&lt;a href=&#34;https://www.google.com/search?q=Importance&amp;#43;Resampling&amp;#43;for&amp;#43;Global&amp;#43;Illumination&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Importance Resampling for Global Illumination&amp;rdquo; by J. Talbot et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RTXDIのSDKには、その概要を把握するのに下記のドキュメントがありますが、これを読んで理解できる人は、この記事はここで読むのを終了していただいて、SDKのドキュメントやソースコードを直接参照した方が良いでしょう。

&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;rtxdi-sampleとminimal-sample&#34;&gt;rtxdi-sampleとminimal-sample&lt;/h4&gt;
&lt;p&gt;このSDKにはサンプルプロジェクトが二つ付いています。&lt;br&gt;
rtxdi-sampleは、RTXDIをパス選択の核として、RTXGIやNRDやDLSSを用いてレンダリングしています。またReGIRという、ワールド空間におけるRISも行っているので、かなり実践的なサンプルになっている一方で、初めのステップとして、RTXDIの動作を理解したい場合には不向きなサンプルです。&lt;br&gt;
一方で、minimal-sampleは、設定を変更することで時間方向のRISや、BRDFに基づくサンプリングも無効にすることが出来ます。また、NRDによるデノイズも行っておらず、レンダリングは極力単純な形で留めてあります。そのため、RTXDIの核であるRISの仕組みや、その効果をわかりやすく見せてくれるサンプルになっています。本記事ではこちらのサンプルプログラムの動作を見ていきます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleのスクリーンショット&#34;&gt;minimal-sampleのスクリーンショット&lt;/h1&gt;
&lt;p&gt;端的にRTXDIの効果の一端を見るためにいくつかのスクリーンショットを用意しました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-1サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;1サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    1サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-8サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;8サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    8サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

まずは上記3枚は、RTXDIのパス選択候補を、8サンプル、16サンプルと増加させたものです。選択候補は増やしているのですが、実際にれらのサンプルでレイトレースを行った訳ではありません。レイトレースはあくまで1回のみ行います。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプルbrdf2サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル＋BRDF2サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル＋BRDF2サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

次は、16サンプル+BRDF2サンプルの場合です。こちらはレイトレース回数は、合計3回となります。BRDFサンプルによって、良い選択候補が見つかるサーフェースでの変化が顕著に見られます。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-4サンプルbrdf1サンプルspatio-temporal-resample&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;4サンプル＋BRDF1サンプル&amp;#43;Spatio-Temporal Resample&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    4サンプル＋BRDF1サンプル+Spatio-Temporal Resample
  &lt;/figcaption&gt;


&lt;/figure&gt;

今回の記事では説明しませんが、Spatio-Temporalのパス選択候補を導入すると、上記のようになります。上記の16サンプルと同等の処理時間ですが、結果は圧倒的にこちらが優れています。デノイズ処理は一切入っていない状態でここまでレンダリングできれば、かなり高画質なレンダリングが期待できます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleを読む前に前提知識&#34;&gt;minimal-sampleを読む前に（前提知識）&lt;/h1&gt;
&lt;p&gt;ここでサンプルプログラムのレンダリングを見る前に、簡単に触れておいた方が良い前提知識について説明します。&lt;/p&gt;
&lt;h4 id=&#34;nvrhiとdonutフレームワーク&#34;&gt;NVRHIとDonutフレームワーク&lt;/h4&gt;
&lt;p&gt;RTXDI SDKのほかに、minimal-sampleが依存している主なライブラリとして、DonutとNVRHIがあります。&lt;br&gt;
NVRHIは、D3D12とVulkanを抽象化するためのグラフィックスAPIの抽象化レイヤーです。とはいえそれほど深い抽象化が行われているわけではありません。&lt;br&gt;
Donutは、サンプルアプリケーションのフレームワークに相当する部分になります。シーンのロードやシェーダーの管理、デバッグUIの表示などを行っています。こちらもサンプル向けのフレームワークなので、シンプルに記述されています。今回のサンプルプログラムでは、それほど多数のDispatchが呼び出されるわけではないので、動作の理解に苦しむことはないかと思います。&lt;/p&gt;
&lt;h4 id=&#34;rab_プレフィックスについて&#34;&gt;RAB_プレフィックスについて&lt;/h4&gt;
&lt;p&gt;RTXDIのサンプルを見ると、RTXDI_プレフィックスの関数や構造体とは別に、RAB_プレフィックスの関数や構造体がたくさんあります。RABの意味はRTXDI Application Bridgeという意味で、その名の通り、RTXDIとアプリケーションの橋渡しの役目があります。&lt;br&gt;
RTXDIがRISを行うときに必要になる情報は、アプリケーションのレンダラーと密接に関係しています。そのため、RTXDIがアプリケーション由来の情報と思われるものを取得する際は、RAB_プレフィックスのついた関数を呼び出します。RTXDIが呼び出している、RABプレフィックスのついた関数を実装するのは、アプリケーション側の責任となります。
しかし実際は、サンプルアプリケーションのRAB実装である、RtxdiApplicationBridge.hlslを改変する形で自身のアプリケーションに組み込む形になると思います。このようにすることで、アプリケーションごとに改変の必要な部分と不要な部分の切り分けを実現しています。&lt;/p&gt;
&lt;h4 id=&#34;rtxdi特有のリソース&#34;&gt;RTXDI特有のリソース&lt;/h4&gt;
&lt;p&gt;通常のG-Bufferなどに加えて、minimal-sampleでRTXDI SDKを導入したことで必要となるリソースは以下の通りです。RTXDIは、SDKの内部でリソースを確保することはありません。リソースの管理は、生成、破棄を含め、すべてアプリケーション側の管理となります。  SDK側からは必要に応じて、リソースのサイズやその中身がAPIを通じて提供されるので、アプリケーションはそれらを正しく管理しなくてはなりません。
以下のリソースは、ソースコード全体の把握では大切な要素ですが、RISのアルゴリズム部分ではあまり関わりが無いので読み飛ばしても問題ありません。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TaskBuffer&lt;br&gt;
RTXDIは、毎フレーム直接光源情報のテーブルの更新を行っています。これはPrepareLightというGPU処理マーカーの中でComputeShaderとして行われています。この処理の入力として TaskBufferが必要となります。このバッファはPrepareLightsTask構造体の配列となっています。
このサンプルでは、シーン上でEmissiveサーフェースを持ったGeometry Instanceの個数分のバッファを確保しています。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightBuffer&lt;br&gt;
RTXDIがアクセスする光源の情報はすべてこのバッファに格納されます。個々の光源は、RAB_LightInfo構造体に格納されます。
このサンプルでは、Emmisiveのマテリアルが設定されたポリゴン一つ一つがEmissiveTriangleの光源としてこの配列に設定されます。
TaskBufferによって入力された情報をもとに、このバッファが構築されます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GeometryInstanceToLightBuffer&lt;br&gt;
Geometry Instanceごとに、そのInstanceに含まれるEmissiveTriangleの光源としてのLightBufferにおける先頭のインデックスを格納します。つまり、GeometryInstanceのインデックスからLightBufferを参照するときに使われるテーブルです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeighborOffsetBuffer&lt;br&gt;
RTXDIがサイズを提供しと内容を指定します。スクリーンスペースでRISを行うときに参照するべきPixelへのオフセットになる値が格納されます。EvenとOddのフィールドがあるのでRTXDIが提供するNeighborOffsetCountの2倍の数で、RG8_SNORMのTypedBufferを確保します。
レンダリングの前に、RTXDIのFillNeighborOffsetBuffer()で取得できるバイト列をこのバッファに書き込む必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightReservoirBuffer&lt;br&gt;
RTXDIがサイズを提供し内容はComputeShaderで算出されます。
ReservoirBuffer一つあたりのサイズはsizeof(RTXDI_PackedReservoir) * context.GetReservoirBufferElementCount()で、RTXDIから提供されます。
これをアプリケーション側の好きな数だけ確保します。サンプルの初期値では3セット分のサイズのバッファを確保しています。
時間方向でRISを行う場合のためのバッファになります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdiのreservoirについて&#34;&gt;RTXDIのReservoirについて&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;（ここより以下、RTXDIもしくはRISの文脈で、&amp;ldquo;サンプル&amp;quot;と言っている場合は、レイトレーシングにおけるサーフェースと光源を結ぶパスを構築するためのLight Sampleを指します。サンプルアプリケーションのことでもなければ、テクスチャのサンプリングのことでもありません。）&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;
RTXDI_Reservoir構造体はRISのReservoirとしての情報を保持します。Reservoirとは、RISをするためのサンプルの集合です。ただし、サンプルの集合の情報をすべて保持していたら、GPU上ではメモリが足りません。したがって、Reservoirは今まで生成してきたサンプルによる確率の計算と、現在そのReservoirで選択されているサンプルの情報を格納しています。具体的には、サンプルの選択確率に関する情報と、パスの接続対象なる光源のインデックス、その光源の表面における位置情報にあたるUVです。これがあれば、ワールド空間でパスを接続するべき位置（つまりは光源の表面位置）が計算でき、シェーディングを行った後にサンプルの確率密度を適用することができます。&lt;br&gt;
Reservoirに関して全くイメージがわかないという場合は、まず初めに紹介した論文を軽く読んで、ReSTIRに関する論文、

&lt;a href=&#34;https://research.nvidia.com/sites/default/files/pubs/2020-07_Spatiotemporal-reservoir-resampling/ReSTIR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting&amp;rdquo;, Bitterli et al. 2020&lt;/a&gt;&lt;br&gt;
を読むとイメージできると思います。（もしこの二つを読んだならば、本記事は、この先読む必要がないでしょう）&lt;/p&gt;
&lt;h4 id=&#34;reservoirを操作する関数群&#34;&gt;Reservoirを操作する関数群&lt;/h4&gt;
&lt;p&gt;ここではRTXDIがReservoirを操作する関数群のなかで、最も基本的なものをザックリと説明します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RTXDI_Reservoir RTXDI_Reservoir RTXDI_EmptyReservoir()&lt;/code&gt;&lt;br&gt;
有効なサンプルが一つも格納されていない、初期化された&lt;code&gt;RTXDI_Reservoir&lt;/code&gt;構造体を返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_StreamSample( inout RTXDI_Reservoir reservoir, uint lightIndex, float2 uv, float random, float targetPdf, float invSourcePdf)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reservoir&lt;/code&gt; - 格納するReservoir&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightIndex&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; - 追加するLight Sampleの情報&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random&lt;/code&gt; - Light Sampleを更新するかどうかをDraw（選択）するときに使う乱数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPdf&lt;/code&gt; - RISにおけるTarget PDF&lt;/li&gt;
&lt;li&gt;&lt;code&gt;invSourcePdf&lt;/code&gt; - 追加するサンプルを生成する確率の逆数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一つのサンプルをReservoirに追加して、現在このReservoirの中で選択されているサンプルを更新します。&lt;br&gt;
&lt;code&gt;targetPDF&lt;/code&gt;は実際は正規化されたPDFである必要はなく、単なるウエイト値で問題ありません。一方で、&lt;code&gt;invSourcePdf&lt;/code&gt;は、サンプルの発生確率に基づいたPDFである必要があります。関数内部では、RIS Weightが &lt;code&gt;targetPdf * invSourcePdf&lt;/code&gt; で計算され、Reservoir構造体の &lt;code&gt;weightSum&lt;/code&gt; に加算されます。Reservoirの保持サンプル数&lt;code&gt;M&lt;/code&gt;もインクリメントされます。また、与えられた &lt;code&gt;random&lt;/code&gt;でサンプルの選択を行い、新たに追加されたサンプルが選択された場合はReservoir内部の選択サンプルの情報を更新します。その場合は、返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;void RTXDI_FinalizeResampling( inout RTXDI_Reservoir reservoir, float normalizationNumerator, float normalizationDenominator) &lt;/code&gt;&lt;br&gt;
通常は、Reservoirへのサンプル追加が終わった段階で呼び出す処理で、Reservoirに蓄積されたサンプルの確率と、現在選択されているサンプルの確率から、選択されているサンプルの評価値（つまりはシェーディング結果）に乗算するべき値 (Importance Samplingにおける 1/PDF) を計算します。&lt;br&gt;
&lt;code&gt;normalizationNumerator&lt;/code&gt;, &lt;code&gt;normalizationDenominator&lt;/code&gt;は蓄積されたサンプルの&lt;code&gt;weightSum&lt;/code&gt;を正規化するときの係数です。単独のReservoirであれば、Reservoirに蓄積されたサンプル数の逆数である、1/&lt;code&gt;M&lt;/code&gt;が係数として適切です。この場合、1/&lt;code&gt;targetPDF&lt;/code&gt; * (1/&lt;code&gt;M&lt;/code&gt; * &lt;code&gt;weightSum&lt;/code&gt;)を計算し、これを &lt;code&gt;weightSum&lt;/code&gt; に代入します。&lt;br&gt;
したがって、この関数を呼び出す前と後では構造体メンバーの&lt;code&gt;weightSum&lt;/code&gt;の値の意味が変わります。呼び出す前はReservoirに蓄積されたサンプルのウエイトの合算で、呼び出した後は、選択されたサンプルの評価値に乗算するべき値となります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float RTXDI_GetReservoirInvPdf(const RTXDI_Reservoir reservoir)&lt;/code&gt;&lt;br&gt;
Sampleの評価値に乗算するべき係数（Importance Samplingにおける1/PDF）を返します。&lt;br&gt;
内部の処理は&lt;code&gt;weightSum&lt;/code&gt;の値を返すだけです。事前に&lt;code&gt;FinalizeResampling()&lt;/code&gt;を呼ぶ必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_CombineReservoirs( inout RTXDI_Reservoir reservoir, const RTXDI_Reservoir newReservoir, float random, float targetPdf)&lt;/code&gt;&lt;br&gt;
二つのReservoirを結合します。&lt;br&gt;
まず、結合前に結合される側の&lt;code&gt;newReservoir&lt;/code&gt;は&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;で正規化されている必要があります。&lt;br&gt;
引数&lt;code&gt;targetPdf&lt;/code&gt;は、結合される&lt;code&gt;newReservoir&lt;/code&gt;で選択されているサンプルの、結合先Reservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;になります。結合される側と結合先でのtargetPdfが同じ場合は、引数の&lt;code&gt;targetPdf&lt;/code&gt;は、&lt;code&gt;newReservoir&lt;/code&gt;に保存されているサンプルのtargetPdfを指定すればよいです。&lt;br&gt;
結合後は、現在どちらかのReservoirで選択されているサンプルが選択サンプルになります。これを&lt;code&gt;random&lt;/code&gt;を用いて決めます。選択サンプルが変更される場合は返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;minimal-sampleの中身brfont-size1spatio-temporalでrisを行わない場合のレンダリングfont&#34;&gt;minimal-sampleの中身&lt;br&gt;&lt;font size=&#34;+1&#34;&gt;~Spatio-TemporalでRISを行わない場合のレンダリング~&lt;/font&gt;&lt;/h1&gt;
&lt;p&gt;レンダリングを理解するうえでの前提知識が整ったので、さっそく一番簡単なケースのレンダリングを見たいと思います。
Spatio-TemporalでのRISは、RTXDIの大きな特長の一つですが、今回は単純化のために無効化した状態でサンプルコードを読み、
RTXDIの最もシンプルな形を理解するこにします。このサンプルアプリケーションは、&amp;ldquo;Enable Resampling&amp;quot;というDebugUIが用意されているのでこれをDisableにします。しかしこれはSpatio-TemporalのRISを行うかどうかを切り替えるためのフラグで、RTXDIを完全にDisableにするためのものではありません。また、BRDF Cutoffも、簡単のため0.0が設定されていると仮定します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-settings&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Settings&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;30%&#34; height=&#34;351&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Settings
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;レイトレーサー本体の概要&#34;&gt;レイトレーサー本体の概要&lt;/h4&gt;
&lt;p&gt;Renderer.hlslのmain()がレイトレーサー本体のシェーダーコードです。カメラからレイを飛ばして、GBuffer相当の情報を取得している部分は特に難しい部分はないと思います。サーフェースにヒットした場合は、乱数シーケンスを初期化して、RTXDI_SampleParamterにサンプリングの設定をしています。その後の主な処理の流れは以下の通りです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空のReservoirに、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;でReservoirの正規化を行う&lt;/li&gt;
&lt;li&gt;選択パスが、RTXDI_SampleLocalLights()だったら、ShadowRayをキャストして、Visibilityをチェック&lt;/li&gt;
&lt;li&gt;ShadeSurfaceWithLightSample()で、Reservoirで選択されたサンプルを使ってシェーディングを行う&lt;/li&gt;
&lt;li&gt;再びShadowRayをキャストしてVisibilityをチェック&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Spatio-TemporalのRISが無効化されている場合は、最後の2度目のVisibilityチェックは必要ないはずです。しかし、大まかな処理の流れとしてはこのようになっています。以上を簡単に言い換えれば、1バウンスのライトサンプル(NEE)と、BRDFサンプルのMulti Importance Samplingのレイトレーサーが実装されているといえると思います。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplelocallights&#34;&gt;RTXDI_SampleLocalLights()&lt;/h3&gt;
&lt;p&gt;さっそくですが、1番めの処理についてです。この関数は&lt;code&gt;ResamplingFunctions.hlsli&lt;/code&gt;に実装されています。
この関数は、&lt;code&gt;numLocalLightSamples&lt;/code&gt;で指定された数だけ、サンプルを構築してReservoirに蓄積する処理を行います。このサンプルアプリケーションの中の様々な個所で行われているRISの最も基本的な形になっています。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;RTXSDKは事前にLight DataバッファにLocal Light (つまりは Emissive Triangle)のリストを構築しています。まず、このリストから、単純に乱数でLocal Lightを選択します。さらに乱数を2つ生成して、光源の三角形上の点を決定して、その位置に向けて、プライマリレイがヒットしたサーフェースからパスを構築します。&lt;br&gt;
構築されたパスのPDFは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;で計算され、&lt;code&gt;blendedSroucePdf&lt;/code&gt;に代入されます。&lt;/p&gt;
&lt;h5 id=&#34;blendedsourcepdfの計算&#34;&gt;blendedSourcePdfの計算&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;blendedSourcePdf&lt;/code&gt;は、RISにおけるsourcePDFなので、実際のパス生成確率に即したものでなければなりません。
この計算を行っているのは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数です。&lt;br&gt;
まず、ライトサンプルの確率は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ライトの選択確率（単なる乱数選択なので、ライトの個数の逆数）&lt;/li&gt;
&lt;li&gt;ライト上の特定の方向に向けたレイを選択する確率（サーフェースから見たLocal Lightの見かけの立体角の逆数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;の乗算で計算できます。&lt;/p&gt;
&lt;p&gt;そして、BRDFサンプルの確率は、&lt;code&gt;RAB_GetSurfaceBrdfPdf()&lt;/code&gt;で計算されるので、アプリケーション側の処理となりますが、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DiffuseRayの場合、CosineWeightedのPDF&lt;/li&gt;
&lt;li&gt;SpecularRayの場合、GGX_VNDFのPDF&lt;/li&gt;
&lt;li&gt;上記いずれかをDiffuseProbabilityで選択&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、&lt;br&gt;
DiffuseProbablity * CosineWeightedPDF + (1 - DiffuseProbability) * GGX_VNDF_PDF&lt;br&gt;
でBRDFサンプルの確率が計算できます。&lt;/p&gt;
&lt;p&gt;1ピクセルあたりで、RISで検討されるライトサンプル数とBRDFサンプル数はDebug UIの設定で決まっていて、&lt;code&gt;numLocalLightSamples&lt;/code&gt;と&lt;code&gt;numBrdfSamples&lt;/code&gt;に設定されます。このサンプル数を用いて、これらはバランスヒューリスティックで結合されます。これは通常のMulti Importance Samplingと同様の考え方です。&lt;/p&gt;
&lt;p&gt;注意点なのですが、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数の最後では、&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;に設定された&amp;quot;ライト上の特定の方向に向けたレイを選択する確率&amp;quot;で除算しています。ここはRTXDIのトリッキーな部分です。あくまで、実際の&amp;quot;sourcePdf&amp;quot;は、この除算の前の値です。
しかし、RTXDIでは&lt;code&gt;targetPdf&lt;/code&gt;も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算するので、計算のつじつまが合うようになっています。また、&lt;code&gt;taregetPdf&lt;/code&gt;は、シェーディング結果を除算しますが、シェーディング結果も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されるので、こちらも計算のつじつまが合う仕組みになっています。&lt;/p&gt;
&lt;h5 id=&#34;targetpdfの計算&#34;&gt;targetPdfの計算&lt;/h5&gt;
&lt;p&gt;説明が多少前後しましたが、&lt;code&gt;targetPdf&lt;/code&gt;の計算についてです。&lt;code&gt;targetPdf&lt;/code&gt;はRISにおいて、積分可能ではないが、理想的なサンプルの確率密度です。(この値は、簡単には積分できず大きさが正規化できないので、PDFと呼ぶべきではなく、単にWeightと呼ぶべきかもしれません。）
&lt;code&gt;targetPdf&lt;/code&gt;はレンダリングの文脈では、サーフェースがカメラ方向に出すRadianceに比例したレイの分布になるのが一番望ましいです。言い換えれば、カメラの方に最も強く反射される光源へのレイを重点的にサンプリングする分布です。これは、光源のサーフェースでのカメラ方向への反射を計算すればわかります。しかし、光源とサーフェースがVisibleかどうかの判断は、実際にShadow Rayをトレースしなくては分かりません。しかし、これを行えば、実際にレイトレースを行ってシェーディングする処理とまったく変わらなくなり、単にレイのサンプル数を増やすことと同義です。これでは、RISの意味がなくなってしまいまいます。&lt;br&gt;
&lt;code&gt;targetPdf&lt;/code&gt;の計算では、シェーディングの中で最も処理負荷の高いShadow Rayのテスト処理を省略した値（つまりい光源とサーフェースがVisibleかどうかの判断をせずにシェーディングした結果）が用いられます。&lt;/p&gt;
&lt;p&gt;実際の計算は、&lt;code&gt;RtxdiApplicationBridge.hlsli&lt;/code&gt;の&lt;code&gt;RAB_GetLightSampleTargetPdfForSurface()&lt;/code&gt;に実装されています。この関数は&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;という関数を呼び出して、シェーディングの計算を行っています。算出された値の輝度値が、そのまま&lt;code&gt;targetPDF&lt;/code&gt;として扱われます。また、&lt;code&gt;blendedSourcePdf&lt;/code&gt;の項で説明した通り、シェーディングの計算の最後で、値は&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されます。&lt;/p&gt;
&lt;h5 id=&#34;reservoirにサンプルを追加する計算&#34;&gt;Reservoirにサンプルを追加する計算&lt;/h5&gt;
&lt;p&gt;上記の通り、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;の計算が完了すれば、Reservoirにサンプルを追加する処理は簡単です。
&lt;code&gt;RTXDI_StreamSample()&lt;/code&gt;に、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;を乱数と共に渡して、渡したサンプルが選択された場合は、現在選択中のサンプルの情報を更新します。&lt;/p&gt;
&lt;h5 id=&#34;サンプル構築後の処理&#34;&gt;サンプル構築後の処理&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;numLocalLightSamples&lt;/code&gt;の数だけサンプルを構築し、Reservoirに蓄積した後は、現在Reservoirが選択中のサンプルの情報と、Reservoirに蓄積されたRISの情報のみが残ります。ここまでで複数のサンプルを検討していますが、実際にレイトレース処理は行っていません。しかし、Reservoirには、一番選択するべきサンプルの情報が残っています。&lt;br&gt;
サンプルを構築するループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;と思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で正規化されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplebrdf&#34;&gt;RTXDI_SampleBrdf()&lt;/h3&gt;
&lt;p&gt;この関数は、numBrdfSamplesで指定された数だけ、サーフェースのBRDFをもとにサンプルを構築してReservoir蓄積する処理を行います。&lt;br&gt;
この処理は、上記で説明した&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の処理と対を成す処理です。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築-1&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RAB_GetSurfaceBrdfSample()&lt;/code&gt;を呼び出して、BRDFに基づいたサンプルを構築します。そして、実際にレイトレースを行い、Local Light（Emissive Triangle）にHitするかをテストします。Hitしなかった場合は、このサンプルの処理は終了しReservoirに関する処理は行われません。（しかし、このサンプルがReservoirに蓄積されないというわけではなく、正確にはtargetPDF=0として蓄積された扱いになります。これはReservoirの結合時の処理を見ると判明します。）&lt;br&gt;
一方でLocal LightにHitした場合は、&lt;code&gt;targetPdf&lt;/code&gt;と&lt;code&gt;blendedSourcePdf&lt;/code&gt;をそれぞれ計算します。計算は、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と全く同じ計算になります。&lt;/p&gt;
&lt;h5 id=&#34;サンプルの構築後の処理&#34;&gt;サンプルの構築後の処理&lt;/h5&gt;
&lt;p&gt;ここも、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と基本的に同じ計算になります。
サンプル構築のループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、Shadow Rayによって棄却されたサンプルを含めるなら、&lt;code&gt;1.0/numBrdfSamples&lt;/code&gt;であるべきと思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;light-sampleとbrdf-sampleのreservoirの結合処理&#34;&gt;Light SampleとBRDF SampleのReservoirの結合処理&lt;/h3&gt;
&lt;p&gt;再び、&lt;code&gt;main()&lt;/code&gt;の処理に戻ります。&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;によって構築された&lt;code&gt;localReservoir&lt;/code&gt;と、&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;によって構築された、&lt;code&gt;brdfReservoir&lt;/code&gt;を結合する処理を見ていきます。&lt;/p&gt;
&lt;h5 id=&#34;rtxdi_combinereservoirsの処理&#34;&gt;RTXDI_CombineReservoirs()の処理&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;を呼ぶ前に、結合される側のReservoirは、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;が呼ばれている約束になっています。したがって、結合される側の&lt;code&gt;weightSum&lt;/code&gt;は、Finalize前の変数で解釈すると&lt;code&gt;1/targetPDF * 1/M * weightSum&lt;/code&gt;
に相当する値が設定されています。（ただし&lt;code&gt;1/M&lt;/code&gt;はFinalize時に引数で渡す正規化係数）&lt;br&gt;
これに、構造体に格納されている&lt;code&gt;M&lt;/code&gt;と、引数で渡された&lt;code&gt;targetPdf&lt;/code&gt;を乗算したものが、&lt;code&gt;risWeight&lt;/code&gt;という変数に設定されます。逆算すれば、&lt;code&gt;risWeight&lt;/code&gt;は、元の&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;(引数の)targetPdf / (構造体に保存されている)targetPdf&lt;/code&gt;を乗算したものですから、もしも、&lt;code&gt;1/M&lt;/code&gt;で正規化されていて、&lt;code&gt;targetPdf&lt;/code&gt;が同じならば、結局のところ元の&lt;code&gt;weightSum&lt;/code&gt;ということになります。&lt;br&gt;
しかし、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の引数に渡す&lt;code&gt;targetPdf&lt;/code&gt;は、結合元のReservoirで現在選択されているサンプルの、結合先のReservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;なので、もしも、結合先で&lt;code&gt;targetPdf&lt;/code&gt;が異なる場合は、その比が&lt;code&gt;weightSum&lt;/code&gt;に乗算されることになります。しかし、今回のサンプルプログラムでは、Spatio-TemporalなRISの結合を行わないので、&lt;code&gt;targetPdf&lt;/code&gt;は結合の前後で変化しないので、この計算について深く考える必要はありません。&lt;/p&gt;
&lt;p&gt;計算された&lt;code&gt;risWeight&lt;/code&gt;は、結合されるReservoir全体の、結合先Reservoirにおけるウエイトに相当する値です。&lt;br&gt;
後は、サンプル数&lt;code&gt;M&lt;/code&gt;を合算し、&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;risWeight&lt;/code&gt;を加算して、選択サンプルを乱数で決定することで、Reservoirの結合が完了します。&lt;/p&gt;
&lt;h5 id=&#34;localreservoir-と-brdfreservoir-の結合&#34;&gt;localReservoir と brdfReservoir の結合&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の項で説明したとおり、&lt;code&gt;localReservoir&lt;/code&gt;は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;で除算して正規化するところを、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算したうえに、サンプル数 &lt;code&gt;M&lt;/code&gt; を1に設定していました。
これを、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の結合される側のReservoirとして処理をすると、&lt;code&gt;risWeight&lt;/code&gt;は、Finalize前の変数で解釈すると以下のようになります。&lt;br&gt;
&lt;code&gt;1/numMisSamples * weightSum&lt;/code&gt;&lt;br&gt;
この式をわかりやすく書き換えると、以下のようになります。&lt;br&gt;
&lt;code&gt;numLocalLightSamples/numMisSamples * 1/numLocalLightSamples * weightSum&lt;/code&gt;&lt;br&gt;
つまり、&lt;code&gt;localReservoir&lt;/code&gt;の正規化処理と、&lt;code&gt;localReservoir&lt;/code&gt;と&lt;code&gt;brdfReservoir&lt;/code&gt;の、それぞれのサンプル数に基づくバランスヒューリスティックによる結合を同時に処理しているわけです。&lt;/p&gt;
&lt;p&gt;同様に、&lt;code&gt;brdfReservoir&lt;/code&gt;の結合時の&lt;code&gt;risWeight&lt;/code&gt;は、&lt;br&gt;
&lt;code&gt;numBrdfSamples/numMisSamples * 1/numBrdfSamples * weightSum&lt;/code&gt;&lt;br&gt;
と解釈できます。（ここで、&lt;code&gt;brdfReservoir&lt;/code&gt;の生成時に、Shadow RayがMissしてサンプルが破棄されているにも関わらず&lt;code&gt;targetPdf&lt;/code&gt;がゼロのサンプルとして扱われているという解釈ができるわけです。）&lt;/p&gt;
&lt;p&gt;最後に、両者の結合後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を正規化係数1.0で呼び出していますが、両者の正規化はMISのウエイトによって行われているので、計算のつじつまが合うわけです。&lt;/p&gt;
&lt;h2 id=&#34;最後のレイトレースとシェーディング処理&#34;&gt;最後のレイトレースとシェーディング処理&lt;/h2&gt;
&lt;p&gt;ついに、最終的に採用すべきサンプルが確定し、乗算すべきPDFの算出も完了しました。&lt;br&gt;
あとはShadow Rayをキャストして、Visibilityを確認すればよいのですが、&lt;code&gt;brdfReservoir&lt;/code&gt;のサンプルはその生成過程ですでにShadow Rayを使ってVisibilityを確認しているので、もし、こちらのReservoirからサンプルが採用された場合は、この作業は不要なのでスキップするように処理が書かれています。&lt;code&gt;localReservoir&lt;/code&gt;側からからサンプルが選択された場合のみShadow Rayのトレースを行います。&lt;/p&gt;
&lt;p&gt;シェーディング関数の&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;は、RISの過程で何度も呼び出しているので説明不要ですが、ここでも&lt;code&gt;solidAndlePDF&lt;/code&gt;が除算されているので、PDFとの計算のつじつまが合うわけです。
&lt;code&gt;RTXDI_GetReservoirInvPdf()&lt;/code&gt;は、既にFinalizeされているReservoirに対して呼び出す関数で、単に&lt;code&gt;weightSum&lt;/code&gt;を返します。Finalizeが行われていればそこには、PDFの逆数に相当する値が格納されているはずです。
シェーディングが終われば、TonemappingをかけてUAVに書き出すと、全体の処理が完了します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projection Matrixについて</title>
      <link>https://shikihuiku.github.io/post/projection_matrix/</link>
      <pubDate>Sun, 27 Dec 2020 00:09:34 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/projection_matrix/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;Projection Matrixは何となくややこしいイメージが強い。実際ややこしい。自分でも勘違いすることがある。
なのでいったんまとめることにする。&lt;/p&gt;
&lt;h2 id=&#34;row-major-column-major-ベクトルとの乗算の順序&#34;&gt;Row Major, Column Major, ベクトルとの乗算の順序&lt;/h2&gt;
&lt;p&gt;Projection Matrixは4x4の正方行列で、メモリに格納するときに行要素を優先して格納すればRow-Major、列要素を優先して格納すればColumn-Majorと呼ばれる。&lt;/p&gt;
&lt;p&gt;Row-Majorは以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} a_1    &amp;amp; a_2    &amp;amp; a_3    &amp;amp; a_4    \\ a_5    &amp;amp; a_6    &amp;amp; a_7    &amp;amp; a_8    \\ a_9    &amp;amp; a_{10} &amp;amp; a_{11} &amp;amp; a_{12} \\ a_{13} &amp;amp; a_{14} &amp;amp; a_{15} &amp;amp; a_{16}  \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;対してColumn-Majorは、以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;\begin{pmatrix} a_1 &amp;amp; a_5 &amp;amp; a_9    &amp;amp; a_{13} \\ a_2 &amp;amp; a_6 &amp;amp; a_{10} &amp;amp; a_{14} \\ a_3 &amp;amp; a_7 &amp;amp; a_{11} &amp;amp; a_{15} \\ a_4 &amp;amp; a_8 &amp;amp; a_{12} &amp;amp; a_{16} \end{pmatrix}&lt;/p&gt;
&lt;p&gt;また、行列の積は可換ではない。たとえば、4次元ベクトルを行列の右から掛けるか左から掛けるかによって演算が変わるので、これには2通りの演算が存在する。&lt;br&gt;
$$
\begin{pmatrix} x^{\prime} \\ y^{\prime} \\ z^{\prime} \\ w^{\prime} \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix} \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x^{\prime} &amp;amp; y^{\prime} &amp;amp; z^{\prime} &amp;amp; w^{\prime} \end{pmatrix} = \begin{pmatrix} x &amp;amp; y &amp;amp; z &amp;amp; w \end{pmatrix} \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;シェーダーを記述する場合は、これらの解釈は実装者に委ねられる。一方で、グラフィックスAPIがこれらの演算を提供する場合もある。
OpenGLのCompatibility Profileでは、Column-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算はベクトルに対して左側からである。
Direct3D 9では、Row-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算は、ベクトルに対して右側からである。&lt;/p&gt;
&lt;h2 id=&#34;座標変換の過程について&#34;&gt;座標変換の過程について&lt;/h2&gt;
&lt;p&gt;次に座標変換の過程について簡単に説明する。頂点シェーダーが出力する4次元ベクトルは、一般的にはView座標系の位置にProjection Matrixを乗算した結果が出力される。
この座標は同次座標と呼ばれ、W成分で(X,Y,Z)を除算して正規化することで、Normalized Device Coordinate(正規化デバイス座標系)に変換される(Perspective Division)。次にViewport変換を行い、Normalized Device Coordinateを、描画用のバッファ（スクリーン）の領域にマッピングする。
多少の用語の違いがあるが、OpenGL、Vulkan、Direct3Dの3つのグラフィックスAPIは概ね同じ座標変換のステップを持っている。ただし各APIごとに座標軸の考え方や値の範囲が異なるので注意が必要である。&lt;/p&gt;
&lt;h2 id=&#34;y軸の反転について&#34;&gt;Y軸の反転について&lt;/h2&gt;
&lt;p&gt;一般的に3D空間上ではY軸を上向きと考える事が多い一方で、2Dスクリーン上では、ピクセルデータを画像の左上から格納する事が多い関係上、Y軸は下向きと考えることが多い。そのため、Projection Matrixによる投影変換、Perspective Division、そしてViewport変換の過程においてY軸を反転させることがある。ここではこれについて説明する。各種変換や用語に関する解説と前後するが、先にここにまとめておく。&lt;/p&gt;
&lt;h4 id=&#34;opengl&#34;&gt;OpenGL&lt;/h4&gt;
&lt;p&gt;OpenGLでは、元来Y軸の反転を行わないという思想の基にAPIが設計されていた。したがって、Viewport変換後のWindow座標系では、画像の左下を原点としてピクセルデータを取り扱う。そのため、Framebufferを画像として表示するときは垂直方向でデータを反転させて表示させるのが一般的である。しかし、現在のOpenGLでは、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective Divisionの際にY軸の符号を反転させる。これによって、Normalized Device CoordinateのY軸の上下が反転するので、Framebufferのデータが画像の左上を原点として格納されるようになる。Perspective Divisionについては、
&lt;a href=&#34;https://www.khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenGL 4.6 Core Pprofile&lt;/a&gt;の13.8に記載がある。&lt;/p&gt;
&lt;h4 id=&#34;direct3d&#34;&gt;Direct3D&lt;/h4&gt;
&lt;p&gt;Direct3Dの座標変換に関しては、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/the-direct3d-transformation-pipeline&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;このドキュメント&lt;/a&gt;に記述がある。これによれば、Perspective DivisionはViewport変換のスケーリングの後に行われており、Y軸の符号反転は、Viewportのスケーリングの係数の符号を逆転し、オフセットを調整することで実装されている。
また、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d9/projection-transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;他のドキュメント&lt;/a&gt;でも、Normalized Device CoordinateのY軸はView座標系と同じ向きに描写されている。したがって、Direct3DではViewport変換でY軸の符号の反転が行われていると解釈できる。
Viewport変換後のScreen座標系では、画像の左上を原点としてピクセルデータを取り扱う。&lt;/p&gt;
&lt;h4 id=&#34;vlukan&#34;&gt;Vlukan&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.khronos.org/registry/vulkan/specs/1.2/pdf/vkspec.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vulkan 1.2&lt;/a&gt;によれば、Perspective DivisionでY軸の符号を反転しない。また、Viewport変換時もY軸の符号を反転しない。そして、Viewport変換後のFramebuffer Coordinateの原点は、左上とされている。そのため、VulkanではProjection Matrixの演算でY軸を反転しない限り、Y軸を上向きとする空間を投影変換した像は上下が反転する。
また、Framebuffer Coordinateとの関連性を考えれば、VulkanのNormalized Device CoordinateのY軸は下向きと考えるのが自然である。&lt;/p&gt;
&lt;h2 id=&#34;perspective-division&#34;&gt;Perspective Division&lt;/h2&gt;
&lt;p&gt;Projection Matrixとの演算を終えた4次元ベクトルは、同次座標を表現する。これを正規化する($w=1$にする）作業は、プログラムなどで制御ができない固定された機能として、グラフィックスAPI側が行う作業となっている。
デフォルトの設定のOpenGL, Vulkan, Direct3Dでは、単純な$w$による除算が行われる。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ \frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;ただし、OpenGLでglClipControl()でGL_UPPER_LEFTが設定されているときは、Perspective Divisionの実行時に$Y$の符号が逆転される。
これは、3D空間上ではY軸を上向きと考えることが一般的である一方、画像フォーマットや、Microsoft Windows や X Window Systemでは、
垂直方向は画面の上から下に向かって座標軸を考えることが多いため、座標軸の向きを入れ替えるための計算である。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ -\frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;正規化された後の(X,Y,Z)はNormalized Device Coordinate（正規化デバイス座標系）を表現する&lt;/p&gt;
&lt;h2 id=&#34;normalized-device-coordinate-ndc&#34;&gt;Normalized Device Coordinate (NDC)&lt;/h2&gt;
&lt;p&gt;NDCは、シェーダーコードが出力した同次座標を、Perspective Divitionにより正規化した後の座標系となる。この座標系は$X,Y$は範囲が[-1, 1]と決まっており、
$Z$は[-1, 1]あるいは[0,1]と決まっている。この座標系は、$X,Y$はRenderTargetピクセル位置を表すスクリーン座標系と線形の関係にある。$Z$は深度バッファの値と線形の関係にある。&lt;/p&gt;
&lt;p&gt;OpenGLでは、glClipControl()でNDCのZ軸の範囲を[-1, 1]か[0, 1]のどちらかで選択することができる。デフォルトでは、GL_NEGATIVE_ONE_TO_ONE[-1, 1]が設定されており、GL_ZERO_TO_ONE[0, 1]を設定することで、Direct3D/Vulkanと同じ範囲になる。また、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective DivisionでY軸の符号が反転されるので、NDCのY軸が反転する。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ndc&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;NDC&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;631&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    NDC
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;viewport変換&#34;&gt;Viewport変換&lt;/h2&gt;
&lt;p&gt;NDCにおける$X,Y$の値の範囲は[-1, 1]だが、これをViewport変換によりRenderTargetのピクセル位置を表すスクリーン座標系に線形にマッピングする。RnederTarget上でのオフセットと幅と高さを指定する事でViewport変換が実現される。
一般的には、オフセットをゼロに設定し、幅と高さをRenderTargetの幅と高さとすることで、NDCの$X,Y$の[-1, 1]の範囲をRenderTargetの全ピクセルにマッピングすることが多いが、描画領域を分けて複数のViewportのレンダリング結果を一枚のRenderTargetにレンダリングする事もある。&lt;/p&gt;
&lt;p&gt;Direct3DはViewport変換時にY軸の上下が入れ替わるように計算される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1207&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;$Z$に関しては、Viewport変換後の深度値の値の範囲を$near, far$の二つの値で指定し、範囲は[0, 1]に収まる様にしなくてはならない。Viewportの$near, far$は深度バッファで使用する値の範囲の事で、
Projection Matrixの$near, far$とは全く意味が異なる。ほとんどの場合では、[0, 1]を指定して、深度バッファが表現できる全ての範囲を使用する。
OpenGLは、NDCのZの範囲を[-1, 1]としているときは、必ずViewport変換時に[near, far]への線形変換が行われる。対して、NDCの範囲が[0, 1]の場合は、Viewport変換の$near, far$が、[0, 1]に設定されている場合は、NDCの$Z$の値がそのまま深度バッファの値として格納される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;374&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;右手系左手系&#34;&gt;右手系、左手系&lt;/h2&gt;
&lt;p&gt;右手系、左手系とは、単位マトリクスのX,Y,Z軸の各ベクトルの、認識している空間におけるマッピングである。右手系は、右手の（親指,人差し指, 中指）を自然な形で直交させたとき、(X, Y, Z)の向きとなる空間を指す。
左手系も同様である。デフォルトのOpenGLとDirect3DのNDCは、はX軸が画面左から右、Y軸が画面下から上、Z軸が画面手前から奥なので、左手系である。
一方で、glClipControl()でGL_UPPER_LEFTを設定したOpenGLとVulkanのNDCは、X軸が画面左から右、Y軸が画面上から下、Z軸が画面手前から奥なので、右手系である。&lt;/p&gt;
&lt;p&gt;よく耳にする話として、OpenGLが右手系でDirect3Dが左手系という話があるが、OpenGLに関してはglFrustum()/glOrtho()という関数が、
右手系のViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するためのProjection Matrixを計算することに起因している。
実際にはProjection MatixにはglLoadMatrixで自由に値を設定することができるので、OpenGLは元来シェーダーを使わなくても、右手系でも左手系でも自在に描画できるはずである。
また、Direct3DにはProjection Matrixを計算するAPIは用意されていない。ただし、ユーティリティ関数群のD3DXには、D3DXMatrixPerspectiveRH()という関数が用意されている。
この関数は右手系ViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。同様に、D3DXMatrixPerspectiveLH()という関数も用意されており、
こちらは、左手系のViewMatrixの+Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。&lt;/p&gt;
&lt;p&gt;このように、ある特定のグラフィックスAPIの座標系が右手系左手系のいずれかに属していると考えること自体が誤りだといえる。&lt;/p&gt;
&lt;h2 id=&#34;projection-matrixの役割&#34;&gt;Projection Matrixの役割&lt;/h2&gt;
&lt;p&gt;さて、ここからが本題ののProjection Matrixに関する説明になる。View座標系からNDC座標系への変換を担うProjection Matrixには、主に4つの要素がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y軸の向きの入れ替え (Vulkan)&lt;/li&gt;
&lt;li&gt;Z軸の向きの入れ替え&lt;/li&gt;
&lt;li&gt;X,Y軸に関する透視投影変換&lt;/li&gt;
&lt;li&gt;Z軸のNDC座標へのマッピング&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透視投影変換を行わない正射影というProjection Matrixもあるが、ここでは割愛する。&lt;/p&gt;
&lt;h2 id=&#34;y軸の向きの入れ替え-vulkan&#34;&gt;Y軸の向きの入れ替え (Vulkan)&lt;/h2&gt;
&lt;p&gt;Vulkan特有の事なので一番最初に解説する。Vulkanは先に説明した通り、NDCのY軸は下向きでPerspective DivisionやViewport変換でY軸の符号反転を行わない。
したがって、Y軸が下向きとなる様に頂点シェーダーの出力を行わなければならない。そのため、View座標系でY軸が上向きになるように座標を扱っていた場合、Projection MatrixでY軸を反転させる必要がある。
具体的にはProjection Matrixの、Y成分のスケーリングとオフセットを担当する成分（以下の場合では$a_{22}, a_{23}$）の符号を入れ替える事で、NDCの上下が反転した結果を得る事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; -a_{22} &amp;amp; -a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44}  \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸の向きの入れ替え&#34;&gt;Z軸の向きの入れ替え&lt;/h2&gt;
&lt;p&gt;同次座標の$w$は、単にPerspective Divisionでの除算に使われるだけでなく、ポリゴン平面上の属性値補間でPerspective Correctionを行うときに使用されるので、$Z$軸に沿って正しく透視投影変換をするときは下記のどちらかの設定になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Z_{View}$の正の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのため、$Z_{View}$と乗算される位置に$1$を設定する。&lt;/li&gt;
&lt;li&gt;$Z_{View}$の負の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$-Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのために$Z_{View}$と乗算される位置に$-1$を設定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、それぞれ$Z_{View}$正負の方向にNDCのZ軸を設定し、透視投影変換をする場合のProjection Matrixである。殆どのProjection Matrixは下記のいずれかである。
余談だが、この、$w$と乗算される行（あるいは列）は特徴的なので、これを手がかりに、メモリにダンプされたマトリクスが、Row-MajorなのかColumn-Majorなのかを簡単に見分ける事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;xy軸に関する透視投影変換&#34;&gt;X,Y軸に関する透視投影変換&lt;/h2&gt;
&lt;p&gt;透視投影変換は、空間にある物体が視点から離れる程小さく投影される様に変換する役割がある。これにより遠近感が演出される。
視点からの距離が二倍になれば、物体は長さで二分の一の大きさで描画されるようにする。したがって$Z$軸向きに透視投影した$X,Y$座標は、$1/Z$に比例する。&lt;/p&gt;
&lt;p&gt;$X,Y$軸に関する透視投影変換は、つまるところ、以下の式の$a, b, c, d$を決定することにある。
$$
X_{NDC} = \frac{a * X_{View}}{Z_{View}} + b
$$
$$
Y_{NDC} = \frac{c * Y_{View}}{Z_{View}} + d
$$&lt;/p&gt;
&lt;p&gt;$a, c$の値が、水平、垂直視野角を決定し、$b, d$がView座標系からNDC座標系に変換するときのオフセットになる。$b, d$は、View座標のZ軸がNDC座標のX,Yの中心を通る場合はゼロになる。
水平、垂直視野角から$a,c$の値を計算する場合は、視野の両端がNDCにおける[-1, 1]になるように計算すれば良い。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;808&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

したがって係数$a,c$は、水平視野角を$\theta$、垂直視野角を$\phi$とすれば以下の様に計算できる。（注意：通常は水平視野角と垂直視野角はアスペクト比を通じた線形の関係ではない。通常は水平視野角か垂直視野角のいずれかを基準として正接を計算して、他方はアスペクト比を乗算することで他方の正接を計算するが、ここでは簡便のためそれぞれの視野角を使う。）
$$
a = \frac{1}{tan(\frac{\theta}{2})}
$$
$$
c = \frac{1}{tan(\frac{\phi}{2})}
$$&lt;/p&gt;
&lt;p&gt;もう一つの、係数$a,c$の計算方法として、$Z_{View}=near$平面上での視野の上下左右に相当する$left, right, top, bottom$を指定する方法である。以下の図には$left, right$による水平視野角を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;992&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

この場合の係数$a,c$は、$l, r, t, b$の値と、$near$平面までの距離$n$を用いて以下の様に表せる。
$$
a = \frac{2n}{r - l}
$$
$$
c = \frac{2n}{t-b}
$$
また、この指定方法の場合は、$l, r$の値がZ軸において対称でない場合は、オフセットの値が発生する。例として、$l, r$によるオフセット計算の図を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野のオフセットの計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu26ba68dc21b12d6542ccc7434c2e9e2e_80001_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野のオフセットの計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu26ba68dc21b12d6542ccc7434c2e9e2e_80001_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;1303&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野のオフセットの計算
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上図はView座標系での、$Z_{View}=near$平面上でのオフセット値になるので、NDC座標系に変換するには、$2/(r-l)$を乗算する必要がある。したがって、オフセットの値は以下の様になる。
$$b = -\frac{r+l}{r-l}$$
$$d = -\frac{t+b}{t-b}$$
オフセットの値は、NDC座標系において一定なので、View座標系においては$Z_{View}$の値に比例する。&lt;/p&gt;
&lt;p&gt;また、オフセットがない場合は、$near, left, right, top, bottom$と$\theta, \phi$に、以下のような関係が成り立つ。
$$
l = n \cdot tan(\frac{\theta}{2})
$$
$$
r = -n \cdot tan(\frac{\theta}{2})
$$
$$
t = n \cdot tan(\frac{\phi}{2})
$$
$$
b = -n \cdot tan(\frac{\phi}{2})
$$&lt;/p&gt;
&lt;p&gt;次に、Projection Matrixへの各係数の設定だが、$a, c$の値は、それぞれ$X_{View}$, $Y_{View}$と乗算されるように格納する。$Z_{View}$の除算の部分はPerspective Divisionで行われる。
$b, d$の値は、$Z_{View}$と乗算されるようにProjection Matrixに格納する。これは、のちにPerspective Divisionで相殺されることでオフセット値として機能する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;以下のマトリクスはD3DXMatrixPerspectiveOffCenterLHが算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; -\frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; -\frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;一方で、Z軸の向きの入れ替えるために、$a_{43}$に$-1$を設定している場合は、$Z_{View}$が乗算される時と、除算される時で符号が異なるため、オフセットの係数の符号が変わる。
以下のマトリクスはD3DXMatrixPerspectiveOffCenterRHが算出する係数や、glFrustum()が算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; \frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; \frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸のndc座標へのマッピング&#34;&gt;Z軸のNDC座標へのマッピング&lt;/h2&gt;
&lt;p&gt;Z軸に関する変換は透視変換ではなく、Z軸の値の一定の範囲をNDCで許されている値の範囲に、大小関係を損なわずに変換することである。通常は、View座標系の広大なZ軸の範囲を、NDCで許されている高々[0, 1]程度の範囲にマッピングする圧縮作業である。
簡単に考えれば、View座標系のZの値にオフセットとスケールを適用すれば実現できるが、これは残念ながら推奨されない。
$$Z_{NDC} = e * Z_{View}  + f$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一つ目の理由は、Projection Matrixを使った座標変換による制限によるものである。$X, Y$の値を透視投影変換するためには、同次座標系の$W$の値を$Z$（もしくは$-Z$)の値としなければ、$X,Y$軸に関する透視投影変換が実現できない。そのため$W$の値は決定されていると言える。
この条件では、Projection Matrixとの乗算では、View座標系の$Z$と1次比例の関係を作ることができない。一応ながら、Pixel Shader内で深度バッファに出力する値を直接計算することで実現可能だが、GPUの早期Zカリング機能が無効化されるので実際のアプリケーションの運用では現実的な方法とは言えない。&lt;/li&gt;
&lt;li&gt;二つ目の理由は、透視投影変換後のNDCでの$X,Y$平面（つまりはスクリーンスペース）では、$Z_{View}$は線形性を失う。代わりに$1/Z_{View}$が線形性を持つことになる。
投影変換されたポリゴン平面の深度値を高速に計算するならば、線形性を失った$Z_{View}$に比例した式で計算された値は単純な補間では計算出来ず、計算コストが高く効率が良くない。それよりも、大小関係を（反転しつつも）保ちつつ、スクリーンスペースで線形性を持つ$1/Z_{View}$を使う方が合理的だったという経緯がある。
（ちなみに、スクリーンスペースでテクスチャのU,Vなどの頂点属性値は、$attribute/W$と$1/W$をスクリーンスペースで線形補間し、その結果を除算することで補完された頂点属性値を計算している。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、一般的にGPUでは$Z_{View}$ではなく$1/Z_{View}$を線形変換した結果をNDCのZ座標として採用している。
$$Z_{NDC} = \frac{e}{Z_{View}}  + f$$&lt;/p&gt;
&lt;p&gt;また、このようにすると、深度バッファに整数の格納フォーマットを使った場合、$Z$の値が小さいときほど、多くのBitを使って表現することになる。
つまり、近くの物体ほど深度バッファの多くのBitが割り当てられるので、これは合理的であるとも考える事ができる。また、$1/Z$の線形変換であれば、Projection Matixで一元的に扱えるのも利点である。&lt;/p&gt;
&lt;p&gt;係数$e, f$の決定は、View座標系における、Z軸の範囲である$near, far$の値が、[0, 1] （もしくは[-1, 1]）になるように連立方程式を解くだけで計算できる。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;下記の式を解けば、D3DXMatrixPerspectiveFovLHに設定される係数と符合する。&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$0 = \frac{e}{near} + f$$
$$1 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{far \cdot near}{far-near}$$
$$f = \frac{far}{far - near}$$&lt;/p&gt;
&lt;p&gt;Projection Matrixに設定するときは、$Z_{View}$と乗算される位置に$f$を設定し、$W$(通常は1.0)と乗算される方に$e$を設定する。Perspective Divisionで$W$(この時点では$Z_{View}$)による除算が行われ、上記の式と等価な計算が行われる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{far - near} &amp;amp; -\frac{far \cdot near}{far-near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合は、Projection Matrixの乗算をよく観察する必要がある。$1/Z_{View}$の係数である$e$は、$W_{View}$と乗算して、$-Z_{View}$で除算される。$W_{View}$は通常$1.0$で$-Z_{View}$も正の数なので、上記で求めた$e$がそのまま使える。
一方で、オフセットの$f$は、$Z_{View}$と乗算して、$-Z_{View}$で除算される。したがって、上記で求めたものの符号を反転させたものを使う必要がある。こうして求めた結果は、D3DXMatrixPerspectiveFovRHの係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{near-far} &amp;amp; \frac{far \cdot near}{near -far} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同様の手順で係数$e, f$を求める事ができる&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$-1 = \frac{e}{near} + f$$
$$2 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{2(far \cdot near)}{far-near}$$
$$f = \frac{far + near}{far - near}$$&lt;/p&gt;
&lt;p&gt;それぞれをProjection Matrixに設定すると以下の様になる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合も先ほどと同様の手順となる。これはglFrustum()関数の係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;inverse-z&#34;&gt;Inverse Z&lt;/h2&gt;
&lt;p&gt;深度バッファに浮動小数点の格納フォーマットが使えるとき、NDCにおける深度のマッピングを、[Near, Far]を[0, 1]ではなく[1, 0]にマッピングすることで、$far$付近での深度バッファの精度不足を解消することができる。
NDCが[-1, 1]の場合や、深度バッファの格納フォーマットが整数表現の場合は、Inverse Zを使う利点はない。
精度については詳しくは以下に解説がある。&lt;br&gt;

&lt;a href=&#34;http://www.reedbeta.com/blog/depth-precision-visualized/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Depth Precision - Nathan Reed&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zの設定は簡単で、先ほどの連立方程式の$near$と$far$を入れ替えて解くだけで係数は求まる。レンダリングの際には、深度バッファのクリア値を、1ではなく0に設定し、ラスタライザーの深度テストの条件を反転させればよい。
$$1 = \frac{e}{near} + f$$
$$0 = \frac{e}{far} + f$$
$$e = \frac{far \cdot near}{far - near}$$
$$f = -\frac{near}{far-near}$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;infinite-far-plane&#34;&gt;Infinite Far Plane&lt;/h2&gt;
&lt;p&gt;$far$を無限遠に設定する事で、Far Clippingを実質無効化するとともに、浮動小数点の丸め誤差を低減することができる。Projection Matrixに設定する係数の計算は、今まで求めてきた係数の、$far$を無限大で極限を取れば算出される。
Infinite Far Planeのメリットは、非常に遠くのオブジェクトを描画してもクリッピングされることがないことと共に、空や星などを描画する際に、$W_{View}$をゼロとすることで、$(X_{View}, Y_{View}, Z_{View})$方向の無限遠を描画することができることである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-1&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$e = \lim_{far\to\infty} -\frac{far \cdot near}{far-near} = -near$$
$$f = \lim_{far\to\infty} \frac{far}{far - near} = 1$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いないInfinite Far Planeは、無限遠の深度値が1.0となるが、$Z_{View}$が極大化すると正確に描画できないことがあるので注意が必要である。これはProjection Matrixを使った演算とPerspective Divisionでオフセットを設定する場合に、$Z_{View}$による乗算と除算が行われるため、この値が非常に大きな値になれば、浮動小数点数としての精度を失ってしまうからである。&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-1&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;一方で、Inverse Zを用いた場合のInfinite Far Planeの係数は以下の様に計算される。
$$e = \lim_{far\to\infty} \frac{far \cdot near}{far - near} = near$$
$$f = \lim_{far\to\infty} -\frac{near}{far-near} = 0$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeは、オフセットの係数がゼロなので、$Z_{View}$が極大化する事によるProjection Matrixとの乗算による精度の問題を起こさない。以下は、Inverse Zを用いたInfinite Far PlaneのProjection Matrixである。$a_{43}$は$1$でも$-1$でも変わらない。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; near \\ 0 &amp;amp; 0 &amp;amp; a_{43} &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからz_viewの逆算&#34;&gt;深度バッファから$Z_{View}$の逆算&lt;/h2&gt;
&lt;p&gt;マルチパスレンダリング等を行っていると、描画された深度バッファより、$Z_{View}$を求めたい時がある。計算自体は単なる逆算なので簡単である。&lt;/p&gt;
&lt;p&gt;深度バッファから$Z_{View}$を逆算するためには、まず、Viewport変換を逆変換して$Z_{NDC}$を計算する必要がある。Viewportの$near, far$とNDCの$Z$軸の範囲が分かれば計算は簡単である。深度バッファとNDCの範囲が一致する場合は、この計算は不要である。
$$Z_{NDC}  = \frac{Depth - near_{Viewport}}{far_{Viewport} - near_{Viewport}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-2&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;Projection Matrixに設定した係数$e, f$を使って$Z_{NDC}$から$Z_{View}$を逆算する。$Z_{NDC}$が正の$Z_{View}$方向ならば以下の式で計算できる。
$$Z_{NDC} = \frac{e}{Z_{View}} + f$$
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は符合の操作が必要である。まず、オフセットの値$f$の符合を反転させてあるので、これを反転する必要がある。加えて$Z_{View}$は負の方向なので、最後に符合を反転する必要がある。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-2&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{near + Z_{NDC} (far - near)}$$
Inverse Zで、$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{near + Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeの場合は、式はもっと単純になる。ただし、$Z_{NDC}$がゼロの場合はゼロ除算になるので注意が必要である。
$$Z_{View}= \frac{e}{Z_{NDC}} = \frac{near}{Z_{NDC}}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= -\frac{e}{Z_{NDC}} = -\frac{near}{Z_{NDC}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合-1&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同じ手順で計算する。
Depthから$Z_{NDC}$は以下の通り。
$$Z_{NDC}  = \frac{2(Depth - near_{Viewport})}{far_{Viewport} - near_{Viewport}} -1$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$から$Z_{View}$は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は
$$Z_{View}= -\frac{e}{Z_{NDC} + f} = -\frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからlinear-depthの計算&#34;&gt;深度バッファからLinear Depthの計算&lt;/h2&gt;
&lt;p&gt;上記で示した通り、Projection MatrixのNearとFarが分かれば、深度バッファから$Z_{View}$を復元できるが、
実際には$Z_{View}$よりも、単に線形性がある深度値としてのLinear Depthが欲しいケースが多い。
ここでのLinear Depthは[near, far]が[0, 1]にマッピングされており、かつ線形性を保っているものを指す。
計算は先の式の[near, far]を[0, 1]に線形でマッピングするだけである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-3&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$Z_{Linear}= \{ \frac{far \cdot near}{far - Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{Z_{NDC} \cdot near}{far - Z_{NDC}(far - near)} = \frac{Z_{NDC}}{\frac{far}{near} - Z_{NDC}(\frac{far}{near}-1)} $$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-3&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。[near, far]を[0, 1]にマッピングするので、Inverse Zの大小関係は再び反転するので注意。
$$Z_{Linear}= \{ \frac{far \cdot near}{near + Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{near (1 - Z_{NDC})}{near + Z_{NDC}(far -near)} = \frac{1 - Z_{NDC}}{ 1 + Z_{NDC}(\frac{far}{near} - 1)}$$&lt;/p&gt;
&lt;h2 id=&#34;render-targetのピクセル位置から視線ベクトルの逆算&#34;&gt;Render Targetのピクセル位置から視線ベクトルの逆算&lt;/h2&gt;
&lt;p&gt;G-Buffer等を用いている場合は、Render Targetのピクセル位置から視線ベクトルを逆算したい事も多い。これも上記と同様で、Projection Matrixからの逆算で計算自体は簡単である。&lt;/p&gt;
&lt;p&gt;Render Targetのピクセル位置から視線ベクトルの逆算するためには、Viewport変換を逆変換して$X_{NDC}, Y_{NDC}$を計算する。
$$X_{NDC} = \frac{2(X_{Pixel} - OfsX_{Viewport})}{Width_{Viewport}}-1$$
$$Y_{NDC} = \frac{2(Y_{Pixel} - OfsY_{Viewport})}{Height_{Viewport}}-1$$&lt;/p&gt;
&lt;p&gt;また、Render Targetのピクセル位置ではなく、フルスクリーン描画したポリゴンのUV値から$X_{NDC}, Y_{NDC}$を逆算する方法も良く用いられる。いずれにせよ、範囲が明確なNDCの座標を再計算するのは簡単である。&lt;/p&gt;
&lt;p&gt;次に$Z_{View}=1$の場合の、$X_{View}, Y_{View}$を計算する。ここでの$a,b,c,d$は、先ほど透視投影変換で求めた値で、$\theta, \phi$は水平、垂直視野角である。
$$X_{View1} = \frac{X_{NDC} - b}{a} = tan(\frac{\theta}{2})X_{NDC}$$
$$Y_{View1} = \frac{Y_{NDC} - d}{c} = tan(\frac{\phi}{2})Y_{NDC}$$&lt;/p&gt;
&lt;p&gt;三次元ベクトル$(X_{View1}, Y_{View1}, 1)$は、View座標系の原点からピクセルへのベクトル：視線ベクトルを表すが、長さが1ではないのでライティングの計算をする場合は正規化する必要がある。
一方で、ピクセルのView座標系における位置を求める場合は、このベクトルに$Z_{View}$を乗算することで求める事ができる。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;もっと簡単にまとめたかったが、ダラダラと長くなってしまった。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
