<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Direct3D | shikihuiku – 色不異空 – Real-time rendering topics in Japanese.</title>
    <link>https://shikihuiku.github.io/tag/direct3d/</link>
      <atom:link href="https://shikihuiku.github.io/tag/direct3d/index.xml" rel="self" type="application/rss+xml" />
    <description>Direct3D</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 07 Jun 2022 19:30:28 +0900</lastBuildDate>
    <image>
      <url>https://shikihuiku.github.io/images/icon_hu127225d7ed9c50974404790b7c221374_401884_512x512_fill_lanczos_center_3.png</url>
      <title>Direct3D</title>
      <link>https://shikihuiku.github.io/tag/direct3d/</link>
    </image>
    
    <item>
      <title>RTXDIのminimal-sampleを理解する</title>
      <link>https://shikihuiku.github.io/post/rtxdi_first_step/</link>
      <pubDate>Tue, 07 Jun 2022 19:30:28 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/rtxdi_first_step/</guid>
      <description>&lt;h1 id=&#34;rtxdiとは&#34;&gt;RTXDIとは？&lt;/h1&gt;
&lt;p&gt;GPU上かどうかにかかわらずレイトレーシングやパストレーシングを行う際の重要な課題の一つは、追跡する光線の軌跡（パスもしくはレイと呼ばれるもの）をどのように構築するかです。これはレンダラーの性能や画質などの特性に直結する問題です。たとえば、物体表面からの反射に限定すれば、最も簡単なパスの構築方法は、物体の表面から半球状ににランダムな方向を選択してパスを構築する方法があると思います。また、物体表面の反射特性に合わせて、より反射率の高い方向を高確率で選択する方法や、シーン上に存在する光源の方向にパスを構築する方法もあります。&lt;br&gt;
このように、いろいろなパスの選択戦略があり、実際のレンダリングでは、これらを組み合わせて使うことがよくある思います。そして、最も理想的なパスの確率分布は、その物体表面から、観測者の方向へのRadianceに比例した確率分布といわれています。しかしこれは、一般的には解析的に解くことが極めて困難であることがほとんどです。なぜなら、物体表面の反射特性は分かっても、どの方向から強い光が差し込んでくるかはわかりません。その光も、シーン上に設定された光源からの直接光なのか、それとも何かほかの物体から反射された光なのかわかりません。&lt;br&gt;
RTXDIは、光源からの直接光によって形成されるRadianceに対して、最適なパスの確率分布を形成するようにパスの選択をするためのNVIDIAのSDKです。名前の由来は、おそらくRTX Direct Illuminationです。&lt;/p&gt;
&lt;h4 id=&#34;リポジトリ&#34;&gt;リポジトリ&lt;/h4&gt;
&lt;p&gt;GitHubのリポジトリがあるので、さっそくCloneしてみましょう。&lt;br&gt;
以降の説明では基本的にCloneしたソースを読める状態にある前提で書いています。&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;ドキュメント&#34;&gt;ドキュメント&lt;/h4&gt;
&lt;p&gt;RTXDIのSDKのドキュメントを見る前に、前提知識として、Resampled Importance Sampling(RIS)のアルゴリズムの基礎部分を理解した方がよいと思います。（これより先は、Resampled Importance SamplingをRISと省略します。）&lt;br&gt;

&lt;a href=&#34;https://www.google.com/search?q=Importance&amp;#43;Resampling&amp;#43;for&amp;#43;Global&amp;#43;Illumination&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Importance Resampling for Global Illumination&amp;rdquo; by J. Talbot et al.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RTXDIのSDKには、その概要を把握するのに下記のドキュメントがありますが、これを読んで理解できる人は、この記事はここで読むのを終了していただいて、SDKのドキュメントやソースコードを直接参照した方が良いでしょう。

&lt;a href=&#34;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIAGameWorks/RTXDI/blob/main/doc/Integration.md&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;rtxdi-sampleとminimal-sample&#34;&gt;rtxdi-sampleとminimal-sample&lt;/h4&gt;
&lt;p&gt;このSDKにはサンプルプロジェクトが二つ付いています。&lt;br&gt;
rtxdi-sampleは、RTXDIをパス選択の核として、RTXGIやNRDやDLSSを用いてレンダリングしています。またReGIRという、ワールド空間におけるRISも行っているので、かなり実践的なサンプルになっている一方で、初めのステップとして、RTXDIの動作を理解したい場合には不向きなサンプルです。&lt;br&gt;
一方で、minimal-sampleは、設定を変更することで時間方向のRISや、BRDFに基づくサンプリングも無効にすることが出来ます。また、NRDによるデノイズも行っておらず、レンダリングは極力単純な形で留めてあります。そのため、RTXDIの核であるRISの仕組みや、その効果をわかりやすく見せてくれるサンプルになっています。本記事ではこちらのサンプルプログラムの動作を見ていきます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleのスクリーンショット&#34;&gt;minimal-sampleのスクリーンショット&lt;/h1&gt;
&lt;p&gt;端的にRTXDIの効果の一端を見るためにいくつかのスクリーンショットを用意しました。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-1サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;1サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample1S_hu58be2117725250a7b77b2fd59d4ee080_555039_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    1サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-8サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;8サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample8S_hu58be2117725250a7b77b2fd59d4ee080_932721_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    8サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S_hu58be2117725250a7b77b2fd59d4ee080_989635_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

まずは上記3枚は、RTXDIのパス選択候補を、8サンプル、16サンプルと増加させたものです。選択候補は増やしているのですが、実際にれらのサンプルでレイトレースを行った訳ではありません。レイトレースはあくまで1回のみ行います。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-16サンプルbrdf2サンプル&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;16サンプル＋BRDF2サンプル&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample16S2S_hu58be2117725250a7b77b2fd59d4ee080_1007168_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    16サンプル＋BRDF2サンプル
  &lt;/figcaption&gt;


&lt;/figure&gt;

次は、16サンプル+BRDF2サンプルの場合です。こちらはレイトレース回数は、合計3回となります。BRDFサンプルによって、良い選択候補が見つかるサーフェースでの変化が顕著に見られます。&lt;/p&gt;
&lt;p&gt;





  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-4サンプルbrdf1サンプルspatio-temporal-resample&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;4サンプル＋BRDF1サンプル&amp;#43;Spatio-Temporal Resample&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/Sample4S1S_ST_hu58be2117725250a7b77b2fd59d4ee080_978847_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1390&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    4サンプル＋BRDF1サンプル+Spatio-Temporal Resample
  &lt;/figcaption&gt;


&lt;/figure&gt;

今回の記事では説明しませんが、Spatio-Temporalのパス選択候補を導入すると、上記のようになります。上記の16サンプルと同等の処理時間ですが、結果は圧倒的にこちらが優れています。デノイズ処理は一切入っていない状態でここまでレンダリングできれば、かなり高画質なレンダリングが期待できます。&lt;/p&gt;
&lt;h1 id=&#34;minimal-sampleを読む前に前提知識&#34;&gt;minimal-sampleを読む前に（前提知識）&lt;/h1&gt;
&lt;p&gt;ここでサンプルプログラムのレンダリングを見る前に、簡単に触れておいた方が良い前提知識について説明します。&lt;/p&gt;
&lt;h4 id=&#34;nvrhiとdonutフレームワーク&#34;&gt;NVRHIとDonutフレームワーク&lt;/h4&gt;
&lt;p&gt;RTXDI SDKのほかに、minimal-sampleが依存している主なライブラリとして、DonutとNVRHIがあります。&lt;br&gt;
NVRHIは、D3D12とVulkanを抽象化するためのグラフィックスAPIの抽象化レイヤーです。とはいえそれほど深い抽象化が行われているわけではありません。&lt;br&gt;
Donutは、サンプルアプリケーションのフレームワークに相当する部分になります。シーンのロードやシェーダーの管理、デバッグUIの表示などを行っています。こちらもサンプル向けのフレームワークなので、シンプルに記述されています。今回のサンプルプログラムでは、それほど多数のDispatchが呼び出されるわけではないので、動作の理解に苦しむことはないかと思います。&lt;/p&gt;
&lt;h4 id=&#34;rab_プレフィックスについて&#34;&gt;RAB_プレフィックスについて&lt;/h4&gt;
&lt;p&gt;RTXDIのサンプルを見ると、RTXDI_プレフィックスの関数や構造体とは別に、RAB_プレフィックスの関数や構造体がたくさんあります。RABの意味はRTXDI Application Bridgeという意味で、その名の通り、RTXDIとアプリケーションの橋渡しの役目があります。&lt;br&gt;
RTXDIがRISを行うときに必要になる情報は、アプリケーションのレンダラーと密接に関係しています。そのため、RTXDIがアプリケーション由来の情報と思われるものを取得する際は、RAB_プレフィックスのついた関数を呼び出します。RTXDIが呼び出している、RABプレフィックスのついた関数を実装するのは、アプリケーション側の責任となります。
しかし実際は、サンプルアプリケーションのRAB実装である、RtxdiApplicationBridge.hlslを改変する形で自身のアプリケーションに組み込む形になると思います。このようにすることで、アプリケーションごとに改変の必要な部分と不要な部分の切り分けを実現しています。&lt;/p&gt;
&lt;h4 id=&#34;rtxdi特有のリソース&#34;&gt;RTXDI特有のリソース&lt;/h4&gt;
&lt;p&gt;通常のG-Bufferなどに加えて、minimal-sampleでRTXDI SDKを導入したことで必要となるリソースは以下の通りです。RTXDIは、SDKの内部でリソースを確保することはありません。リソースの管理は、生成、破棄を含め、すべてアプリケーション側の管理となります。  SDK側からは必要に応じて、リソースのサイズやその中身がAPIを通じて提供されるので、アプリケーションはそれらを正しく管理しなくてはなりません。
以下のリソースは、ソースコード全体の把握では大切な要素ですが、RISのアルゴリズム部分ではあまり関わりが無いので読み飛ばしても問題ありません。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;TaskBuffer&lt;br&gt;
RTXDIは、毎フレーム直接光源情報のテーブルの更新を行っています。これはPrepareLightというGPU処理マーカーの中でComputeShaderとして行われています。この処理の入力として TaskBufferが必要となります。このバッファはPrepareLightsTask構造体の配列となっています。
このサンプルでは、シーン上でEmissiveサーフェースを持ったGeometry Instanceの個数分のバッファを確保しています。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightBuffer&lt;br&gt;
RTXDIがアクセスする光源の情報はすべてこのバッファに格納されます。個々の光源は、RAB_LightInfo構造体に格納されます。
このサンプルでは、Emmisiveのマテリアルが設定されたポリゴン一つ一つがEmissiveTriangleの光源としてこの配列に設定されます。
TaskBufferによって入力された情報をもとに、このバッファが構築されます。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GeometryInstanceToLightBuffer&lt;br&gt;
Geometry Instanceごとに、そのInstanceに含まれるEmissiveTriangleの光源としてのLightBufferにおける先頭のインデックスを格納します。つまり、GeometryInstanceのインデックスからLightBufferを参照するときに使われるテーブルです。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NeighborOffsetBuffer&lt;br&gt;
RTXDIがサイズを提供しと内容を指定します。スクリーンスペースでRISを行うときに参照するべきPixelへのオフセットになる値が格納されます。EvenとOddのフィールドがあるのでRTXDIが提供するNeighborOffsetCountの2倍の数で、RG8_SNORMのTypedBufferを確保します。
レンダリングの前に、RTXDIのFillNeighborOffsetBuffer()で取得できるバイト列をこのバッファに書き込む必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LightReservoirBuffer&lt;br&gt;
RTXDIがサイズを提供し内容はComputeShaderで算出されます。
ReservoirBuffer一つあたりのサイズはsizeof(RTXDI_PackedReservoir) * context.GetReservoirBufferElementCount()で、RTXDIから提供されます。
これをアプリケーション側の好きな数だけ確保します。サンプルの初期値では3セット分のサイズのバッファを確保しています。
時間方向でRISを行う場合のためのバッファになります。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rtxdiのreservoirについて&#34;&gt;RTXDIのReservoirについて&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;（ここより以下、RTXDIもしくはRISの文脈で、&amp;ldquo;サンプル&amp;quot;と言っている場合は、レイトレーシングにおけるサーフェースと光源を結ぶパスを構築するためのLight Sampleを指します。サンプルアプリケーションのことでもなければ、テクスチャのサンプリングのことでもありません。）&lt;/strong&gt;&lt;/em&gt;&lt;br&gt;
RTXDI_Reservoir構造体はRISのReservoirとしての情報を保持します。Reservoirとは、RISをするためのサンプルの集合です。ただし、サンプルの集合の情報をすべて保持していたら、GPU上ではメモリが足りません。したがって、Reservoirは今まで生成してきたサンプルによる確率の計算と、現在そのReservoirで選択されているサンプルの情報を格納しています。具体的には、サンプルの選択確率に関する情報と、パスの接続対象なる光源のインデックス、その光源の表面における位置情報にあたるUVです。これがあれば、ワールド空間でパスを接続するべき位置（つまりは光源の表面位置）が計算でき、シェーディングを行った後にサンプルの確率密度を適用することができます。&lt;br&gt;
Reservoirに関して全くイメージがわかないという場合は、まず初めに紹介した論文を軽く読んで、ReSTIRに関する論文、

&lt;a href=&#34;https://research.nvidia.com/sites/default/files/pubs/2020-07_Spatiotemporal-reservoir-resampling/ReSTIR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting&amp;rdquo;, Bitterli et al. 2020&lt;/a&gt;&lt;br&gt;
を読むとイメージできると思います。（もしこの二つを読んだならば、本記事は、この先読む必要がないでしょう）&lt;/p&gt;
&lt;h4 id=&#34;reservoirを操作する関数群&#34;&gt;Reservoirを操作する関数群&lt;/h4&gt;
&lt;p&gt;ここではRTXDIがReservoirを操作する関数群のなかで、最も基本的なものをザックリと説明します。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;RTXDI_Reservoir RTXDI_Reservoir RTXDI_EmptyReservoir()&lt;/code&gt;&lt;br&gt;
有効なサンプルが一つも格納されていない、初期化された&lt;code&gt;RTXDI_Reservoir&lt;/code&gt;構造体を返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_StreamSample( inout RTXDI_Reservoir reservoir, uint lightIndex, float2 uv, float random, float targetPdf, float invSourcePdf)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reservoir&lt;/code&gt; - 格納するReservoir&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lightIndex&lt;/code&gt;, &lt;code&gt;uv&lt;/code&gt; - 追加するLight Sampleの情報&lt;/li&gt;
&lt;li&gt;&lt;code&gt;random&lt;/code&gt; - Light Sampleを更新するかどうかをDraw（選択）するときに使う乱数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPdf&lt;/code&gt; - RISにおけるTarget PDF&lt;/li&gt;
&lt;li&gt;&lt;code&gt;invSourcePdf&lt;/code&gt; - 追加するサンプルを生成する確率の逆数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一つのサンプルをReservoirに追加して、現在このReservoirの中で選択されているサンプルを更新します。&lt;br&gt;
&lt;code&gt;targetPDF&lt;/code&gt;は実際は正規化されたPDFである必要はなく、単なるウエイト値で問題ありません。一方で、&lt;code&gt;invSourcePdf&lt;/code&gt;は、サンプルの発生確率に基づいたPDFである必要があります。関数内部では、RIS Weightが &lt;code&gt;targetPdf * invSourcePdf&lt;/code&gt; で計算され、Reservoir構造体の &lt;code&gt;weightSum&lt;/code&gt; に加算されます。Reservoirの保持サンプル数&lt;code&gt;M&lt;/code&gt;もインクリメントされます。また、与えられた &lt;code&gt;random&lt;/code&gt;でサンプルの選択を行い、新たに追加されたサンプルが選択された場合はReservoir内部の選択サンプルの情報を更新します。その場合は、返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;void RTXDI_FinalizeResampling( inout RTXDI_Reservoir reservoir, float normalizationNumerator, float normalizationDenominator) &lt;/code&gt;&lt;br&gt;
通常は、Reservoirへのサンプル追加が終わった段階で呼び出す処理で、Reservoirに蓄積されたサンプルの確率と、現在選択されているサンプルの確率から、選択されているサンプルの評価値（つまりはシェーディング結果）に乗算するべき値 (Importance Samplingにおける 1/PDF) を計算します。&lt;br&gt;
&lt;code&gt;normalizationNumerator&lt;/code&gt;, &lt;code&gt;normalizationDenominator&lt;/code&gt;は蓄積されたサンプルの&lt;code&gt;weightSum&lt;/code&gt;を正規化するときの係数です。単独のReservoirであれば、Reservoirに蓄積されたサンプル数の逆数である、1/&lt;code&gt;M&lt;/code&gt;が係数として適切です。この場合、1/&lt;code&gt;targetPDF&lt;/code&gt; * (1/&lt;code&gt;M&lt;/code&gt; * &lt;code&gt;weightSum&lt;/code&gt;)を計算し、これを &lt;code&gt;weightSum&lt;/code&gt; に代入します。&lt;br&gt;
したがって、この関数を呼び出す前と後では構造体メンバーの&lt;code&gt;weightSum&lt;/code&gt;の値の意味が変わります。呼び出す前はReservoirに蓄積されたサンプルのウエイトの合算で、呼び出した後は、選択されたサンプルの評価値に乗算するべき値となります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;float RTXDI_GetReservoirInvPdf(const RTXDI_Reservoir reservoir)&lt;/code&gt;&lt;br&gt;
Sampleの評価値に乗算するべき係数（Importance Samplingにおける1/PDF）を返します。&lt;br&gt;
内部の処理は&lt;code&gt;weightSum&lt;/code&gt;の値を返すだけです。事前に&lt;code&gt;FinalizeResampling()&lt;/code&gt;を呼ぶ必要があります。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;bool RTXDI_CombineReservoirs( inout RTXDI_Reservoir reservoir, const RTXDI_Reservoir newReservoir, float random, float targetPdf)&lt;/code&gt;&lt;br&gt;
二つのReservoirを結合します。&lt;br&gt;
まず、結合前に結合される側の&lt;code&gt;newReservoir&lt;/code&gt;は&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;で正規化されている必要があります。&lt;br&gt;
引数&lt;code&gt;targetPdf&lt;/code&gt;は、結合される&lt;code&gt;newReservoir&lt;/code&gt;で選択されているサンプルの、結合先Reservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;になります。結合される側と結合先でのtargetPdfが同じ場合は、引数の&lt;code&gt;targetPdf&lt;/code&gt;は、&lt;code&gt;newReservoir&lt;/code&gt;に保存されているサンプルのtargetPdfを指定すればよいです。&lt;br&gt;
結合後は、現在どちらかのReservoirで選択されているサンプルが選択サンプルになります。これを&lt;code&gt;random&lt;/code&gt;を用いて決めます。選択サンプルが変更される場合は返り値としてtrueを返します。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;minimal-sampleの中身brfont-size1spatio-temporalでrisを行わない場合のレンダリングfont&#34;&gt;minimal-sampleの中身&lt;br&gt;&lt;font size=&#34;+1&#34;&gt;~Spatio-TemporalでRISを行わない場合のレンダリング~&lt;/font&gt;&lt;/h1&gt;
&lt;p&gt;レンダリングを理解するうえでの前提知識が整ったので、さっそく一番簡単なケースのレンダリングを見たいと思います。
Spatio-TemporalでのRISは、RTXDIの大きな特長の一つですが、今回は単純化のために無効化した状態でサンプルコードを読み、
RTXDIの最もシンプルな形を理解するこにします。このサンプルアプリケーションは、&amp;ldquo;Enable Resampling&amp;quot;というDebugUIが用意されているのでこれをDisableにします。しかしこれはSpatio-TemporalのRISを行うかどうかを切り替えるためのフラグで、RTXDIを完全にDisableにするためのものではありません。また、BRDF Cutoffも、簡単のため0.0が設定されていると仮定します。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-settings&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Settings&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/rtxdi_first_step/RTXDI_FirstStep_2_huccd38741da5f3de97312c8042bf911a5_51702_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;30%&#34; height=&#34;351&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Settings
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;レイトレーサー本体の概要&#34;&gt;レイトレーサー本体の概要&lt;/h4&gt;
&lt;p&gt;Renderer.hlslのmain()がレイトレーサー本体のシェーダーコードです。カメラからレイを飛ばして、GBuffer相当の情報を取得している部分は特に難しい部分はないと思います。サーフェースにヒットした場合は、乱数シーケンスを初期化して、RTXDI_SampleParamterにサンプリングの設定をしています。その後の主な処理の流れは以下の通りです。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;空のReservoirに、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;(後述)で計算されたReservoirを結合する&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;でReservoirの正規化を行う&lt;/li&gt;
&lt;li&gt;選択パスが、RTXDI_SampleLocalLights()だったら、ShadowRayをキャストして、Visibilityをチェック&lt;/li&gt;
&lt;li&gt;ShadeSurfaceWithLightSample()で、Reservoirで選択されたサンプルを使ってシェーディングを行う&lt;/li&gt;
&lt;li&gt;再びShadowRayをキャストしてVisibilityをチェック&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Spatio-TemporalのRISが無効化されている場合は、最後の2度目のVisibilityチェックは必要ないはずです。しかし、大まかな処理の流れとしてはこのようになっています。以上を簡単に言い換えれば、1バウンスのライトサンプル(NEE)と、BRDFサンプルのMulti Importance Samplingのレイトレーサーが実装されているといえると思います。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplelocallights&#34;&gt;RTXDI_SampleLocalLights()&lt;/h3&gt;
&lt;p&gt;さっそくですが、1番めの処理についてです。この関数は&lt;code&gt;ResamplingFunctions.hlsli&lt;/code&gt;に実装されています。
この関数は、&lt;code&gt;numLocalLightSamples&lt;/code&gt;で指定された数だけ、サンプルを構築してReservoirに蓄積する処理を行います。このサンプルアプリケーションの中の様々な個所で行われているRISの最も基本的な形になっています。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;RTXSDKは事前にLight DataバッファにLocal Light (つまりは Emissive Triangle)のリストを構築しています。まず、このリストから、単純に乱数でLocal Lightを選択します。さらに乱数を2つ生成して、光源の三角形上の点を決定して、その位置に向けて、プライマリレイがヒットしたサーフェースからパスを構築します。&lt;br&gt;
構築されたパスのPDFは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;で計算され、&lt;code&gt;blendedSroucePdf&lt;/code&gt;に代入されます。&lt;/p&gt;
&lt;h5 id=&#34;blendedsourcepdfの計算&#34;&gt;blendedSourcePdfの計算&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;blendedSourcePdf&lt;/code&gt;は、RISにおけるsourcePDFなので、実際のパス生成確率に即したものでなければなりません。
この計算を行っているのは、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数です。&lt;br&gt;
まず、ライトサンプルの確率は&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ライトの選択確率（単なる乱数選択なので、ライトの個数の逆数）&lt;/li&gt;
&lt;li&gt;ライト上の特定の方向に向けたレイを選択する確率（サーフェースから見たLocal Lightの見かけの立体角の逆数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;の乗算で計算できます。&lt;/p&gt;
&lt;p&gt;そして、BRDFサンプルの確率は、&lt;code&gt;RAB_GetSurfaceBrdfPdf()&lt;/code&gt;で計算されるので、アプリケーション側の処理となりますが、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DiffuseRayの場合、CosineWeightedのPDF&lt;/li&gt;
&lt;li&gt;SpecularRayの場合、GGX_VNDFのPDF&lt;/li&gt;
&lt;li&gt;上記いずれかをDiffuseProbabilityで選択&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、&lt;br&gt;
DiffuseProbablity * CosineWeightedPDF + (1 - DiffuseProbability) * GGX_VNDF_PDF&lt;br&gt;
でBRDFサンプルの確率が計算できます。&lt;/p&gt;
&lt;p&gt;1ピクセルあたりで、RISで検討されるライトサンプル数とBRDFサンプル数はDebug UIの設定で決まっていて、&lt;code&gt;numLocalLightSamples&lt;/code&gt;と&lt;code&gt;numBrdfSamples&lt;/code&gt;に設定されます。このサンプル数を用いて、これらはバランスヒューリスティックで結合されます。これは通常のMulti Importance Samplingと同様の考え方です。&lt;/p&gt;
&lt;p&gt;注意点なのですが、&lt;code&gt;RTXDI_LightBrdfMisWeight()&lt;/code&gt;関数の最後では、&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;に設定された&amp;quot;ライト上の特定の方向に向けたレイを選択する確率&amp;quot;で除算しています。ここはRTXDIのトリッキーな部分です。あくまで、実際の&amp;quot;sourcePdf&amp;quot;は、この除算の前の値です。
しかし、RTXDIでは&lt;code&gt;targetPdf&lt;/code&gt;も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算するので、計算のつじつまが合うようになっています。また、&lt;code&gt;taregetPdf&lt;/code&gt;は、シェーディング結果を除算しますが、シェーディング結果も&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されるので、こちらも計算のつじつまが合う仕組みになっています。&lt;/p&gt;
&lt;h5 id=&#34;targetpdfの計算&#34;&gt;targetPdfの計算&lt;/h5&gt;
&lt;p&gt;説明が多少前後しましたが、&lt;code&gt;targetPdf&lt;/code&gt;の計算についてです。&lt;code&gt;targetPdf&lt;/code&gt;はRISにおいて、積分可能ではないが、理想的なサンプルの確率密度です。(この値は、簡単には積分できず大きさが正規化できないので、PDFと呼ぶべきではなく、単にWeightと呼ぶべきかもしれません。）
&lt;code&gt;targetPdf&lt;/code&gt;はレンダリングの文脈では、サーフェースがカメラ方向に出すRadianceに比例したレイの分布になるのが一番望ましいです。言い換えれば、カメラの方に最も強く反射される光源へのレイを重点的にサンプリングする分布です。これは、光源のサーフェースでのカメラ方向への反射を計算すればわかります。しかし、光源とサーフェースがVisibleかどうかの判断は、実際にShadow Rayをトレースしなくては分かりません。しかし、これを行えば、実際にレイトレースを行ってシェーディングする処理とまったく変わらなくなり、単にレイのサンプル数を増やすことと同義です。これでは、RISの意味がなくなってしまいまいます。&lt;br&gt;
&lt;code&gt;targetPdf&lt;/code&gt;の計算では、シェーディングの中で最も処理負荷の高いShadow Rayのテスト処理を省略した値（つまりい光源とサーフェースがVisibleかどうかの判断をせずにシェーディングした結果）が用いられます。&lt;/p&gt;
&lt;p&gt;実際の計算は、&lt;code&gt;RtxdiApplicationBridge.hlsli&lt;/code&gt;の&lt;code&gt;RAB_GetLightSampleTargetPdfForSurface()&lt;/code&gt;に実装されています。この関数は&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;という関数を呼び出して、シェーディングの計算を行っています。算出された値の輝度値が、そのまま&lt;code&gt;targetPDF&lt;/code&gt;として扱われます。また、&lt;code&gt;blendedSourcePdf&lt;/code&gt;の項で説明した通り、シェーディングの計算の最後で、値は&lt;code&gt;lightSolidAnglePdf&lt;/code&gt;で除算されます。&lt;/p&gt;
&lt;h5 id=&#34;reservoirにサンプルを追加する計算&#34;&gt;Reservoirにサンプルを追加する計算&lt;/h5&gt;
&lt;p&gt;上記の通り、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;の計算が完了すれば、Reservoirにサンプルを追加する処理は簡単です。
&lt;code&gt;RTXDI_StreamSample()&lt;/code&gt;に、&lt;code&gt;blendedSourcePdf&lt;/code&gt;と&lt;code&gt;targetPdf&lt;/code&gt;を乱数と共に渡して、渡したサンプルが選択された場合は、現在選択中のサンプルの情報を更新します。&lt;/p&gt;
&lt;h5 id=&#34;サンプル構築後の処理&#34;&gt;サンプル構築後の処理&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;numLocalLightSamples&lt;/code&gt;の数だけサンプルを構築し、Reservoirに蓄積した後は、現在Reservoirが選択中のサンプルの情報と、Reservoirに蓄積されたRISの情報のみが残ります。ここまでで複数のサンプルを検討していますが、実際にレイトレース処理は行っていません。しかし、Reservoirには、一番選択するべきサンプルの情報が残っています。&lt;br&gt;
サンプルを構築するループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;と思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で正規化されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;rtxdi_samplebrdf&#34;&gt;RTXDI_SampleBrdf()&lt;/h3&gt;
&lt;p&gt;この関数は、numBrdfSamplesで指定された数だけ、サーフェースのBRDFをもとにサンプルを構築してReservoir蓄積する処理を行います。&lt;br&gt;
この処理は、上記で説明した&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の処理と対を成す処理です。&lt;/p&gt;
&lt;h5 id=&#34;個々のサンプルの構築-1&#34;&gt;個々のサンプルの構築&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RAB_GetSurfaceBrdfSample()&lt;/code&gt;を呼び出して、BRDFに基づいたサンプルを構築します。そして、実際にレイトレースを行い、Local Light（Emissive Triangle）にHitするかをテストします。Hitしなかった場合は、このサンプルの処理は終了しReservoirに関する処理は行われません。（しかし、このサンプルがReservoirに蓄積されないというわけではなく、正確にはtargetPDF=0として蓄積された扱いになります。これはReservoirの結合時の処理を見ると判明します。）&lt;br&gt;
一方でLocal LightにHitした場合は、&lt;code&gt;targetPdf&lt;/code&gt;と&lt;code&gt;blendedSourcePdf&lt;/code&gt;をそれぞれ計算します。計算は、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と全く同じ計算になります。&lt;/p&gt;
&lt;h5 id=&#34;サンプルの構築後の処理&#34;&gt;サンプルの構築後の処理&lt;/h5&gt;
&lt;p&gt;ここも、&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;と基本的に同じ計算になります。
サンプル構築のループの直後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を呼び出しています。ここでの正規化の係数は、Shadow Rayによって棄却されたサンプルを含めるなら、&lt;code&gt;1.0/numBrdfSamples&lt;/code&gt;であるべきと思われるかもしれません。しかし実際のプログラムでは、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算されています。またReservoirのサンプル数&lt;code&gt;M&lt;/code&gt;も1.0に設定しています。これについては後ほど説明します。&lt;/p&gt;
&lt;h3 id=&#34;light-sampleとbrdf-sampleのreservoirの結合処理&#34;&gt;Light SampleとBRDF SampleのReservoirの結合処理&lt;/h3&gt;
&lt;p&gt;再び、&lt;code&gt;main()&lt;/code&gt;の処理に戻ります。&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;によって構築された&lt;code&gt;localReservoir&lt;/code&gt;と、&lt;code&gt;RTXDI_SampleBrdf()&lt;/code&gt;によって構築された、&lt;code&gt;brdfReservoir&lt;/code&gt;を結合する処理を見ていきます。&lt;/p&gt;
&lt;h5 id=&#34;rtxdi_combinereservoirsの処理&#34;&gt;RTXDI_CombineReservoirs()の処理&lt;/h5&gt;
&lt;p&gt;まず、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;を呼ぶ前に、結合される側のReservoirは、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;が呼ばれている約束になっています。したがって、結合される側の&lt;code&gt;weightSum&lt;/code&gt;は、Finalize前の変数で解釈すると&lt;code&gt;1/targetPDF * 1/M * weightSum&lt;/code&gt;
に相当する値が設定されています。（ただし&lt;code&gt;1/M&lt;/code&gt;はFinalize時に引数で渡す正規化係数）&lt;br&gt;
これに、構造体に格納されている&lt;code&gt;M&lt;/code&gt;と、引数で渡された&lt;code&gt;targetPdf&lt;/code&gt;を乗算したものが、&lt;code&gt;risWeight&lt;/code&gt;という変数に設定されます。逆算すれば、&lt;code&gt;risWeight&lt;/code&gt;は、元の&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;(引数の)targetPdf / (構造体に保存されている)targetPdf&lt;/code&gt;を乗算したものですから、もしも、&lt;code&gt;1/M&lt;/code&gt;で正規化されていて、&lt;code&gt;targetPdf&lt;/code&gt;が同じならば、結局のところ元の&lt;code&gt;weightSum&lt;/code&gt;ということになります。&lt;br&gt;
しかし、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の引数に渡す&lt;code&gt;targetPdf&lt;/code&gt;は、結合元のReservoirで現在選択されているサンプルの、結合先のReservoirにおける&lt;code&gt;targetPdf&lt;/code&gt;なので、もしも、結合先で&lt;code&gt;targetPdf&lt;/code&gt;が異なる場合は、その比が&lt;code&gt;weightSum&lt;/code&gt;に乗算されることになります。しかし、今回のサンプルプログラムでは、Spatio-TemporalなRISの結合を行わないので、&lt;code&gt;targetPdf&lt;/code&gt;は結合の前後で変化しないので、この計算について深く考える必要はありません。&lt;/p&gt;
&lt;p&gt;計算された&lt;code&gt;risWeight&lt;/code&gt;は、結合されるReservoir全体の、結合先Reservoirにおけるウエイトに相当する値です。&lt;br&gt;
後は、サンプル数&lt;code&gt;M&lt;/code&gt;を合算し、&lt;code&gt;weightSum&lt;/code&gt;に&lt;code&gt;risWeight&lt;/code&gt;を加算して、選択サンプルを乱数で決定することで、Reservoirの結合が完了します。&lt;/p&gt;
&lt;h5 id=&#34;localreservoir-と-brdfreservoir-の結合&#34;&gt;localReservoir と brdfReservoir の結合&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;RTXDI_SampleLocalLights()&lt;/code&gt;の項で説明したとおり、&lt;code&gt;localReservoir&lt;/code&gt;は、&lt;code&gt;1.0/numLocalLightSamples&lt;/code&gt;で除算して正規化するところを、&lt;code&gt;1.0/numMisSamples&lt;/code&gt;で除算したうえに、サンプル数 &lt;code&gt;M&lt;/code&gt; を1に設定していました。
これを、&lt;code&gt;RTXDI_CombineReservoirs()&lt;/code&gt;の結合される側のReservoirとして処理をすると、&lt;code&gt;risWeight&lt;/code&gt;は、Finalize前の変数で解釈すると以下のようになります。&lt;br&gt;
&lt;code&gt;1/numMisSamples * weightSum&lt;/code&gt;&lt;br&gt;
この式をわかりやすく書き換えると、以下のようになります。&lt;br&gt;
&lt;code&gt;numLocalLightSamples/numMisSamples * 1/numLocalLightSamples * weightSum&lt;/code&gt;&lt;br&gt;
つまり、&lt;code&gt;localReservoir&lt;/code&gt;の正規化処理と、&lt;code&gt;localReservoir&lt;/code&gt;と&lt;code&gt;brdfReservoir&lt;/code&gt;の、それぞれのサンプル数に基づくバランスヒューリスティックによる結合を同時に処理しているわけです。&lt;/p&gt;
&lt;p&gt;同様に、&lt;code&gt;brdfReservoir&lt;/code&gt;の結合時の&lt;code&gt;risWeight&lt;/code&gt;は、&lt;br&gt;
&lt;code&gt;numBrdfSamples/numMisSamples * 1/numBrdfSamples * weightSum&lt;/code&gt;&lt;br&gt;
と解釈できます。（ここで、&lt;code&gt;brdfReservoir&lt;/code&gt;の生成時に、Shadow RayがMissしてサンプルが破棄されているにも関わらず&lt;code&gt;targetPdf&lt;/code&gt;がゼロのサンプルとして扱われているという解釈ができるわけです。）&lt;/p&gt;
&lt;p&gt;最後に、両者の結合後に、&lt;code&gt;RTXDI_FinalizeResampling()&lt;/code&gt;を正規化係数1.0で呼び出していますが、両者の正規化はMISのウエイトによって行われているので、計算のつじつまが合うわけです。&lt;/p&gt;
&lt;h2 id=&#34;最後のレイトレースとシェーディング処理&#34;&gt;最後のレイトレースとシェーディング処理&lt;/h2&gt;
&lt;p&gt;ついに、最終的に採用すべきサンプルが確定し、乗算すべきPDFの算出も完了しました。&lt;br&gt;
あとはShadow Rayをキャストして、Visibilityを確認すればよいのですが、&lt;code&gt;brdfReservoir&lt;/code&gt;のサンプルはその生成過程ですでにShadow Rayを使ってVisibilityを確認しているので、もし、こちらのReservoirからサンプルが採用された場合は、この作業は不要なのでスキップするように処理が書かれています。&lt;code&gt;localReservoir&lt;/code&gt;側からからサンプルが選択された場合のみShadow Rayのトレースを行います。&lt;/p&gt;
&lt;p&gt;シェーディング関数の&lt;code&gt;ShadeSurfaceWithLightSample()&lt;/code&gt;は、RISの過程で何度も呼び出しているので説明不要ですが、ここでも&lt;code&gt;solidAndlePDF&lt;/code&gt;が除算されているので、PDFとの計算のつじつまが合うわけです。
&lt;code&gt;RTXDI_GetReservoirInvPdf()&lt;/code&gt;は、既にFinalizeされているReservoirに対して呼び出す関数で、単に&lt;code&gt;weightSum&lt;/code&gt;を返します。Finalizeが行われていればそこには、PDFの逆数に相当する値が格納されているはずです。
シェーディングが終われば、TonemappingをかけてUAVに書き出すと、全体の処理が完了します。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;最後まで読んじゃった人は「にゃ～ん」ってつぶやいてほしいです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projection Matrixについて</title>
      <link>https://shikihuiku.github.io/post/projection_matrix/</link>
      <pubDate>Sun, 27 Dec 2020 00:09:34 +0900</pubDate>
      <guid>https://shikihuiku.github.io/post/projection_matrix/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;Projection Matrixは何となくややこしいイメージが強い。実際ややこしい。自分でも勘違いすることがある。
なのでいったんまとめることにする。&lt;/p&gt;
&lt;h2 id=&#34;row-major-column-major-ベクトルとの乗算の順序&#34;&gt;Row Major, Column Major, ベクトルとの乗算の順序&lt;/h2&gt;
&lt;p&gt;Projection Matrixは4x4の正方行列で、メモリに格納するときに行要素を優先して格納すればRow-Major、列要素を優先して格納すればColumn-Majorと呼ばれる。&lt;/p&gt;
&lt;p&gt;Row-Majorは以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} a_1    &amp;amp; a_2    &amp;amp; a_3    &amp;amp; a_4    \\ a_5    &amp;amp; a_6    &amp;amp; a_7    &amp;amp; a_8    \\ a_9    &amp;amp; a_{10} &amp;amp; a_{11} &amp;amp; a_{12} \\ a_{13} &amp;amp; a_{14} &amp;amp; a_{15} &amp;amp; a_{16}  \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;対してColumn-Majorは、以下の添え字の順番で格納したものを指す。&lt;/p&gt;
&lt;p&gt;\begin{pmatrix} a_1 &amp;amp; a_5 &amp;amp; a_9    &amp;amp; a_{13} \\ a_2 &amp;amp; a_6 &amp;amp; a_{10} &amp;amp; a_{14} \\ a_3 &amp;amp; a_7 &amp;amp; a_{11} &amp;amp; a_{15} \\ a_4 &amp;amp; a_8 &amp;amp; a_{12} &amp;amp; a_{16} \end{pmatrix}&lt;/p&gt;
&lt;p&gt;また、行列の積は可換ではない。たとえば、4次元ベクトルを行列の右から掛けるか左から掛けるかによって演算が変わるので、これには2通りの演算が存在する。&lt;br&gt;
$$
\begin{pmatrix} x^{\prime} \\ y^{\prime} \\ z^{\prime} \\ w^{\prime} \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix} \begin{pmatrix} x \\ y \\ z \\ w \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x^{\prime} &amp;amp; y^{\prime} &amp;amp; z^{\prime} &amp;amp; w^{\prime} \end{pmatrix} = \begin{pmatrix} x &amp;amp; y &amp;amp; z &amp;amp; w \end{pmatrix} \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;シェーダーを記述する場合は、これらの解釈は実装者に委ねられる。一方で、グラフィックスAPIがこれらの演算を提供する場合もある。
OpenGLのCompatibility Profileでは、Column-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算はベクトルに対して左側からである。
Direct3D 9では、Row-Majorでマトリクスをメモリに格納し、Projection Matrixとの乗算は、ベクトルに対して右側からである。&lt;/p&gt;
&lt;h2 id=&#34;座標変換の過程について&#34;&gt;座標変換の過程について&lt;/h2&gt;
&lt;p&gt;次に座標変換の過程について簡単に説明する。頂点シェーダーが出力する4次元ベクトルは、一般的にはView座標系の位置にProjection Matrixを乗算した結果が出力される。
この座標は同次座標と呼ばれ、W成分で(X,Y,Z)を除算して正規化することで、Normalized Device Coordinate(正規化デバイス座標系)に変換される(Perspective Division)。次にViewport変換を行い、Normalized Device Coordinateを、描画用のバッファ（スクリーン）の領域にマッピングする。
多少の用語の違いがあるが、OpenGL、Vulkan、Direct3Dの3つのグラフィックスAPIは概ね同じ座標変換のステップを持っている。ただし各APIごとに座標軸の考え方や値の範囲が異なるので注意が必要である。&lt;/p&gt;
&lt;h2 id=&#34;y軸の反転について&#34;&gt;Y軸の反転について&lt;/h2&gt;
&lt;p&gt;一般的に3D空間上ではY軸を上向きと考える事が多い一方で、2Dスクリーン上では、ピクセルデータを画像の左上から格納する事が多い関係上、Y軸は下向きと考えることが多い。そのため、Projection Matrixによる投影変換、Perspective Division、そしてViewport変換の過程においてY軸を反転させることがある。ここではこれについて説明する。各種変換や用語に関する解説と前後するが、先にここにまとめておく。&lt;/p&gt;
&lt;h4 id=&#34;opengl&#34;&gt;OpenGL&lt;/h4&gt;
&lt;p&gt;OpenGLでは、元来Y軸の反転を行わないという思想の基にAPIが設計されていた。したがって、Viewport変換後のWindow座標系では、画像の左下を原点としてピクセルデータを取り扱う。そのため、Framebufferを画像として表示するときは垂直方向でデータを反転させて表示させるのが一般的である。しかし、現在のOpenGLでは、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective Divisionの際にY軸の符号を反転させる。これによって、Normalized Device CoordinateのY軸の上下が反転するので、Framebufferのデータが画像の左上を原点として格納されるようになる。Perspective Divisionについては、
&lt;a href=&#34;https://www.khronos.org/registry/OpenGL/specs/gl/glspec46.core.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenGL 4.6 Core Pprofile&lt;/a&gt;の13.8に記載がある。&lt;/p&gt;
&lt;h4 id=&#34;direct3d&#34;&gt;Direct3D&lt;/h4&gt;
&lt;p&gt;Direct3Dの座標変換に関しては、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/the-direct3d-transformation-pipeline&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;このドキュメント&lt;/a&gt;に記述がある。これによれば、Perspective DivisionはViewport変換のスケーリングの後に行われており、Y軸の符号反転は、Viewportのスケーリングの係数の符号を逆転し、オフセットを調整することで実装されている。
また、
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/direct3d9/projection-transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;他のドキュメント&lt;/a&gt;でも、Normalized Device CoordinateのY軸はView座標系と同じ向きに描写されている。したがって、Direct3DではViewport変換でY軸の符号の反転が行われていると解釈できる。
Viewport変換後のScreen座標系では、画像の左上を原点としてピクセルデータを取り扱う。&lt;/p&gt;
&lt;h4 id=&#34;vlukan&#34;&gt;Vlukan&lt;/h4&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.khronos.org/registry/vulkan/specs/1.2/pdf/vkspec.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Vulkan 1.2&lt;/a&gt;によれば、Perspective DivisionでY軸の符号を反転しない。また、Viewport変換時もY軸の符号を反転しない。そして、Viewport変換後のFramebuffer Coordinateの原点は、左上とされている。そのため、VulkanではProjection Matrixの演算でY軸を反転しない限り、Y軸を上向きとする空間を投影変換した像は上下が反転する。
また、Framebuffer Coordinateとの関連性を考えれば、VulkanのNormalized Device CoordinateのY軸は下向きと考えるのが自然である。&lt;/p&gt;
&lt;h2 id=&#34;perspective-division&#34;&gt;Perspective Division&lt;/h2&gt;
&lt;p&gt;Projection Matrixとの演算を終えた4次元ベクトルは、同次座標を表現する。これを正規化する($w=1$にする）作業は、プログラムなどで制御ができない固定された機能として、グラフィックスAPI側が行う作業となっている。
デフォルトの設定のOpenGL, Vulkan, Direct3Dでは、単純な$w$による除算が行われる。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ \frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;ただし、OpenGLでglClipControl()でGL_UPPER_LEFTが設定されているときは、Perspective Divisionの実行時に$Y$の符号が逆転される。
これは、3D空間上ではY軸を上向きと考えることが一般的である一方、画像フォーマットや、Microsoft Windows や X Window Systemでは、
垂直方向は画面の上から下に向かって座標軸を考えることが多いため、座標軸の向きを入れ替えるための計算である。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \end{pmatrix} = \begin{pmatrix} \frac{x_v}{w_v} \\ -\frac{y_v}{w_v} \\ \frac{z_v}{w_v} \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;正規化された後の(X,Y,Z)はNormalized Device Coordinate（正規化デバイス座標系）を表現する&lt;/p&gt;
&lt;h2 id=&#34;normalized-device-coordinate-ndc&#34;&gt;Normalized Device Coordinate (NDC)&lt;/h2&gt;
&lt;p&gt;NDCは、シェーダーコードが出力した同次座標を、Perspective Divitionにより正規化した後の座標系となる。この座標系は$X,Y$は範囲が[-1, 1]と決まっており、
$Z$は[-1, 1]あるいは[0,1]と決まっている。この座標系は、$X,Y$はRenderTargetピクセル位置を表すスクリーン座標系と線形の関係にある。$Z$は深度バッファの値と線形の関係にある。&lt;/p&gt;
&lt;p&gt;OpenGLでは、glClipControl()でNDCのZ軸の範囲を[-1, 1]か[0, 1]のどちらかで選択することができる。デフォルトでは、GL_NEGATIVE_ONE_TO_ONE[-1, 1]が設定されており、GL_ZERO_TO_ONE[0, 1]を設定することで、Direct3D/Vulkanと同じ範囲になる。また、glClipControl()でGL_UPPER_LEFTを設定すると、Perspective DivisionでY軸の符号が反転されるので、NDCのY軸が反転する。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-ndc&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;NDC&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/NDC_hu4fd7cebfd46de71214c033fa7c48caa4_34850_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;631&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    NDC
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;viewport変換&#34;&gt;Viewport変換&lt;/h2&gt;
&lt;p&gt;NDCにおける$X,Y$の値の範囲は[-1, 1]だが、これをViewport変換によりRenderTargetのピクセル位置を表すスクリーン座標系に線形にマッピングする。RnederTarget上でのオフセットと幅と高さを指定する事でViewport変換が実現される。
一般的には、オフセットをゼロに設定し、幅と高さをRenderTargetの幅と高さとすることで、NDCの$X,Y$の[-1, 1]の範囲をRenderTargetの全ピクセルにマッピングすることが多いが、描画領域を分けて複数のViewportのレンダリング結果を一枚のRenderTargetにレンダリングする事もある。&lt;/p&gt;
&lt;p&gt;Direct3DはViewport変換時にY軸の上下が入れ替わるように計算される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_XY_hua2bbf105df949899b049bc3dd40aae94_68866_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;1207&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;$Z$に関しては、Viewport変換後の深度値の値の範囲を$near, far$の二つの値で指定し、範囲は[0, 1]に収まる様にしなくてはならない。Viewportの$near, far$は深度バッファで使用する値の範囲の事で、
Projection Matrixの$near, far$とは全く意味が異なる。ほとんどの場合では、[0, 1]を指定して、深度バッファが表現できる全ての範囲を使用する。
OpenGLは、NDCのZの範囲を[-1, 1]としているときは、必ずViewport変換時に[near, far]への線形変換が行われる。対して、NDCの範囲が[0, 1]の場合は、Viewport変換の$near, far$が、[0, 1]に設定されている場合は、NDCの$Z$の値がそのまま深度バッファの値として格納される。&lt;/p&gt;






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-viewport変換&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; data-caption=&#34;Viewport変換&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Viewport_Transform_Z_hu942a46d8dcfeda85742502a3e3fb79d7_19884_2000x2000_fit_lanczos_3.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;374&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Viewport変換
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;右手系左手系&#34;&gt;右手系、左手系&lt;/h2&gt;
&lt;p&gt;右手系、左手系とは、単位マトリクスのX,Y,Z軸の各ベクトルの、認識している空間におけるマッピングである。右手系は、右手の（親指,人差し指, 中指）を自然な形で直交させたとき、(X, Y, Z)の向きとなる空間を指す。
左手系も同様である。デフォルトのOpenGLとDirect3DのNDCは、はX軸が画面左から右、Y軸が画面下から上、Z軸が画面手前から奥なので、左手系である。
一方で、glClipControl()でGL_UPPER_LEFTを設定したOpenGLとVulkanのNDCは、X軸が画面左から右、Y軸が画面上から下、Z軸が画面手前から奥なので、右手系である。&lt;/p&gt;
&lt;p&gt;よく耳にする話として、OpenGLが右手系でDirect3Dが左手系という話があるが、OpenGLに関してはglFrustum()/glOrtho()という関数が、
右手系のViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するためのProjection Matrixを計算することに起因している。
実際にはProjection MatixにはglLoadMatrixで自由に値を設定することができるので、OpenGLは元来シェーダーを使わなくても、右手系でも左手系でも自在に描画できるはずである。
また、Direct3DにはProjection Matrixを計算するAPIは用意されていない。ただし、ユーティリティ関数群のD3DXには、D3DXMatrixPerspectiveRH()という関数が用意されている。
この関数は右手系ViewMatrixの-Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。同様に、D3DXMatrixPerspectiveLH()という関数も用意されており、
こちらは、左手系のViewMatrixの+Z方向を、左手系のNDCの+Z方向として変換するProjection Matrixを計算する。&lt;/p&gt;
&lt;p&gt;このように、ある特定のグラフィックスAPIの座標系が右手系左手系のいずれかに属していると考えること自体が誤りだといえる。&lt;/p&gt;
&lt;h2 id=&#34;projection-matrixの役割&#34;&gt;Projection Matrixの役割&lt;/h2&gt;
&lt;p&gt;さて、ここからが本題ののProjection Matrixに関する説明になる。View座標系からNDC座標系への変換を担うProjection Matrixには、主に4つの要素がある。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y軸の向きの入れ替え (Vulkan)&lt;/li&gt;
&lt;li&gt;Z軸の向きの入れ替え&lt;/li&gt;
&lt;li&gt;X,Y軸に関する透視投影変換&lt;/li&gt;
&lt;li&gt;Z軸のNDC座標へのマッピング&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透視投影変換を行わない正射影というProjection Matrixもあるが、ここでは割愛する。&lt;/p&gt;
&lt;h2 id=&#34;y軸の向きの入れ替え-vulkan&#34;&gt;Y軸の向きの入れ替え (Vulkan)&lt;/h2&gt;
&lt;p&gt;Vulkan特有の事なので一番最初に解説する。Vulkanは先に説明した通り、NDCのY軸は下向きでPerspective DivisionやViewport変換でY軸の符号反転を行わない。
したがって、Y軸が下向きとなる様に頂点シェーダーの出力を行わなければならない。そのため、View座標系でY軸が上向きになるように座標を扱っていた場合、Projection MatrixでY軸を反転させる必要がある。
具体的にはProjection Matrixの、Y成分のスケーリングとオフセットを担当する成分（以下の場合では$a_{22}, a_{23}$）の符号を入れ替える事で、NDCの上下が反転した結果を得る事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; -a_{22} &amp;amp; -a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ a_{41} &amp;amp; a_{42} &amp;amp; a_{43} &amp;amp; a_{44}  \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸の向きの入れ替え&#34;&gt;Z軸の向きの入れ替え&lt;/h2&gt;
&lt;p&gt;同次座標の$w$は、単にPerspective Divisionでの除算に使われるだけでなく、ポリゴン平面上の属性値補間でPerspective Correctionを行うときに使用されるので、$Z$軸に沿って正しく透視投影変換をするときは下記のどちらかの設定になる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Z_{View}$の正の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのため、$Z_{View}$と乗算される位置に$1$を設定する。&lt;/li&gt;
&lt;li&gt;$Z_{View}$の負の方向にNDCのZ軸を取る場合は、Projection Matrixを乗算した後の同次座標の$w$に、$-Z_{View}$が格納されるようにしなければならない。&lt;br&gt;
そのために$Z_{View}$と乗算される位置に$-1$を設定する。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下は、それぞれ$Z_{View}$正負の方向にNDCのZ軸を設定し、透視投影変換をする場合のProjection Matrixである。殆どのProjection Matrixは下記のいずれかである。
余談だが、この、$w$と乗算される行（あるいは列）は特徴的なので、これを手がかりに、メモリにダンプされたマトリクスが、Row-MajorなのかColumn-Majorなのかを簡単に見分ける事ができる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; a_{14} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; a_{24} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;xy軸に関する透視投影変換&#34;&gt;X,Y軸に関する透視投影変換&lt;/h2&gt;
&lt;p&gt;透視投影変換は、空間にある物体が視点から離れる程小さく投影される様に変換する役割がある。これにより遠近感が演出される。
視点からの距離が二倍になれば、物体は長さで二分の一の大きさで描画されるようにする。したがって$Z$軸向きに透視投影した$X,Y$座標は、$1/Z$に比例する。&lt;/p&gt;
&lt;p&gt;$X,Y$軸に関する透視投影変換は、つまるところ、以下の式の$a, b, c, d$を決定することにある。
$$
X_{NDC} = \frac{a * X_{View}}{Z_{View}} + b
$$
$$
Y_{NDC} = \frac{c * Y_{View}}{Z_{View}} + d
$$&lt;/p&gt;
&lt;p&gt;$a, c$の値が、水平、垂直視野角を決定し、$b, d$がView座標系からNDC座標系に変換するときのオフセットになる。$b, d$は、View座標のZ軸がNDC座標のX,Yの中心を通る場合はゼロになる。
水平、垂直視野角から$a,c$の値を計算する場合は、視野の両端がNDCにおける[-1, 1]になるように計算すれば良い。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z1_hu67487b2524c3038e83bd1adbcfbe3e80_33075_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;808&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

したがって係数$a,c$は、水平視野角を$\theta$、垂直視野角を$\phi$とすれば以下の様に計算できる。（注意：通常は水平視野角と垂直視野角はアスペクト比を通じた線形の関係ではない。通常は水平視野角か垂直視野角のいずれかを基準として正接を計算して、他方はアスペクト比を乗算することで他方の正接を計算するが、ここでは簡便のためそれぞれの視野角を使う。）
$$
a = \frac{1}{tan(\frac{\theta}{2})}
$$
$$
c = \frac{1}{tan(\frac{\phi}{2})}
$$&lt;/p&gt;
&lt;p&gt;もう一つの、係数$a,c$の計算方法として、$Z_{View}=near$平面上での視野の上下左右に相当する$left, right, top, bottom$を指定する方法である。以下の図には$left, right$による水平視野角を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野角による係数の計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野角による係数の計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z2_huf5ee3975d2bdd72ab528fd0d389e5569_53727_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;992&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野角による係数の計算
  &lt;/figcaption&gt;


&lt;/figure&gt;

この場合の係数$a,c$は、$l, r, t, b$の値と、$near$平面までの距離$n$を用いて以下の様に表せる。
$$
a = \frac{2n}{r - l}
$$
$$
c = \frac{2n}{t-b}
$$
また、この指定方法の場合は、$l, r$の値がZ軸で対称でない場合は、オフセットの値が発生する。例として、$l, r$によるオフセットの図を示す。






  



  
  











&lt;figure class=&#34;center&#34; id=&#34;figure-視野のオフセットの計算&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu770a23a06793a884f7075f1eec4e4997_39058_2000x2000_fit_lanczos_3.PNG&#34; data-caption=&#34;視野のオフセットの計算&#34;&gt;


  &lt;img data-src=&#34;https://shikihuiku.github.io/post/projection_matrix/Perspective_Z3_hu770a23a06793a884f7075f1eec4e4997_39058_2000x2000_fit_lanczos_3.PNG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;50%&#34; height=&#34;893&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    視野のオフセットの計算
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上図はView座標系でのオフセット値になるので、NDC座標系に変換するには、$2/(r-l)$を乗算する必要がある。したがってオフセットの値は以下の様に計算できる。
$$b = -\frac{r+l}{r-l}$$
$$d = -\frac{t+b}{t-b}$$&lt;/p&gt;
&lt;p&gt;また、オフセットがない場合は、$near, left, right, top, bottom$と$\theta, \phi$に、以下のような関係が成り立つ。
$$
l = n \cdot tan(\frac{\theta}{2})
$$
$$
r = -n \cdot tan(\frac{\theta}{2})
$$
$$
t = n \cdot tan(\frac{\phi}{2})
$$
$$
b = -n \cdot tan(\frac{\phi}{2})
$$&lt;/p&gt;
&lt;p&gt;次に、Projection Matrixへの各係数の設定だが、$a, c$の値は、それぞれ$X_{View}$, $Y_{View}$と乗算されるように格納する。$Z_{View}$の除算の部分はPerspective Divisionで行われる。
$b, d$の値は、$Z_{View}$と乗算されるようにProjection Matrixに格納する。これは、のちにPerspective Divisionで相殺されることでオフセット値として機能する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;以下のマトリクスはD3DXMatrixPerspectiveOffCenterLHが算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; -\frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; -\frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;一方で、Z軸の向きの入れ替えるために、$a_{43}$に$-1$を設定している場合は、$Z_{View}$が乗算される時と、除算される時で符号が異なるため、オフセットの係数の符号が変わる。
以下のマトリクスはD3DXMatrixPerspectiveOffCenterRHが算出する係数や、glFrustum()が算出する係数と符合する。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{2n}{r - l} &amp;amp; 0 &amp;amp; \frac{r+l}{r-l} &amp;amp; 0 \\ 0 &amp;amp; \frac{2n}{t-b} &amp;amp; \frac{t+b}{t-b} &amp;amp; 0 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; a_{34} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;z軸のndc座標へのマッピング&#34;&gt;Z軸のNDC座標へのマッピング&lt;/h2&gt;
&lt;p&gt;Z軸に関する変換は透視変換ではなく、Z軸の値の一定の範囲をNDCで許されている値の範囲に、大小関係を損なわずに変換することである。通常は、View座標系の広大なZ軸の範囲を、NDCで許されている高々[0, 1]程度の範囲にマッピングする圧縮作業である。
簡単に考えれば、View座標系のZの値にオフセットとスケールを適用すれば実現できるが、これは残念ながら推奨されない。
$$Z_{NDC} = e * Z_{View}  + f$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一つ目の理由は、Projection Matrixを使った座標変換による制限によるものである。$X, Y$の値を透視投影変換するためには、同次座標系の$W$の値を$Z$（もしくは$-Z$)の値としなければ、$X,Y$軸に関する透視投影変換が実現できない。そのため$W$の値は決定されていると言える。
この条件では、Projection Matrixとの乗算では、View座標系の$Z$と1次比例の関係を作ることができない。一応ながら、Pixel Shader内で深度バッファに出力する値を直接計算することで実現可能だが、GPUの早期Zカリング機能が無効化されるので実際のアプリケーションの運用では現実的な方法とは言えない。&lt;/li&gt;
&lt;li&gt;二つ目の理由は、透視投影変換後のNDCでの$X,Y$平面（つまりはスクリーンスペース）では、$Z_{View}$は線形性を失う。代わりに$1/Z_{View}$が線形性を持つことになる。
投影変換されたポリゴン平面の深度値を高速に計算するならば、線形性を失った$Z_{View}$に比例した式で計算された値は単純な補間では計算出来ず、計算コストが高く効率が良くない。それよりも、大小関係を（反転しつつも）保ちつつ、スクリーンスペースで線形性を持つ$1/Z_{View}$を使う方が合理的だったという経緯がある。
（ちなみに、スクリーンスペースでテクスチャのU,Vなどの頂点属性値は、$attribute/W$と$1/W$をスクリーンスペースで線形補間し、その結果を除算することで補完された頂点属性値を計算している。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;したがって、一般的にGPUでは$Z_{View}$ではなく$1/Z_{View}$を線形変換した結果をNDCのZ座標として採用している。
$$Z_{NDC} = \frac{e}{Z_{View}}  + f$$&lt;/p&gt;
&lt;p&gt;また、このようにすると、深度バッファに整数の格納フォーマットを使った場合、$Z$の値が小さいときほど、多くのBitを使って表現することになる。
つまり、近くの物体ほど深度バッファの多くのBitが割り当てられるので、これは合理的であるとも考える事ができる。また、$1/Z$の線形変換であれば、Projection Matixで一元的に扱えるのも利点である。&lt;/p&gt;
&lt;p&gt;係数$e, f$の決定は、View座標系における、Z軸の範囲である$near, far$の値が、[0, 1] （もしくは[-1, 1]）になるように連立方程式を解くだけで計算できる。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;下記の式を解けば、D3DXMatrixPerspectiveFovLHに設定される係数と符合する。&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$0 = \frac{e}{near} + f$$
$$1 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{far \cdot near}{far-near}$$
$$f = \frac{far}{far - near}$$&lt;/p&gt;
&lt;p&gt;Projection Matrixに設定するときは、$Z_{View}$と乗算される位置に$f$を設定し、$W$(通常は1.0)と乗算される方に$e$を設定する。Perspective Divisionで$W$(この時点では$Z_{View}$)による除算が行われ、上記の式と等価な計算が行われる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{far - near} &amp;amp; -\frac{far \cdot near}{far-near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合は、Projection Matrixの乗算をよく観察する必要がある。$1/Z_{View}$の係数である$e$は、$W_{View}$と乗算して、$-Z_{View}$で除算される。$W_{View}$は通常$1.0$で$-Z_{View}$も正の数なので、上記で求めた$e$がそのまま使える。
一方で、オフセットの$f$は、$Z_{View}$と乗算して、$-Z_{View}$で除算される。したがって、上記で求めたものの符号を反転させたものを使う必要がある。こうして求めた結果は、D3DXMatrixPerspectiveFovRHの係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far}{near-far} &amp;amp; \frac{far \cdot near}{near -far} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同様の手順で係数$e, f$を求める事ができる&lt;/p&gt;
&lt;p&gt;$$1 = \frac{e}{far} + f$$
$$-1 = \frac{e}{near} + f$$
$$2 = e (\frac{1}{far} - \frac{1}{near})$$
$$e = -\frac{2(far \cdot near)}{far-near}$$
$$f = \frac{far + near}{far - near}$$&lt;/p&gt;
&lt;p&gt;それぞれをProjection Matrixに設定すると以下の様になる。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;Z軸の向きを反転させる場合も先ほどと同様の手順となる。これはglFrustum()関数の係数と符合する。&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{far + near}{far - near} &amp;amp; -\frac{2(far \cdot near)}{far-near}　\\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;inverse-z&#34;&gt;Inverse Z&lt;/h2&gt;
&lt;p&gt;深度バッファに浮動小数点の格納フォーマットが使えるとき、NDCにおける深度のマッピングを、[Near, Far]を[0, 1]ではなく[1, 0]にマッピングすることで、$far$付近での深度バッファの精度不足を解消することができる。
NDCが[-1, 1]の場合や、深度バッファの格納フォーマットが整数表現の場合は、Inverse Zを使う利点はない。
精度については詳しくは以下に解説がある。&lt;br&gt;

&lt;a href=&#34;http://www.reedbeta.com/blog/depth-precision-visualized/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Depth Precision - Nathan Reed&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zの設定は簡単で、先ほどの連立方程式の$near$と$far$を入れ替えて解くだけで係数は求まる。レンダリングの際には、深度バッファのクリア値を、1ではなく0に設定し、ラスタライザーの深度テストの条件を反転させればよい。
$$1 = \frac{e}{near} + f$$
$$0 = \frac{e}{far} + f$$
$$e = \frac{far \cdot near}{far - near}$$
$$f = -\frac{near}{far-near}$$&lt;/p&gt;
&lt;p&gt;$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; -\frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{near}{far-near} &amp;amp; \frac{far \cdot near}{far - near} \\ 0 &amp;amp; 0 &amp;amp; -1 &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;infinite-far-plane&#34;&gt;Infinite Far Plane&lt;/h2&gt;
&lt;p&gt;$far$を無限遠に設定する事で、Far Clippingを実質無効化するとともに、浮動小数点の丸め誤差を低減することができる。Projection Matrixに設定する係数の計算は、今まで求めてきた係数の、$far$を無限大で極限を取れば算出される。
Infinite Far Planeのメリットは、非常に遠くのオブジェクトを描画してもクリッピングされることがないことと共に、空や星などを描画する際に、$W_{View}$をゼロとすることで、$(X_{View}, Y_{View}, Z_{View})$方向の無限遠を描画することができることである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-1&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$e = \lim_{far\to\infty} -\frac{far \cdot near}{far-near} = -near$$
$$f = \lim_{far\to\infty} \frac{far}{far - near} = 1$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いないInfinite Far Planeは、無限遠の深度値が1.0となるが、$Z_{View}$が極大化すると正確に描画できないことがあるので注意が必要である。これはProjection Matrixを使った演算とPerspective Divisionでオフセットを設定する場合に、$Z_{View}$による乗算と除算が行われるため、この値が非常に大きな値になれば、浮動小数点数としての精度を失ってしまうからである。&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-1&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;一方で、Inverse Zを用いた場合のInfinite Far Planeの係数は以下の様に計算される。
$$e = \lim_{far\to\infty} \frac{far \cdot near}{far - near} = near$$
$$f = \lim_{far\to\infty} -\frac{near}{far-near} = 0$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeは、オフセットの係数がゼロなので、$Z_{View}$が極大化する事によるProjection Matrixとの乗算による精度の問題を起こさない。以下は、Inverse Zを用いたInfinite Far PlaneのProjection Matrixである。$a_{43}$は$1$でも$-1$でも変わらない。
$$
\begin{pmatrix} x_d \\ y_d \\ z_d \\ w_d \end{pmatrix} = \begin{pmatrix} \frac{1}{tan(\frac{\theta}{2})} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{1}{tan(\frac{\phi}{2})} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; near \\ 0 &amp;amp; 0 &amp;amp; a_{43} &amp;amp; 0 \end{pmatrix} \begin{pmatrix} x_v \\ y_v \\ z_v \\ w_v \end{pmatrix}
$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからz_viewの逆算&#34;&gt;深度バッファから$Z_{View}$の逆算&lt;/h2&gt;
&lt;p&gt;マルチパスレンダリング等を行っていると、描画された深度バッファより、$Z_{View}$を求めたい時がある。計算自体は単なる逆算なので簡単である。&lt;/p&gt;
&lt;p&gt;深度バッファから$Z_{View}$を逆算するためには、まず、Viewport変換を逆変換して$Z_{NDC}$を計算する必要がある。Viewportの$near, far$とNDCの$Z$軸の範囲が分かれば計算は簡単である。深度バッファとNDCの範囲が一致する場合は、この計算は不要である。
$$Z_{NDC}  = \frac{Depth - near_{Viewport}}{far_{Viewport} - near_{Viewport}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-2&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;Projection Matrixに設定した係数$e, f$を使って$Z_{NDC}$から$Z_{View}$を逆算する。$Z_{NDC}$が正の$Z_{View}$方向ならば以下の式で計算できる。
$$Z_{NDC} = \frac{e}{Z_{View}} + f$$
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は符合の操作が必要である。まず、オフセットの値$f$の符合を反転させてあるので、これを反転する必要がある。加えて$Z_{View}$は負の方向なので、最後に符合を反転する必要がある。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{far - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-2&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{far \cdot near}{near + Z_{NDC} (far - near)}$$
Inverse Zで、$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= - \frac{e}{Z_{NDC} + f} = -\frac{far \cdot near}{near + Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;p&gt;Inverse Zを用いたInfinite Far Planeの場合は、式はもっと単純になる。ただし、$Z_{NDC}$がゼロの場合はゼロ除算になるので注意が必要である。
$$Z_{View}= \frac{e}{Z_{NDC}} = \frac{near}{Z_{NDC}}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は以下の通り。
$$Z_{View}= -\frac{e}{Z_{NDC}} = -\frac{near}{Z_{NDC}}$$&lt;/p&gt;
&lt;h3 id=&#34;ndc-1-1の場合-1&#34;&gt;NDC[-1, 1]の場合&lt;/h3&gt;
&lt;p&gt;上記と同じ手順で計算する。
Depthから$Z_{NDC}$は以下の通り。
$$Z_{NDC}  = \frac{2(Depth - near_{Viewport})}{far_{Viewport} - near_{Viewport}} -1$$&lt;/p&gt;
&lt;p&gt;$Z_{NDC}$から$Z_{View}$は以下の通り。
$$Z_{View}= \frac{e}{Z_{NDC} - f} = \frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$
$Z_{NDC}$を負の$Z_{View}$方向に取っている場合は
$$Z_{View}= -\frac{e}{Z_{NDC} + f} = -\frac{2 \cdot far \cdot near}{far + near - Z_{NDC} (far - near)}$$&lt;/p&gt;
&lt;h2 id=&#34;深度バッファからlinear-depthの計算&#34;&gt;深度バッファからLinear Depthの計算&lt;/h2&gt;
&lt;p&gt;上記で示した通り、Projection MatrixのNearとFarが分かれば、深度バッファから$Z_{View}$を復元できるが、
実際には$Z_{View}$よりも、単に線形性がある深度値としてのLinear Depthが欲しいケースが多い。
ここでのLinear Depthは[near, far]が[0, 1]にマッピングされており、かつ線形性を保っているものを指す。
計算は先の式の[near, far]を[0, 1]に線形でマッピングするだけである。&lt;/p&gt;
&lt;h3 id=&#34;ndc0-1の場合-3&#34;&gt;NDC[0, 1]の場合&lt;/h3&gt;
&lt;p&gt;$$Z_{Linear}= \{ \frac{far \cdot near}{far - Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{Z_{NDC} \cdot near}{far - Z_{NDC}(far - near)} = \frac{Z_{NDC}}{\frac{far}{near} - Z_{NDC}(\frac{far}{near}-1)} $$&lt;/p&gt;
&lt;h3 id=&#34;ndc1-0の場合-3&#34;&gt;NDC[1, 0]の場合&lt;/h3&gt;
&lt;p&gt;Inverse Zを用いた場合は以下の通り。[near, far]を[0, 1]にマッピングするので、Inverse Zの大小関係は再び反転するので注意。
$$Z_{Linear}= \{ \frac{far \cdot near}{near + Z_{NDC} (far - near)} - near \} \frac{1}{far -near} = \frac{near (1 - Z_{NDC})}{near + Z_{NDC}(far -near)} = \frac{1 - Z_{NDC}}{ 1 + Z_{NDC}(\frac{far}{near} - 1)}$$&lt;/p&gt;
&lt;h2 id=&#34;render-targetのピクセル位置から視線ベクトルの逆算&#34;&gt;Render Targetのピクセル位置から視線ベクトルの逆算&lt;/h2&gt;
&lt;p&gt;G-Buffer等を用いている場合は、Render Targetのピクセル位置から視線ベクトルを逆算したい事も多い。これも上記と同様で、Projection Matrixからの逆算で計算自体は簡単である。&lt;/p&gt;
&lt;p&gt;Render Targetのピクセル位置から視線ベクトルの逆算するためには、Viewport変換を逆変換して$X_{NDC}, Y_{NDC}$を計算する。
$$X_{NDC} = \frac{2(X_{Pixel} - OfsX_{Viewport})}{Width_{Viewport}}-1$$
$$Y_{NDC} = \frac{2(Y_{Pixel} - OfsY_{Viewport})}{Height_{Viewport}}-1$$&lt;/p&gt;
&lt;p&gt;また、Render Targetのピクセル位置ではなく、フルスクリーン描画したポリゴンのUV値から$X_{NDC}, Y_{NDC}$を逆算する方法も良く用いられる。いずれにせよ、範囲が明確なNDCの座標を再計算するのは簡単である。&lt;/p&gt;
&lt;p&gt;次に$Z_{View}=1$の場合の、$X_{View}, Y_{View}$を計算する。ここでの$a,b,c,d$は、先ほど透視投影変換で求めた値で、$\theta, \phi$は水平、垂直視野角である。
$$X_{View1} = \frac{X_{NDC} - b}{a} = tan(\frac{\theta}{2})X_{NDC}$$
$$Y_{View1} = \frac{Y_{NDC} - d}{c} = tan(\frac{\phi}{2})Y_{NDC}$$&lt;/p&gt;
&lt;p&gt;三次元ベクトル$(X_{View1}, Y_{View1}, 1)$は、View座標系の原点からピクセルへのベクトル：視線ベクトルを表すが、長さが1ではないのでライティングの計算をする場合は正規化する必要がある。
一方で、ピクセルのView座標系における位置を求める場合は、このベクトルに$Z_{View}$を乗算することで求める事ができる。&lt;/p&gt;
&lt;h2 id=&#34;まとめ&#34;&gt;まとめ&lt;/h2&gt;
&lt;p&gt;もっと簡単にまとめたかったが、ダラダラと長くなってしまった。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
